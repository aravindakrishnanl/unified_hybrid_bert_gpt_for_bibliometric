title,authors,year,doi,full_text,clean_text,keywords,cluster
Natural Language Processing using Hadoop and KOSHIK,"['Emre Erturk', 'Hong Shi']",2016,http://arxiv.org/abs/1608.04434v1,"Natural Language Processing using Hadoop  and KOSHIK  
Hong Shi , Emre Erturk   
Eastern Institute of Technology, New Zealand  
 
Abstract  
Natural language processing , as a data analytic s related technology,  is used widely in many 
research areas such as artificial intelligence, human language processing , and translation. At 
present, due to explosive growth of  data, there are many challenges for natural language 
processing. Hadoop is one of the platform s that can process the large amount of data required  for 
natural language processing. KOSHIK is one of the natural language processing architecture s, and 
utilizes Hadoop and contains  language processing components such as Stanford CoreNLP and 
OpenNLP . This study describes how to build a KOSHIK platform with the  relevant  tools , and provides  
the steps to analyze wiki data. Finally, it evaluates and discusses the advantages and disadvantages 
of the KOSHIK architecture , and gives recommendation s on improving  the processing performance.   
1. Introduction  
1.1. Natural Language P rocessing  
Natural l anguage processing  (NLP)  is a technique to analyze readable text that is  generated by 
human s for artificial intelligence, language processing , and translation  (Behzadi, 2015) . In order to 
accurately analyze  the text, there are some  methods  for NLP to use in order to deal with the 
challenges such  as the collection and storage of the  text corpus, and analysis.  NLP techniques also 
gain experience and benefits through  research in lingui stics, computational statics, artificial 
intelligence, m achine learning  and other sciences  (Behzadi, 2015) . However, at present, because 
of the information explosion, the use of traditional NLP faces many challenges such as  the volume 
of structured and uns tructured  data , velocity of processing data, accura cy of the result s. In addition, 
there are many slangs and ambigu ous expressions used on social media network s, which give NLP 
pressure to analyze the meanings , which may also be hard for some people. Moreover, people 
nowadays h eavily depend on search engines like Google and Bing  (which use NLP as their core 
technique ) in their daily study , work,  and entertainment . All of these  factors encourage  computer 
scientists and research ers to find more robust, e fficien t and standardized  solutions for NLP .   
1.2. Big Data  
Big Data is designed as generic platform to resolve the issues of volume, velocity, variety, 
veracity and value in data analytics  (IBM, 2012) . The data is collected from different sources, for 
example,  daily logs, social media, and business transactions. Big Data demands the ability to hoard 
large amounts of data. With advanced storage technologies, the data size could be as high as 
terabytes (1012 bytes), petabytes (1015 bytes) and exabytes (1018 bytes ). Furthermore, research on 
NLP often overlaps with research on or the use of Big Data platforms. Big Data handles  all types of 
formats which are structured and unstructured. The structured data is readable and well -designed 
that is commonly stored in traditional relationship databases. Unstructure d data does not have a 
predefined format.  This type of data can be  foun d in, for example, emails, images , and videos. Big 
Data  is widely used in business forecasts , scientific research , analysis of social issues, healthcare , 
and meteorology. While promoting advances in NLP , it is also important to be aware of ethical 
issues a round the potential misuse and dual -use of big data and NLP tools (Hovy & Spruit, 2016). 
1 
 Some of these issues can be very interesting for information technology students to debate and 
learn more about  (Erturk, 2013) .  
1.3. Hadoop  
Hadoop is a application created  using Java, and  provides a set of tools to do data processing 
which includes data storage, access, analysis ( White , 2012) . According to White (2012), the main 
components in Hadoop are HDFS (Hadoop distributed file system) and MapReduce. HDFS is solid 
and fault -tolerant, and provides a Java -based API that integrates with MapReduce to process the 
large data in parallel using a cluster of  servers (Taylor, 2010 ). As Murthy, Padmakar  and Reddy ( 2015)  
observe d, traditional relational  database s, which store struc tured data, could also be used together 
with Hadoop HDFS with full database management systems  (DBMS) features. MapReduce is 
created with inspiration from the theory  published by Google , and it provides function s that split  
large set of data computing into small computing tasks ( White , 2012) .  
1.4. Natural Language Processing on Hadoop  
Ideal y, Hadoop, with the features of distributed storage system, multi -tasks processing system, 
generic platform and open source, can be used for NLP research . There are many papers discuss ing 
the solutions which utilize  Hadoop for NLP . For example, HDFS is used in the research of Markham, 
Kowolenko and  Michaelis (2015)  to manage large amount of unstructured data, which was 
collected from the Intern et with Hadoop  tools . Idris, Hussain,  Siddiqi, Hassan, Bilal and Lee (2015)  
designed a system named MRPack which gives an end -to-end MapReduce processing model for 
text processing, which includes a job task for NLP . MRPack shows it has better performance i n data 
accessing, data managing and data writing, as well as less programming work and demanding for 
I/O management ( Idris  et al., 2015).  
This study reviews  KOSHIK , a Hadoop based framework  which has been developed from  the 
paper written  by Exner  and Nugues  (2014) . Then it gives the findings for what Hadoop components 
this framework used , and recommendations to improve the NLP performance.  Finally, it shows the 
steps to test KOSHIK.  
2. Literature Review  
2.1. Introduction  
It is described that “KOSHIK is a framework for batch -oriented large scale -processing and 
querying of unstructured natural language documents . In particular, it builds on the Hadoop 
ecosystem and takes full advantage of the data formats and tools present in this environment to 
achieve its task” (Exner  & Nugues, 2014 , p. 463 ). KOSHIK tries to resolve the common challenges 
in NLP such as v olume, velocity, and variety  by adopting Hadoop for the system infrastructure,  
using a batch -oriented annotation model to continually add annotations and en abling a generic 
algorithm platform to analyze the variety of text (Exner & Nugues, 2014). It is also argued that 
before developing KOSHIK, there were many other NLP frameworks such as MULTEXT, GATE, and 
UIMA , which were important for document retrieval, i ndexing, and querying of processed 
information  applications  (Exner & Nugues, 2014).  
2 
 2.2. KOSHIK Architecture  
 
Figure 1. An overv iew of the KOSHIK architecture.  (Exner  & Nugues , 2014) . 
Exner and Nugues (2014)  stated that “KOSHIK supports a variety of NLP tools implemented 
atop of the Hadoop distributed computing framework. The requirements on KOSHIK were driven 
by the desire to support scalability, reliability, and a large number of input formats and processing 
tasks ”. KOSHIK supp orts different kinds of documents such as CoNLL -X, CoNLL 2008 and 2009 and 
Wikipedia dump files (Exner & Nugues, 2014; Buchholz and Marsi, 2006 ; Surdeanu et al., 2008 ). In 
order to analyze different kinds of language, KOSHIK involves a large set of filters , tokenizers, 
taggers, parsers, and coreference solvers  through several language specific NLP tools such as 
OpenNLP , Mate Tools, Stanford CoreNLP , etc. (Exner & Nugues, 2014).  With the developed 
annotation model in KOSHIK, this framework could simplify the  process of content processors, 
which only require computing resource focus on the input and output of annotated documents  
(Exner & Nugues, 2014).  
KOSHIK utilizes Hadoop as its distributed computing framework, which not only used for a 
better performance o n large corpus  analysis, but also for the division and distribution of a set of 
documents, management of processing jobs, and to get the process result  (Exner & Nugues, 2014). 
Pig and Hive which are core members of Hadoop ecosystem are adopted into this fr amework to 
manage the workflows for processing large data -sets and easily query information by SQL -like 
language  respectively  (Exner & Nugues, 2014).  
3. Key Terms  
After evaluating this paper, Hive and Pig which are dat a querying components of Hadoop , and 
Open NLP and Stanford CoreNLP which are NLP process tools are identified for future research.  
According to Thusoo  et al.  (2009), Hive is a data warehouse infrastructure built based on  
Hadoop for providing data summarization, query, and analysis.  It could be used to deal with large 
distributed data such as HDFS and traditional file systems like FAT, NTFS and exFat (Thusoo et al., 
2009).  In addition, HiveQL, a SQL-like language , is created to query data on Hadoop which will 
translate the query to Ma pReduce jobs for high performance  (Thusoo et al., 2009) . 
 

3 
 The Pig is a high -level declarative querying language inspired by SQL which will translate the 
query to MapReduce jobs ( Pis Olston , Reed, Srivastava, Kumar & Tomkins , 2008 ). According to 
Gates  et al . (2009), there are many data analysis projects which adopted Pig because it is easy to 
learn and use, and could quickly implement different versions of algorithms.  
Lingad, Karimi and Yin (2013) found  that “OpenNLP is a Java based library for various  natur al 
language processing tasks, such as tokenization,  part-of-speech (POS) tagging, and named entity  
recognition. For named entity recognition, it trains a  Maximum Entropy model using the 
information from  the whole document  to recognize entities in documents ”. Although OpenNLP 
provides many functions for NLP , the model to process the document should be considered that 
Verspoor  (2012) argued  that OpenNLP has low quality to divide sentence into parts, but it could 
improve the performance by using annotator.  
Stanford CoreNLP is  a NLP tool and utilize s annotation  to analyse text that it provides  most of 
the common core NLP steps, from tokenization through to  coreference resolution  (Manning , 2014) . 
It is also described that Stanford CoreNLP provides a complete t oolkit and tools for grammatical 
analysis, accurate analysis, and supports different kinds of languages ( Manning , 2014) .  
4. Testing KOSHIK  
4.1. Preparing  the Hardware  Environment  
According to Exner and Nugues (2014) , KOSHIK runs on Hadoop with Hive, and requires other 
NLP process libraries (OpenNLP , Mate and Stanford CoreNLP). The experiment al environment 
(including hardware, software, and test data) used in this paper is  described  in the following tables .  
 
Hardware Environment  
Hardware  Description  
CPU INTEL i5 quad cores 2.7Ghz  
Hard disk  SATA 500G  
Memory  DDR3 16G  
Graphic Card  NVidia 940  
Network  1G LAN  
 
Software Environment  
Operation 
System/application/library  Version  
Operation System  Centos 6.7  
KOSHIK  1.01  
JAVA  1.80  
Hadoop  2.60  
Hive  1.1.0  
Cloudera  5.70  
Hue 3.90  
VirtualBox  5.0.20 
Stanford CoreNLP  3.6 
OpenNLP  1.5.0  
Mate   
 
Test Data  
Item  Description  
Wiki Data  12GB English wiki data.  
 
4 
 In this test environment, Cloudera Quickstart VM is utilized to quickly construct the software 
environment . According to Cloudera (2016), Cloudera Quickstart VM is a virtual machine which 
installed most of the applications related to Hadoop such as Hive, Spark, HBase. One benefit to use 
this virtual machine is that it has already configured Hadoop a nd integrated with Hive, HBase and 
Hue, which is a management tool for applications in Hadoop ecosystem  (Cloudera, 2016).  
Therefore, it is an ideal platform for researching and making proof of concept.  
4.2. Preparing the Software  
4.2.1.  Download software and wiki data  
The following table list the download links for the required software.  
Software  Link 
KOSHIK  https://github.com/peterexner/KOSHIK  
Cloudera Quickstart VM  http://www.cloudera.com/downloads/quickstart_vms/5 -
7.html  
VirtualBox  https://www.virtualbox.org/wiki /Downloads  
Stanford CoreNLP  http://nlp.stanford.edu/software/corenlp.shtml  
OpenNLP  http://opennlp.sourceforge.net/models -1.5/ 
Mate  https://code.google.com/p/mate -tools/downloads/list  
WikiData  https://dumps.wikimedia.org/enwiki/20160501/enwiki -
20160501 -pages -articles.xml.bz2  
 
4.2.2.  Configure software  
The following table describes steps to configure the required software.  
Software  Step Description  
VirtualBox  1. Unzip Cloudera Quickstart VM.  
2. Import the unzipped Cloudera Quickstart 
VM into VirtualBox.  
KOSHIK required libraries  1. Create a folder anywhere named model.  
2. Create a folder named is2 in model folder 
and put downloaded files CoNLL2009 -ST-
English -ALL.anna -3.3.lemmatizer.model , 
CoNLL2009 -ST-English -ALL.anna -
3.3.parser.model , CoNLL2009 -ST-English -
ALL.anna -3.3.postagger.model  in it.  
3. Create a folder named lth in model folder 
and put downloaded file CoNLL2009 -ST-
English -ALL.anna -3.3.srl -4.1.srl.model  in 
it. 
4. Create a folder named opennlp in model  
folder and put downloaded file en-
sent.bin  in it.  
5. Compress the model folder to model.zip.  
Virtual Machine.  1. Start virtual machine.  
2. Create a folder named koshik_test.  
3. Copy enwiki -20160501 -pages -
articles.xml.bz2  to koshik_test folder.  
4. Copy downloaded KOSHIK to koshik_test 
folder.  
5. Copy model.zip to koshik_test folder.  
Hadoop  1. Under koshik_test folder, copy enwiki -
20160501 -pages -articles.xml.bz2  to 
Hadoop file system.  
5 
  
4.3. Testing  
The following show the steps to test KOSHIK to analyze the WIKI data.  Steps 4, 5, and 6 are similar 
to those mentioned by Nugues (2014).  
 
Step  Description  Command  
1 Import WIKI data 
into KOSHIK.  hadoop jar Koshik -1.0.1.jar se.lth.cs.koshik.util.Import -input 
/enwiki -20160501 -pages -articles.xml -inputformat wikipedia -
language eng -charset utf -8 -output /enwiki_avro  
2 Start KOSHIK map -
reduce jobs to 
analyze the data.  hadoop jar Koshik -1.0.1.jar se.lth.cs.koshik.util.EnglishPipeline -D 
mapred.reduce.tasks=12 -D mapred.child.java.opts= -Xmx8G -
archives model.zi p -input /enwiki_avro -output 
/enwiki_semantic  
3 Import the 
analyzed result 
into Hive for 
querying.  CREATE EXTERNAL TABLE koshikdocs ROW FORMAT SERDE 
'org.apache.hadoop.hive.serde2.avro.AvroSerDe' STORED AS 
INPUTFORMAT 
'org.apache.hadoop.hive.ql.io.avro.A vroContainerInputFormat' 
OUTPUTFORMAT 
'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat' 
LOCATION '/hivetablekoshik' 
TBLPROPERTIES('avro.schema.url'='hdfs:///AvroDocument.avsc');  
LOAD DATA INPATH '/enwiki_semantic/*.avro' INTO TABLE 
koshikdocs;  
4 Query number of 
analyzed articles.  SELECT count(identifier) from koshikdocs;  
SELECT count(key) FROM (SELECT explode(ann) AS (key,value) 
FROM (SELECT ann FROM koshikdocs LATERAL VIEW 
explode(annotations.features) annTable as ann) annmap) 
decmap WHERE key ='POSTAG' AND value LIKE 'NN%';  
5 Query number of 
sentences  SELECT count(ann) FROM koshikdocs LATERAL VIEW 
explode(annotations.layer) annTable as ann WHERE ann LIKE 
'%Sentence';  
6 Query number of 
nouns.  SELECT count(key) FROM (SELECT explode(ann) AS ( key,value) 
FROM (SELECT ann FROM koshikdocs LATERAL VIEW 
explode(annotations.features) annTable as ann) annmap) 
decmap WHERE key='POSTAG' AND value LIKE 'NN%';  
 
5. Findings: A dvantages and Disadvantages  of KOSHIK  
KOSHIK provides an architecture which utilize s Hadoop and related tools  as well as  individual  
NLP tools and language models, and simplifies the construction of a whole NLP system. By adopting 
this architecture, people who work  with  an NLP system could focus on their own professional areas. 
For example, linguists could focus on creating effective language model s to improve the accura cy 
of NLP , while algorithm designers could provide high performance NLP analysis components. When  
KOSHIK uses  the sentence detection component  from Mate and Stanford, it has the potential to 
process  other human language s in the future , if the NLP tools continue to add new language 
model s. Another advantage is that KOSHIK supports different kinds of document types , and it is 
given related APIs to  expand the compatible document types. M oreover, with HDFS, KOSHIK has 
the ability to analyze a large sets of data with high input and output performance. The data  
processing can be  passed on to  MapReduce , which will  provide more  computing power as require d.  
Currently, KOSHIK has not yet become a mature product that is ready to  be used by business es. 
6 
 First, it lacks support and documentation , and  the learning curve for this tool is high. For example, 
this tool utilizes  the language models of Mate, OpenNLP and Stanford CoreNLP . However,  there are 
too many components  for the user to discern  which one KOSHIK is using for a particular task.  
Perhaps only its developers can see it from  the source code.  Second ly, since the last recorded 
change of code, this tool has not been  maint ained regularly,  and there has not  been  any update 
for almost two years . It is un certain  whether this tool will have more functions and a stable version.  
6. Conclusion s 
Natural language processing pla ys an important role in search engine s, speech to text  
conversion tools , intelligent assistants, and artificial intelligence . It will continue to influence  the 
user experience on the i nternet. With more and more data generated, there will be different kind s 
of data processed on Big Data platfo rms. Hadoop provides useful tools and has a mature ecosystem 
which is ideal for natural language processing. There are already some  research reports, and 
software tools for natural language processing utiliz ing Hadoop. KOSHIK is one that provides an 
NLP architecture which utilize s Hadoop and Hive to process large amount of data. It is friendly for 
developers and linguists  because  it can separate these two types of work and allow each of them 
to focus  on their own  areas , thereby  increas ing the performance of NLP system. The architecture  
of KOSHIK  is expandable ; so it provides APIs to add new functions for the system. By utilizing 
OpenNLP , Mate and Stanford CoreNLP , KOSHIK support s different  types of natural language  
processing. Documentation  for KOSHIK is required to learn this tool , and to enable other 
developers to contribute toward  it. However, because the source code has not been  updated for a 
while, it is not ready  for business  use, but  rather  for personal testing and development . 
7. Recomm endation s 
Based on the architecture of KOSHIK and the process speed of large data, this architecture 
could increase processing speed by adopting Spark and GPU processing.  
Spark is a cluster computing system maintained by Apache and it supports in -memory 
computing . This can improve the data analysis speed as high as possible , compared to the original 
MapReduce method  in Hadoop ( Zaharia, Chowdhury, Franklin, Shenker  & Stoica , 2010) . Based on 
the test result s of Zaharia et al. (2010) wh ere they used Spark to analyze a 39 GB wiki data, the 
query time using Spark was 0.5 to 1  second.  The Hadoop query took 35 seconds;  therefore, Spark 
is much faster than Hadoop.  
At present, GPU s are successfully integrated into Hadoop and MapReduce framework s which 
could increase the data processing speed (Yadav,  Bhadoria & Suri, 2015). In addition, Yadav,  
Bhadoria and Suri ( 2015 ) found that there are some libraries such as JCUDA and Java Aparapi that 
provide APIs to interact with GPU s and extract  better  perfo rmance from  them to support high 
performance computing within  Hadoop.  
 
  
7 
 Reference s 
Behzadi, F. (2015). Natural language processing and machine learning: A review. 
International Journal of Computer Science and Information Security , 13(9), 101 -
106.  
Clouder a. (2016). Overview of Cloudera and the Cloudera Documentation Set. 
Retrieved from 
http://www.cloudera.com/documentation/enterprise/latest/topics/introduction
.html . 
Erturk , E. (2013). The impact of intellectual property policies on ethical attitudes 
toward internet piracy. Knowledge Management: An International Journal, 
12(1), 101 -109.   
Exner, P ., & Nugues, P . (2014). KOSHIK: A large -scale distributed computing 
framework fo r NLP . In 3rd International Conference on Pattern Recognition 
Applications and Methods , 463-470. 
Gates, A. F., Natkovich, O., Chopra, S., Kamath, P ., Narayanamurthy, S. M., Olston , 
C., ... & Srivastava, U. (2009). Building a high -level dataflow system on top of 
Map -Reduce: The Pig experience. Proceedings of the VLDB Endowment , 2(2), 
1414 -1425.  
Hashem, I. A. T., Yaqoob, I., Anuar, N. B., Mokhtar, S., Gani, A., & Khan, S. U. (2015). 
The rise of “big data ” on cloud computing: Review and open research issues. 
Information Systems , 47, 98-115.  
Hovy, D., & Spruit, S. (2016). The Social Impact of Natural Language Processing . 
Annual M eeting of the Association for Computational Linguistics , Berlin, 
Germany.  
IBM (2012). What is big data. Retrieved from http://www -
01.ibm.com/software/data/bigdata/what -is-big-data.html . 
Idris, M., Hussain, S., Siddiqi, M. H., Hassan, W., Bilal, H. S., & Lee, S. (2015). MRPack: 
Multi -algorithm execution using com pute -intensive approach in MapReduce. 
PLoS One , 10(8). http://dx.doi.org/10.1371/journal.pone.0136259 . 
Lingad, J., Karimi, S., & Yin, J. (2013 ). Location extraction from disaster -related 
microblogs. In Proceedings of the 22nd international conference on World Wide 
Web companion , 1017 -1020 . 
Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., & McClosky, D. 
(2014, June). The Stanford CoreNLP Natural Language Processing Toolkit. ACL 
(System Demonstrations) , 55-60. 
Markham, S. K., Kowolenko, M., & Michaelis, T. L. (2015). Unstructured text analytics 
to support new product development decisions. Research Technology 
Management , 58(2), 30 -38.  
Mell, P . & Grance, T. (2011).  The NIST Definition of Cloud  Computing:  
Recommendations of the National In stitute of Standards and Technology . 
Retrieved from  
http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800 -145.pdf . 
8 
 Murthy, B. V. R., Padmakar, V., & Reddy, M. A. (2015). Hadoop architecture and its 
functionality. International Journal of Computer Science and Information 
Security , 13(4), 97 -103.  
Nugues, P . (2014). Question answering and the development of the Hajen s ystem . 
Retrieved from 
http://cst.ku.dk/projekter/semantikprojekt/arrangementer/information/Copenh
ague20141103.pdf   
Olston, C. , Reed, B., Srivastava, U., Kumar, R., & Tomkins, A. (2008, June). Pig latin: a 
not-so-foreign language for data processing. In Proceedings of the 2008 ACM 
SIGMOD international conference on Management of data , 1099 -1110 . 
Taylor, R. C. (2010). An overview of the Hadoop/MapReduce/HBase framework and 
its current applications in bioinformatics. BMC Bioinformatics , 11. 
http://dx.doi.org/10.1186/1471 -2105 -11-S12-S1. 
Thusoo, A., Sarma, J. S., Jain, N., Shao, Z., Chakka, P ., Anthony, S., ... & Murthy, R. 
(2009). H ive: a warehousing solution over a map -reduce framework. 
Proceedings of the VLDB Endowment , 2(2), 1626 -1629.  
Verspoor, K., Cohen, K. B., Lanfranchi, A., Warner, C., Johnson, H. L., Roeder, C., . . . 
Hunter, L. E. (2012). A corpus of full -text journal artic les is a robust evaluation 
tool for revealing differences in performance of biomedical natural language 
processing tools. BMC Bioinformatics , 13, 207. http://dx.doi.org/10.1186/1471 -
2105 -13-207. 
White, T. ( 2012 ). Hadoop: The definitive guide . O'Reilly Media : Sepastopol, USA . 
Zaharia, M., Chowdhury, M., Franklin , M. J., Shenker, S., & Stoica, I. (2010). Spark: 
Cluster Computing with Working Sets.  HotCloud , 10, 10-10.  ","natural language processing using hadoop  and koshik  
hong shi  emre erturk   
eastern institute of technology new zealand  
 
abstract  
natural language processing  as a data analytic s related technology  is used widely in many 
research areas such as artificial intelligence human language processing  and translation at 
present due to explosive growth of  data there are many challenges for natural language 
processing hadoop is one of the platform s that can process the large amount of data required  for 
natural language processing koshik is one of the natural language processing architecture s and 
utilizes hadoop and contains  language processing components such as stanford corenlp and 
opennlp  this study describes how to build a koshik platform with the  relevant  tools  and provides  
the steps to analyze wiki data finally it evaluates and discusses the advantages and disadvantages 
of the koshik architecture  and gives recommendation s on improving  the processing performance   
1 introduction  
11 natural language p rocessing  
natural l anguage processing  nlp  is a technique to analyze readable text that is  generated by 
human s for artificial intelligence language processing  and translation  behzadi 2015  in order to 
accurately analyze  the text there are some  methods  for nlp to use in order to deal with the 
challenges such  as the collection and storage of the  text corpus and analysis  nlp techniques also 
gain experience and benefits through  research in lingui stics computational statics artificial 
intelligence m achine learning  and other sciences  behzadi 2015  however at present because 
of the information explosion the use of traditional nlp faces many challenges such as  the volume 
of structured and uns tructured  data  velocity of processing data accura cy of the result s in addition 
there are many slangs and ambigu ous expressions used on social media network s which give nlp 
pressure to analyze the meanings  which may also be hard for some people moreover people 
nowadays h eavily depend on search engines like google and bing  which use nlp as their core 
technique  in their daily study  work  and entertainment  all of these  factors encourage  computer 
scientists and research ers to find more robust e fficien t and standardized  solutions for nlp    
12 big data  
big data is designed as generic platform to resolve the issues of volume velocity variety 
veracity and value in data analytics  ibm 2012  the data is collected from different sources for 
example  daily logs social media and business transactions big data demands the ability to hoard 
large amounts of data with advanced storage technologies the data size could be as high as 
terabytes 1012 bytes petabytes 1015 bytes and exabytes 1018 bytes  furthermore research on 
nlp often overlaps with research on or the use of big data platforms big data handles  all types of 
formats which are structured and unstructured the structured data is readable and well designed 
that is commonly stored in traditional relationship databases unstructure d data does not have a 
predefined format  this type of data can be  foun d in for example emails images  and videos big 
data  is widely used in business forecasts  scientific research  analysis of social issues healthcare  
and meteorology while promoting advances in nlp  it is also important to be aware of ethical 
issues a round the potential misuse and dual use of big data and nlp tools hovy  spruit 2016 
1 
 some of these issues can be very interesting for information technology students to debate and 
learn more about  erturk 2013   
13 hadoop  
hadoop is a application created  using java and  provides a set of tools to do data processing 
which includes data storage access analysis  white  2012  according to white 2012 the main 
components in hadoop are hdfs hadoop distributed file system and mapreduce hdfs is solid 
and fault tolerant and provides a java based api that integrates with mapreduce to process the 
large data in parallel using a cluster of  servers taylor 2010  as murthy padmakar  and reddy  2015  
observe d traditional relational  database s which store struc tured data could also be used together 
with hadoop hdfs with full database management systems  dbms features mapreduce is 
created with inspiration from the theory  published by google  and it provides function s that split  
large set of data computing into small computing tasks  white  2012   
14 natural language processing on hadoop  
ideal y hadoop with the features of distributed storage system multi tasks processing system 
generic platform and open source can be used for nlp research  there are many papers discuss ing 
the solutions which utilize  hadoop for nlp  for example hdfs is used in the research of markham 
kowolenko and  michaelis 2015  to manage large amount of unstructured data which was 
collected from the intern et with hadoop  tools  idris hussain  siddiqi hassan bilal and lee 2015  
designed a system named mrpack which gives an end toend mapreduce processing model for 
text processing which includes a job task for nlp  mrpack shows it has better performance i n data 
accessing data managing and data writing as well as less programming work and demanding for 
io management  idris  et al 2015  
this study reviews  koshik  a hadoop based framework  which has been developed from  the 
paper written  by exner  and nugues  2014  then it gives the findings for what hadoop components 
this framework used  and recommendations to improve the nlp performance  finally it shows the 
steps to test koshik  
2 literature review  
21 introduction  
it is described that koshik is a framework for batch oriented large scale processing and 
querying of unstructured natural language documents  in particular it builds on the hadoop 
ecosystem and takes full advantage of the data formats and tools present in this environment to 
achieve its task exner   nugues 2014  p 463  koshik tries to resolve the common challenges 
in nlp such as v olume velocity and variety  by adopting hadoop for the system infrastructure  
using a batch oriented annotation model to continually add annotations and en abling a generic 
algorithm platform to analyze the variety of text exner  nugues 2014 it is also argued that 
before developing koshik there were many other nlp frameworks such as multext gate and 
uima  which were important for document retrieval i ndexing and querying of processed 
information  applications  exner  nugues 2014  
2 
 22 koshik architecture  
 
figure 1 an overv iew of the koshik architecture  exner   nugues  2014  
exner and nugues 2014  stated that koshik supports a variety of nlp tools implemented 
atop of the hadoop distributed computing framework the requirements on koshik were driven 
by the desire to support scalability reliability and a large number of input formats and processing 
tasks  koshik supp orts different kinds of documents such as conll x conll 2008 and 2009 and 
wikipedia dump files exner  nugues 2014 buchholz and marsi 2006  surdeanu et al 2008  in 
order to analyze different kinds of language koshik involves a large set of filters  tokenizers 
taggers parsers and coreference solvers  through several language specific nlp tools such as 
opennlp  mate tools stanford corenlp  etc exner  nugues 2014  with the developed 
annotation model in koshik this framework could simplify the  process of content processors 
which only require computing resource focus on the input and output of annotated documents  
exner  nugues 2014  
koshik utilizes hadoop as its distributed computing framework which not only used for a 
better performance o n large corpus  analysis but also for the division and distribution of a set of 
documents management of processing jobs and to get the process result  exner  nugues 2014 
pig and hive which are core members of hadoop ecosystem are adopted into this fr amework to 
manage the workflows for processing large data sets and easily query information by sql like 
language  respectively  exner  nugues 2014  
3 key terms  
after evaluating this paper hive and pig which are dat a querying components of hadoop  and 
open nlp and stanford corenlp which are nlp process tools are identified for future research  
according to thusoo  et al  2009 hive is a data warehouse infrastructure built based on  
hadoop for providing data summarization query and analysis  it could be used to deal with large 
distributed data such as hdfs and traditional file systems like fat ntfs and exfat thusoo et al 
2009  in addition hiveql a sqllike language  is created to query data on hadoop which will 
translate the query to ma preduce jobs for high performance  thusoo et al 2009  
 

3 
 the pig is a high level declarative querying language inspired by sql which will translate the 
query to mapreduce jobs  pis olston  reed srivastava kumar  tomkins  2008  according to 
gates  et al  2009 there are many data analysis projects which adopted pig because it is easy to 
learn and use and could quickly implement different versions of algorithms  
lingad karimi and yin 2013 found  that opennlp is a java based library for various  natur al 
language processing tasks such as tokenization  partofspeech pos tagging and named entity  
recognition for named entity recognition it trains a  maximum entropy model using the 
information from  the whole document  to recognize entities in documents  although opennlp 
provides many functions for nlp  the model to process the document should be considered that 
verspoor  2012 argued  that opennlp has low quality to divide sentence into parts but it could 
improve the performance by using annotator  
stanford corenlp is  a nlp tool and utilize s annotation  to analyse text that it provides  most of 
the common core nlp steps from tokenization through to  coreference resolution  manning  2014  
it is also described that stanford corenlp provides a complete t oolkit and tools for grammatical 
analysis accurate analysis and supports different kinds of languages  manning  2014   
4 testing koshik  
41 preparing  the hardware  environment  
according to exner and nugues 2014  koshik runs on hadoop with hive and requires other 
nlp process libraries opennlp  mate and stanford corenlp the experiment al environment 
including hardware software and test data used in this paper is  described  in the following tables   
 
hardware environment  
hardware  description  
cpu intel i5 quad cores 27ghz  
hard disk  sata 500g  
memory  ddr3 16g  
graphic card  nvidia 940  
network  1g lan  
 
software environment  
operation 
systemapplicationlibrary  version  
operation system  centos 67  
koshik  101  
java  180  
hadoop  260  
hive  110  
cloudera  570  
hue 390  
virtualbox  5020 
stanford corenlp  36 
opennlp  150  
mate   
 
test data  
item  description  
wiki data  12gb english wiki data  
 
4 
 in this test environment cloudera quickstart vm is utilized to quickly construct the software 
environment  according to cloudera 2016 cloudera quickstart vm is a virtual machine which 
installed most of the applications related to hadoop such as hive spark hbase one benefit to use 
this virtual machine is that it has already configured hadoop a nd integrated with hive hbase and 
hue which is a management tool for applications in hadoop ecosystem  cloudera 2016  
therefore it is an ideal platform for researching and making proof of concept  
42 preparing the software  
421  download software and wiki data  
the following table list the download links for the required software  
software  link 
koshik  httpsgithubcompeterexnerkoshik  
cloudera quickstart vm  httpwwwclouderacomdownloadsquickstartvms5 
7html  
virtualbox  httpswwwvirtualboxorgwiki downloads  
stanford corenlp  httpnlpstanfordedusoftwarecorenlpshtml  
opennlp  httpopennlpsourceforgenetmodels 15 
mate  httpscodegooglecompmate toolsdownloadslist  
wikidata  httpsdumpswikimediaorgenwiki20160501enwiki 
20160501 pages articlesxmlbz2  
 
422  configure software  
the following table describes steps to configure the required software  
software  step description  
virtualbox  1 unzip cloudera quickstart vm  
2 import the unzipped cloudera quickstart 
vm into virtualbox  
koshik required libraries  1 create a folder anywhere named model  
2 create a folder named is2 in model folder 
and put downloaded files conll2009 st
english allanna 33lemmatizermodel  
conll2009 stenglish allanna 
33parsermodel  conll2009 stenglish 
allanna 33postaggermodel  in it  
3 create a folder named lth in model folder 
and put downloaded file conll2009 st
english allanna 33srl 41srlmodel  in 
it 
4 create a folder named opennlp in model  
folder and put downloaded file en
sentbin  in it  
5 compress the model folder to modelzip  
virtual machine  1 start virtual machine  
2 create a folder named koshiktest  
3 copy enwiki 20160501 pages 
articlesxmlbz2  to koshiktest folder  
4 copy downloaded koshik to koshiktest 
folder  
5 copy modelzip to koshiktest folder  
hadoop  1 under koshiktest folder copy enwiki 
20160501 pages articlesxmlbz2  to 
hadoop file system  
5 
  
43 testing  
the following show the steps to test koshik to analyze the wiki data  steps 4 5 and 6 are similar 
to those mentioned by nugues 2014  
 
step  description  command  
1 import wiki data 
into koshik  hadoop jar koshik 101jar selthcskoshikutilimport input 
enwiki 20160501 pages articlesxml inputformat wikipedia 
language eng charset utf 8 output enwikiavro  
2 start koshik map 
reduce jobs to 
analyze the data  hadoop jar koshik 101jar selthcskoshikutilenglishpipeline d 
mapredreducetasks12 d mapredchildjavaopts xmx8g 
archives modelzi p input enwikiavro output 
enwikisemantic  
3 import the 
analyzed result 
into hive for 
querying  create external table koshikdocs row format serde 
orgapachehadoophiveserde2avroavroserde stored as 
inputformat 
orgapachehadoophiveqlioavroa vrocontainerinputformat 
outputformat 
orgapachehadoophiveqlioavroavrocontaineroutputformat 
location hivetablekoshik 
tblpropertiesavroschemaurlhdfsavrodocumentavsc  
load data inpath enwikisemanticavro into table 
koshikdocs  
4 query number of 
analyzed articles  select countidentifier from koshikdocs  
select countkey from select explodeann as keyvalue 
from select ann from koshikdocs lateral view 
explodeannotationsfeatures anntable as ann annmap 
decmap where key postag and value like nn  
5 query number of 
sentences  select countann from koshikdocs lateral view 
explodeannotationslayer anntable as ann where ann like 
sentence  
6 query number of 
nouns  select countkey from select explodeann as  keyvalue 
from select ann from koshikdocs lateral view 
explodeannotationsfeatures anntable as ann annmap 
decmap where keypostag and value like nn  
 
5 findings a dvantages and disadvantages  of koshik  
koshik provides an architecture which utilize s hadoop and related tools  as well as  individual  
nlp tools and language models and simplifies the construction of a whole nlp system by adopting 
this architecture people who work  with  an nlp system could focus on their own professional areas 
for example linguists could focus on creating effective language model s to improve the accura cy 
of nlp  while algorithm designers could provide high performance nlp analysis components when  
koshik uses  the sentence detection component  from mate and stanford it has the potential to 
process  other human language s in the future  if the nlp tools continue to add new language 
model s another advantage is that koshik supports different kinds of document types  and it is 
given related apis to  expand the compatible document types m oreover with hdfs koshik has 
the ability to analyze a large sets of data with high input and output performance the data  
processing can be  passed on to  mapreduce  which will  provide more  computing power as require d  
currently koshik has not yet become a mature product that is ready to  be used by business es 
6 
 first it lacks support and documentation  and  the learning curve for this tool is high for example 
this tool utilizes  the language models of mate opennlp and stanford corenlp  however  there are 
too many components  for the user to discern  which one koshik is using for a particular task  
perhaps only its developers can see it from  the source code  second ly since the last recorded 
change of code this tool has not been  maint ained regularly  and there has not  been  any update 
for almost two years  it is un certain  whether this tool will have more functions and a stable version  
6 conclusion s 
natural language processing pla ys an important role in search engine s speech to text  
conversion tools  intelligent assistants and artificial intelligence  it will continue to influence  the 
user experience on the i nternet with more and more data generated there will be different kind s 
of data processed on big data platfo rms hadoop provides useful tools and has a mature ecosystem 
which is ideal for natural language processing there are already some  research reports and 
software tools for natural language processing utiliz ing hadoop koshik is one that provides an 
nlp architecture which utilize s hadoop and hive to process large amount of data it is friendly for 
developers and linguists  because  it can separate these two types of work and allow each of them 
to focus  on their own  areas  thereby  increas ing the performance of nlp system the architecture  
of koshik  is expandable  so it provides apis to add new functions for the system by utilizing 
opennlp  mate and stanford corenlp  koshik support s different  types of natural language  
processing documentation  for koshik is required to learn this tool  and to enable other 
developers to contribute toward  it however because the source code has not been  updated for a 
while it is not ready  for business  use but  rather  for personal testing and development  
7 recomm endation s 
based on the architecture of koshik and the process speed of large data this architecture 
could increase processing speed by adopting spark and gpu processing  
spark is a cluster computing system maintained by apache and it supports in memory 
computing  this can improve the data analysis speed as high as possible  compared to the original 
mapreduce method  in hadoop  zaharia chowdhury franklin shenker   stoica  2010  based on 
the test result s of zaharia et al 2010 wh ere they used spark to analyze a 39 gb wiki data the 
query time using spark was 05 to 1  second  the hadoop query took 35 seconds  therefore spark 
is much faster than hadoop  
at present gpu s are successfully integrated into hadoop and mapreduce framework s which 
could increase the data processing speed yadav  bhadoria  suri 2015 in addition yadav  
bhadoria and suri  2015  found that there are some libraries such as jcuda and java aparapi that 
provide apis to interact with gpu s and extract  better  perfo rmance from  them to support high 
performance computing within  hadoop  
 
  
7 
 reference s 
behzadi f 2015 natural language processing and machine learning a review 
international journal of computer science and information security  139 101 
106  
clouder a 2016 overview of cloudera and the cloudera documentation set 
retrieved from 
httpwwwclouderacomdocumentationenterpriselatesttopicsintroduction
html  
erturk  e 2013 the impact of intellectual property policies on ethical attitudes 
toward internet piracy knowledge management an international journal 
121 101 109   
exner p   nugues p  2014 koshik a large scale distributed computing 
framework fo r nlp  in 3rd international conference on pattern recognition 
applications and methods  463470 
gates a f natkovich o chopra s kamath p  narayanamurthy s m olston  
c   srivastava u 2009 building a high level dataflow system on top of 
map reduce the pig experience proceedings of the vldb endowment  22 
1414 1425  
hashem i a t yaqoob i anuar n b mokhtar s gani a  khan s u 2015 
the rise of big data  on cloud computing review and open research issues 
information systems  47 98115  
hovy d  spruit s 2016 the social impact of natural language processing  
annual m eeting of the association for computational linguistics  berlin 
germany  
ibm 2012 what is big data retrieved from httpwww 
01ibmcomsoftwaredatabigdatawhat isbigdatahtml  
idris m hussain s siddiqi m h hassan w bilal h s  lee s 2015 mrpack 
multi algorithm execution using com pute intensive approach in mapreduce 
plos one  108 httpdxdoiorg101371journalpone0136259  
lingad j karimi s  yin j 2013  location extraction from disaster related 
microblogs in proceedings of the 22nd international conference on world wide 
web companion  1017 1020  
manning c d surdeanu m bauer j finkel j r bethard s  mcclosky d 
2014 june the stanford corenlp natural language processing toolkit acl 
system demonstrations  5560 
markham s k kowolenko m  michaelis t l 2015 unstructured text analytics 
to support new product development decisions research technology 
management  582 30 38  
mell p   grance t 2011  the nist definition of cloud  computing  
recommendations of the national in stitute of standards and technology  
retrieved from  
httpnvlpubsnistgovnistpubslegacyspnistspecialpublication800 145pdf  
8 
 murthy b v r padmakar v  reddy m a 2015 hadoop architecture and its 
functionality international journal of computer science and information 
security  134 97 103  
nugues p  2014 question answering and the development of the hajen s ystem  
retrieved from 
httpcstkudkprojektersemantikprojektarrangementerinformationcopenh
ague20141103pdf   
olston c  reed b srivastava u kumar r  tomkins a 2008 june pig latin a 
notsoforeign language for data processing in proceedings of the 2008 acm 
sigmod international conference on management of data  1099 1110  
taylor r c 2010 an overview of the hadoopmapreducehbase framework and 
its current applications in bioinformatics bmc bioinformatics  11 
httpdxdoiorg1011861471 2105 11s12s1 
thusoo a sarma j s jain n shao z chakka p  anthony s   murthy r 
2009 h ive a warehousing solution over a map reduce framework 
proceedings of the vldb endowment  22 1626 1629  
verspoor k cohen k b lanfranchi a warner c johnson h l roeder c    
hunter l e 2012 a corpus of full text journal artic les is a robust evaluation 
tool for revealing differences in performance of biomedical natural language 
processing tools bmc bioinformatics  13 207 httpdxdoiorg1011861471 
2105 13207 
white t  2012  hadoop the definitive guide  oreilly media  sepastopol usa  
zaharia m chowdhury m franklin  m j shenker s  stoica i 2010 spark 
cluster computing with working sets  hotcloud  10 1010","['httpcstkudkprojektersemantikprojektarrangementerinformationcopenh', 'httpdxdoiorg101371journalpone0136259', 'httpsdumpswikimediaorgenwiki20160501enwiki', 'httpopennlpsourceforgenetmodels', 'tblpropertiesavroschemaurlhdfsavrodocumentavsc', 'explodeannotationsfeatures', 'httpwwwclouderacomdocumentationenterpriselatesttopicsintroduction', 'isbigdatahtml', 'hadoopmapreducehbase', 'articlesxmlbz2']",2
NLI4DB: A Systematic Review of Natural Language Interfaces for Databases,"['Mengyi Liu', 'Jianqiu Xu']",2025,http://arxiv.org/abs/2503.02435v1,"NLI4DB: A Systematic Review of Natural Language
Interfaces for Databases
Mengyi Liu and Jianqiu Xu*
Nanjing University of Aeronautics and Astronautics, Nanjing, China
{liumengyi,jianqiu }@nuaa.edu.cn
Abstract
As the demand for querying databases in all areas of life continues to grow, researchers have devoted signifi-
cant attention to the n atural l anguage i nterface for d atabases (NLIDB). This paper presents a comprehensive sur-
vey of recently proposed NLIDBs. We begin with a brief introduction to natural language processing techniques,
executable database languages and the intermediate representation between natural language and executable lan-
guage, and then provide an overview of the translation process from natural language to executable database
language. The translation process is divided into three stages: (i) natural language preprocessing , (ii) natural
language understanding , and (iii) natural language translation . Traditional and data-driven methods are utilized
in the preprocessing stage. Traditional approaches rely on predefined rules and grammars, and involve techniques
such as regular expressions, dependency parsing and named entity recognition. Data-driven approaches depend
on large-scale data and machine learning models, using techniques including word embedding and pattern link-
ing. Natural language understanding methods are classified into three categories: (i) rule-based , (ii) machine
learning-based , and (iii) hybrid . We then describe a general construction process for executable languages over
relational and spatio-temporal databases. Subsequently, common benchmarks and evaluation metrics for trans-
forming natural language into executable language are presented, and methods for generating new benchmarks
are explored. Finally, we summarize the classification, development, and enhancement of NLIDB systems, and
discuss deep language understanding and database interaction techniques related to NLIDB, including (i) us-
ing LLM for Text2SQL tasks , (ii) generating natural language interpretations from SQL , and (iii) transforming
speech queries into SQL .
Keywords: Natural language interface for database, Semantic parsing, Structured language, Query processing
1 Introduction
In today’s data-driven world, databases are the backbone of a number of applications, from social media plat-
forms to financial systems. However, accessing and querying these vast repositories of information often requires
specialized knowledge of query languages such as SQL, which can be a significant barrier for non-expert users,
limiting their ability to harness the full potential of the data at their fingertips. The advent of n atural l anguage
interface (NLI) has the potential to eliminate the interaction barrier between users and terminals [130]. The
integration of n atural l anguage p rocessing (NLP) and database technology represents an intriguing avenue for
future research. There are systems that facilitate the transformation of natural language into structured language
[141, 22], provide the natural language description for query execution plans [139, 23], and transform SQL into
natural language [40, 132].
Imagine a world where anyone, regardless of technical proficiency, can effortlessly interact with complex
databases using everyday language. This vision is becoming a reality through the development of natural language
*Corresponding author.
1arXiv:2503.02435v1  [cs.DB]  4 Mar 2025
Who is the director of
""Inglourious Basterds""?
Natural Language QuerySELECT   DISTINCT p.* 
FROM  movie m, person p, directing d  
WHERE m.id = d.movieId AND person.id = d.directorId  
AND m.title = ""Inglourious Basterds""
Translated Executable LanguageNLIDB
Manual
ProcessingFigure 1: Example of translating a natural language into an executable language
Natural language pr eprocessing
Natural language understanding
Natural language translationNatural Language Query
Executable Database LanguageNLIDB Methods Techniques involved Examples of NLIDBs
traditionalnamed entity recognition,
dictionary generation, regular
expression, dependency parsingPRECISE, Querix, QuestIO,
gAnswer , MEANS, NL2CM,  
ATHENA, SQLizer , NALMO
data-driven word embedding, pattern linking IRNet, xDBT agger
Methods Techniques involved Examples of NLIDBs
rule-basedsemantic accessibility ,
intermediate query languagePRECISE, NaLIX, DaNaLIX, NaLIR, NL2CM,
ATHENA, NALMO, ezNL2SQL
machine learning-basedstatistical machine translation, 
encoder -decoder frameworksSeq2SQL, DialSQL, SyntaxSQLNet, DBT agger , 
IRNet, SpatialNLI, ValueNet, SV2-SQL
hybrid intermediate query language,
encoder -decoder frameworksTypeSQL, NALMO, Veezoo, GAR, CatSQL,  
GENSQL, NALSpatial, xDBT agger
database elements + SELECT ,
FROM, WHERE partsjoin condition + WHERE clause
participating relations + FROM clause
query type operators the executable languagerelational database
spatio-temporal  
databasekey semantic informationsegmentation, 
part-of-speech tagging
Figure 2: A summary of translation techniques
interface for databases (NLIDB), which aims to transform a n atural l anguage q uery (NLQ) into an executable
language, as illustrated in Figure 1. Users tend to favor an interactive interface that allows them to confirm the
accuracy and precision of the generated structured language [95]. The NLIDB enables users to avoid the necessity
of possessing expertise in structured query languages and database schema, thereby significantly streamlining the
efforts of users and enhancing the benefits of utilizing databases [70]. The initial NLIDBs, including BASEBALL,
LUNAR, LADDER, Chat-80, and ASK, were released in rapid succession [2]. Subsequently, NLIDBs have
emerged and are primarily utilized in relational databases (e.g., GENSQL [44] and CatSQL [48]), spatial domains
(e.g., SpatialNLI [80, 141] and NALSpatial [89]), RDF question and answer (e.g., Querix [69] and TEQUILA
[64]), and XML databases (e.g., NaLIX [84, 85] and DaNaLIX [81]).
Despite years of research, the landscape of NLIDB is fraught with challenges [9, 82]. The inherent ambiguity
and variability of natural language make NLIDB difficult to ensure accurate query interpretation. Additionally,
understanding the structure and semantics of different databases adds another layer of complexity. Furthermore,
achieving real-time performance while maintaining high accuracy in query translation remains an ongoing chal-
lenge. While l arge l anguage m odels (LLMs) offer new avenues for querying databases using natural language,
the training and reasoning of such models necessitate a substantial amount of computational resources, which
may prove challenging to implement in resource-limited scenarios [97]. Moreover, the decision-making process
of LLMs is frequently opaque and lacks interpretability, making it difficult to ascertain whether the generated
query results align with the user’s intent [126]. These obstacles underscore the need for continued research and
development to refine NLIDB.
2
In light of these observations, this systematic review explores the current state of NLIDB, examining the var-
ious approaches and technologies that have been proposed to connect natural language with database querying,
named NLI4DB. The aim of this survey is to offer a comprehensive overview that serves as both a valuable ref-
erence for researchers and a practical guide for practitioners aiming to implement effective NLIDB solutions.
NLI4DB presents a thorough examination of the NLIDB subject, categorizing the work into subtopics and pro-
viding in-depth analysis for each one. The translation process from natural language to executable language is
divided into three stages: (i) natural language preprocessing , (ii) natural language understanding , and (iii) nat-
ural language translation . The three-stage division provides physical independence by separating the physical
arrangement of data from the semantics of queries [113]. The techniques for the translation are shown in Figure
2.
(i) Natural language preprocessing generally involves the construction of dedicated data dictionaries for the
domain using stemming extraction and synonym techniques. Part-of-speech tagging and word segmentation are
then performed on the input natural language. Methods used in the preprocessing stage include traditional and
data-driven. Traditional approaches rely on predefined rules and grammars for domain-specific text processing,
and involve techniques such as regular expressions, dependency parsing and n amed e ntity r ecognition (NER).
Data-driven approaches depend on large-scale data and machine learning models for complex or variable text
processing, using techniques such as word embedding and pattern linking.
(ii) Natural language understanding has rule-based, machine learning-based, and hybrid approaches. Rule-
based systems can only deal with knowledge bases of specific domains, whose semantic understanding processes
either define the concept of semantic accessibility or translate the NLQ into an intermediate representation that
can describe the semantics and relationships in an accessible manner. Machine learning-based systems employ
a variety of techniques to parse text, including unsupervised approaches, question-and-answer supervised learn-
ing, statistical machine translation techniques, encoder-decoder frameworks with recurrent neural networks, and
combinations of deterministic algorithms and machine learning. Hybrid approaches combine rules and machine
learning techniques to maximize their benefits.
(iii) Natural language translation uses distinctive algorithms to map processed key semantic information to
corresponding structured language components. To build the SQL, the database elements matched by the NLQ are
placed in the appropriate locations in the SELECT, FROM, and WHERE parts. In the event that a query involves
multiple relations, it is necessary to include the join condition and the names of the participating relations in the
WHERE and FROM clause, respectively. In the process of building an executable language of a spatio-temporal
database, the query type of the input NLQ is initially identified. The operators required to build the executable
language are then determined according to the query type. Finally, the key semantic information obtained from
the natural language understanding stage is integrated to form an executable language.
The existing survey [2] related to NLIDB focuses on the comparative analysis of the entire natural language
interface system. Affolter et al. [2] divide NLIs into four groups: (i) keyword-based systems , (ii) pattern-based
systems , (iii) parsing-based systems , and (iv) grammar-based systems . For each group, they provide an overview
of representative systems and describe the most illustrative one in detail. In addition, they systematically compare
24 recently developed NLIDBs on the basis of the sample world designed in the paper. Each system is evaluated
using 10 example questions to show the advantages and disadvantages.
Compared with Affolter et al. [2], we divide the system translation process into three steps and focus on
the comparative analysis of each step. We investigate the recently developed NLIDB systems and divide the
translation process into three stages: (i) natural language preprocessing , (ii) natural language understanding ,
and (iii) natural language translation . We classify natural language preprocessing techniques into traditional
and data-driven. Natural language understanding methods are then analyzed in three categories: (i) rule-based ,
(ii)machine learning-based , and (iii) hybrid . Next, we provide a comprehensive outline of the construction
process of executable languages for relational and spatio-temporal databases. Finally, we present commonly used
benchmarks and evaluation metrics, and describe the classification, development, and enhancement of NLIDBs.
3
Table 1: Frequently used notations
Name Abbreviation
Natural language interface for database NLIDB
Natural language interface NLI
Natural language query NLQ
Natural language processing NLP
Named entity recognition NER
Large language model LLM
First-order logic FOL
Automatic speech recognition ASR
sequence-to-sequence seq2seq
The rest of the paper is structured as follows. Section 2 furnishes the background concerning NLIDB, in-
cluding natural language processing techniques, executable database languages and intermediate representation
languages. Section 3 describes the generation of executable database languages in terms of three stages: (i) nat-
ural language preprocessing , (ii) natural language understanding and (iii) natural language translation . Section
4 summarizes 11 popular benchmarks for transforming NLQ into SQL and 3 evaluation metrics, including re-
sponse time, translatability, and translation precision, and explores the methods for generating new benchmarks.
Section 5 analyzes the classification, development and enhancement of NLIDBs. Section 6 discuss deep language
understanding and database interaction techniques related to NLIDB, including (i) using LLM for Text2SQL tasks ,
(ii)generating natural language interpretations from SQL , and (iii) transforming speech queries into SQL . Sec-
tion 7 explores the open problems of NLIDB and concludes the survey. Table 1 summarizes the frequently used
notations.
2 Background: NLP techniques and query languages
We introduce the background related to NLIDB, including natural language processing techniques, executable
database languages, and intermediate representation languages.
2.1 Natural language processing techniques
NLP is an interdisciplinary discipline that integrates several fields such as linguistics, computer science, and math-
ematics, and aims to make computers capable of understanding, processing and generating natural language text
or speech. Through segmentation, lexical annotation, and syntactic analysis, NLP provides structured processing
of text to achieve semantic understanding and information extraction. The application areas of NLP cover machine
translation, sentiment analysis, information retrieval, and dialogue systems, providing people with an intelligent
and convenient way of language interaction.
A Brief History. The earliest research on natural language processing is machine translation. In 1950, Alan
Turing proposed the ultimate test for determining the arrival of truly “ intelligent ” machines, which is generally
regarded as the inception of the idea of NLP [96]. From the 1950s to the 1970s, the rule-based method was
used to process natural language, which was based on grammatical rules and formal logic. In the 1970s, the
statistic-based method gradually supplanted the rule-based method. At this juncture, NLP built on mathematical
models and statistic made a substantial breakthrough and was applied to practical applications. From 2008 to the
present, researchers have introduced deep learning to NLP in response to the achievements in image recognition
and speech recognition.
The NLP techniques commonly used in NLIDBs are as follows.
(i)Part of speech tagging refers to assigning the correct part of speech to each word in the segmented text,
4
(a) Part of speech tagging
(b) Lemmatization
(c) Named entity recognition
DT
Alldet acl NNS
moviesVBG
starringNNP
Bradcompound NNP
PittIN
fromcase CD
2000IN
untilcase CD
2010.
.objobloblpunct
(d) Dependency parsing
Figure 3: Processing natural language using Stanford CoreNLP
determining whether each word is a noun, verb, or adjective. In NLIDB, part of speech tagging facilitates the
identification of the grammatical roles of individual words in natural language queries, leading to an accurate
comprehension of users’ intent. Taking the natural language query “ All movies starring Brad Pitt from 2000 until
2010. ” as an example, the result of part of speech tagging using Stanford CoreNLP is shown in Figure 3(a). In the
figure, DT = determiner; NNS = plural noun; VBG = the gerund or present participle of a verb; NNP = singular
proper noun; IN = preposition or subordinating conjunction; CD = cardinal number.
(ii)Lemmatization is the process of reducing the different forms of a word to the original form. In NLIDB,
lemmatization is beneficial in unifying words of various tenses and morphs in natural language queries into base
forms in order to match the content in the database. Taking the natural language query “ All movies starring Brad
Pitt from 2000 until 2010. ” as an example, the result of lemmatization using Stanford CoreNLP is shown in Figure
3(b).
(iii)Named entity recognition is the procedure of identifying entities with specific meanings in natural lan-
guage text [114]. Generally, the recognized entities can be categorized into three primary groups (entity, temporal,
and numeric) and seven subgroups (PERSON, ORGANIZATION, LOCATION, TIME, DATE, MONEY , and
PERCENT). NER in NLIDB enables the identification of entities involved in a natural language query to locate
the topic and scope of the query. Taking the natural language query “ All movies starring Brad Pitt from 2000 until
2010. ” as an example, the result of NER using Stanford CoreNLP is shown in Figure 3(c).
(iv)Dependency parsing involves analyzing the dependencies between words in natural language sentences.
A binary asymmetric relationship between words is called dependency, which is described as an arrow from the
head (the subject to be modified) to the dependent (the modifier). Dependency parsing in NLIDB facilitates the
understanding of grammatical relationships between words in NLQs, so that the structure and meaning of the
query can be accurately understood. Taking the natural language query “ All movies starring Brad Pitt from 2000
until 2010. ” as an example, the result of dependency parsing using Stanford CoreNLP is illustrated in Figure 3(d).
In the figure, punct = punctuation; obl = oblique nominal; obj = object; det = determiner; acl = clausal modifier of
noun; case = case marking.
With the vigorous development of NLP technology, a number of NLP tools are appearing [114]. These tools
can perform basic tasks, including dependency parsing, named entity recognition, lemmatization, and part of
5
speech tagging, each of which has distinct advantages and disadvantages. The following is a list of the established
open source natural language processing tools.
(i)NLTK is a natural language processing toolkit using Python as the programming language. NLTK has
complete functions and realizes many of the functional components in natural language processing, such as named
entity recognition, sentence structure analysis, part-of-speech tagging, and text classification [13]. Born for the
academic field, NLTK is suitable for study and research. The disadvantage is that NLTK has a slower processing
speed than other tools.
(ii)spaCy , a commercial open source software, is an industrial-grade natural language processing software
programmed in Python and Cython languages [45]. spaCy, which follows NLTK, includes pre-trained statistical
models and word vectors. spaCy can break down text into semantic units like articles, words and punctuation, and
support named entity recognition. spaCy is characterized by fast and accurate syntax analysis, and comprehensive
functions ranging from simple part-of-speech tagging to advanced deep learning.
(iii)Stanford CoreNLP is a tool set developed by Stanford University using the Java programming language.
Stanford CoreNLP supports a variety of natural languages and has rich interfaces for programming languages that
can be used without Java [91]. Stanford CoreNLP is an efficient tool created by high-level research institutions
and is widely used in scientific research and experiments, but may incur additional costs in production systems.
Stanford CoreNLP may not be the best choice for industry.
(iv)TextBlob is an extension to NLTK, which provides an easier way to use the functionality of NLTK [57].
TextBlob supports sentiment analysis, tokenization, part-of-speech tagging, and text classification. One of the
advantages is that TextBlob can be used in production environments where performance requirements are not too
high. TextBlob can be applied in a wide range of scenarios, especially for small projects.
2.2 Executable database languages
The output of NLIDB is an executable database language, and we present executable languages over relational
data, RDF data, and spatial data.
2.2.1 Query language for relational data
The standard executable query language for relational data is SQL. Such a language is a general-purpose, ex-
tremely powerful relational database language whose functions are not limited to querying, but also include creat-
ing database schema, inserting and modifying data, and defining and controlling database security integrity [29].
Following the establishment of SQL as an international standard language, numerous database manufacturers have
released SQL-compatible software, including both database management systems and interfaces. Consequently,
SQL serves as the universal data access language and standard interface for most databases, fostering a shared
foundation for interoperability among different database systems. SQL has become the mainstream language in
the database field which is of great significance.
SQL provides the SELECT statement for querying data, which has flexible usage and rich functionality. The
SELECT statement can perform simple single-table queries as well as complex join queries and nested queries,
whose general format is:
SELECT [ALL|DISTINCT] <target column expression >[alias] [, <target column expression >[alias]]
FROM <table name or view name >[,<table name or view name >]|(SELECT statement) [AS] <alias>
[WHERE <conditional expression >]
[GROUP BY <column name 1 >[HAVING <conditional expression >]]
[ORDER BY <column name 2 >[ASC|DESC]];
The purpose of the SELECT statement is to find the tuples that satisfy the conditions specified in the FROM clause,
which may be a basic table, view, or derived table ,according to the conditional expression in the WHERE clause.
6
The attribute value in the tuple is then selected on the basis of the target column expression in the SELECT clause
to form the result table. When a GROUP BY clause is present, the output is organized by the value of <column
name 1 >, where tuples sharing identical attribute column values are grouped together. Aggregation functions are
usually applied to each group. When the GROUP BY clause is accompanied by a HA VING clause, the output
will only include groups that satisfy the specified conditions. If an ORDER BY clause is present, the result table
is sorted in ascending or descending order according to the values of <column name 2 >.
2.2.2 Query language for RDF data
The complete designation of RDF is Resource Description Framework, which is a data model designed to represent
information about resources on the Internet. The data model typically describes a fact composed of three parts
known as a triple, including (i) a subject , (ii) a predicate , and (iii) an object . An RDF graph contains multiple
triples. RDF documents are written in XML to offer a standardized method for describing information. RDF is
intended for computer applications to read and understand, rather than for visual presentation to web users.
SPARQL is a specialized query language and data retrieval protocol designed for RDF, which stands for
SPARQL Protocol and RDF Query Language [24]. SPARQL is a query language over RDF graphs, where the
database is represented as a collection of “ subject-predicate-object ” triples. Although RDF data is inferential,
SPARQL does not have an inference query function. SPARQL is tailored for managing data stored in RDF
format, enabling both retrieval and manipulation. SPARQL is composed of the following components.
• The PREFIX clause is employed to declare a prefix with the objective of simplifying the use of URIs. The
declaration of the prefix is optional.
• The SELECT clause serves the purpose of specifying the variables returned by a query.
• The WHERE clause is utilized to match data in RDF graphs. The clause contains one or more triple patterns
that are employed to indicate the conditions of a query.
• The FILTER clause is designed to conditionally filter the results of a query. The clause can include boolean
expressions to limit the set of results matched by the WHERE clause.
The fundamental query types of SPARQL are as follows [101].
SELECT query is the most frequently used type of query, whose function is to select variables and return a
result set. A table is typically generated as the outcome of a SELECT query, which includes the variables that
meet the query’s criteria along with their corresponding values.
CONSTRUCT query is used to generate a new RDF graph by utilizing the query pattern. In contrast to
tabular results, the CONSTRUCT query produces an RDF graph that is constructed from the matching data of the
query pattern.
ASK query is designed to ascertain the existence of RDF data that satisfies the query pattern. The ASK query
provides a response in the form of a boolean value (true or false) to indicate the presence or absence of a match.
DESCRIBE query is employed to obtain the detailed description of resources. The description is determined
by the query engine and typically consists of triples that are directly related to the resource.
Each query type employs a WHERE clause to limit the scope of the query. Nevertheless, in the context of
DESCRIBE queries, the inclusion of a WHERE clause is not mandatory. To illustrate, the subsequent query
retrieves people from the data set who are above the age of 24:
PREFIX info: <http://somewhere/peopleInfo# >
SELECT ?resource
WHERE
{
?resource info:age ?age .
FILTER (?age >=24)
}
7
Table 2: Operators to query spatial data
Operator Signature Meaning
distance point |line|region ×point|line|region →real Compute the distance between two spa-
tial objects.
direction point ×point→real Compute the direction between two
points.
size line →real Return the length of a line.
area region →real Return the area of a region.
intersects line |region ×line|region →bool TRUE, if both arguments intersect.
intersection point |line|region ×point|line|region →T, where
T is point if point is one of the arguments, otherwise
T is the argument having the smaller dimensionIntersection of two spatial objects.
distancescan rtree ×relation ×object×int→stream Compute the integer knearest neigh-
bors for a query object.
In this query, the “ ?” symbol represents a variable, followed by the variable name. The middle of the “ <>”
symbol is the URI that describes the resource address. The “ info:age ” in the above query is a URI shorthand
and stands for “ <http://somewhere/peopleInfo #age>”. The FILTER keyword is employed to impose limitations
on the outcomes that are retrieved. In addition, RDF is semi-structured data, and different entities in RDF may
have distinct properties. SPARQL is capable of querying information that exists in RDF. However, when querying
information that does not exist, SPARQL does not show a failure and does not return any results. The OPTIONAL
keyword can then be used to signify that the query is optional, indicating that the query will return a result if the
entity has the attribute, and a null value otherwise. The FILTER keyword can also be used in conjunction with the
OPTIONAL keyword.
2.2.3 Query language for spatial data
The increasing reliance on geographic information systems in many aspects of people’s production and life has
led to a significant increase in the demand for spatial data query in all walks of life. The popularity of spatial
applications has brought great attention to spatial databases [55]. In databases, fundamental data types utilized for
the representation and manipulation of spatial objects include point, line, and region. The common operators to
query spatial data are shown in Table 2.
Mature systems for storing and managing spatial data include Esri’s ArcGIS, PostGIS, Google Earth Engine,
GRASS GIS, and SECONDO [56]. As an illustration, SECONDO is a freely available platform created for
the purpose of organizing and examining spatial and temporal data. The basic commands of SECONDO are as
follows.
query <value expression >.The command evaluates the given value expression and subsequently displays
the result to the user.
let<identifier >=<value expression >.The command initially evaluates the provided value expression in a
manner analogous to the preceding command. In contrast to the previous command, the results of the evaluation
are not immediately displayed but rather stored in an object named identifier . If the object already exists in the
database, the command will result in an error.
delete <identifier >.The command removes the object named identifier from the current database, and is
typically utilized in conjunction with the second command.
When an expert or system developer writes the executable query language for SECONDO, one needs to com-
prehensively understand the intricate relationship between data flow and operators. The rel2stream operator trans-
forms a relation into a stream of tuples, as shown in Figure 4. The stream2rel operator, in contrast, converts a
stream of tuples into a relation. Among the fundamental operators of SECONDO, the filter operator is the most
8
a stream of tuples
city (Name:String, GeoData:Region)Name GeoData
Nanjing
Zhenjiang
Yangzhou
(Nanjing,         ), (Zhenjiang,              ), (Y angzhou,         ), ...
rel2stream
stream2rel
a stream of tuplesfilter
Name = ""Nanjing""(Nanjing,        )
Figure 4: Functions of the operators rel2stream, stream2rel and filter in SECONDO
frequently utilized. Similar to the SELECT keyword in SQL, the function of the filter operator is to extract in-
formation from data that satisfies specific conditions. The SELECT keyword operates on a two-dimensional table
structure to query, filter, and project data by specifying columns and conditions. The filter operator works on a
stream of tuples, followed by a filter condition. The tuples that match the condition are then collected and out-
putted as a stream. For example, the following executable language will output all information about Nanjing in
the relation cityin SECONDO.
query city rel2stream filter [.Name = “Nanjing”] stream2rel;
During the execution of the query, the rel2stream operator first transforms the relation cityinto a stream of tuples,
then the filter operator extracts the tuple named “ Nanjing ” from the stream, and finally the stream2rel operator
converts the tuple into a relation from the stream.
2.3 Intermediate representation languages
The intermediate representation language in NLIDB is designed to accommodate the semantic discrepancies and
diversity between natural language and executable database language, thus improving the translation accuracy,
flexibility and maintainability of the system [7]. The intermediate representation serves as a translator between
natural language and executable language, mapping complex natural language structures to a unified semantic
representation for the purpose of efficient subsequent query processing and execution. By decoupling NLQ from
the underlying database query language, the intermediate representation language makes the NLIDB system flex-
ible, portable, and adaptable to various database types and query requirements. The design of the intermediate
representation considers several factors, such as:
(i) The intermediate representation should convey the query request that the user wishes to submit to the
database, rather than the full meaning of the user’s input.
(ii) To facilitate subsequent translation into the executable language of the database, the intermediate repre-
sentation should be unambiguous.
(iii) To make re-development easier, the intermediate representation should be reusable.
Popular intermediate representations are parse trees [78], first-order logic [121], OQL [113], query sketch
[153], SemQL [53], and NatSQL [50].
Parse tree. The syntactic structure of a query in natural language is closely tied to the design of a parse tree.
The tree structure is typically applied to represent the hierarchical and structural relationships of the query. Each
node in a parse tree indicates a grammatical unit (e.g., phrase, word group, and vocabulary), while edges indicate
grammatical relations (e.g., modification and conjunction) between these grammatical units. The nodes and edges
on the parse tree can be labeled with semantic information to identify the semantic roles and constraints present
in the query, providing important information for subsequent query processing.
First-order logic. When transforming an NLQ into f irst-o rder l ogic (FOL), words and phrases in the natural
language are first mapped to predicates, constants, variables, and logical connectives in FOL to represent entities,
9
attributes, and relations in the query. Subsequently, on the basis of the syntactic structure of the NLQ, the syntax
tree or syntax graph of the FOL representation is constructed to capture the semantic relations and logical struc-
tures in the query. Finally, the topics, conditions, and operations in the query are identified and converted into
logical expressions in FOL to denote the constraints and operational requirements of the query.
When converting the natural language query “ Find the names and salaries of all employees older than 30. ”
into a first-order logic representation, predicates and constants are defined as follows.
Employee (x):xis an employee
Name (x, n): the name of employee xisn
Age(x, a): the age of employee xisa
Salary (x, s): the salary of employee xiss
The query condition is expressed as ∀x(Employee (x)∧Age(x, a)∧a > 30). The query result is expressed
as∃n, s(Name (x, n)∧Salary (x, s)). The complete first-order logic representation is obtained by combining
the condition and result of the query.
∀x(Employee (x)∧Age(x, a)∧a > 30)∧ ∃n, s(Name (x, n)∧Salary (x, s))
OQL is built on an ontology knowledge graph, where words and phrases in natural language queries are
associated with concepts, attributes and relations within the ontology knowledge graph. The semantic information
of natural language queries is captured through semantic representations and query patterns to effectively interact
with the database. OQL grammars permit the expression of complex aggregation, union and nested queries. OQL
queries operate upon individual concepts, with each concept being assigned an alias as specified in the FROM
clause of the query.
Query sketch is a form of SQL with natural language hints. Taking the NLQ “ Find the number of papers in
OOPSLA 2010. ” as an example, the query sketch is as follows.
SELECT count(?[papers]) FROM ??[papers] WHERE ? = “OOPSLA 2010”;
In the query sketch, the symbols “ ??” and “ ?” represent an unspecified table and an unspecified column, respec-
tively. Hints for the corresponding gaps are indicated by words enclosed in square brackets. As an illustration, the
first hint in the sketch suggests that the symbol “ ?” has a similar semantic meaning to the term papers .
SemQL is designed as a tree structure that not only constrains the search space during synthesis, but also main-
tains the same structural characteristics as SQL. In SemQL queries, the GROUP BY , HA VING, and FROM clauses
in SQL are removed, and the conditions from the WHERE and HA VING clauses are consistently represented in
the Filter sub-tree. Furthermore, in the later inference phase, domain knowledge is utilized to deterministically
infer implementation details from SemQL queries. For instance, the columns included the GROUP BY clause of
SQL are typically present in the SELECT clause.
NatSQL retains the core functionality of SQL while streamlining the structure of SQL to align more closely
with the syntax of natural language. NatSQL keeps only the SELECT, WHERE, and FROM clauses, omitting
the JOIN ON, HA VING, and GROUP BY clauses. Additionally, NatSQL does not require nested sub-queries or
aggregation operators, and employs a single SELECT clause. In the case of the natural language query “ Which
film has more than 5 actors and less than 3 in the inventory? ”, the SQL and NatSQL are as follows.
SQL: SELECT T1.title FROM film AS T1 JOIN film actor AS T2 ON T1.film id = T2.film id GROUP BY
T1.film id HAVING count(*) >5 INTERSECT SELECT T1.title FROM film AS T1 JOIN inventory AS T2 ON
T1.film id = T2.film id GROUP BY T1.film id HAVING count(*) <3;
NatSQL: SELECT film.title WHERE count(film actor.*) >5 and count(inventory.*) <3;
10
Table 3: Natural language preprocessing for NLIDBs
NLIDB Year Underlying datatype
Segmentation
Part of speech
NER
Dictionary generation
Regular expression
Dependency parsing
Word Embedding
Pattern Linking
PRECISE [107] 2003 relational data ✓✓✓✓
Querix [69] 2006 ontology ✓✓ ✓
QuestIO [27] 2008 ontology ✓✓ ✓
gAnswer [60] 2013 RDF data ✓
MEANS [1] 2015 RDF data ✓ ✓
NL2CM [6, 5] 2015 RDF data ✓✓ ✓
NL2TRANQUYL [16] 2015 relational data ✓
ATHENA [113] 2016 relational data ✓✓✓ ✓
SQLizer [153] 2017 relational data ✓✓✓
TEQUILA [64] 2018 RDF data ✓✓✓
MyNLIDB [28] 2019 relational data ✓✓ ✓
IRNet [53] 2019 relational data ✓✓
NLMO [145] 2020 moving objects ✓✓✓✓✓
NALMO [144, 143] 2021 moving objects ✓✓✓✓✓
NALSD [88] 2023 spatial data ✓✓✓✓
NALSpatial [89] 2023 spatial data ✓✓✓✓
xDBTagger [132] 2024 relation data ✓✓ ✓✓
3 Generation of executable database languages
The generation of executable database languages can be divided into three stages: (i) natural language preprocess-
ing, (ii) natural language understanding , and (iii) natural language translation . In stage (i), the system performs a
preliminary analysis of the raw natural language query in order to prepare for the subsequent stage of natural lan-
guage understanding. In stage (ii), the system performs semantic parsing and understanding of the preprocessed
natural language query to extract the semantic details and intent of the query. In stage (iii), the system converts
the comprehended natural language into a language that can be executed within the database.
3.1 Natural language preprocessing
Prior to the semantic understanding and translation of natural language queries, preprocessing is performed using
traditional and data-driven methods. In order to preprocess natural language queries, the recently developed
NLIDBs utilize techniques as illustrated in Table 3.
The preprocessing process of many NLIDBs commences with the construction of a dedicated data dictionary
for the domain. The extraction process of domain knowledge exerts a profound influence on the portability of the
system. In addition, the semantic parsing component needs to accurately comprehend NLQ with the assistance
of the dictionary, and the extraction process of domain knowledge will impact the availability of the NLIDB. The
primary goal of the extraction technique is to minimize the burden on system users while enhancing the capacity
to automatically generate a dictionary. The extraction process is primarily reliant on stemming and synonym
techniques. The system then needs to perform word segmentation and part-of-speech tagging on the input natural
language. This process necessitates the utilization of natural language processing tools. When choosing the tool,
the high accuracy of the segmentation and part-of-speech tagging results should be considered first, followed
by the speed of processing. Furthermore, the query must be oriented to database information, and the relevant
11
Table 4: Rules for parsing natural language queries
Rules Typical NLIDBs
Parse tree PRECISE [107], NaLIX [84, 85], Querix [69], DaNaLIX [81], gAnswer [60],
NaLIR [78, 77, 79], NL2TRANQUYL [16], Unnamed method [65], MyNLIDB
[28]
Ontology QuestIO [27], ATHENA [113], FINESSE [63], Unnamed method [41], CNL-
RDF-Query [58], ATHENA++ [115], Unnamed method [4]
Semantic graph Unnamed method [168], MEANS [1], NL2CM [6, 5]
Template matching SQLizer [153], Unnamed method [3], LogicalBeam [11]
Pattern matching SODA [15]
Context-free grammar TR Discover [121]
Semantic grammar Unnamed method [49]
statements used in the query request are closely related to the database to be used. Therefore, part-of-speech
tagging is often employed in conjunction with named entity recognition and data dictionary.
Traditional preprocessing methods rely on predefined rules and grammars, involving techniques including
NER, regular expressions, and dependency parsing. NLMO performs segmentation and entity recognition using
a natural language processing toolkit spaCy, and sets regular expressions for temporal information extraction.
ATHENA utilizes the TIMEX annotator to detect all temporal intervals mentioned in the text, and the Stan-
ford Numeric Expressions annotator to pinpoint all tokens containing numerical values. ATHENA employs the
Stanford Dependency Parser to identify the dependency relationship in the context of the GROUP BY clause.
PRECISE utilizes the Charniak parser for the precise parsing of questions and the extraction of token relation-
ships from the resulting parse tree. NL2CM employs dependency parsing and part-of-speech tagging techniques.
NL2TRANQUYL analyzes the input natural language using the Stanford Parser, resulting in constituency and
dependency parses.
Data-driven preprocessing methods depend on large-scale data and machine learning models, and the tech-
niques used include word embedding and pattern linking. Word2Vec and GloVe are word embedding models
that are able to represent words as points in a sequential vector space, thereby capturing the semantic relation-
ships between words. These vectors can be employed for calculating semantic similarity and extracting features.
xDBTagger utilizes a pre-trained word embedding model to convert tokens into a 300-dimensional vector repre-
sentation. IRNet performs schema linking by connecting the natural language with the database schema, aiming
to identify the specific columns and tables referenced in the natural language. The columns are then assigned
different types according to the manner mentioned in the question.
3.2 Natural language understanding
Three principal technical approaches to understand natural language are (i) rule-based , (ii) machine learning-
based , and (iii) hybrid . Based on the techniques, the process of natural language understanding for the recently
developed NLIDBs is summarized. We provide three timelines describing the research on rule-based, machine
learning-based, and hybrid approaches, as shown in Figure 5.
3.2.1 Rule-based methods
The semantic parsing of mature NLIs is predominantly based on rules. The systems require specific rules to parse
natural language queries, including parse tree, ontology, semantic graph, template matching, pattern matching,
context-free grammar, and semantic grammar, as shown in Table 4. Rule-based systems can only deal with knowl-
edge bases in fixed domains and are generally not portable to other knowledge bases. In order to enhance the
accuracy of semantic understanding, systems are typically constrained by limitations in their ability to support
12
2014NaLIR
2015NL2CM
2016ATHENA
2017NLQ/A
2018TEQUILA
2020ATHENA++
2021EXAQTNL2TRANQUYL DialSQL SQLizer2003PRECISE
2005NaLIX
2007DaNaLIX
2006Querix
2009QUICK
(to be continued )
2019MyNLIDBezNL2SQL2008QuestIO
2013gAnswerTR DiscoverMEANS
SPARKLIS
NLMO(a) Rule-based methods
2020R Y ANSQL
2022Auto-Query
2021V alueNetSP-CNN
2017Seq2SQL
2019IRNet
2018SyntaxSQLNetCOMBINE
2023DTE
2024SV2-SQLIKnow-SQL SpatialNLI DialSQLBiBER T -SQLDBT aggerMIE
(b) Machine learning-based methods
2022V eezoo
2021NALMO
2018T ypeSQL
2023GAR
2024xDBT aggerCatSQLGENSQLNALSpatialNALSD
(c) Hybrid methods based on rule and machine learning
Figure 5: Timelines of the research progress of techniques for understanding natural language
natural language features, such as grammar and vocabulary [144]. PRECISE [107] elucidates the notion of se-
mantic tractability and delineates a specific subset of natural language that can be accurately converted into SQL.
However, natural language queries that cannot be processed semantically will be rejected by PRECISE. NaLIX
[84, 85] restricts natural language queries to a regulated subset according to a predetermined grammar. DaNaLIX
[81] is constructed on NaLIX and employs domain knowledge for query translation. Domain knowledge is en-
capsulated within a collection of regulations that map terms with domain meaning in the parse tree to terms that
can be understood by a generic system such as NaLIX. The domain adapter within DaNaLIX assesses the current
domain expertise and modifies the parse tree with related rules. NaLIR [78, 77, 79] identifies nodes within the
language parse tree that have the potential to correspond to SQL components resulting from the preprocessing
step, and represents semantic coverage as a subset of the parse tree. Such a tree explicitly corresponds to SQL
and serves as a query tree, which mediates between NLQ and SQL. To comprehend the challenge of integrating
individual and collective knowledge, NL2CM first uses RDF to represent individual and general knowledge. Indi-
vidual expression detectors are then used to distinguish between individual and general query components, which
are created through a declarative selection schema in conjunction with a specialized vocabulary. ATHENA uses
domain-specific ontology to transform the natural language input into an intermediate language on the ontology.
The intermediate language is then used to describe the semantic entities in the domain, as well as the relationships
between the entities. Ontology provides richer semantic information than relational schema, including inheritance
13
and membership. By reasoning about the ontology, ATHENA demonstrates the capability to effectively discern
and capture the intentions of users. However, ATHENA is highly sensitive to changes and interpretations of user
queries [99]. Both the NLIDB system described in the paper [116] and ATHENA++ [115] are extensions of
ATHENA. They combine linguistic analysis with deep domain reasoning to translate complex join and nested
SQL. NL2TRANQUYL [16] is a system designed for the planning of journeys within a complex multi-modal
transportation system, taking into account a number of constraints, including the minimization of journey time,
distance and cost. NL2TRANQUYL utilizes the ontology comprising a range of concepts to store and model re-
lated information, and generates knowledge graphs to determine the relationships between them. To discover and
process temporal information in NLQ, TEQUILA decomposes the detected temporal problems and rewrites the
generated sub-problems. These papers [60, 168] utilize the Stanford Parser to generate dependency trees and ex-
tract semantic relations from the parsed data. Subsequently, a semantic query graph is constructed by connecting
these semantic relations to depict the user’s query intent. Querix [69] examines the syntax of natural language us-
ing a syntactic analyzer, which is only effective when the natural language components are complete. Incomplete
components may result in inaccurate results, which could compromise the accuracy of the final results.
An optimal NLIDB enables users to formulate intricate queries on the database system and retrieve precise
information with minimal exertion. Consequently, a number of systems incorporate user interaction during the
process of comprehending semantics. NaLIX and DialSQL [54] adjust the query during following user engage-
ments to revise the parse tree, however, the revision frequently necessitates a high number of user interactions.
DaNaLIX acquires domain knowledge through the interaction that occurs between the user and the system in an
automated manner. In addition to elucidating the user on the query processing procedure, NaLIR also presents a
spectrum of interpretations for the user to select from, thus alleviating the user’s need to address potential misun-
derstandings. NaLIR is capable of detecting the parse tree, thereby enabling users to modify the parse tree directly,
rather than reformulating the natural language query. NaLIR can provide recommendations to users for revising
their queries in instances where the natural language queries fall beyond the semantic boundaries. QUICK [162]
improves user interactions by utilizing keyword search to enrich the expressiveness of semantic queries. In practi-
cal application, QUICK assists users in determining the specific intent behind natural language through a series of
iterative refinement steps following the initial submission of a keyword-based question. NLQ/A [166] enhances
the user interaction component in order to more effectively address the issue of ambiguity. SPARKLIS [46] em-
ploys a sequential process consisting of three stages in order to guarantee the thoroughness of user input during
searches for concepts, entities or modifiers. While interacting with the system may result in the user feeling con-
strained, slowed down, and less natural when entering a query, SPARKLIS provides guidance and safety through
intermediate answers and suggestions [2]. In order to reduce user involvement during the disambiguation process,
ATHENA utilizes the extensive semantic data within the ontology to produce a prioritized list of explanations,
and employs a ranking algorithm that is intuitive and relies on ontology metrics to determine the most appropriate
explanation.
3.2.2 Machine learning-based methods
As the usage of statistical learning methods continues to expand, there has been a growing interest in conducting
semantic analysis on sentences through a variety of forms of supervision. Pasupat and Liang [102] employ
question-and-answer format to provide guidance in responding to intricate natural language queries presented
within semi-structured tables. The paper [105] represents the inaugural attempt to develop a semantic parsing
model through unsupervised learning [66]. Artzi and Zettlemoyer [8] solicit feedback during the conversation to
determine the meaning of the user’s statements. In a domain where no training examples are available, Wang et al.
[146] demonstrate the successful development of a semantic parser. Their approach comprises two key elements:
(i)a builder and (ii) a domain-general grammar .Wong and Mooney [150] utilize statistical machine translation
technology for the purpose of accomplishing semantic parsing tasks.
14
Table 5: NLIDBs with encoder-decoder frameworks
NLIDB Year Encoder Decoder
DialSQL [54] 2018 Encode dialogue history using
RNN networksDecode errors and candidate se-
lections
SyntaxSQLNet [159] 2018 Table-aware column encoder Syntax tree-based decoder
Unnamed method [87] 2020 Encode NLQs and table headers
using XLNet [155]The parsing layer splices the vec-
tor
ValueNet [19] 2021 Extension of IRNet’s encoder LSTM architecture and multiple
pointer networks
Unnamed method [30] 2021 The encoder of LSTM The decoder of LSTM
MIE [138] 2021 Multi-integrated encoder with
three integrated modulesNo decoder
Auto-Query [100] 2022 The encoder of RATSQL [137] SmBoP [112]
STAMP [51] 2023 The encoder of T5 The decoder of T5
Unnamed method [154] 2023 The encoder of Transformer The decoder of Transformer
In recent times, there has been a growing utilization of encoder-decoder frameworks that rely on recurrent
neural networks for semantic parsing, as demonstrated in Table 5. Many systems combine machine learning and
deterministic algorithms to generate structured languages [93]. This method allows the direct acquisition of the
correlation between natural language and the semantic representation, eliminating the need for an intermediate
representation like a parse tree [66]. Mapping natural language directly to the semantic representation can reduce
the dependence of rule-based semantic parsing models on preset vocabulary, templates, and hand-generated fea-
tures. Machine learning-based models are not limited to specific knowledge bases or logical formal expressions,
thus enabling the implementation of natural language interfaces that support cross-knowledge bases or cross-
languages. Wang et al. [140, 142] propose a cross-domain NLI, which translates the marked natural language
into the intermediate representation of the target query type by building a cross-domain multilingual seq uence-
to-sequence (seq2seq) model. Symbols inserted into the natural language query are utilized to substitute the data
elements present in the intermediate query. However, this method is a supervised machine learning model whose
effectiveness is closely related to the quality of the training data. To ensure the accuracy of semantic understand-
ing, a substantial quantity of training data must be provided to the model. A number of researchers employ a
synthetic data generator as a solution to the challenge of having a restricted amount of training data available.
The paper [159] introduces SyntaxSQLNet, which can generate NLQ data sets for cross-domain SQL single-table
operations, solely as a means of augmenting the training set. The method outlined in the paper [149] encompasses
single-table and multi-table join queries of SQL, and can be utilized as either an augmentation or as a standalone
training data set. In terms of model training, the rule-based method is more effective than the neural network-
based method, which requires more training parameters and takes longer to establish the model, consuming more
memory space.
One of the earliest examples of machine learning-based systems is demonstrated in the paper [161]. This work
utilizes a deterministic shift-reduce parser and develops a learning algorithm called CHILL to learn the governing
rules of parsing on the basis of inductive logic programming techniques. The corpus is trained using the CHILL
method to build the parser. Instead of learning dictionaries, this approach assumes that a dictionary is created
in advance that pairs words with semantic content rather than grammar. The paper [163] translates the mean-
ing of natural language sentences into lambda calculus encoding. The paper [163] outlines a learning algorithm
whose input is a collection of sentences identified as lambda calculus expressions, and applies the method to the
task of learning NLIDB to build a parser. While providing considerable flexibility, encoder-decoder frameworks
frequently lack the ability to interpret and understand combinations of meaning [66]. The method employed by
Cheng et al. [25] involves the construction of the intermediate structure in two stages, which facilitates a com-
prehensive understanding of the model’s learning process. Similarly, the paper [39] also produces an intermediate
15
template that presents the final output in a preliminary format, thereby facilitating the subsequent decoding pro-
cess. Yin and Neubig [157] address the issue of insufficient training data by incorporating explicit constraints
for decoders through the utilization of target language syntax. The approach enables the model to concentrate
on parsing, directed by established grammar rules. Xiao et al. [151] utilize the grammar model as prior knowl-
edge, requiring the creation of a derivation tree while adhering to the constraints imposed by the grammar. The
approach in the paper [74] can significantly outperform the Seq2Tree model from the aforementioned paper [38]
by verifying that the decoder’s forecasts adhere to the type constraints outlined in the type constraint grammar.
This suggests that satisfying type constraints and good formatting are equally important when generating logical
expressions. SpatialNLI [80, 141] is a natural language interface for the spatial field that employs the seq2seq
model to understand the semantic structure of natural language, while utilizing an external spatial understanding
model to identify the meaning of spatial entities. Subsequently, the spatial semantics learned from the spatial
understanding model are integrated into natural language problems, thereby reducing the necessity of acquiring
specific spatial semantics. SpatialNLI represents a pioneering system that integrates an external spatial semantic
comprehension model to optimize the effectiveness of the principal seq2seq model. The paper [129] uses a tree
model to analyze the target entity in natural language, and employs a tree-structured LSTM to understand the
problem. The paper [62] adjusts the neural sequence model to directly convert natural language into SQL, thus
circumventing the intermediate query language representation. Then the user feedback is utilized to mark error
queries, which are directly used to improve the model. The complete feedback loop does not necessitate the use
of any intermediate language representation and is not limited to a specific domain. This method offers the benefit
of enabling the rapid and straightforward construction of a semantic parser from scratch, and the performance of
the parser improves as user feedback increases. The encoder of ValueNet [19] is an extension of the encoder of
IRNet [53], receiving not only details regarding the database schema, but also extracted value candidates from the
database content.
3.2.3 Hybrid methods based on rule and machine learning
Hybrid methods integrate rules and machine learning techniques to capitalize on the respective strengths of each,
thereby enhancing the ability of the system to understand and process NLQs [72]. Table 6 enumerates the rep-
resentative systems that employ the hybrid approach. Hybrid approaches are highly flexible and adaptable, as
they can utilize rules for tasks with explicit rules as well as machine learning models for complex and ambiguous
semantic tasks. In addition, hybrid methods can flexibly incorporate new rules or train new machine learning
models as needed to accommodate the requirements of diverse domains and tasks, and are highly scalable [135].
TypeSQL [158], like SQLNet [152], is built on sketches and formats translation tasks as slot-filling problems.
The difference is that TypeSQL employs type information to enhance the understanding of entities and numbers
in NLQs. TypeSQL assigns a type to each word, such as entity, column, number and date, within the knowledge
graph. Subsequently, two bidirectional LSTM networks are utilized to encode the words in the NLQ with the
corresponding column names and types. Finally, the LSTM output hidden states are leveraged to forecast the
slot values within the SQL sketch. NALMO is a natural language interface for moving objects. To understand
NLQs, NALMO employs an entity extraction algorithm to obtain entity information, including time, location and
the number of nearest neighbors. A pre-constructed corpus is then trained using LSTM to determine the query
type. Veezoo [75] uses a range of techniques, including temporal expression parsing, entity linking, and relation
extraction, to identify key information in NLQs. The information is then extended and combined using predefined
rules to generate multiple candidate intermediate representations. Finally, Veezoo utilizes a machine learning
model to score these intermediate representations in order to select the most probable interpretation of the NLQ.
The process of data preparation in GAR [42] commences with a collection of sample SQLs that are tailored to a
specific database. For a given NLQ, GAR searches for the NLQs generated during data preparation and employs
a learning-to-rank model to identify the most relevant query, which is then used to obtain the translation result.
16
Table 6: NLIDBs based on rules and machine learning techniques
NLIDB Year Rule Machine learning technique
Unnamed method
[52]2012 Generate candidate SQLs via rules and
heuristic weighting schemesReorder candidate SQLs using the SVM
sorter
TypeSQL [158] 2018 Assign a type to each word to under-
stand the entityEncode using bidirectional LSTM
NALMO
[144, 143]2021 Semantic grammar and template
matchingIdentify the query type using LSTM
Veezoo [75] 2022 Knowledge graph Score intermediate representations using
machine learning models
GAR [42] 2023 Parse tree Find the matching expression for NLQ
using a learn-to-rank model
GENSQL [44] 2023 Capture the structure of the database
with sample SQLsFind the matching expression for NLQ
using a learn-to-rank model
CatSQL [48] 2023 Template matching The decoder of Transformer. Train the
model using Adam [71]
NALSpatial [89] 2023 Semantic grammar and template
matchingIdentify the query type using LSTM
NALSD [88] 2023 Semantic grammar and template
matchingIdentify the query type using LSTM
xDBTagger [132] 2024 Semantic graph Bidirectional recurrent neural network
The learning-to-rank model learns to rank the semantic similarities from NLQs to generated NLQs and then finds
the best matching expression for a given NLQ. GENSQL [44], a generative NLIDB, utilizes a given example SQL
from the database (e.g., from query logs) to comprehend the unique structure and semantics of a given database,
thereby guaranteeing precise translation outcomes. The fundamental model used in GENSQL for converting nat-
ural language to SQL is GAR. CatSQL [48] is a method for the generation of SQL that makes use of sketches. In
addition, semantic constraints are merged into the neural network-driven SQL generation procedure for semantic
refinement. CatSQL sketches are templates with keywords and slots. CatSQL employs a deep learning algorithm
to populate vacant slots in order to generate the ultimate SQL. The deep learning algorithm is developed to focus
on the generation of essential NLQ-related information, with the objective of filling the gaps without requiring the
explicit generation of keywords like SELECT, FROM, and WHERE.
Hybrid approaches based on rules and machine learning offer several advantages, including flexibility, accu-
racy, and scalability. Nevertheless, such approaches present certain challenges, such as complexity, dependence
on data, and tuning difficulties [68]. Hybrid methods require the simultaneous management and maintenance of
rule engines and machine learning models, including rule definition, feature engineering, and model training, and
thus have high complexity [52]. Furthermore, the rules and machine learning models utilized in hybrid approaches
may encounter parameter tuning problems, which necessitate a significant investment of time and effort for opti-
mization and debugging, thus increasing the costs associated with the development and maintenance of the system.
During the design and implementation of natural language interfaces, it is essential to take a comprehensive view
of the advantages and challenges involved, and to make trade-offs and choices in accordance with the specific
needs.
3.3 Natural language translation
The natural language translation stage employs the semantic information derived from the natural language un-
derstanding stage, subsequently integrating the underlying structure of the database to transform the input natural
language into the corresponding executable language. A prevalent approach for translation is to employ com-
plex algorithms and machine learning models to generate structured language based on the domain knowledge
of the underlying database and the semantic representation of natural language [83]. Most established NLIDBs
17
Parsed NLQ
Number of  
query relations
Database elements Database elementsJoin conditions and  
involved relations
SELECT , FROM, WHERE SELECT , FROM, WHERE WHERE, FROM
SQL1 >1Figure 6: General build process for SQL
construct queries by query combination, mapping key information expressed in natural languages to correspond-
ing components in structured languages. We examine the process of natural language translation in recently
developed NLIDBs, and summarize the general construction process of executable languages for relational and
spatio-temporal databases.
The general build process for SQL is illustrated in Figure 6 and further elaborated in the subsequent two cases.
(i) When querying a single relation, it is only necessary to place the database elements matched by NLQ in the
correct positions in the SELECT, FROM, and WHERE parts, respectively. Then, SQL can be composed directly.
(ii) When querying multiple relations, the join condition and the names of the participating relations need to
be included in the WHERE and FROM clauses, respectively. Additionally, it is necessary to determine whether
the join path is unique. If only one join path is available, SQL can be generated directly. Otherwise, a query
is typically generated for each possible join path, and then the most probable one is selected according to the
corresponding algorithm.
In recent years, there has been significant interest in NLI for spatio-temporal databases [26]. Temporal and
spatial concepts are derived from the natural language description using symbolic representations in order to depict
spatio-temporal features and their relationships [14, 106]. Due to the particularity and expressiveness of spatio-
temporal problems, executable query languages over spatio-temporal databases are quite different from SQL.
Consequently, the method employed for the construction of SQL cannot be directly applied to the generation of
executable languages over spatio-temporal databases. The general process for the construction of an executable
language for a spatio-temporal database is shown in Figure 7. Preliminary parsing of the input natural language
query is performed to obtain semantic information including key entities and query types. Subsequently, the
operators necessary to construct the executable language are determined according to the type of query. Finally,
key entities and operators are combined according to certain rules to compose an executable database language.
Taking the range query over spatial data as an example, the key entities involved include spatial relations and
locations. The operator intersects will return all objects in the relation that intersect the location if the spatial
attribute of the relation and the data type of the location are both lineorregion . Conversely, the operator intersects
will return all objects in the relation that lie within the location if the spatial attribute of the relation is point and
the data type of the location is region .
Different DBMSs and structured languages offer a range of clauses and operators for various queries. ATHENA
employs a mapping strategy that correlates the ontology with the database schema in order to convert the interme-
diate query language utilized in the ontology into SQL. The system described in the paper [63] extends ATHENA
to access multiple structured backends, which is achieved through the automated translation of the intermediate
18
Parsed NLQKey semantic  
information
Query typeKey e ntities
OperatorQuery  
combinationExecutable languageMapping rulesFigure 7: General construction process for executable languages over spatio-temporal data
query language into the specific structured query language utilized by these backend stores. NLPQC [124] is
capable of processing queries formulated using predefined domain-specific templates. Querix selectively isolates
specific elements from the syntactic tree in order to align acquired knowledge with the knowledge base, thereby
obtaining the final outcome. NL2CM leverages crowd intelligence by converting audience queries into OASSIS-
QL (an extended version of SPARQL). NaLIR utilizes the structure of the user-validated query tree to produce
the suitable structure in the SQL statement and determine the join path. In order to ascertain whether the target
SQL contains aggregate functions or sub-queries, NaLIR initially identifies function nodes or quantifier nodes
in the query tree and subsequently generates SQL statements based on the identified conditions. The paper [52]
employs lexical dependencies found in the question and database metadata to build a reasonable collection of
SELECT, WHERE, and FROM clauses that enhance the quality of meaningful joins. The paper [52] combines
clauses through a rule and heuristic weighting scheme, and then generates a sorted list of candidate SQLs, demon-
strating that full semantic interpretation can be avoided by relying on a simple SQL generator. This method can
be employed iteratively to address intricate issues necessitating nested SELECT commands. Finally, this paper
[52] applies the re-ranker to reorder the list of questions and SQL candidate pairs with the aim of enhancing the
accuracy of the system. TEQUILA uses a standard KB-QA system to evaluate the sub-questions from the se-
mantic understanding part individually. The results of the sub-questions are then combined with the reasoning
to calculate the answer to the full question. NL2TRANQUYL translates English requests into formal TRAN-
QUYL [17] queries using the knowledge graph generated by the semantic comprehension component. The traffic
query language TRANQUYL for travel planning follows the conventional SQL structure of “ SELECT, FROM,
WHERE ”. NALMO supports five distinct types of moving object queries, including (i) time interval queries , (ii)
range queries , (iii) nearest neighbor queries , (iv) trajectory similarity queries , and (v) join queries . In the query
translation process, NALMO first constructs a corpus comprising the five query types, collectively referred to as
MOQ. Then the LSTM neural network is used for training, resulting in a model that is capable of accurately iden-
tifying the specific type of query. Finally, the appropriate operators are selected according to the query type, and
the entity information extracted by the semantic parsing component is combined to build the executable language
for SECONDO.
4 NL2SQL benchmarks
We presents 11 frequently used benchmarks for transforming NLQ into SQL and three evaluation metrics, explor-
ing the methods for generating new benchmarks.
4.1 Existing benchmarks
The details of NLQ and executable language pairs for common domains are presented in Table 7. The majority
of existing benchmarks are utilized in the domain of relational databases to transform n atural l anguage query into
SQL (NL2SQL). The comparison of fields and types of SQL supported by the benchmarks for NL2SQL is shown
in Table 8. We can conclude that GeoQuery and Spider support the most types of SQL, while WikiSQL supports
19
Table 7: Examples of NLQ and executable language pairs for common domains
Domain Examples of NLQ and executable language pairs
Relational databaseNLQ: How many CFL teams are from York College?
SQL:
SELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”
Spatial domainNLQ1: What is the population of San Antonio?
Lambda expression:
answer(A,population(B,A),const(B,cityid(San Antonio)))
NLQ2: Could you tell me what parks are in the center?
Executable language:
query park feed filter [.GeoData ininterior center] consume;
Moving ObjectsNLQ: Where did the train 7 go at 8am?
Executable language:
query Trains feed filter [.Id = 7] filter [.Trip present [const instant value “2020-11-
20-8:00”]] extend [Pos: val (.Trip atinstant [const instant value “2020-11-20-8:00”])]
project [Id, Line, Pos] consume;
Trip planningNLQ: Can I walk to 300 W. Humboldt Blvd. by 4:00 p.m.?
TRANQUYL:
SELECT ∗FROM ALL TRIPS(user.current location, 300 W. Humboldt Blvd.) AS t
WITH MODES pedestrian WITH CERTAINTY .78 WHERE ENDS(t) ≤4:00 p.m.
MINIMIZE DURATION(t)
Crowd miningNLQ: What are the most interesting places near Forest Hotel, Buffalo, we should visit
in the fall?
OASSIS-QL:
SELECT V ARIABLES $x WHERE {$x instanceOf Place. $x near For-
estHotel, Buffalo, NY}SATISFYING {$x hasLabel “interesting” }ORDER BY
DESC(SUPPORT) LIMIT 5 AND {[] visit $x. [] in Fall }WITH SUPPORT
THRESHOLD = 0.1
only the simple select query. The queries in WikiSQL and Spider cover a multitude of domains. In recent years,
GeoQuery, MAS, WikiSQL and Spider have been employed with considerable frequency.
The details of popular benchmarks are shown in Table 9. Early data sets consist of only one domain and one
database, such as ATIS, Restaurant and GeoQuery. In contrast, the latest data sets, for example WikiSQL and
Spider, contain multiple domains and several databases with larger and more diverse NLQs and SQLs.
(i)ATIS (Airline T ravel I nformation S ystem) [108] is a classical data set with a relatively old age, having
been introduced by Texas Instruments in 1990. ATIS is built on the relational database Official Airline Guide,
comprising 25 tables and 5871 queries written in English. The queries pertain to details regarding flights, ticket
prices, destinations, and services available at airports. The queries in ATIS are for the air travel field, including
join queries and nested queries, but no grouping and sorting queries. The average length of NLQs and SQLs
in ATIS is approximately 11 and 67 words, respectively. Each query operates on an average of six tables. An
example query is as follows.
Q1:What aircraft is used on delta flight 1984 from Kansas city to Salt Lake city?
(ii)Restaurant [127] comprises a vast collection of dining establishments located in Northern California,
storing restaurant names, locations, features, and travel guide ratings. The benchmark contains 250 questions
about restaurants, food types and locations. An example query is as follows.
Q2:Where is a good Chinese restaurant in Palo Alto?
(iii)GeoQuery [128] consists of 8 tables and 880 natural language queries in the US geographic database. The
queries in GeoQuery are designed for the geographic domain, including join queries, nested queries, grouping
20
Table 8: Comparison of benchmarks for NL2SQL
Benchmark
Select query
Group query
Sort query
Join query
Nested queryFields involved Usage in papers
ATIS ✓ ✓✓ air travel [62, 47, 103, 104, 120]
Restaurant ✓ ✓ restaurant [127, 107, 81, 80]
GeoQuery ✓✓✓✓✓ geography [127, 128, 107, 163, 81, 52,
113, 62, 47, 80, 104, 115,
120, 42, 141]
MAS ✓✓ ✓ academic [77, 113, 153, 35, 9, 115, 131,
132]
Scholar ✓ ✓ academic [47]
IMDB ✓ ✓ internet movie [153, 9, 58, 131, 132]
YELP ✓ ✓ business review [153, 9, 131, 132]
WikiSQL ✓ multiple fields (e.g. state,
college, manufacturer)[167, 54, 158, 156, 87, 142,
48, 51, 125]
ParaphraseBench ✓✓ medical [133]
Advising ✓ ✓✓ university course [47]
Spider ✓✓✓✓✓ 138 different fields (e.g.
car, stadium, country)[160, 53, 156, 115, 19, 50, 92,
131, 42, 43, 48, 51, 125]
Table 9: Details of popular benchmarks
Benchmark Year #queries #tables Domains covered
ATIS [108] 1990 5871 25 single field
Restaurant [127] 2000 250 3 single field
GeoQuery [128] 2001 880 7 single field
MAS [77] 2014 196 17 single field
Scholar [62] 2017 816 10 single field
IMDB [153] 2017 131 16 single field
YELP [153] 2017 128 7 single field
WikiSQL [167] 2017 80654 24241 multiple fields
ParaphraseBench [133] 2018 290 1 single field
Advising [47] 2018 4387 15 single field
Spider [160] 2018 10181 1020 multiple fields
queries and sorting queries. The average length of NLQs and SQLs in GeoQuery is about 8 and 16 words,
respectively. Additionally, each query operates on an average of one table. Although the queries are relatively
brief in length, they are highly composable, with nearly half of the SQL containing at least one nested sub-query.
One of the English queries is as follows.
Q3:What is the largest city in states that border California?
(iv)MAS [77] is generated from the Microsoft Academic Search database, which stores information such as
academic papers, authors, journals, and conferences. The source of NLQs in MAS is the logical queries that are
capable of being articulated in the search interface of the Microsoft Academic Search platform. The fields of MAS
and Scholar are both academic in nature, but exhibit distinct patterns. One English query is as follows.
Q4:Return authors who have more papers than Bob in VLDB after 2000.
(v)Scholar [62] consists of 816 NLQs for academic database search that are annotated with SQL. The average
length of NLQs and SQLs in Scholar is approximately 7 and 29 words, respectively. Each query operates on an
21
Table 10: Query categories and examples for ParaphraseBench
Category Example queries
Naive What is the average length of stay of patients where age is 80?
Syntactic Where age is 80, what is the average length of stay of patients?
Morphological What is the averaged length of stay of patients where age equaled 80?
Lexical What is the mean length of stay of patients where age is 80 years?
Semantic What is the average length of stay of patients older than 80?
Missing Information What is the average stay of patients who are 80?
average of 3 tables. Iyer et al. [62] provide a database for performing these queries, which includes academic
articles, journal details, author information, keywords, citations, and utilized datasets. One of the English queries
is as follows.
Q5:Get all author having data set as DATASET TYPE.
(vi)IMDB and YELP [153] are generated using data from the Internet Movie Database and Business Review
Database, respectively. The NLQs are obtained from coworkers of the authors of the paper [153], who are only
aware of the types of data available in the database and not the underlying database schema.
(vii) WikiSQL [167], introduced in 2017, is a comprehensive and meticulously annotated collection of natural
language to SQL mappings, and currently represents the most extensive data set for NL2SQL. WikiSQL contains
SQL table instances extracted from 24241 HTML tables on Wikipedia, and 80654 natural language queries, each
accompanied by an SQL. WikiSQL comprises genuine data extracted from the web, with queries involving a
multitude of tables, but the queries do not involve complex operations such as GROUP BY and multi-table union
queries. The majority of questions in WikiSQL are between 8 and 15 words in length, most SQLs are between
8 and 11 words, and most table columns are between 5 and 7. In addition, most natural language queries are of
thewhat type, followed by which ,name ,how many ,who. The execution accuracy of WikiSQL has significantly
improved from the initial 59.4% to 93.0%, and the method has undergone a transformation from a simple seq2seq
approach to a multi-tasking, transfer learning, and pre-training paradigm. A pair of questions and SQLs for the
CFLDraft table can be formulated as follows.
Q6:How many CFL teams are from York College?
SQL Q6:SELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”
(viii) ParaphraseBench [133], a component of the DBPal paper [10], is a benchmark utilized to assess the
robustness of NLIDBs. Unlike existing benchmarks, ParaphraseBench covers diverse language variants of user
input NLQs and maps natural language to the anticipated SQL output. The benchmark is constructed upon a
medical database that contains a single table for storing patient information. The language variants utilized in
NLQs permit the classification of NLQs into six categories, as illustrated in Table 10.
(ix)Advising [47] was proposed in 2018, and the NLQs were built on a database of course information from
the University of Michigan containing fictitious student profiles. A portion of the queries are collected from the
Facebook platform of the EECS department, and the remaining questions are formulated by computer science
students well-versed in database topics that might be raised in academic consulting appointments. The queries in
Advising are for student-advising tasks, including join queries and nested queries. One of the English queries is
as follows.
Q7:For next semester, who is teaching EECS 123?
(x)Spider [160] is a large NL2SQL data set introduced by Yale University in 2018, in order to solve the
requirement for extensive and high-caliber datasets for a novel intricate cross-domain semantic parsing challenge.
22
The data set contains 10181 natural language queries and 5693 corresponding complex SQLs, which are dis-
tributed across 200 independent databases, and the content covers 138 different domains. The average length of
questions and SQL statements in Spider is approximately 13 and 21 words, respectively. While the number of
questions and SQLs in Spider is not as extensive as that of WikiSQL, Spider contains all common SQL patterns
and complex SQL usages, including advanced operations like HA VING, GROUP BY , ORDER BY , table joins,
and nested queries, which makes Spider closely aligned with real-world scenarios. The following is an illustra-
tive example of a complex problem and the corresponding SQL, which contains a nested query, a GROUP BY
component, and multiple table joins.
Q8:What are the name and budget of the departments with average instructor salary greater than the overall
average?
SQL Q8:SELECT T2.name, T2.budget FROM instructor as T1 JOIN department as T2 ON T1.department id =
T2.id GROUP BY T1.department id HAVING avg (T1.salary) >(SELECT avg (salary) FROM instructor)
4.2 Generation of new benchmarks
Modifying an existing NL2SQL benchmark to generate a new one is a common practice. The following steps
describe the process in detail.
(i) Researchers are required to conduct a meticulous analysis of the existing benchmarks, including an exam-
ination of the data structures, query types, and complexity. Through the analysis, they can gain insight into the
constraints of the benchmark and identify potential avenues for enhancement.
(ii) Designing a modification strategy is a critical step, which involves determining how to modify and extend
the benchmark on the basis of the analysis results. The step may include adding new queries, changing the
linguistic expression of queries, and introducing complex query types.
(iii) In the process of implementing modifications, researchers are expected to execute the designed modifica-
tion strategy with precision in order to ensure that the new benchmark meets the expected requirements.
(iv) Evaluating the performance is a pivotal aspect of the process. The researchers employ the modified
benchmark to train and test NL2SQL models, subsequently assessing the models’ performance and generalization
capabilities according to the new benchmark.
Building on Spider [160], Kaoshik et al. [67] propose a new NL2SQL benchmark, named ACL-SQL, contain-
ing five tables and 3100 pairs of NLQ and SQL. By defining and annotating three types of questions on temporal
aspects in Spider: (i) questions querying for temporal information , (ii) questions querying for temporal infor-
mation with grouping or ordering , and (iii) questions with temporal conditions ,Vo et al. [136] propose a new
data set, TempQ4NLIDB, which can assist NLIDB systems based on machine learning approaches to improve
their performance on temporal aspects. To address the dearth of publicly available benchmarks on ambiguous
queries, Bhaskar et al. [11] generate a new benchmark called AmbiQT by modifying Spider with a combination
of synonym generation and ChatGPT-based and standard rules-based perturbation. AmbiQT comprises in excess
of 3000 examples, each of which can be interpreted as two valid SQLs due to lexical ambiguities (namely, unam-
biguous column and table names) or structural ambiguities (namely, the necessity of joins and the pre-computation
of aggregations).
In light of the limitations of existing benchmarks, including (i) the presence of data bias or linguistic ex-
pression limitations , and (ii) the limited coverage of domains and contexts that cannot fully represent real-world
diversity , researchers have proposed generators for Text2SQL benchmarks. Weir et al. [149] present a synthesized
data generator that synthesizes SQL patterns in the template syntax, including aggregations, simple nesting, and
column joins. Each SQL pattern is matched with numerous different n atural l anguage (NL) patterns, allowing
for the generation of a vast number of domain-specific NLQs and SQLs. Luo et al. [90] propose an NL2VIS
synthesizer, named NL2SQL-to-NL2VIS, which is capable of generating multiple pairs of natural language and
VIS from a single NL and SQL pair based on semantic joins between SQL and VIS queries. NL2SQL-to-NL2VIS
23
can be utilized to create NL2VIS benchmarks from established NL2SQL benchmarks. Hu et al. [59] suggest
a framework for synthesizing Text2SQL benchmarks. The framework involves first synthesizing SQL and then
generating NLQs. At the stage of synthesizing SQL, a method is suggested for column sampling based on pattern
distance weighting to prevent excessive complexity in concatenation. In the process of generating text from SQL,
an intermediate representation is used to facilitate the transition from SQL to NLQ, thereby enhancing the quality
of the generated NLQ.
4.3 Evaluation metrics
NLIDB is intended to assist users in efficiently querying and retrieving query results, and thus evaluating the
response time and effectiveness of the system is essential. Response time measures how quickly the system can
process a user’s natural language queries and return the relevant results. Effectiveness measures how well the
system translates natural languages into accurate and relevant executable database languages, which consists of
two measures: (i) translatability and (ii) translation precision .
DEFINITION 1 (Translatability ).Given the set Eof executable languages generated by the system and the set
Nof input natural language queries, the translatability Tis defined as follows.
T=|E|
|N|
DEFINITION 2 (Translation precision ).Given the set ER of executable languages that meet the expected
results, the set Nof natural language queries entered into the system, the translation precision TPis defined as
follows.
TP=|ER|
|N|
Response time denotes the duration necessary for the system to transform the input natural language into the
executable language of the database. This temporal interval represents the difference between the moment when
the system furnishes the translated output and the moment when the natural language is received. Translatability
is a measure of the likelihood of the system accurately translating a natural language into an executable language.
This metric is quantified as the proportion of correctly translated queries out of the total number of queries sub-
mitted to the system. Translation precision refers to the likelihood that the final output of the translated executable
language matches the expected outcome, and is quantified as the ratio of executable languages producing the
desired results to the overall number of queries.
The outcomes of evaluating a system may be different depending on the benchmark used. The size of the
benchmark affects the accuracy of the semantic parsing part of the system. Complex queries in the benchmark can
be used to assess the system’s ability for generalization. In related papers, PRECISE achieves 95.0% translatabil-
ity and translation precision on the Restaurant benchmark and 77.5% on the GeoQuery benchmark. ATHENA has
a translatability and translation precision of 87.2% on the GeoQuery benchmark and 88.3% on the MAS bench-
mark. The translatability and translation precision of NALMO on the benchmark MOQ are 98.1% and 88.1%,
respectively.
5 System interfaces development
We categorize recently developed NLIDBs according to the technical approach and the data stored in the backend.
The methods of developing and using the system interfaces are then divided into two categories for analysis and
summary:(i) used as an independent software and (ii) used as a module of a database management system . Finally,
enhancements to the existing NLIDB system are presented in three aspects.
24
5.1 Recently developed NLIDBs
We are concerned with the NLIDBs, which have emerged since 2000. There are several ways to classify NLIDBs.
Affolter et al. [2] divide recently developed systems into four categories.
(i)Keyword-based systems are represented by SODA [15]. The core of such a system lies in the search
process, where the inverted index containing fundamental data and metadata from the database is utilized as the
retrieval target. This process involves comparison with natural language, and identification of keywords referenced
in the query. Although simple, the approach fails to identify the potential semantics that are not directly present
in natural language. Such systems are unable to respond to aggregation queries and complex questions involving
sub-queries.
(ii)Pattern-based systems , exemplified by NLQ/A [166] and QuestIO [27], are extensions of keyword-based
systems that are capable of incorporating natural language patterns and mapping to pre-specified query sentence
patterns.
(iii)Parsing-based systems are typified by NaLIR, a general interactive natural language interface designed
for querying relational databases. NaLIR employs the existing natural language parser to acquire the semantic
understanding of the given NLQ which is represented by a parse tree, and then converts the semantic understand-
ing into database understanding and finally into SQL. Such systems incorporate a multitude of natural language
processing methods, including the parsing of natural language sentences employing parse trees. One principal
benefit of this method is the ability to map semantics into predefined SQL templates.
(iv)Grammar-based systems are represented by TR Discover [121] and MEANS [1]. The foundation of such
systems consists of a predetermined set of grammar rules, which are used to constrain the questions that users can
pose to the system in order to form formal NLQs that are straightforward to analyze. The primary advantage of
this approach is that the systems are capable of providing users with guidance as they enter questions, and can
respond to all questions that adhere to the established rules. In comparison to keyword-based, pattern-based and
parsing-based systems, grammar-based systems are considered to be the most robust, despite relying significantly
on predefined manual rules.
In this survey, we categorize NLIDBs into seven distinct groups according to the data stored in the backend.
The representative systems for each category are depicted in Figure 8. Among the various categories, natural
language interfaces for relational data are the most prevalent and functional, and are subjected to ongoing research
on an annual basis. Recently, research on NLIs for XML data has not advanced, remaining at the same stage as
in 2007. The two main reasons are (i) an increasing preference for JSON as a format for data exchange over
XML , and (ii) the suitability of NoSQL databases for handling unstructured or semi-structured data over XML
databases . Since 2013, NLIs for natural language queries over RDF data, ontology data, graph data, spatial data,
and spatio-temporal data have been developed. The executable languages transformed by these NLIs correspond
to the databases used.
NLIDB for relational data transforms natural language queries into SQL. IRNet [53] first identifies the entities
contained in the NLQ, including columns, tables and values. Subsequently, a neural model based on syntax is
used to synthesize an intermediate representation connecting natural language with SQL. Finally, IRNet derives
SQLs on the basis of intermediate representations. Representative NLIDBs for XML databases are NaLIX [85]
and DaNaLIX [81], which transform natural language queries into XQuery. NaLIX restricts natural language to a
predefined subset of the grammar. DaNaLIX builds upon NaLIX and enables users to leverage domain knowledge
for query transformation. TEQUILA [64] is a typical NLIDB for RDF data, which transforms natural language
queries into SPARQL. TEQUILA employs a standard knowledge-based question and answer system to evaluate
sub-questions independently. The results of the sub-questions are then combined for inference to compute the
answer to the full question. QuestIO [27] works for querying structured data represented in ontology format.
Built on the ontology and a knowledge base containing instances of the ontology’s concepts, QuestIO accepts
NLQ as input and produces SeRQL as output. Utilizing the language processing framework GATE, QuestIO
25
CHILL, BIN-CA T, PRECISE, SODA,  
NLProv , ATHENA, SQLizer , Seq2SQL, NLProveNAns,  
DialSQL, SyntaxSQLNet, T ypeSQL, TEMPLAR, MyNLIDB, IRNet,  
MISP-SQL, GLAMORISE,                                          A THENA++, DBPal,
BiBER T-SQL, ezNL2SQL,                                         ValueNet, COMBINE,  
DBT agger , MIE, V eezoo, Auto-Query , ApproxEDA, LogicalBeam,  
GAR, GENSQL, IKnow-SQL, CatSQL, ST AMP , 
   SV2-SQL, xDBT agger , NaLIRRelational data
gAnswerMEANS
NL2CM
TEQUILAEXAQTRDF dataSpatialNLI
SP-CNNNALSpatial
NALSDNeuroSPE
Spatial dataNL2TRANQUYL NLMO NALMO
Spatio-temporal data
NaLIX
DaNaLIX
XML dataQuerix
QuestIOCNL-RDF-Query
Ontology data
Graph dataTR Discover FINESSEFigure 8: Classification of NLIDBs based on data stored in the backend
combines fundamental concepts with keywords, blocks and phrases to deduce potential relationships among the
concepts in the ontology. In the spatio-temporal domain, NLIDB can handle GIS-related queries, such as historical
meteorological data at a specific location, and geographic position information at different moments. NeuroSPE
[109] is a spatial extraction model designed to identify spatial relations within Chinese natural language text. The
model extends a bidirectional gated recurrent neural network with a series of pre-trained models and is able to
address specific challenges in a variety of natural language text, including the absence of direct context and the
occurrence of abbreviations, special languages, and symbols. NALMO [144, 143] is a natural language interface
designed for moving objects that allows users to submit queries of five types, including (i) time interval queries ,
(ii)range queries , (iii) nearest neighbor queries , (iv) trajectory similarity queries , and (v) join queries .
Several systems have been created that can be used across various back-end data stores, with the objective of
enhancing the generality of NLIDB. TR Discover [121] is one such system which transforms NLQ into SPARQL
or SQL. TR Discover generates FOL representations by analyzing natural language using a feature-based context-
independent grammar consisting of entries in the vocabulary for leaf nodes and rules governing the phrase structure
for non-terminal nodes. The FOL representation is then parsed into a parse tree through the utilization of a first-
order logic parser. The parse tree is traversed sequentially and transformed into SPARQL or SQL. FINESSE
[63], an extension to ATHENA, is a system that seamlessly connects to multiple structured data stores. FINESSE
can access various structured backends (e.g., RDF stores and Graph stores) by automatically transforming the
intermediate query language OQL into the corresponding structured query language specific to the backends (e.g.,
SPARQL and Gremlin).
5.2 Development and usage of system interfaces
The combination of the aforementioned three components, including (i) natural language preprocessing , (ii) nat-
ural language understanding and (iii) natural language translation , constitutes a comprehensive system architec-
ture. Then the theoretical knowledge is implemented in the form of a system. There are two primary methods of
development and usage:
(i) A stand-alone software. In this scenario, the system generally comprises a separate visual interface and a
database, and the architecture is shown in Figure 9(a). A visual interface allows users to write natural language
26
Natural Language
Interface
DBMSUser  (a) A stand-alone software
User  
Natural Language
InterfaceQuery Processor  
DBMS (b) A plug-in for DBMS
Figure 9: The architecture of the database system with NLI
problems that are interactively translated into executable language. By submitting the executable language in
the corresponding database management system, the query results can be obtained. The paper [78] presents
the JavaScript-driven interface of NaLIR, which interacts with a master server implemented in Java. NL2CM
is implemented in Java 7, whose web user interface is constructed in PHP 5.3 and jQuery 1.x. The paper [62]
develops a web interface designed to receive NLQs from users directed towards academic databases and display
translated SQLs. The interface also shows several example utterances to assist users in comprehending the domain.
The tool that comes with the NLMO system is a web application written in Java.
(ii) A plug-in for the database management system. In this instance, the system exists in a format analogous
to a Python custom module and interacts with the user through the visual interface of the database management
system. The system architecture is illustrated in Figure 9(b). The user inputs NLQ by invoking the interface
provided by the system. Thereafter, the database management system automatically calls the NLI module to
process the NLQ, and displays the translated executable language on the visual interface. One of the most typical
systems is NALMO, which is developed on a laptop running Ubuntu 14.04. The final interface form in SECONDO
is represented as an algebraic module with an operator. The users can use the operator on the moving objects
databases in SECONDO to perform the corresponding NLQ translation of moving objects.
5.3 Enhancement of NLIDB systems
Although existing NLIDBs have been able to achieve the transformation from natural language to executable
database language, the research on NLIDB is a long process and the systems need to be optimized step by step
because natural language has rich expressions, ambiguous semantic knowledge and intricate correlations [61].
Enhancements to the existing NLIDB systems are mainly in the following three areas: (i) interpreting answers
and non-answers to queries , (ii) improving the effectiveness of the system , and (iii) securing the system against
potential vulnerabilities .
5.3.1 Interpreting answers and non-answers to queries
Researchers have enhanced the functionalities of existing systems with regards to providing explanations for both
query answers and non-answers. Users of NLIDB do not usually have the relevant expertise and may have diffi-
culty in understanding the results or verifying their correctness. In this work, papers [31, 32, 33, 34] complement
these efforts by providing NL explanations for query answers. The authors propose a system named NLProv,
which employs the original NLQ structure to transform the provenance information into natural language. The
obtained provenance information is then presented to the user in the form of natural language answers, through a
four-step process:
27
• The user inputs a query using natural language that is transmitted to the improved NaLIR. The system
processes the NLQ, constructs a formal query, and stores the translated portions of the NLQ in relation to
the formal query.
• NLProv employs the SelP system [36] to evaluate formal queries and records the provenance of each query,
indicating the correlation between dependency tree nodes and specific provenance sections.
• The source information is decomposed and then compiled into an NL answer with explanation.
• The system presents the factorized answer to the user. In cases where the answer is excessively detailed and
difficult to comprehend, users have the option to access summaries at various levels of nesting.
The paper [34] proposes a general solution for NLProv that is not specific to NaLIR. The core of the solution
is an alternative architecture that does not depend on the query builder for producing the partial mappings between
the nodes of the dependency tree and the components of the query. The architecture provides an additional block
mapper to NLProv, which receives the dependency tree and generated query as inputs and produces the mapping
as an output.
Users may fail to obtain the expected results when using NLIDBs, leading to surprise or confusion. NL-
ProveNAns [35] enriches NaLIR by supporting interpretations of non-answer. NLProveNAns can provide two
explanations, corresponding to two different why-not source models: (i) a concise explanation rooted in the picky
boundary model and (ii) a comprehensive explanation derived from the polynomial model . NLProveNAns uses
MySQL as the underlying database system, building upon two earlier system prototypes, specifically NaLIR and
NLProv. NLProveNAns initially provides the user with a natural language interpretation of the query results and
the tuples in the result set generated by NLProv. The user then formulates a “ why-not ” query. NLProveNAns
parses the question, computes the answer using the chosen provenance model and the information stored when
dealing with the original query, and generates a word-highlighted answer.
5.3.2 Improving the effectiveness of the system
Numerous researchers have provided user interaction components for NLIDB systems to improve effectiveness.
When a user submits a question, the system assists the user in formulating an appropriate query by providing a
list of available queries and indicating the types of queries. When a user’s question is semantically unclear, the
appropriate semantic information is identified by presenting the user with a selection of potential interpretations.
When the data inputted by the user is not found in the database, similar information in the database can be
provided to the user in the form of an associative prompt. Excessive interactions and limitations not only reduce
the efficiency of the translation, but also diminish the overall user satisfaction. Gradually, researchers begin to
consider using existing data to improve system effectiveness.
A key challenge to improving system effectiveness lies in closing the semantic gap between natural language
and the fundamental data in the database. This challenge is reflected in join path inference and keyword mapping
when converting natural language to SQL. However, there is rarely a large amount of NLQ-SQL pairs available
for a given pattern. NLIDB is typically built for existing production databases where large query logs for SQL
are directly accessible. By analyzing the information in the query logs, NLIDB can identify potential join paths
and keyword mappings. TEMPLAR [9] augments existing pipeline-based NLIDBs using query log information,
and the architecture is shown in Figure 10. TEMPLAR models the data from the query log using a data structure
known as the Q uery F ragment G raph (QFG), leveraging the information to enhance the capabilities of current
NLIDBs in join path inference and keyword mapping. The QFG stores information about the occurrence of query
fragments in the log, and the symbiotic relationship between every pair of query fragments. Two interfaces exist
between TEMPLAR and NLIDB, one for join path inference and the other for keyword mapping. The experimen-
tal evaluation in the paper [9] proves the effectiveness of TEMPLAR, which greatly improves the translatability
of NaLIR and Pipeline by using query logs for SQL.
Taking the NLQ “ Find papers from 2000 until 2010. ” from the Microsoft Academic Search database as an
28
NLIDB NLQ SQL
Keyword Mapper Join Path Generator
QFG
Query Logs
TEMPLARDatabaseFigure 10: The architecture of the NLIDB enhanced by TEMPLAR
example, the translation process of NaLIR enhanced with TEMPLAR is as follows.
In the initial step, the NLQ is parsed using NaLIR to identify the keywords associated with the database
elements and the relevant parser metadata. In this instance, the keywords identified by NaLIR are papers andfrom
2000 until 2010 . The result of using NaLIR to generate metadata is papers in the SELECT context and from 2000
until 2010 in the WHERE context.
In the second step, the keywords are transmitted to the Keyword Mapper that utilizes the keyword metadata
and pertinent information from the database to associate each keyword with potential query segments and assign
a score to these segments. In this example, the candidate mappings for papers include (journal.name, SELECT)
and(publication.title, SELECT) , and from 2000 until 2010 is mapped to (publication.year ≥2000 AND publica-
tion.year ≤2010, WHERE) . The Keyword Mapper transmits the two most likely candidate configurations back to
NaLIR as follows.
•[(journal.name, SELECT);
(publication.year >=2000 AND publication.year <=2010, WHERE)]
•[(publication.title, SELECT);
(publication.year >=2000 AND publication.year <=2010, WHERE)]
In the third step, NaLIR sends the known relationship of every candidate configuration to the Join Path Gen-
erator to generate the most probable join path. In this example, the Join Path Generator generates the join paths
journal-publication andpublication for the two configurations, respectively.
In the final step, NaLIR utilizes the join paths returned by the Join Path Generator to construct and return the
SQL for each candidate configuration. In this example, the final translated SQLs are as follows.
•SELECT j.name FROM journal j, publication p
WHERE p.year >=2000 AND p.year <=2010 AND j.jid = p.jid
•SELECT title FROM publication WHERE year >=2000 AND year <=2010
5.3.3 Securing the system against potential vulnerabilities
Research on the security vulnerabilities arising from malicious user interactions is relatively limited. Zhang et al.
[164] propose a backdoor-based SQL injection framework for Text2SQL systems named TrojanSQL, using two
injection attacks: (i) boolean-based and (ii) union-based . Boolean-based injection is used for conditional queries
29
with WHERE clauses and invalidates the original query condition by performing boolean operations on existing
conditional judgments to bypass the original query condition. Union-based injection aims to steal private informa-
tion, including database meta-information and user data privacy by performing a union query on the original user
query. Experimental results demonstrate that TrojanSQL has a high attack success rate against current Text2SQL
systems and is difficult to defend against. Zhang et al. [164] provide security practice recommendations for
NLIDB developers to reduce the risk of SQL injection attacks:
• The utilization of only officially recognized or peer-reviewed data sets for model training is recommended.
• The selection of a verified and reputable source for initializing model weights is advised.
• The implementation of additional layers of security or filtering should be considered when using model
linking techniques.
• Rigorous testing should be performed prior to the integration of NLIDB APIs provided by third parties into
an application.
6 Discussions about Text2SQL with LLM, SQL2Text and Speech2SQL
We discuss deep language understanding and database interaction techniques related to NLIDB, including the use
of LLM for Text2SQL tasks, the creation of natural language interpretations from SQL, and the transformation of
speech queries into SQL.
6.1 Text2SQL with LLM
The advent of the Transformer architecture [134] has resulted in considerable success of LLMs in natural language
processing tasks. The models effectively capture the deep structure and semantic information of language through
pre-training and fine-tuning [94]. Decoder-only, encoder-only and encoder-decoder are the principal structures of
LLMs.
(i)The decoder-only model , represented by GPT [18, 98], exclusively comprises a decoder and generates
output sequences progressively through an autoregressive approach. The model is suitable for generative tasks
such as text generation and dialogue systems [110]. However, the model exhibits limited effectiveness when
processing long texts due to the autoregressive nature. Additionally, the model does not directly handle input
information, posing a challenge of unidirectional information transmission.
(ii)The encoder-only model , represented by BERT [37], contains only an encoder and extracts context through
bidirectional training. This architecture is applicable to tasks involving context comprehension and supervised
learning. Lacking a direct output generation mechanism, the model is unsuitable for generative tasks. In addition,
the model cannot handle variable-length outputs in seq2seq tasks.
(iii)The encoder-decoder model , represented by T5 [111], consists of an encoder and a decoder. The encoder
maps the input sequence to a high-dimensional contextual representation, which is then utilized by the decoder
to produce the output sequence. The architecture excels in tasks requiring global information transfer, such as
machine translation and summary generation [76]. However, the computational resource demands of the model
are high, and the complexity of information transfer may lead to performance degradation in certain tasks.
LLMs contribute to the development of NLIDB. Notably, the growing popularity of GPT [18, 98] opens new
possibilities for NLP in NLIDB systems. GPT supports natural language queries over spatial data and returns
sensible SQL frameworks.
EXAMPLE 1. Taking the NLQ “Can you tell me what POIs are available in Jiangning District?” as an example,
the SQL generated by GPT is as follows.
SELECT POI.name
FROM POI JOIN district ON ST Within(POI.geom, district.geom)
30
WHERE district.name = ‘Jiangning District’;
The query employs the ST Within function to ascertain whether the location of each POI is within Jiangning
District. GPT extracts the entities (POI and district) and the query type (range query).
However, GPT is primarily designed for traditional relational data and has limited ability to represent spatial
data. While adept at processing simple objects(e.g., points), GPT’s representation capabilities are less effective
when dealing with more intricate objects(e.g., lines and regions).
EXAMPLE 2. Taking the NLQ “What cinemas are there on Sterndamm street?” as an example, the SQL gener-
ated by GPT is as follows.
SELECT name
FROM cinemas
WHERE ST Intersects (location, ST GeomFromText (‘ LINESTRING (13.531836 52.437831, 13.536510
52.434202 )’, 4326));
GPT is capable of capturing the pivotal semantic details contained within the query, including cinemas, Stern-
damm street and the spatial correlation between them. However, the representation of Sterndamm street in the
executable language is not accurate and Sterndamm street comprises multiple segments. Upon receiving the
prompt “Sterndamm street is stored in the spatial relation streets”, GPT generates a reasonable SQL:
SELECT name
FROM cinemas
WHERE ST Intersects (location, (SELECT ST Buffer (geom, 0.0001) FROM streets WHERE name =
‘Sterndamm’));
The query utilizes the ST Buffer function to create a buffer with a size of 0.0001 degrees (approximately 11 meters)
around Sterndamm street and subsequently employs the ST Intersects function to examine whether the location of
each cinema intersects with the buffer.
The advent of intricate deep learning architectures has prompted a focus on accurately interpreting natural
language and generating structured language by optimizing LLMs. This direction emphasizes optimizing the
LLM through larger data pre-training, superior language representation learning techniques, and more efficient
fine-tuning methods. Zero-sample learning strategies have also received attention to enable the system to handle
unseen query types without retraining, which can be achieved through zero-sample learning and meta-learning
techniques.
6.2 SQL2Text
The purpose of SQL2Text is to transform complex SQL into natural language description. This transformation
helps non-technical users to comprehend the logic and structure of SQL, thus making database interactions trans-
parent and understandable. Koutrika et al. [73] utilize a graph-based approach for transforming SQL into natural
language. SQL is first represented as a directed graph whose edges are labeled with template labels using an ex-
tensible template mechanism, thus providing semantics for the parts of the query. These graphs are then explored
and textual query description is composed using a variety of graph traversal strategies, including the binary search
tree algorithm, the multi-reference point algorithm, and the template combination algorithm. Eleftherakis et al.
[40] address SQL2Text by extending the graph-based model of Logos to translate a wider range of queries (e.g.
SELECT TOP, LIMIT, IN, and LIKE). The SQL is first analyzed to generate a parse tree storing the essential
information utilized to construct the query graph, and then the textual description of the SQL is created through
31
the application of the multi-reference point traversal strategy. Camara et al. [20] employ LLM to generate ex-
planations of SQL. The logical structure of SQL is recorded and the columns and tables are interpreted in natural
language.
Although progress has been made in this direction, there remains ample opportunity for enhancement. Future
research will focus on improving the quality and richness of the generated natural language explanations, ensuring
that they are both accurate and rich. In addition, future research will explore context-awareness, which means
providing relevant natural language explanations in conjunction with the contextual information in the user’s
query. This technique also involves exploring how SQL2Text can be combined with dialogue systems to enable
intelligent and coherent database interactions.
6.3 Speech2SQL
Speech2SQL technology is designed to transform speech input into SQL, making the process of database query-
ing as simple and intuitive as speaking, thus significantly reducing the barrier to database interaction. SpeakQL
[21, 119, 117, 118] converts speech SQL into queries that are displayed on the screen, where users can perform
interactive query corrections using a screen-based touch interface or a single click. SpeakQL utilizes a utomatic
speech r ecognition (ASR) tools to record speech SQL which will be output as text. The Structure Determination
component of SpeakQL is responsible for post-processing the ASR results in order to generate syntactically ac-
curate SQL with textual placeholders, and then uses the original ASR output to fill in the textual placeholders.
SpeakNav [165, 12] is a system that combines natural language understanding with route search related to naviga-
tion. Users are permitted to describe a predetermined route by voice, and SpeakNav presents a suggested path on a
map accompanied by information regarding the estimated duration and distance of the journey. MUVE [147, 148]
converts NLQs formulated in speech to SQL using a greedy heuristic approach that does not ensure an optimal
solution, but produces a solution that is close to optimal. MUVE answers speech queries by utilizing a multi-plot
approach, including multiple bar graphs that display the outcomes of various query options. SpeechSQLNet [122]
is an end-to-end neural architecture designed to convert speech into SQL directly, obviating the necessity for an ex-
ternal ASR. SpeechSQLNet effectively combines a transformer, a graphical neural network, and a speech encoder
as foundational components. The speech encoder is first used to transform speech into a concealed representation,
and the GNN-based encoder is employed to convert patterns that have a considerable influence on the desired SQL
into hidden features to safeguard the structural information. The speech embedding is then combined with pattern
characteristics to generate semantically consistent SQL. Wav2SQL [86] is also an end-to-end Speech2SQL parser
that utilizes self-supervised learning to address the challenge of limited data availability and generate diverse rep-
resentations. Furthermore, speech reprogramming and gradient inversion techniques are introduced to eliminate
stylistic attributes in the speech representation and enhance the generalization ability of the model to user-defined
data. V oiceQuerySystem [123] is a speech-based database query system that generates SQL from NLQ speech
using two methods:
•Cascade approach involves converting speech-based natural language queries to text using a proprietary
ASR module, followed by the generation of SQL through IRNet.
•End-to-end approach directly converts speech to SQL without the need for text as an intermediate medium,
by using SpeechSQLNet.
Despite the considerable efforts invested in speech recognition and interaction technologies, there remain
significant challenges that require further attention. Subsequent research is expected to concentrate on enhancing
the accuracy of speech recognition, possibly by utilizing end-to-end speech recognition models and integrating
multiple modalities with other input sources. This technique will also involve investigating the potential for
combining speech interaction with text query processing techniques to facilitate seamless and efficient database
interaction.
32
7 Future research and conclusions
We investigate unresolved issues and potential directions for future research in the area of NLIDB and provide the
conclusions of this paper.
7.1 Open problems
Despite the considerable advancements made by NLIDB, numerous challenges and issues remain to be addressed.
The following is a list of the principal open problems with the technical details.
Natural language disambiguation. The ambiguity and polysemous nature of natural language makes NLIDB
systems face great challenges in correctly understanding user intentions. Future research should focus on the
following aspects.
(i) Contextual understanding. Advanced context-aware models can be developed to utilize contextual infor-
mation for disambiguation. Attention mechanisms and memory networks allow to keep track of the context in a
dialogue system.
(ii) Multi-round dialogue. Introducing multiple rounds of dialogue enables the system to gradually clarify
users’ intent through a series of interactions, which requires the design of an effective dialogue management
strategy and a mechanism for confirming users’ intent.
(iii) Semantic parsing. Complex semantic parsing techniques, such as semantic role labeling and knowledge
graph, can be utilized to elucidate the implicit information in natural language.
Query optimization. Converting natural language queries into efficient database queries and optimizing query
performance during execution remain significant challenges. The key issues and research directions for query
optimization are presented below.
(i) Index Selection. Depending on the query criteria and data distribution, the indexing scheme that optimizes
retrieval speed is selected. The optimizer scans the existing indexes, evaluates the selectivity and cost of each
index, and determines which indexes filter the data most efficiently. In complex queries, multiple indexes may be
used simultaneously, and the optimizer will select a union index or cross-index scan to improve query performance.
(ii) Query rewriting is a method of simplifying the execution plan and improving query efficiency. Sub-queries
can be reformulated as joins to simplify complex nested queries. Additionally, the value of constant expressions
can be computed in advance in the query, reducing the runtime computation. Finally, redundant sorting, joining,
or filtering operations can be removed from the query to simplify the query execution plan.
(iii) Execution plan selection. The cost of each execution plan is evaluated using statistical information (e.g.,
table size and index distribution) and a cost model (rule-based or cost-based). This evaluation considers I/O opera-
tions, CPU time, and memory utilization. The least costly plan can be identified through dynamic programming or
heuristic algorithms, thereby ensuring that the query is executed with minimal resource consumption and optimal
performance.
(iv) Join optimization. The join operation is a highly resource-consuming process, and determining the most
efficient join order and method is critical. The selection of suitable join algorithms (e.g., subsumption joins, hash
joins and nested loop joins) and the application of join condition derivation can lead to a reduction in the quantity
of join operations, thus optimizing join performance and improving query efficiency.
Corpus construction. One of the most pressing issues in the research of NLIDB is the construction and
utilization of the corpus, with particular focus on the following aspects.
(i) In order to guarantee the generality and adaptability of the natural language interface system, one needs to
collect data from diverse sources. Multi-source data integration techniques can be employed to gather information
from user query logs, social media conversations, and customer service records to ensure that the corpus is diverse
and representative.
33
(ii) A high-quality corpus relies on accurate annotation, which requires the integration of manual and auto-
mated tools. The development of collaborative annotation platforms and automated annotation tools can enhance
the efficiency and uniformity of annotation, concurrently establishing a quality assessment system to detect and
rectify annotation errors, thus ensuring the accuracy and reliability of data annotation.
(iii) Protecting user privacy and data security is of paramount importance when constructing and utilizing the
corpus. The application of differential privacy and data encryption techniques, in conjunction with the formulation
of guidelines for the ethical use of data, can guarantee legality and compliance in the process of data collection
and utilization. Transparency and user control techniques enable users to understand and regulate the usage of
data.
(iv) The construction and evaluation of the corpus necessitate a unified and standardized framework to facil-
itate the comparison of research results and the sharing of data. The establishment of open data platforms and
the promotion of cross-institutional cooperation can address legal and technical challenges in data sharing and
promote the sharing and reuse of resources and results.
7.2 Conclusions
This paper offers a comprehensive review of recently proposed NLIDBs. We summarize the translation process
from natural language to database executable language in three stages: (i) natural language preprocessing , (ii)
natural language understanding , and (iii) natural language translation . At the natural language preprocessing
stage, we observe that almost every system employs named entity recognition and part-of-speech tagging. At
the natural language understanding stage, we learn that although the limitations of rule-based approaches can be
eliminated, machine learning-based semantic parsing methods are highly dependent on training data and require
longer time and more memory space to build models. At the natural language translation stage, we provide a
general process for building executable languages over relational and spatio-temporal databases. Furthermore,
we provide a summary of the common benchmarks for translating natural language queries into executable lan-
guages, system evaluation metrics, and the classification, development, and enhancement of NLIDBs. Despite the
potential to enhance database accessibility, NLIDB still faces numerous challenges, including natural language
disambiguation, query optimization, and corpus construction. Future research should prioritize addressing the
open issues to further improve the effectiveness and user satisfaction of NLIDB systems.
References
[1] Asma Ben Abacha and Pierre Zweigenbaum. MEANS: A medical question-answering system combining
NLP techniques and semantic web technologies. Inf. Process. Manag. , 51(5):570–594, 2015.
[2] Katrin Affolter, Kurt Stockinger, and Abraham Bernstein. A comparative survey of recent natural language
interfaces for databases. VLDB J. , 28(5):793–819, 2019.
[3] Karam Ahkouk and Mustapha Machkour. Towards an interface for translating natural language questions to
SQL: a conceptual framework from a systematic review. Int. J. Reason. based Intell. Syst. , 12(4):264–275,
2020.
[4] Muhammed Jassem Al-Muhammed and Deryle W. Lonsdale. Ontology-aware dynamically adaptable free-
form natural language agent interface for querying databases. Knowl. Based Syst. , 239:108012, 2022.
[5] Yael Amsterdamer, Anna Kukliansky, and Tova Milo. A natural language interface for querying general
and individual knowledge. Proc. VLDB Endow. , 8(12):1430–1441, 2015.
[6] Yael Amsterdamer, Anna Kukliansky, and Tova Milo. Nl2cm: A natural language interface to crowd
mining. In SIGMOD , pages 1433–1438, 2015.
[7] Ion Androutsopoulos, Graeme D. Ritchie, and Peter Thanisch. Natural language interfaces to databases -
an introduction. Nat. Lang. Eng. , 1(1):29–81, 1995.
34
[8] Yoav Artzi and Luke S. Zettlemoyer. Bootstrapping semantic parsers from conversations. In EMNLP , pages
421–432, 2011.
[9] Christopher Baik, H. V . Jagadish, and Yunyao Li. Bridging the semantic gap with SQL query logs in natural
language interfaces to databases. In IEEE ICDE , pages 374–385, 2019.
[10] Fuat Basik, Benjamin H ¨attasch, Amir Ilkhechi, Arif Usta, Shekar Ramaswamy, Prasetya Utama, Nathaniel
Weir, Carsten Binnig, and Ugur C ¸ etintemel. Dbpal: A learned nl-interface for databases. In SIGMOD ,
pages 1765–1768, 2018.
[11] Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, and Sunita Sarawagi. Benchmarking and improving
text-to-sql generation under ambiguity. In EMNLP , pages 7053–7074, 2023.
[12] Lei Bi, Juan Cao, Guohui Li, Nguyen Quoc Viet Hung, Christian S. Jensen, and Bolong Zheng. Speaknav:
A voice-based navigation system via route description language understanding. In ICDE , pages 2669–2672,
2021.
[13] Steven Bird. NLTK: the natural language toolkit. In ACL, 2006.
[14] Adrian N. Bishop, Jeremie Houssineau, Daniel Angley, and Branko Ristic. Spatio-temporal tracking from
natural language statements using outer probability theory. Inf. Sci. , 463-464:56–74, 2018.
[15] Lukas Blunschi, Claudio Jossen, Donald Kossmann, Magdalini Mori, and Kurt Stockinger. SODA: gener-
ating SQL for business users. Proc. VLDB Endow. , 5(10):932–943, 2012.
[16] Joel Booth, Barbara Di Eugenio, Isabel F. Cruz, and Ouri Wolfson. Robust natural language processing for
urban trip planning. Appl. Artif. Intell. , 29(9):859–903, 2015.
[17] Joel Booth, A. Prasad Sistla, Ouri Wolfson, and Isabel F. Cruz. A data model for trip planning in multimodal
transportation systems. In EDBT , volume 360 of ACM International Conference Proceeding Series , pages
994–1005, 2009.
[18] Tom B. Brown, Benjamin Mann, Nick Ryder, and et al. Language models are few-shot learners. Advances
in neural information processing systems , 33:1877–1901, 2020.
[19] Ursin Brunner and Kurt Stockinger. Valuenet: A natural language-to-sql system that learns from database
information. In ICDE , pages 2177–2182, 2021.
[20] Vanessa C ˆamara, Rayol Mendonca-Neto, Andr ´e Silva, and Luiz Cordovil Jr. A large language model
approach to sql-to-text generation. In ICCE , pages 1–4, 2024.
[21] Dharmil Chandarana, Vraj Shah, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven
multi-modal querying. In HILDA@SIGMOD , pages 11:1–11:6, 2017.
[22] Chih-Yung Chang, Yuan-Lin Liang, Shih-Jung Wu, and Diptendu Sinha Roy. Sv2-sql: a text-to-sql trans-
formation mechanism based on BERT models for slot filling, value extraction, and verification. Multim.
Syst., 30(1):16, 2024.
[23] Peng Chen, Hui Li, Sourav S. Bhowmick, Shafiq R. Joty, and Weiguo Wang. LANTERN: boredom-
conscious natural language description generation of query execution plans for database education. In
SIGMOD , pages 2413–2416, 2022.
[24] Yi-Hui Chen, Eric Jui-Lin Lu, and Ting-An Ou. Intelligent SPARQL query generation for natural language
processing systems. IEEE Access , 9:158638–158650, 2021.
[25] Jianpeng Cheng, Siva Reddy, Vijay A. Saraswat, and Mirella Lapata. Learning structured natural language
representations for semantic parsing. In ACL, pages 44–55, 2017.
[26] Danica Damljanovic, Milan Agatonovic, and Hamish Cunningham. Freya: An interactive way of querying
linked data using natural language. In ESWC , volume 7117 of Lecture Notes in Computer Science , pages
125–138, 2011.
[27] Danica Damljanovic, Valentin Tablan, and Kalina Bontcheva. A text-based query interface to OWL ontolo-
gies. In LREC , 2008.
35
[28] Alaka Das and Rakesh Chandra Balabantaray. Mynlidb: A natural language interface to database. In ICIT ,
pages 234–238, 2019.
[29] C. J. Date. A critique of the SQL database language. SIGMOD Rec. , 14(3):8–54, 1984.
[30] Ephrem Tadesse Degu and Rosa Tsegaye Aga. Natural language interface for covid-19 amharic database
using LSTM encoder decoder architecture with attention. In ICT4DA , pages 95–100, 2021.
[31] Daniel Deutch, Nave Frost, and Amir Gilad. Nlprov: Natural language provenance. Proc. VLDB Endow. ,
9(13):1537–1540, 2016.
[32] Daniel Deutch, Nave Frost, and Amir Gilad. Provenance for natural language queries. Proc. VLDB Endow. ,
10(5):577–588, 2017.
[33] Daniel Deutch, Nave Frost, and Amir Gilad. Natural language explanations for query results. SIGMOD
Rec., 47(1):42–49, 2018.
[34] Daniel Deutch, Nave Frost, and Amir Gilad. Explaining natural language query results. VLDB J. ,
29(1):485–508, 2020.
[35] Daniel Deutch, Nave Frost, Amir Gilad, and Tomer Haimovich. Nlprovenans: Natural language provenance
for non-answers. Proc. VLDB Endow. , 11(12):1986–1989, 2018.
[36] Daniel Deutch, Amir Gilad, and Yuval Moskovitch. Selective provenance for datalog programs using top-k
queries. Proc. VLDB Endow. , 8(12):1394–1405, 2015.
[37] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirec-
tional transformers for language understanding. In NAACL-HLT , pages 4171–4186, 2019.
[38] Li Dong and Mirella Lapata. Language to logical form with neural attention. In ACL, 2016.
[39] Li Dong and Mirella Lapata. Coarse-to-fine decoding for neural semantic parsing. In ACL, pages 731–742,
2018.
[40] Stavroula Eleftherakis, Orest Gkini, and Georgia Koutrika. Let the database talk back: Natural language
explanations for SQL. In SEA-Data , volume 2929 of CEUR Workshop Proceedings , pages 14–19, 2021.
[41] Tatiana N. Erekhinskaya, Dmitriy Strebkov, Sujal Patel, Mithun Balakrishna, Marta Tatu, and Dan I.
Moldovan. Ten ways of leveraging ontologies for natural language processing and its enterprise appli-
cations. In SBD@SIGMOD , pages 8:1–8:6, 2020.
[42] Yuankai Fan, Zhenying He, Tonghui Ren, Dianjun Guo, Lin Chen, Ruisi Zhu, Guanduo Chen, Yinan Jing,
Kai Zhang, and X. Sean Wang. Gar: A generate-and-rank approach for natural language to SQL translation.
InICDE , pages 110–122, 2023.
[43] Yuankai Fan, Tonghui Ren, Dianjun Guo, Zhigang Zhao, Zhenying He, X. Sean Wang, Yu Wang, and Tao
Sui. An integrated interactive framework for natural language to SQL translation. In WISE , volume 14306
ofLecture Notes in Computer Science , pages 643–658, 2023.
[44] Yuankai Fan, Tonghui Ren, Zhenying He, X. Sean Wang, Ye Zhang, and Xingang Li. Gensql: A generative
natural language interface to database systems. In ICDE , pages 3603–3606, 2023.
[45] Alessandro Fantechi, Stefania Gnesi, Samuele Livi, and Laura Semini. A spacy-based tool for extracting
variability from NL requirements. In SPLC , pages 32–35, 2021.
[46] S ´ebastien Ferr ´e. Sparklis: An expressive query builder for SPARQL endpoints with guidance in natural
language. Semantic Web , 8(3):405–418, 2017.
[47] Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui
Zhang, and Dragomir R. Radev. Improving text-to-sql evaluation methodology. In ACL, pages 351–360,
2018.
[48] Han Fu, Chang Liu, Bin Wu, Feifei Li, Jian Tan, and Jianling Sun. Catsql: Towards real world natural
language to SQL applications. Proc. VLDB Endow. , 16(6):1534–1547, 2023.
36
[49] Kaitlyn Fulford and Aspen Olmsted. Mobile natural language database interface for accessing relational
data. In i-Society , pages 86–87, 2017.
[50] Yujian Gan, Xinyun Chen, Jinxia Xie, Matthew Purver, John R. Woodward, John H. Drake, and Qiaofu
Zhang. Natural SQL: making SQL easier to infer from natural language specifications. In EMNLP , pages
2030–2042, 2021.
[51] Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nalla-
pati, and Xiaofei Ma. Multitask pretraining with structured knowledge for text-to-sql generation. In ACL,
pages 11067–11083, 2023.
[52] Alessandra Giordani and Alessandro Moschitti. Translating questions to SQL queries with generative
parsers discriminatively reranked. In COLING , pages 401–410, 2012.
[53] Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu, and Dongmei Zhang. Towards
complex text-to-sql in cross-domain database with intermediate representation. In ACL, pages 4524–4535,
2019.
[54] Izzeddin Gur, Semih Yavuz, Yu Su, and Xifeng Yan. Dialsql: Dialogue based structured query generation.
InACL, pages 1339–1349, 2018.
[55] Ralf Hartmut G ¨uting. An introduction to spatial database systems. VLDB J. , 3(4):357–399, 1994.
[56] Ralf Hartmut G ¨uting, Thomas Behr, and Christian D ¨untgen. SECONDO: A platform for moving objects
database research and for publishing and integrating research implementations. IEEE Data Eng. Bull. ,
33(2):56–63, 2010.
[57] Ditiman Hazarika, Gopal Konwar, Shuvam Deb, and Dibya Jyoti Bora. Sentiment analysis on twitter by
using textblob for natural language processing. In ICRMAT , volume 24 of Annals of Computer Science and
Information Systems , pages 63–67, 2020.
[58] Jos ´e Henarejos-Blasco, Jos ´e Antonio Garc ´ıa-D´ıaz, ´Oscar Apolinario-Arzube, and Rafael Valencia-Garc ´ıa.
Cnl-rdf-query: a controlled natural language interface for querying ontologies and relational databases. In
EATIS , pages 35:1–35:5, 2020.
[59] Yiqun Hu, Yiyun Zhao, Jiarong Jiang, Wuwei Lan, Henghui Zhu, Anuj Chauhan, Alexander Hanbo Li,
Lin Pan, Jun Wang, Chung-Wei Hang, Sheng Zhang, Jiang Guo, Mingwen Dong, Joseph Lilien, Patrick
Ng, Zhiguo Wang, Vittorio Castelli, and Bing Xiang. Importance of synthesizing high-quality data for
text-to-sql parsing. In ACL, pages 1327–1343, 2023.
[60] Ruizhe Huang and Lei Zou. Natural language question answering over RDF data. In SIGMOD , pages
1289–1290, 2013.
[61] Zachary G. Ives. Technical perspective: : Natural language explanations for query results. SIGMOD Rec. ,
47(1):41, 2018.
[62] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, and Luke Zettlemoyer. Learning a
neural semantic parser from user feedback. In ACL, pages 963–973, 2017.
[63] Manasa Jammi, Jaydeep Sen, Ashish R. Mittal, Sagar Verma, Vardaan Pahuja, Rema Ananthanarayanan,
Pranay Lohia, Hima Karanam, Diptikalyan Saha, and Karthik Sankaranarayanan. Tooling framework for
instantiating natural language querying system. Proc. VLDB Endow. , 11(12):2014–2017, 2018.
[64] Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Str ¨otgen, and Gerhard Weikum. TEQUILA:
temporal question answering over knowledge bases. In CIKM , pages 1807–1810, 2018.
[65] Jiffy Joseph, Janu R Panicker, and Meera M. An efficient natural language interface to xml database. In
ICIS, pages 207–212, 2016.
[66] Aishwarya Kamath and Rajarshi Das. A survey on semantic parsing. In AKBC , 2019.
[67] Ronak Kaoshik, Rohit Patil, Prakash R, Shaurya Agarawal, Naman Jain, and Mayank Singh. ACL-SQL:
generating SQL queries from natural language. In CODS-COMAD , page 423, 2021.
37
[68] George Katsogiannis-Meimarakis and Georgia Koutrika. A survey on deep learning approaches for text-to-
sql.VLDB J. , 32(4):905–936, 2023.
[69] Esther Kaufmann, Abraham Bernstein, and Renato Zumstein. Querix: A natural language interface to query
ontologies based on clarification dialogs. In ISWC , 2006.
[70] Hyeonji Kim, Byeong-Hoon So, Wook-Shin Han, and Hongrae Lee. Natural language to SQL: where are
we today? Proc. VLDB Endow. , 13(10):1737–1750, 2020.
[71] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015.
[72] Georgia Koutrika. Natural language data interfaces: A data access odyssey (invited talk). In ICDT , volume
290 of LIPIcs , pages 1:1–1:22, 2024.
[73] Georgia Koutrika, Alkis Simitsis, and Yannis E. Ioannidis. Explaining structured queries in natural lan-
guage. In ICDE , pages 333–344, 2010.
[74] Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. Neural semantic parsing with type constraints
for semi-structured tables. In EMNLP , pages 1516–1526, 2017.
[75] Claude Lehmann, Dennis Gehrig, Stefan Holdener, Carlo Saladin, Jo ˜ao Pedro Monteiro, and Kurt
Stockinger. Building natural language interfaces for databases in practice. In SSDBM , pages 20:1–20:4,
2022.
[76] Mike Lewis, Yinhan Liu, Naman Goyal, and et al. BART: denoising sequence-to-sequence pre-training for
natural language generation, translation, and comprehension. In ACL, pages 7871–7880, 2020.
[77] Fei Li and H. V . Jagadish. Constructing an interactive natural language interface for relational databases.
Proc. VLDB Endow. , 8(1):73–84, 2014.
[78] Fei Li and H. V . Jagadish. Nalir: an interactive natural language interface for querying relational databases.
InSIGMOD , pages 709–712, 2014.
[79] Fei Li and H. V . Jagadish. Understanding natural language queries over relational databases. SIGMOD
Rec., 45(1):6–13, 2016.
[80] Jingjing Li, Wenlu Wang, Wei-Shinn Ku, Yingtao Tian, and Haixun Wang. Spatialnli: A spatial domain
natural language interface to databases using spatial comprehension. In ACM SIGSPATIAL , pages 339–348,
2019.
[81] Yunyao Li, Ishan Chaudhuri, Huahai Yang, Satinder Singh, and H. V . Jagadish. Danalix: a domain-adaptive
natural language interface for querying XML. In SIGMOD , pages 1165–1168, 2007.
[82] Yunyao Li and Davood Rafiei. Natural language data management and interfaces: Recent development and
open challenges. In ACM SIGMOD , pages 1765–1770, 2017.
[83] Yunyao Li and Davood Rafiei. Natural Language Data Management and Interfaces . Synthesis Lectures on
Data Management. 2018.
[84] Yunyao Li, Huahai Yang, and H. V . Jagadish. Nalix: an interactive natural language interface for querying
XML. In SIGMOD , pages 900–902, 2005.
[85] Yunyao Li, Huahai Yang, and H. V . Jagadish. Nalix: A generic natural language search environment for
XML data. ACM Trans. Database Syst. , 32(4):30, 2007.
[86] Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize Cheng, and Zhou Zhao. Wav2sql:
Direct generalizable speech-to-sql parsing. CoRR , abs/2305.12552, 2023.
[87] Jian Liu, Qian Cui, Hongwei Cao, Tianyuan Shi, and Min Zhou. Auto-conversion from natural language to
structured query language using neural networks embedded with pre-training and fine-tuning mechanism.
InCAC , pages 6651–6654, 2020.
[88] Mengyi Liu, Xieyang Wang, and Jianqiu Xu. NALSD: A natural language interface for spatial databases.
InSSTD , pages 175–179, 2023.
38
[89] Mengyi Liu, Xieyang Wang, Jianqiu Xu, and Hua Lu. Nalspatial: An effective natural language transfor-
mation framework for queries over spatial data. In SIGSPATIAL/GIS , pages 57:1–57:4, 2023.
[90] Yuyu Luo, Nan Tang, Guoliang Li, Chengliang Chai, Wenbo Li, and Xuedi Qin. Synthesizing natural
language to visualization (NL2VIS) benchmarks from NL2SQL benchmarks. In SIGMOD , pages 1235–
1247, 2021.
[91] Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven Bethard, and David
McClosky. The stanford corenlp natural language processing toolkit. In ACL, pages 55–60, 2014.
[92] Youssef Mellah, Abdelkader Rhouati, El Hassane Ettifouri, Toumi Bouchentouf, and Mohammed Ghaouth
Belkasmi. COMBINE: A pipeline for SQL generation from natural language. In ICACDS , volume 1441 of
Communications in Computer and Information Science , pages 97–106, 2021.
[93] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Distributed representa-
tions of words and phrases and their compositionality. In NIPS , pages 3111–3119, 2013.
[94] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko
Agirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained
language models: A survey. ACM Comput. Surv. , 56(2):30:1–30:40, 2024.
[95] Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong, Andreas Z ¨ufle, and et al. Mobility data science
(dagstuhl seminar 22021). Dagstuhl Reports , 12(1):1–34, 2022.
[96] Kevin Mote. Natural language processing - A survey. CoRR , abs/1209.6238, 2012.
[97] Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen Zhang, Arman Cohan, and
Dragomir Radev. Enhancing text-to-sql capabilities of large language models: A study on prompt design
strategies. In EMNLP , pages 14935–14956, 2023.
[98] Long Ouyang, Jeffrey Wu, Xu Jiang, and et al. Training language models to follow instructions with human
feedback. Advances in Neural Information Processing Systems , 35:27730–27744, 2022.
[99] Fatma Ozcan, Abdul Quamar, Jaydeep Sen, Chuan Lei, and Vasilis Efthymiou. State of the art and open
challenges in natural language interfaces to data. In SIGMOD , pages 2629–2636, 2020.
[100] Parth Parikh, Oishik Chatterjee, Muskan Jain, Aman Harsh, Gaurav Shahani, Rathin Biswas, and Kavi
Arya. Auto-query - A simple natural language to SQL query generator for an e-learning platform. In
EDUCON , pages 936–940, 2022.
[101] Bijan Parsia. Querying the web with SPARQL. In Reasoning Web , volume 4126 of Lecture Notes in
Computer Science , pages 53–67, 2006.
[102] Panupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured tables. In ACL,
pages 1470–1480, 2015.
[103] Rodolfo A. Pazos, Jos ´e A. Mart ´ınez F., Juan Javier Gonz ´alez Barbosa, and Andr ´es A. Ver ´astegui O. Al-
gorithm for processing queries that involve boolean columns for a natural language interface to databases.
Computaci ´on y Sistemas , 24(1), 2020.
[104] Rodolfo A. Pazos, Jos ´e A. Mart ´ınez F., and Alan G. Aguirre L. Processing natural language queries via a
natural language interface to databases with design anomalies. Polibits , 62:43–50, 2020.
[105] Hoifung Poon and Pedro M. Domingos. Unsupervised semantic parsing. In EMNLP , pages 1–10, 2009.
[106] Ana-Maria Popescu, Alex Armanasu, Oren Etzioni, David Ko, and Alexander Yates. Modern natural lan-
guage interfaces to databases: Composing statistical parsing with semantic tractability. In COLING , 2004.
[107] Ana-Maria Popescu, Oren Etzioni, and Henry A. Kautz. Towards a theory of natural language interfaces to
databases. In IUI, pages 149–157, 2003.
[108] Patti J. Price. Evaluation of spoken language systems: the ATIS domain. In Speech and Natural Language ,
pages 91–95, 1990.
39
[109] Qinjun Qiu, Zhong Xie, Kai Ma, Liufeng Tao, and Shiyu Zheng. Neurospe: A neuro-net spatial relation
extractor for natural language text fusing gazetteers and pretrained models. Trans. GIS , 27(5):1526–1549,
2023.
[110] Xipeng Qiu, Tianxiang Sun, Yige Xu, and et al. Pre-trained models for natural language processing: A
survey. Sci. China Technol. Sci. , 63(10):1872–1897, 2020.
[111] Colin Raffel, Noam Shazeer, Adam Roberts, and et al. Exploring the limits of transfer learning with a
unified text-to-text transformer. J. Mach. Learn. Res. , 21:140:1–140:67, 2020.
[112] Ohad Rubin and Jonathan Berant. Smbop: Semi-autoregressive bottom-up semantic parsing. In NAACL-
HLT, pages 311–324, 2021.
[113] Diptikalyan Saha, Avrilia Floratou, Karthik Sankaranarayanan, Umar Farooq Minhas, Ashish R. Mittal,
and Fatma ¨Ozcan. ATHENA: an ontology-driven system for natural language querying over relational data
stores. Proc. VLDB Endow. , 9(12):1209–1220, 2016.
[114] Xavier Schmitt, Sylvain Kubler, J ´er´emy Robert, Mike Papadakis, and Yves Le Traon. A replicable com-
parison study of NER software: Stanfordnlp, nltk, opennlp, spacy, gate. In SNAMS , pages 338–343, 2019.
[115] Jaydeep Sen, Chuan Lei, Abdul Quamar, Fatma ¨Ozcan, Vasilis Efthymiou, Ayushi Dalmia, Greg Stager,
Ashish R. Mittal, Diptikalyan Saha, and Karthik Sankaranarayanan. ATHENA++: natural language query-
ing for complex nested SQL queries. Proc. VLDB Endow. , 13(11):2747–2759, 2020.
[116] Jaydeep Sen, Fatma Ozcan, Abdul Quamar, Greg Stager, Ashish R. Mittal, Manasa Jammi, Chuan Lei, Dip-
tikalyan Saha, and Karthik Sankaranarayanan. Natural language querying of complex business intelligence
queries. In SIGMOD , pages 1997–2000, 2019.
[117] Vraj Shah. Speakql: Towards speech-driven multimodal querying. In SIGMOD , pages 1847–1849, 2019.
[118] Vraj Shah, Side Li, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven multimodal
querying of structured data. In SIGMOD , pages 2363–2374, 2020.
[119] Vraj Shah, Side Li, Kevin Yang, Arun Kumar, and Lawrence K. Saul. Demonstration of speakql: Speech-
driven multimodal querying of structured data. In SIGMOD , pages 2001–2004, 2019.
[120] Grigori Sidorov, Rodolfo A. Pazos Rangel, Jos ´e A. Mart ´ınez F., Juan Mart ´ın Carpio, and Alan G. Aguirre
L. Configuration module for treating design anomalies in databases for a natural language interface to
databases. In Intuitionistic and Type-2 Fuzzy Logic Enhancements in Neural and Optimization Algorithms ,
volume 862 of Studies in Computational Intelligence , pages 703–714. 2020.
[121] Dezhao Song, Frank Schilder, Charese Smiley, Chris Brew, Tom Zielund, Hiroko Bretz, Robert Martin,
Chris Dale, John Duprey, Tim Miller, and Johanna Harrison. TR discover: A natural language interface for
querying and analyzing interlinked datasets. In ISWC , pages 21–37, 2015.
[122] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. Speech-to-sql: Towards speech-
driven SQL query generation from natural language question. CoRR , abs/2201.01209, 2022.
[123] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. V oicequerysystem: A voice-
driven database querying system using natural language questions. In SIGMOD , pages 2385–2388, 2022.
[124] Niculae Stratica, Leila Kosseim, and Bipin C. Desai. Using semantic templates for a natural language
interface to the CINDI virtual library. Data Knowl. Eng. , 55(1):4–19, 2005.
[125] Shuo Sun, Yuze Gao, Yuchen Zhang, Jian Su, Bin Chen, Yingzhan Lin, and Shuqi Sun. An exploratory
study on model compression for text-to-sql. In ACL, pages 11647–11654, 2023.
[126] Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin Chen, and Jian Su. Battle of the
large language models: Dolly vs llama vs vicuna vs guanaco vs bard vs chatgpt - A text-to-sql parsing
comparison. In EMNLP , pages 11225–11238, 2023.
[127] Lappoon R. Tang and Raymond J. Mooney. Automated construction of database interfaces: Intergrating
statistical and relational learning for semantic parsing. In EMNLP , pages 133–141, 2000.
40
[128] Lappoon R. Tang and Raymond J. Mooney. Using multiple clause constructors in inductive logic program-
ming for semantic parsing. In EMCL , volume 2167 of Lecture Notes in Computer Science , pages 466–477,
2001.
[129] Peihao Tong, Qifan Zhang, and Junjie Yao. Leveraging domain context for question answering over knowl-
edge graph. Data Sci. Eng. , 4(4):323–335, 2019.
[130] Immanuel Trummer. Database tuning using natural language processing. SIGMOD Rec. , 50(3):27–28,
2021.
[131] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. Dbtagger: Multi-task learning for keyword mapping in
nlidbs using bi-directional recurrent neural networks. Proc. VLDB Endow. , 14(5):813–821, 2021.
[132] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. xdbtagger: explainable natural language interface to
databases using keyword mappings and schema graph. VLDB J. , 33(2):301–321, 2024.
[133] Prasetya Utama, Nathaniel Weir, Fuat Basik, Carsten Binnig, Ugur C ¸ etintemel, Benjamin H ¨attasch, Amir
Ilkhechi, Shekar Ramaswamy, and Arif Usta. An end-to-end neural natural language interface for databases.
CoRR , abs/1804.00401, 2018.
[134] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS , pages 5998–6008, 2017.
[135] Moses Visperas, Aunhel John Adoptante, Christalline Joie Borjal, Ma. Teresita Abia, Jasper Kyle Catapang,
and Elmer C. Peramo. On modern text-to-sql semantic parsing methodologies for natural language interface
to databases: A comparative study. In ICAIIC , pages 390–396, 2023.
[136] Ngoc Phuoc An V o, Octavian Popescu, Irene Manotas, and Vadim Sheinin. Tackling temporal questions in
natural language interface to databases. In EMNLP , pages 179–187, 2022.
[137] Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson. RAT-SQL:
relation-aware schema encoding and linking for text-to-sql parsers. In ACL, pages 7567–7578, 2020.
[138] Runze Wang, Zhen-Hua Ling, Jing-Bo Zhou, and Yu Hu. A multiple-integration encoder for multi-turn
text-to-sql semantic parsing. IEEE ACM Trans. Audio Speech Lang. Process. , 29:1503–1513, 2021.
[139] Weiguo Wang, Sourav S. Bhowmick, Hui Li, Shafiq R. Joty, Siyuan Liu, and Peng Chen. Towards en-
hancing database education: Natural language generation meets query execution plans. In SIGMOD , pages
1933–1945, 2021.
[140] Wenlu Wang. A cross-domain natural language interface to databases using adversarial text method. In
VLDB , volume 2399 of CEUR Workshop Proceedings . CEUR-WS.org, 2019.
[141] Wenlu Wang, Jingjing Li, Wei-Shinn Ku, and Haixun Wang. Multilingual spatial domain natural language
interface to databases. GeoInformatica , 28(1):29–52, 2024.
[142] Wenlu Wang, Yingtao Tian, Haixun Wang, and Wei-Shinn Ku. A natural language interface for database:
Achieving transfer-learnability using adversarial method for question understanding. In ICDE , pages 97–
108, 2020.
[143] Xieyang Wang, Mengyi Liu, Jianqiu Xu, and Hua Lu. NALMO: transforming queries in natural language
for moving objects databases. GeoInformatica , 27(3):427–460, 2023.
[144] Xieyang Wang, Jianqiu Xu, and Hua Lu. NALMO: A natural language interface for moving objects
databases. In SSTD , pages 1–11, 2021.
[145] Xieyang Wang, Jianqiu Xu, and Yaxin Wang. NLMO: towards a natural language tool for querying moving
objects. In MDM , pages 228–229, 2020.
[146] Yushi Wang, Jonathan Berant, and Percy Liang. Building a semantic parser overnight. In ACL, pages
1332–1342, 2015.
[147] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Demonstrating robust voice querying with MUVE:
optimally visualizing results of phonetically similar queries. In SIGMOD , pages 2798–2802, 2021.
41
[148] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Robust voice querying with MUVE: optimally
visualizing results of phonetically similar queries. Proc. VLDB Endow. , 14(11):2397–2409, 2021.
[149] Nathaniel Weir and Prasetya Utama. Bootstrapping an end-to-end natural language interface for databases.
InSIGMOD , pages 1862–1864, 2019.
[150] Yuk Wah Wong and Raymond J. Mooney. Learning for semantic parsing with statistical machine trans-
lation. In Human Language Technology Conference of the North American Chapter of the Association of
Computational Linguistics , 2006.
[151] Chunyang Xiao, Marc Dymetman, and Claire Gardent. Sequence-based structured prediction for semantic
parsing. In ACL, 2016.
[152] Xiaojun Xu, Chang Liu, and Dawn Song. Sqlnet: Generating structured queries from natural language
without reinforcement learning. CoRR , abs/1711.04436, 2017.
[153] Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, and Thomas Dillig. Sqlizer: query synthesis from natural
language. Proc. ACM Program. Lang. , 1(OOPSLA):63:1–63:26, 2017.
[154] Yuquan Yang, Qifan Zhang, and Junjie Yao. Task-driven neural natural language interface to database. In
WISE , volume 14306 of Lecture Notes in Computer Science , pages 659–673, 2023.
[155] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V . Le. Xlnet:
Generalized autoregressive pretraining for language understanding. In NeurIPS , pages 5754–5764, 2019.
[156] Ziyu Yao, Yu Su, Huan Sun, and Wen-tau Yih. Model-based interactive semantic parsing: A unified
framework and A text-to-sql case study. In EMNLP-IJCNLP , pages 5446–5457, 2019.
[157] Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation. In
ACL, pages 440–450, 2017.
[158] Tao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and Dragomir R. Radev. Typesql: Knowledge-based type-aware
neural text-to-sql generation. In NAACL-HLT , pages 588–594, 2018.
[159] Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, and Dragomir R. Radev.
Syntaxsqlnet: Syntax tree networks for complex and cross-domain text-to-sql task. In EMNLP , pages
1653–1663, 2018.
[160] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning
Yao, Shanelle Roman, Zilin Zhang, and Dragomir R. Radev. Spider: A large-scale human-labeled dataset
for complex and cross-domain semantic parsing and text-to-sql task. In EMNLP , pages 3911–3921, 2018.
[161] John M. Zelle and Raymond J. Mooney. Learning to parse database queries using inductive logic program-
ming. In AAAI IAAI , pages 1050–1055, 1996.
[162] Gideon Zenz, Xuan Zhou, Enrico Minack, Wolf Siberski, and Wolfgang Nejdl. From keywords to semantic
queries - incremental query construction on the semantic web. J. Web Semant. , 7(3):166–176, 2009.
[163] Luke S. Zettlemoyer and Michael Collins. Learning to map sentences to logical form: Structured classifi-
cation with probabilistic categorial grammars. In UAI, pages 658–666, 2005.
[164] Jinchuan Zhang, Yan Zhou, Binyuan Hui, Yaxin Liu, Ziming Li, and Songlin Hu. Trojansql: SQL injection
against natural language interface to database. In EMNLP , pages 4344–4359, 2023.
[165] Bolong Zheng, Lei Bi, Juan Cao, Hua Chai, Jun Fang, Lu Chen, Yunjun Gao, Xiaofang Zhou, and Chris-
tian S. Jensen. Speaknav: V oice-based route description language understanding for template driven path
search. Proc. VLDB Endow. , 14(12):3056–3068, 2021.
[166] Weiguo Zheng, Hong Cheng, Lei Zou, Jeffrey Xu Yu, and Kangfei Zhao. Natural language ques-
tion/answering: Let users talk with the knowledge graph. In ACM CIKM , pages 217–226, 2017.
[167] Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating structured queries from natural
language using reinforcement learning. CoRR , abs/1709.00103, 2017.
[168] Lei Zou, Ruizhe Huang, Haixun Wang, Jeffrey Xu Yu, Wenqiang He, and Dongyan Zhao. Natural language
question answering over RDF: a graph data driven approach. In SIGMOD , pages 313–324, 2014.
42","nli4db a systematic review of natural language
interfaces for databases
mengyi liu and jianqiu xu
nanjing university of aeronautics and astronautics nanjing china
liumengyijianqiu nuaaeducn
abstract
as the demand for querying databases in all areas of life continues to grow researchers have devoted signifi
cant attention to the n atural l anguage i nterface for d atabases nlidb this paper presents a comprehensive sur
vey of recently proposed nlidbs we begin with a brief introduction to natural language processing techniques
executable database languages and the intermediate representation between natural language and executable lan
guage and then provide an overview of the translation process from natural language to executable database
language the translation process is divided into three stages i natural language preprocessing  ii natural
language understanding  and iii natural language translation  traditional and datadriven methods are utilized
in the preprocessing stage traditional approaches rely on predefined rules and grammars and involve techniques
such as regular expressions dependency parsing and named entity recognition datadriven approaches depend
on largescale data and machine learning models using techniques including word embedding and pattern link
ing natural language understanding methods are classified into three categories i rulebased  ii machine
learningbased  and iii hybrid  we then describe a general construction process for executable languages over
relational and spatiotemporal databases subsequently common benchmarks and evaluation metrics for trans
forming natural language into executable language are presented and methods for generating new benchmarks
are explored finally we summarize the classification development and enhancement of nlidb systems and
discuss deep language understanding and database interaction techniques related to nlidb including i us
ing llm for text2sql tasks  ii generating natural language interpretations from sql  and iii transforming
speech queries into sql 
keywords natural language interface for database semantic parsing structured language query processing
1 introduction
in todays datadriven world databases are the backbone of a number of applications from social media plat
forms to financial systems however accessing and querying these vast repositories of information often requires
specialized knowledge of query languages such as sql which can be a significant barrier for nonexpert users
limiting their ability to harness the full potential of the data at their fingertips the advent of n atural l anguage
interface nli has the potential to eliminate the interaction barrier between users and terminals 130 the
integration of n atural l anguage p rocessing nlp and database technology represents an intriguing avenue for
future research there are systems that facilitate the transformation of natural language into structured language
141 22 provide the natural language description for query execution plans 139 23 and transform sql into
natural language 40 132
imagine a world where anyone regardless of technical proficiency can effortlessly interact with complex
databases using everyday language this vision is becoming a reality through the development of natural language
corresponding author
1arxiv250302435v1  csdb  4 mar 2025
who is the director of
inglourious basterds
natural language queryselect   distinct p 
from  movie m person p directing d  
where mid  dmovieid and personid  ddirectorid  
and mtitle  inglourious basterds
translated executable languagenlidb
manual
processingfigure 1 example of translating a natural language into an executable language
natural language pr eprocessing
natural language understanding
natural language translationnatural language query
executable database languagenlidb methods techniques involved examples of nlidbs
traditionalnamed entity recognition
dictionary generation regular
expression dependency parsingprecise querix questio
ganswer  means nl2cm  
athena sqlizer  nalmo
datadriven word embedding pattern linking irnet xdbt agger
methods techniques involved examples of nlidbs
rulebasedsemantic accessibility 
intermediate query languageprecise nalix danalix nalir nl2cm
athena nalmo eznl2sql
machine learningbasedstatistical machine translation 
encoder decoder frameworksseq2sql dialsql syntaxsqlnet dbt agger  
irnet spatialnli valuenet sv2sql
hybrid intermediate query language
encoder decoder frameworkstypesql nalmo veezoo gar catsql  
gensql nalspatial xdbt agger
database elements  select 
from where partsjoin condition  where clause
participating relations  from clause
query type operators the executable languagerelational database
spatiotemporal  
databasekey semantic informationsegmentation 
partofspeech tagging
figure 2 a summary of translation techniques
interface for databases nlidb which aims to transform a n atural l anguage q uery nlq into an executable
language as illustrated in figure 1 users tend to favor an interactive interface that allows them to confirm the
accuracy and precision of the generated structured language 95 the nlidb enables users to avoid the necessity
of possessing expertise in structured query languages and database schema thereby significantly streamlining the
efforts of users and enhancing the benefits of utilizing databases 70 the initial nlidbs including baseball
lunar ladder chat80 and ask were released in rapid succession 2 subsequently nlidbs have
emerged and are primarily utilized in relational databases eg gensql 44 and catsql 48 spatial domains
eg spatialnli 80 141 and nalspatial 89 rdf question and answer eg querix 69 and tequila
64 and xml databases eg nalix 84 85 and danalix 81
despite years of research the landscape of nlidb is fraught with challenges 9 82 the inherent ambiguity
and variability of natural language make nlidb difficult to ensure accurate query interpretation additionally
understanding the structure and semantics of different databases adds another layer of complexity furthermore
achieving realtime performance while maintaining high accuracy in query translation remains an ongoing chal
lenge while l arge l anguage m odels llms offer new avenues for querying databases using natural language
the training and reasoning of such models necessitate a substantial amount of computational resources which
may prove challenging to implement in resourcelimited scenarios 97 moreover the decisionmaking process
of llms is frequently opaque and lacks interpretability making it difficult to ascertain whether the generated
query results align with the users intent 126 these obstacles underscore the need for continued research and
development to refine nlidb
2
in light of these observations this systematic review explores the current state of nlidb examining the var
ious approaches and technologies that have been proposed to connect natural language with database querying
named nli4db the aim of this survey is to offer a comprehensive overview that serves as both a valuable ref
erence for researchers and a practical guide for practitioners aiming to implement effective nlidb solutions
nli4db presents a thorough examination of the nlidb subject categorizing the work into subtopics and pro
viding indepth analysis for each one the translation process from natural language to executable language is
divided into three stages i natural language preprocessing  ii natural language understanding  and iii nat
ural language translation  the threestage division provides physical independence by separating the physical
arrangement of data from the semantics of queries 113 the techniques for the translation are shown in figure
2
i natural language preprocessing generally involves the construction of dedicated data dictionaries for the
domain using stemming extraction and synonym techniques partofspeech tagging and word segmentation are
then performed on the input natural language methods used in the preprocessing stage include traditional and
datadriven traditional approaches rely on predefined rules and grammars for domainspecific text processing
and involve techniques such as regular expressions dependency parsing and n amed e ntity r ecognition ner
datadriven approaches depend on largescale data and machine learning models for complex or variable text
processing using techniques such as word embedding and pattern linking
ii natural language understanding has rulebased machine learningbased and hybrid approaches rule
based systems can only deal with knowledge bases of specific domains whose semantic understanding processes
either define the concept of semantic accessibility or translate the nlq into an intermediate representation that
can describe the semantics and relationships in an accessible manner machine learningbased systems employ
a variety of techniques to parse text including unsupervised approaches questionandanswer supervised learn
ing statistical machine translation techniques encoderdecoder frameworks with recurrent neural networks and
combinations of deterministic algorithms and machine learning hybrid approaches combine rules and machine
learning techniques to maximize their benefits
iii natural language translation uses distinctive algorithms to map processed key semantic information to
corresponding structured language components to build the sql the database elements matched by the nlq are
placed in the appropriate locations in the select from and where parts in the event that a query involves
multiple relations it is necessary to include the join condition and the names of the participating relations in the
where and from clause respectively in the process of building an executable language of a spatiotemporal
database the query type of the input nlq is initially identified the operators required to build the executable
language are then determined according to the query type finally the key semantic information obtained from
the natural language understanding stage is integrated to form an executable language
the existing survey 2 related to nlidb focuses on the comparative analysis of the entire natural language
interface system affolter et al 2 divide nlis into four groups i keywordbased systems  ii patternbased
systems  iii parsingbased systems  and iv grammarbased systems  for each group they provide an overview
of representative systems and describe the most illustrative one in detail in addition they systematically compare
24 recently developed nlidbs on the basis of the sample world designed in the paper each system is evaluated
using 10 example questions to show the advantages and disadvantages
compared with affolter et al 2 we divide the system translation process into three steps and focus on
the comparative analysis of each step we investigate the recently developed nlidb systems and divide the
translation process into three stages i natural language preprocessing  ii natural language understanding 
and iii natural language translation  we classify natural language preprocessing techniques into traditional
and datadriven natural language understanding methods are then analyzed in three categories i rulebased 
iimachine learningbased  and iii hybrid  next we provide a comprehensive outline of the construction
process of executable languages for relational and spatiotemporal databases finally we present commonly used
benchmarks and evaluation metrics and describe the classification development and enhancement of nlidbs
3
table 1 frequently used notations
name abbreviation
natural language interface for database nlidb
natural language interface nli
natural language query nlq
natural language processing nlp
named entity recognition ner
large language model llm
firstorder logic fol
automatic speech recognition asr
sequencetosequence seq2seq
the rest of the paper is structured as follows section 2 furnishes the background concerning nlidb in
cluding natural language processing techniques executable database languages and intermediate representation
languages section 3 describes the generation of executable database languages in terms of three stages i nat
ural language preprocessing  ii natural language understanding and iii natural language translation  section
4 summarizes 11 popular benchmarks for transforming nlq into sql and 3 evaluation metrics including re
sponse time translatability and translation precision and explores the methods for generating new benchmarks
section 5 analyzes the classification development and enhancement of nlidbs section 6 discuss deep language
understanding and database interaction techniques related to nlidb including i using llm for text2sql tasks 
iigenerating natural language interpretations from sql  and iii transforming speech queries into sql  sec
tion 7 explores the open problems of nlidb and concludes the survey table 1 summarizes the frequently used
notations
2 background nlp techniques and query languages
we introduce the background related to nlidb including natural language processing techniques executable
database languages and intermediate representation languages
21 natural language processing techniques
nlp is an interdisciplinary discipline that integrates several fields such as linguistics computer science and math
ematics and aims to make computers capable of understanding processing and generating natural language text
or speech through segmentation lexical annotation and syntactic analysis nlp provides structured processing
of text to achieve semantic understanding and information extraction the application areas of nlp cover machine
translation sentiment analysis information retrieval and dialogue systems providing people with an intelligent
and convenient way of language interaction
a brief history the earliest research on natural language processing is machine translation in 1950 alan
turing proposed the ultimate test for determining the arrival of truly  intelligent  machines which is generally
regarded as the inception of the idea of nlp 96 from the 1950s to the 1970s the rulebased method was
used to process natural language which was based on grammatical rules and formal logic in the 1970s the
statisticbased method gradually supplanted the rulebased method at this juncture nlp built on mathematical
models and statistic made a substantial breakthrough and was applied to practical applications from 2008 to the
present researchers have introduced deep learning to nlp in response to the achievements in image recognition
and speech recognition
the nlp techniques commonly used in nlidbs are as follows
ipart of speech tagging refers to assigning the correct part of speech to each word in the segmented text
4
a part of speech tagging
b lemmatization
c named entity recognition
dt
alldet acl nns
moviesvbg
starringnnp
bradcompound nnp
pittin
fromcase cd
2000in
untilcase cd
2010
objobloblpunct
d dependency parsing
figure 3 processing natural language using stanford corenlp
determining whether each word is a noun verb or adjective in nlidb part of speech tagging facilitates the
identification of the grammatical roles of individual words in natural language queries leading to an accurate
comprehension of users intent taking the natural language query  all movies starring brad pitt from 2000 until
2010  as an example the result of part of speech tagging using stanford corenlp is shown in figure 3a in the
figure dt  determiner nns  plural noun vbg  the gerund or present participle of a verb nnp  singular
proper noun in  preposition or subordinating conjunction cd  cardinal number
iilemmatization is the process of reducing the different forms of a word to the original form in nlidb
lemmatization is beneficial in unifying words of various tenses and morphs in natural language queries into base
forms in order to match the content in the database taking the natural language query  all movies starring brad
pitt from 2000 until 2010  as an example the result of lemmatization using stanford corenlp is shown in figure
3b
iiinamed entity recognition is the procedure of identifying entities with specific meanings in natural lan
guage text 114 generally the recognized entities can be categorized into three primary groups entity temporal
and numeric and seven subgroups person organization location time date money  and
percent ner in nlidb enables the identification of entities involved in a natural language query to locate
the topic and scope of the query taking the natural language query  all movies starring brad pitt from 2000 until
2010  as an example the result of ner using stanford corenlp is shown in figure 3c
ivdependency parsing involves analyzing the dependencies between words in natural language sentences
a binary asymmetric relationship between words is called dependency which is described as an arrow from the
head the subject to be modified to the dependent the modifier dependency parsing in nlidb facilitates the
understanding of grammatical relationships between words in nlqs so that the structure and meaning of the
query can be accurately understood taking the natural language query  all movies starring brad pitt from 2000
until 2010  as an example the result of dependency parsing using stanford corenlp is illustrated in figure 3d
in the figure punct  punctuation obl  oblique nominal obj  object det  determiner acl  clausal modifier of
noun case  case marking
with the vigorous development of nlp technology a number of nlp tools are appearing 114 these tools
can perform basic tasks including dependency parsing named entity recognition lemmatization and part of
5
speech tagging each of which has distinct advantages and disadvantages the following is a list of the established
open source natural language processing tools
inltk is a natural language processing toolkit using python as the programming language nltk has
complete functions and realizes many of the functional components in natural language processing such as named
entity recognition sentence structure analysis partofspeech tagging and text classification 13 born for the
academic field nltk is suitable for study and research the disadvantage is that nltk has a slower processing
speed than other tools
iispacy  a commercial open source software is an industrialgrade natural language processing software
programmed in python and cython languages 45 spacy which follows nltk includes pretrained statistical
models and word vectors spacy can break down text into semantic units like articles words and punctuation and
support named entity recognition spacy is characterized by fast and accurate syntax analysis and comprehensive
functions ranging from simple partofspeech tagging to advanced deep learning
iiistanford corenlp is a tool set developed by stanford university using the java programming language
stanford corenlp supports a variety of natural languages and has rich interfaces for programming languages that
can be used without java 91 stanford corenlp is an efficient tool created by highlevel research institutions
and is widely used in scientific research and experiments but may incur additional costs in production systems
stanford corenlp may not be the best choice for industry
ivtextblob is an extension to nltk which provides an easier way to use the functionality of nltk 57
textblob supports sentiment analysis tokenization partofspeech tagging and text classification one of the
advantages is that textblob can be used in production environments where performance requirements are not too
high textblob can be applied in a wide range of scenarios especially for small projects
22 executable database languages
the output of nlidb is an executable database language and we present executable languages over relational
data rdf data and spatial data
221 query language for relational data
the standard executable query language for relational data is sql such a language is a generalpurpose ex
tremely powerful relational database language whose functions are not limited to querying but also include creat
ing database schema inserting and modifying data and defining and controlling database security integrity 29
following the establishment of sql as an international standard language numerous database manufacturers have
released sqlcompatible software including both database management systems and interfaces consequently
sql serves as the universal data access language and standard interface for most databases fostering a shared
foundation for interoperability among different database systems sql has become the mainstream language in
the database field which is of great significance
sql provides the select statement for querying data which has flexible usage and rich functionality the
select statement can perform simple singletable queries as well as complex join queries and nested queries
whose general format is
select alldistinct target column expression alias  target column expression alias
from table name or view name table name or view name select statement as alias
where conditional expression 
group by column name 1 having conditional expression 
order by column name 2 ascdesc
the purpose of the select statement is to find the tuples that satisfy the conditions specified in the from clause
which may be a basic table view or derived table according to the conditional expression in the where clause
6
the attribute value in the tuple is then selected on the basis of the target column expression in the select clause
to form the result table when a group by clause is present the output is organized by the value of column
name 1  where tuples sharing identical attribute column values are grouped together aggregation functions are
usually applied to each group when the group by clause is accompanied by a ha ving clause the output
will only include groups that satisfy the specified conditions if an order by clause is present the result table
is sorted in ascending or descending order according to the values of column name 2 
222 query language for rdf data
the complete designation of rdf is resource description framework which is a data model designed to represent
information about resources on the internet the data model typically describes a fact composed of three parts
known as a triple including i a subject  ii a predicate  and iii an object  an rdf graph contains multiple
triples rdf documents are written in xml to offer a standardized method for describing information rdf is
intended for computer applications to read and understand rather than for visual presentation to web users
sparql is a specialized query language and data retrieval protocol designed for rdf which stands for
sparql protocol and rdf query language 24 sparql is a query language over rdf graphs where the
database is represented as a collection of  subjectpredicateobject  triples although rdf data is inferential
sparql does not have an inference query function sparql is tailored for managing data stored in rdf
format enabling both retrieval and manipulation sparql is composed of the following components
 the prefix clause is employed to declare a prefix with the objective of simplifying the use of uris the
declaration of the prefix is optional
 the select clause serves the purpose of specifying the variables returned by a query
 the where clause is utilized to match data in rdf graphs the clause contains one or more triple patterns
that are employed to indicate the conditions of a query
 the filter clause is designed to conditionally filter the results of a query the clause can include boolean
expressions to limit the set of results matched by the where clause
the fundamental query types of sparql are as follows 101
select query is the most frequently used type of query whose function is to select variables and return a
result set a table is typically generated as the outcome of a select query which includes the variables that
meet the querys criteria along with their corresponding values
construct query is used to generate a new rdf graph by utilizing the query pattern in contrast to
tabular results the construct query produces an rdf graph that is constructed from the matching data of the
query pattern
ask query is designed to ascertain the existence of rdf data that satisfies the query pattern the ask query
provides a response in the form of a boolean value true or false to indicate the presence or absence of a match
describe query is employed to obtain the detailed description of resources the description is determined
by the query engine and typically consists of triples that are directly related to the resource
each query type employs a where clause to limit the scope of the query nevertheless in the context of
describe queries the inclusion of a where clause is not mandatory to illustrate the subsequent query
retrieves people from the data set who are above the age of 24
prefix info httpsomewherepeopleinfo 
select resource
where

resource infoage age 
filter age 24

7
table 2 operators to query spatial data
operator signature meaning
distance point lineregion pointlineregion real compute the distance between two spa
tial objects
direction point pointreal compute the direction between two
points
size line real return the length of a line
area region real return the area of a region
intersects line region lineregion bool true if both arguments intersect
intersection point lineregion pointlineregion t where
t is point if point is one of the arguments otherwise
t is the argument having the smaller dimensionintersection of two spatial objects
distancescan rtree relation objectintstream compute the integer knearest neigh
bors for a query object
in this query the   symbol represents a variable followed by the variable name the middle of the  
symbol is the uri that describes the resource address the  infoage  in the above query is a uri shorthand
and stands for  httpsomewherepeopleinfo age the filter keyword is employed to impose limitations
on the outcomes that are retrieved in addition rdf is semistructured data and different entities in rdf may
have distinct properties sparql is capable of querying information that exists in rdf however when querying
information that does not exist sparql does not show a failure and does not return any results the optional
keyword can then be used to signify that the query is optional indicating that the query will return a result if the
entity has the attribute and a null value otherwise the filter keyword can also be used in conjunction with the
optional keyword
223 query language for spatial data
the increasing reliance on geographic information systems in many aspects of peoples production and life has
led to a significant increase in the demand for spatial data query in all walks of life the popularity of spatial
applications has brought great attention to spatial databases 55 in databases fundamental data types utilized for
the representation and manipulation of spatial objects include point line and region the common operators to
query spatial data are shown in table 2
mature systems for storing and managing spatial data include esris arcgis postgis google earth engine
grass gis and secondo 56 as an illustration secondo is a freely available platform created for
the purpose of organizing and examining spatial and temporal data the basic commands of secondo are as
follows
query value expression the command evaluates the given value expression and subsequently displays
the result to the user
letidentifier value expression the command initially evaluates the provided value expression in a
manner analogous to the preceding command in contrast to the previous command the results of the evaluation
are not immediately displayed but rather stored in an object named identifier  if the object already exists in the
database the command will result in an error
delete identifier the command removes the object named identifier from the current database and is
typically utilized in conjunction with the second command
when an expert or system developer writes the executable query language for secondo one needs to com
prehensively understand the intricate relationship between data flow and operators the rel2stream operator trans
forms a relation into a stream of tuples as shown in figure 4 the stream2rel operator in contrast converts a
stream of tuples into a relation among the fundamental operators of secondo the filter operator is the most
8
a stream of tuples
city namestring geodataregionname geodata
nanjing
zhenjiang
yangzhou
nanjing          zhenjiang               y angzhou          
rel2stream
stream2rel
a stream of tuplesfilter
name  nanjingnanjing        
figure 4 functions of the operators rel2stream stream2rel and filter in secondo
frequently utilized similar to the select keyword in sql the function of the filter operator is to extract in
formation from data that satisfies specific conditions the select keyword operates on a twodimensional table
structure to query filter and project data by specifying columns and conditions the filter operator works on a
stream of tuples followed by a filter condition the tuples that match the condition are then collected and out
putted as a stream for example the following executable language will output all information about nanjing in
the relation cityin secondo
query city rel2stream filter name  nanjing stream2rel
during the execution of the query the rel2stream operator first transforms the relation cityinto a stream of tuples
then the filter operator extracts the tuple named  nanjing  from the stream and finally the stream2rel operator
converts the tuple into a relation from the stream
23 intermediate representation languages
the intermediate representation language in nlidb is designed to accommodate the semantic discrepancies and
diversity between natural language and executable database language thus improving the translation accuracy
flexibility and maintainability of the system 7 the intermediate representation serves as a translator between
natural language and executable language mapping complex natural language structures to a unified semantic
representation for the purpose of efficient subsequent query processing and execution by decoupling nlq from
the underlying database query language the intermediate representation language makes the nlidb system flex
ible portable and adaptable to various database types and query requirements the design of the intermediate
representation considers several factors such as
i the intermediate representation should convey the query request that the user wishes to submit to the
database rather than the full meaning of the users input
ii to facilitate subsequent translation into the executable language of the database the intermediate repre
sentation should be unambiguous
iii to make redevelopment easier the intermediate representation should be reusable
popular intermediate representations are parse trees 78 firstorder logic 121 oql 113 query sketch
153 semql 53 and natsql 50
parse tree the syntactic structure of a query in natural language is closely tied to the design of a parse tree
the tree structure is typically applied to represent the hierarchical and structural relationships of the query each
node in a parse tree indicates a grammatical unit eg phrase word group and vocabulary while edges indicate
grammatical relations eg modification and conjunction between these grammatical units the nodes and edges
on the parse tree can be labeled with semantic information to identify the semantic roles and constraints present
in the query providing important information for subsequent query processing
firstorder logic when transforming an nlq into f irsto rder l ogic fol words and phrases in the natural
language are first mapped to predicates constants variables and logical connectives in fol to represent entities
9
attributes and relations in the query subsequently on the basis of the syntactic structure of the nlq the syntax
tree or syntax graph of the fol representation is constructed to capture the semantic relations and logical struc
tures in the query finally the topics conditions and operations in the query are identified and converted into
logical expressions in fol to denote the constraints and operational requirements of the query
when converting the natural language query  find the names and salaries of all employees older than 30 
into a firstorder logic representation predicates and constants are defined as follows
employee xxis an employee
name x n the name of employee xisn
agex a the age of employee xisa
salary x s the salary of employee xiss
the query condition is expressed as xemployee xagex aa  30 the query result is expressed
asn sname x nsalary x s the complete firstorder logic representation is obtained by combining
the condition and result of the query
xemployee xagex aa  30 n sname x nsalary x s
oql is built on an ontology knowledge graph where words and phrases in natural language queries are
associated with concepts attributes and relations within the ontology knowledge graph the semantic information
of natural language queries is captured through semantic representations and query patterns to effectively interact
with the database oql grammars permit the expression of complex aggregation union and nested queries oql
queries operate upon individual concepts with each concept being assigned an alias as specified in the from
clause of the query
query sketch is a form of sql with natural language hints taking the nlq  find the number of papers in
oopsla 2010  as an example the query sketch is as follows
select countpapers from papers where   oopsla 2010
in the query sketch the symbols   and   represent an unspecified table and an unspecified column respec
tively hints for the corresponding gaps are indicated by words enclosed in square brackets as an illustration the
first hint in the sketch suggests that the symbol   has a similar semantic meaning to the term papers 
semql is designed as a tree structure that not only constrains the search space during synthesis but also main
tains the same structural characteristics as sql in semql queries the group by  ha ving and from clauses
in sql are removed and the conditions from the where and ha ving clauses are consistently represented in
the filter subtree furthermore in the later inference phase domain knowledge is utilized to deterministically
infer implementation details from semql queries for instance the columns included the group by clause of
sql are typically present in the select clause
natsql retains the core functionality of sql while streamlining the structure of sql to align more closely
with the syntax of natural language natsql keeps only the select where and from clauses omitting
the join on ha ving and group by clauses additionally natsql does not require nested subqueries or
aggregation operators and employs a single select clause in the case of the natural language query  which
film has more than 5 actors and less than 3 in the inventory  the sql and natsql are as follows
sql select t1title from film as t1 join film actor as t2 on t1film id  t2film id group by
t1film id having count 5 intersect select t1title from film as t1 join inventory as t2 on
t1film id  t2film id group by t1film id having count 3
natsql select filmtitle where countfilm actor 5 and countinventory 3
10
table 3 natural language preprocessing for nlidbs
nlidb year underlying datatype
segmentation
part of speech
ner
dictionary generation
regular expression
dependency parsing
word embedding
pattern linking
precise 107 2003 relational data 
querix 69 2006 ontology  
questio 27 2008 ontology  
ganswer 60 2013 rdf data 
means 1 2015 rdf data  
nl2cm 6 5 2015 rdf data  
nl2tranquyl 16 2015 relational data 
athena 113 2016 relational data  
sqlizer 153 2017 relational data 
tequila 64 2018 rdf data 
mynlidb 28 2019 relational data  
irnet 53 2019 relational data 
nlmo 145 2020 moving objects 
nalmo 144 143 2021 moving objects 
nalsd 88 2023 spatial data 
nalspatial 89 2023 spatial data 
xdbtagger 132 2024 relation data  
3 generation of executable database languages
the generation of executable database languages can be divided into three stages i natural language preprocess
ing ii natural language understanding  and iii natural language translation  in stage i the system performs a
preliminary analysis of the raw natural language query in order to prepare for the subsequent stage of natural lan
guage understanding in stage ii the system performs semantic parsing and understanding of the preprocessed
natural language query to extract the semantic details and intent of the query in stage iii the system converts
the comprehended natural language into a language that can be executed within the database
31 natural language preprocessing
prior to the semantic understanding and translation of natural language queries preprocessing is performed using
traditional and datadriven methods in order to preprocess natural language queries the recently developed
nlidbs utilize techniques as illustrated in table 3
the preprocessing process of many nlidbs commences with the construction of a dedicated data dictionary
for the domain the extraction process of domain knowledge exerts a profound influence on the portability of the
system in addition the semantic parsing component needs to accurately comprehend nlq with the assistance
of the dictionary and the extraction process of domain knowledge will impact the availability of the nlidb the
primary goal of the extraction technique is to minimize the burden on system users while enhancing the capacity
to automatically generate a dictionary the extraction process is primarily reliant on stemming and synonym
techniques the system then needs to perform word segmentation and partofspeech tagging on the input natural
language this process necessitates the utilization of natural language processing tools when choosing the tool
the high accuracy of the segmentation and partofspeech tagging results should be considered first followed
by the speed of processing furthermore the query must be oriented to database information and the relevant
11
table 4 rules for parsing natural language queries
rules typical nlidbs
parse tree precise 107 nalix 84 85 querix 69 danalix 81 ganswer 60
nalir 78 77 79 nl2tranquyl 16 unnamed method 65 mynlidb
28
ontology questio 27 athena 113 finesse 63 unnamed method 41 cnl
rdfquery 58 athena 115 unnamed method 4
semantic graph unnamed method 168 means 1 nl2cm 6 5
template matching sqlizer 153 unnamed method 3 logicalbeam 11
pattern matching soda 15
contextfree grammar tr discover 121
semantic grammar unnamed method 49
statements used in the query request are closely related to the database to be used therefore partofspeech
tagging is often employed in conjunction with named entity recognition and data dictionary
traditional preprocessing methods rely on predefined rules and grammars involving techniques including
ner regular expressions and dependency parsing nlmo performs segmentation and entity recognition using
a natural language processing toolkit spacy and sets regular expressions for temporal information extraction
athena utilizes the timex annotator to detect all temporal intervals mentioned in the text and the stan
ford numeric expressions annotator to pinpoint all tokens containing numerical values athena employs the
stanford dependency parser to identify the dependency relationship in the context of the group by clause
precise utilizes the charniak parser for the precise parsing of questions and the extraction of token relation
ships from the resulting parse tree nl2cm employs dependency parsing and partofspeech tagging techniques
nl2tranquyl analyzes the input natural language using the stanford parser resulting in constituency and
dependency parses
datadriven preprocessing methods depend on largescale data and machine learning models and the tech
niques used include word embedding and pattern linking word2vec and glove are word embedding models
that are able to represent words as points in a sequential vector space thereby capturing the semantic relation
ships between words these vectors can be employed for calculating semantic similarity and extracting features
xdbtagger utilizes a pretrained word embedding model to convert tokens into a 300dimensional vector repre
sentation irnet performs schema linking by connecting the natural language with the database schema aiming
to identify the specific columns and tables referenced in the natural language the columns are then assigned
different types according to the manner mentioned in the question
32 natural language understanding
three principal technical approaches to understand natural language are i rulebased  ii machine learning
based  and iii hybrid  based on the techniques the process of natural language understanding for the recently
developed nlidbs is summarized we provide three timelines describing the research on rulebased machine
learningbased and hybrid approaches as shown in figure 5
321 rulebased methods
the semantic parsing of mature nlis is predominantly based on rules the systems require specific rules to parse
natural language queries including parse tree ontology semantic graph template matching pattern matching
contextfree grammar and semantic grammar as shown in table 4 rulebased systems can only deal with knowl
edge bases in fixed domains and are generally not portable to other knowledge bases in order to enhance the
accuracy of semantic understanding systems are typically constrained by limitations in their ability to support
12
2014nalir
2015nl2cm
2016athena
2017nlqa
2018tequila
2020athena
2021exaqtnl2tranquyl dialsql sqlizer2003precise
2005nalix
2007danalix
2006querix
2009quick
to be continued 
2019mynlidbeznl2sql2008questio
2013ganswertr discovermeans
sparklis
nlmoa rulebased methods
2020r y ansql
2022autoquery
2021v aluenetspcnn
2017seq2sql
2019irnet
2018syntaxsqlnetcombine
2023dte
2024sv2sqliknowsql spatialnli dialsqlbiber t sqldbt aggermie
b machine learningbased methods
2022v eezoo
2021nalmo
2018t ypesql
2023gar
2024xdbt aggercatsqlgensqlnalspatialnalsd
c hybrid methods based on rule and machine learning
figure 5 timelines of the research progress of techniques for understanding natural language
natural language features such as grammar and vocabulary 144 precise 107 elucidates the notion of se
mantic tractability and delineates a specific subset of natural language that can be accurately converted into sql
however natural language queries that cannot be processed semantically will be rejected by precise nalix
84 85 restricts natural language queries to a regulated subset according to a predetermined grammar danalix
81 is constructed on nalix and employs domain knowledge for query translation domain knowledge is en
capsulated within a collection of regulations that map terms with domain meaning in the parse tree to terms that
can be understood by a generic system such as nalix the domain adapter within danalix assesses the current
domain expertise and modifies the parse tree with related rules nalir 78 77 79 identifies nodes within the
language parse tree that have the potential to correspond to sql components resulting from the preprocessing
step and represents semantic coverage as a subset of the parse tree such a tree explicitly corresponds to sql
and serves as a query tree which mediates between nlq and sql to comprehend the challenge of integrating
individual and collective knowledge nl2cm first uses rdf to represent individual and general knowledge indi
vidual expression detectors are then used to distinguish between individual and general query components which
are created through a declarative selection schema in conjunction with a specialized vocabulary athena uses
domainspecific ontology to transform the natural language input into an intermediate language on the ontology
the intermediate language is then used to describe the semantic entities in the domain as well as the relationships
between the entities ontology provides richer semantic information than relational schema including inheritance
13
and membership by reasoning about the ontology athena demonstrates the capability to effectively discern
and capture the intentions of users however athena is highly sensitive to changes and interpretations of user
queries 99 both the nlidb system described in the paper 116 and athena 115 are extensions of
athena they combine linguistic analysis with deep domain reasoning to translate complex join and nested
sql nl2tranquyl 16 is a system designed for the planning of journeys within a complex multimodal
transportation system taking into account a number of constraints including the minimization of journey time
distance and cost nl2tranquyl utilizes the ontology comprising a range of concepts to store and model re
lated information and generates knowledge graphs to determine the relationships between them to discover and
process temporal information in nlq tequila decomposes the detected temporal problems and rewrites the
generated subproblems these papers 60 168 utilize the stanford parser to generate dependency trees and ex
tract semantic relations from the parsed data subsequently a semantic query graph is constructed by connecting
these semantic relations to depict the users query intent querix 69 examines the syntax of natural language us
ing a syntactic analyzer which is only effective when the natural language components are complete incomplete
components may result in inaccurate results which could compromise the accuracy of the final results
an optimal nlidb enables users to formulate intricate queries on the database system and retrieve precise
information with minimal exertion consequently a number of systems incorporate user interaction during the
process of comprehending semantics nalix and dialsql 54 adjust the query during following user engage
ments to revise the parse tree however the revision frequently necessitates a high number of user interactions
danalix acquires domain knowledge through the interaction that occurs between the user and the system in an
automated manner in addition to elucidating the user on the query processing procedure nalir also presents a
spectrum of interpretations for the user to select from thus alleviating the users need to address potential misun
derstandings nalir is capable of detecting the parse tree thereby enabling users to modify the parse tree directly
rather than reformulating the natural language query nalir can provide recommendations to users for revising
their queries in instances where the natural language queries fall beyond the semantic boundaries quick 162
improves user interactions by utilizing keyword search to enrich the expressiveness of semantic queries in practi
cal application quick assists users in determining the specific intent behind natural language through a series of
iterative refinement steps following the initial submission of a keywordbased question nlqa 166 enhances
the user interaction component in order to more effectively address the issue of ambiguity sparklis 46 em
ploys a sequential process consisting of three stages in order to guarantee the thoroughness of user input during
searches for concepts entities or modifiers while interacting with the system may result in the user feeling con
strained slowed down and less natural when entering a query sparklis provides guidance and safety through
intermediate answers and suggestions 2 in order to reduce user involvement during the disambiguation process
athena utilizes the extensive semantic data within the ontology to produce a prioritized list of explanations
and employs a ranking algorithm that is intuitive and relies on ontology metrics to determine the most appropriate
explanation
322 machine learningbased methods
as the usage of statistical learning methods continues to expand there has been a growing interest in conducting
semantic analysis on sentences through a variety of forms of supervision pasupat and liang 102 employ
questionandanswer format to provide guidance in responding to intricate natural language queries presented
within semistructured tables the paper 105 represents the inaugural attempt to develop a semantic parsing
model through unsupervised learning 66 artzi and zettlemoyer 8 solicit feedback during the conversation to
determine the meaning of the users statements in a domain where no training examples are available wang et al
146 demonstrate the successful development of a semantic parser their approach comprises two key elements
ia builder and ii a domaingeneral grammar wong and mooney 150 utilize statistical machine translation
technology for the purpose of accomplishing semantic parsing tasks
14
table 5 nlidbs with encoderdecoder frameworks
nlidb year encoder decoder
dialsql 54 2018 encode dialogue history using
rnn networksdecode errors and candidate se
lections
syntaxsqlnet 159 2018 tableaware column encoder syntax treebased decoder
unnamed method 87 2020 encode nlqs and table headers
using xlnet 155the parsing layer splices the vec
tor
valuenet 19 2021 extension of irnets encoder lstm architecture and multiple
pointer networks
unnamed method 30 2021 the encoder of lstm the decoder of lstm
mie 138 2021 multiintegrated encoder with
three integrated modulesno decoder
autoquery 100 2022 the encoder of ratsql 137 smbop 112
stamp 51 2023 the encoder of t5 the decoder of t5
unnamed method 154 2023 the encoder of transformer the decoder of transformer
in recent times there has been a growing utilization of encoderdecoder frameworks that rely on recurrent
neural networks for semantic parsing as demonstrated in table 5 many systems combine machine learning and
deterministic algorithms to generate structured languages 93 this method allows the direct acquisition of the
correlation between natural language and the semantic representation eliminating the need for an intermediate
representation like a parse tree 66 mapping natural language directly to the semantic representation can reduce
the dependence of rulebased semantic parsing models on preset vocabulary templates and handgenerated fea
tures machine learningbased models are not limited to specific knowledge bases or logical formal expressions
thus enabling the implementation of natural language interfaces that support crossknowledge bases or cross
languages wang et al 140 142 propose a crossdomain nli which translates the marked natural language
into the intermediate representation of the target query type by building a crossdomain multilingual seq uence
tosequence seq2seq model symbols inserted into the natural language query are utilized to substitute the data
elements present in the intermediate query however this method is a supervised machine learning model whose
effectiveness is closely related to the quality of the training data to ensure the accuracy of semantic understand
ing a substantial quantity of training data must be provided to the model a number of researchers employ a
synthetic data generator as a solution to the challenge of having a restricted amount of training data available
the paper 159 introduces syntaxsqlnet which can generate nlq data sets for crossdomain sql singletable
operations solely as a means of augmenting the training set the method outlined in the paper 149 encompasses
singletable and multitable join queries of sql and can be utilized as either an augmentation or as a standalone
training data set in terms of model training the rulebased method is more effective than the neural network
based method which requires more training parameters and takes longer to establish the model consuming more
memory space
one of the earliest examples of machine learningbased systems is demonstrated in the paper 161 this work
utilizes a deterministic shiftreduce parser and develops a learning algorithm called chill to learn the governing
rules of parsing on the basis of inductive logic programming techniques the corpus is trained using the chill
method to build the parser instead of learning dictionaries this approach assumes that a dictionary is created
in advance that pairs words with semantic content rather than grammar the paper 163 translates the mean
ing of natural language sentences into lambda calculus encoding the paper 163 outlines a learning algorithm
whose input is a collection of sentences identified as lambda calculus expressions and applies the method to the
task of learning nlidb to build a parser while providing considerable flexibility encoderdecoder frameworks
frequently lack the ability to interpret and understand combinations of meaning 66 the method employed by
cheng et al 25 involves the construction of the intermediate structure in two stages which facilitates a com
prehensive understanding of the models learning process similarly the paper 39 also produces an intermediate
15
template that presents the final output in a preliminary format thereby facilitating the subsequent decoding pro
cess yin and neubig 157 address the issue of insufficient training data by incorporating explicit constraints
for decoders through the utilization of target language syntax the approach enables the model to concentrate
on parsing directed by established grammar rules xiao et al 151 utilize the grammar model as prior knowl
edge requiring the creation of a derivation tree while adhering to the constraints imposed by the grammar the
approach in the paper 74 can significantly outperform the seq2tree model from the aforementioned paper 38
by verifying that the decoders forecasts adhere to the type constraints outlined in the type constraint grammar
this suggests that satisfying type constraints and good formatting are equally important when generating logical
expressions spatialnli 80 141 is a natural language interface for the spatial field that employs the seq2seq
model to understand the semantic structure of natural language while utilizing an external spatial understanding
model to identify the meaning of spatial entities subsequently the spatial semantics learned from the spatial
understanding model are integrated into natural language problems thereby reducing the necessity of acquiring
specific spatial semantics spatialnli represents a pioneering system that integrates an external spatial semantic
comprehension model to optimize the effectiveness of the principal seq2seq model the paper 129 uses a tree
model to analyze the target entity in natural language and employs a treestructured lstm to understand the
problem the paper 62 adjusts the neural sequence model to directly convert natural language into sql thus
circumventing the intermediate query language representation then the user feedback is utilized to mark error
queries which are directly used to improve the model the complete feedback loop does not necessitate the use
of any intermediate language representation and is not limited to a specific domain this method offers the benefit
of enabling the rapid and straightforward construction of a semantic parser from scratch and the performance of
the parser improves as user feedback increases the encoder of valuenet 19 is an extension of the encoder of
irnet 53 receiving not only details regarding the database schema but also extracted value candidates from the
database content
323 hybrid methods based on rule and machine learning
hybrid methods integrate rules and machine learning techniques to capitalize on the respective strengths of each
thereby enhancing the ability of the system to understand and process nlqs 72 table 6 enumerates the rep
resentative systems that employ the hybrid approach hybrid approaches are highly flexible and adaptable as
they can utilize rules for tasks with explicit rules as well as machine learning models for complex and ambiguous
semantic tasks in addition hybrid methods can flexibly incorporate new rules or train new machine learning
models as needed to accommodate the requirements of diverse domains and tasks and are highly scalable 135
typesql 158 like sqlnet 152 is built on sketches and formats translation tasks as slotfilling problems
the difference is that typesql employs type information to enhance the understanding of entities and numbers
in nlqs typesql assigns a type to each word such as entity column number and date within the knowledge
graph subsequently two bidirectional lstm networks are utilized to encode the words in the nlq with the
corresponding column names and types finally the lstm output hidden states are leveraged to forecast the
slot values within the sql sketch nalmo is a natural language interface for moving objects to understand
nlqs nalmo employs an entity extraction algorithm to obtain entity information including time location and
the number of nearest neighbors a preconstructed corpus is then trained using lstm to determine the query
type veezoo 75 uses a range of techniques including temporal expression parsing entity linking and relation
extraction to identify key information in nlqs the information is then extended and combined using predefined
rules to generate multiple candidate intermediate representations finally veezoo utilizes a machine learning
model to score these intermediate representations in order to select the most probable interpretation of the nlq
the process of data preparation in gar 42 commences with a collection of sample sqls that are tailored to a
specific database for a given nlq gar searches for the nlqs generated during data preparation and employs
a learningtorank model to identify the most relevant query which is then used to obtain the translation result
16
table 6 nlidbs based on rules and machine learning techniques
nlidb year rule machine learning technique
unnamed method
522012 generate candidate sqls via rules and
heuristic weighting schemesreorder candidate sqls using the svm
sorter
typesql 158 2018 assign a type to each word to under
stand the entityencode using bidirectional lstm
nalmo
144 1432021 semantic grammar and template
matchingidentify the query type using lstm
veezoo 75 2022 knowledge graph score intermediate representations using
machine learning models
gar 42 2023 parse tree find the matching expression for nlq
using a learntorank model
gensql 44 2023 capture the structure of the database
with sample sqlsfind the matching expression for nlq
using a learntorank model
catsql 48 2023 template matching the decoder of transformer train the
model using adam 71
nalspatial 89 2023 semantic grammar and template
matchingidentify the query type using lstm
nalsd 88 2023 semantic grammar and template
matchingidentify the query type using lstm
xdbtagger 132 2024 semantic graph bidirectional recurrent neural network
the learningtorank model learns to rank the semantic similarities from nlqs to generated nlqs and then finds
the best matching expression for a given nlq gensql 44 a generative nlidb utilizes a given example sql
from the database eg from query logs to comprehend the unique structure and semantics of a given database
thereby guaranteeing precise translation outcomes the fundamental model used in gensql for converting nat
ural language to sql is gar catsql 48 is a method for the generation of sql that makes use of sketches in
addition semantic constraints are merged into the neural networkdriven sql generation procedure for semantic
refinement catsql sketches are templates with keywords and slots catsql employs a deep learning algorithm
to populate vacant slots in order to generate the ultimate sql the deep learning algorithm is developed to focus
on the generation of essential nlqrelated information with the objective of filling the gaps without requiring the
explicit generation of keywords like select from and where
hybrid approaches based on rules and machine learning offer several advantages including flexibility accu
racy and scalability nevertheless such approaches present certain challenges such as complexity dependence
on data and tuning difficulties 68 hybrid methods require the simultaneous management and maintenance of
rule engines and machine learning models including rule definition feature engineering and model training and
thus have high complexity 52 furthermore the rules and machine learning models utilized in hybrid approaches
may encounter parameter tuning problems which necessitate a significant investment of time and effort for opti
mization and debugging thus increasing the costs associated with the development and maintenance of the system
during the design and implementation of natural language interfaces it is essential to take a comprehensive view
of the advantages and challenges involved and to make tradeoffs and choices in accordance with the specific
needs
33 natural language translation
the natural language translation stage employs the semantic information derived from the natural language un
derstanding stage subsequently integrating the underlying structure of the database to transform the input natural
language into the corresponding executable language a prevalent approach for translation is to employ com
plex algorithms and machine learning models to generate structured language based on the domain knowledge
of the underlying database and the semantic representation of natural language 83 most established nlidbs
17
parsed nlq
number of  
query relations
database elements database elementsjoin conditions and  
involved relations
select  from where select  from where where from
sql1 1figure 6 general build process for sql
construct queries by query combination mapping key information expressed in natural languages to correspond
ing components in structured languages we examine the process of natural language translation in recently
developed nlidbs and summarize the general construction process of executable languages for relational and
spatiotemporal databases
the general build process for sql is illustrated in figure 6 and further elaborated in the subsequent two cases
i when querying a single relation it is only necessary to place the database elements matched by nlq in the
correct positions in the select from and where parts respectively then sql can be composed directly
ii when querying multiple relations the join condition and the names of the participating relations need to
be included in the where and from clauses respectively additionally it is necessary to determine whether
the join path is unique if only one join path is available sql can be generated directly otherwise a query
is typically generated for each possible join path and then the most probable one is selected according to the
corresponding algorithm
in recent years there has been significant interest in nli for spatiotemporal databases 26 temporal and
spatial concepts are derived from the natural language description using symbolic representations in order to depict
spatiotemporal features and their relationships 14 106 due to the particularity and expressiveness of spatio
temporal problems executable query languages over spatiotemporal databases are quite different from sql
consequently the method employed for the construction of sql cannot be directly applied to the generation of
executable languages over spatiotemporal databases the general process for the construction of an executable
language for a spatiotemporal database is shown in figure 7 preliminary parsing of the input natural language
query is performed to obtain semantic information including key entities and query types subsequently the
operators necessary to construct the executable language are determined according to the type of query finally
key entities and operators are combined according to certain rules to compose an executable database language
taking the range query over spatial data as an example the key entities involved include spatial relations and
locations the operator intersects will return all objects in the relation that intersect the location if the spatial
attribute of the relation and the data type of the location are both lineorregion  conversely the operator intersects
will return all objects in the relation that lie within the location if the spatial attribute of the relation is point and
the data type of the location is region 
different dbmss and structured languages offer a range of clauses and operators for various queries athena
employs a mapping strategy that correlates the ontology with the database schema in order to convert the interme
diate query language utilized in the ontology into sql the system described in the paper 63 extends athena
to access multiple structured backends which is achieved through the automated translation of the intermediate
18
parsed nlqkey semantic  
information
query typekey e ntities
operatorquery  
combinationexecutable languagemapping rulesfigure 7 general construction process for executable languages over spatiotemporal data
query language into the specific structured query language utilized by these backend stores nlpqc 124 is
capable of processing queries formulated using predefined domainspecific templates querix selectively isolates
specific elements from the syntactic tree in order to align acquired knowledge with the knowledge base thereby
obtaining the final outcome nl2cm leverages crowd intelligence by converting audience queries into oassis
ql an extended version of sparql nalir utilizes the structure of the uservalidated query tree to produce
the suitable structure in the sql statement and determine the join path in order to ascertain whether the target
sql contains aggregate functions or subqueries nalir initially identifies function nodes or quantifier nodes
in the query tree and subsequently generates sql statements based on the identified conditions the paper 52
employs lexical dependencies found in the question and database metadata to build a reasonable collection of
select where and from clauses that enhance the quality of meaningful joins the paper 52 combines
clauses through a rule and heuristic weighting scheme and then generates a sorted list of candidate sqls demon
strating that full semantic interpretation can be avoided by relying on a simple sql generator this method can
be employed iteratively to address intricate issues necessitating nested select commands finally this paper
52 applies the reranker to reorder the list of questions and sql candidate pairs with the aim of enhancing the
accuracy of the system tequila uses a standard kbqa system to evaluate the subquestions from the se
mantic understanding part individually the results of the subquestions are then combined with the reasoning
to calculate the answer to the full question nl2tranquyl translates english requests into formal tran
quyl 17 queries using the knowledge graph generated by the semantic comprehension component the traffic
query language tranquyl for travel planning follows the conventional sql structure of  select from
where  nalmo supports five distinct types of moving object queries including i time interval queries  ii
range queries  iii nearest neighbor queries  iv trajectory similarity queries  and v join queries  in the query
translation process nalmo first constructs a corpus comprising the five query types collectively referred to as
moq then the lstm neural network is used for training resulting in a model that is capable of accurately iden
tifying the specific type of query finally the appropriate operators are selected according to the query type and
the entity information extracted by the semantic parsing component is combined to build the executable language
for secondo
4 nl2sql benchmarks
we presents 11 frequently used benchmarks for transforming nlq into sql and three evaluation metrics explor
ing the methods for generating new benchmarks
41 existing benchmarks
the details of nlq and executable language pairs for common domains are presented in table 7 the majority
of existing benchmarks are utilized in the domain of relational databases to transform n atural l anguage query into
sql nl2sql the comparison of fields and types of sql supported by the benchmarks for nl2sql is shown
in table 8 we can conclude that geoquery and spider support the most types of sql while wikisql supports
19
table 7 examples of nlq and executable language pairs for common domains
domain examples of nlq and executable language pairs
relational databasenlq how many cfl teams are from york college
sql
select count cfl team from cfldraft where college  york
spatial domainnlq1 what is the population of san antonio
lambda expression
answerapopulationbaconstbcityidsan antonio
nlq2 could you tell me what parks are in the center
executable language
query park feed filter geodata ininterior center consume
moving objectsnlq where did the train 7 go at 8am
executable language
query trains feed filter id  7 filter trip present const instant value 202011
20800 extend pos val trip atinstant const instant value 20201120800
project id line pos consume
trip planningnlq can i walk to 300 w humboldt blvd by 400 pm
tranquyl
select from all tripsusercurrent location 300 w humboldt blvd as t
with modes pedestrian with certainty 78 where endst 400 pm
minimize durationt
crowd miningnlq what are the most interesting places near forest hotel buffalo we should visit
in the fall
oassisql
select v ariables x where x instanceof place x near for
esthotel buffalo nysatisfying x haslabel interesting order by
descsupport limit 5 and  visit x  in fall with support
threshold  01
only the simple select query the queries in wikisql and spider cover a multitude of domains in recent years
geoquery mas wikisql and spider have been employed with considerable frequency
the details of popular benchmarks are shown in table 9 early data sets consist of only one domain and one
database such as atis restaurant and geoquery in contrast the latest data sets for example wikisql and
spider contain multiple domains and several databases with larger and more diverse nlqs and sqls
iatis airline t ravel i nformation s ystem 108 is a classical data set with a relatively old age having
been introduced by texas instruments in 1990 atis is built on the relational database official airline guide
comprising 25 tables and 5871 queries written in english the queries pertain to details regarding flights ticket
prices destinations and services available at airports the queries in atis are for the air travel field including
join queries and nested queries but no grouping and sorting queries the average length of nlqs and sqls
in atis is approximately 11 and 67 words respectively each query operates on an average of six tables an
example query is as follows
q1what aircraft is used on delta flight 1984 from kansas city to salt lake city
iirestaurant 127 comprises a vast collection of dining establishments located in northern california
storing restaurant names locations features and travel guide ratings the benchmark contains 250 questions
about restaurants food types and locations an example query is as follows
q2where is a good chinese restaurant in palo alto
iiigeoquery 128 consists of 8 tables and 880 natural language queries in the us geographic database the
queries in geoquery are designed for the geographic domain including join queries nested queries grouping
20
table 8 comparison of benchmarks for nl2sql
benchmark
select query
group query
sort query
join query
nested queryfields involved usage in papers
atis   air travel 62 47 103 104 120
restaurant   restaurant 127 107 81 80
geoquery  geography 127 128 107 163 81 52
113 62 47 80 104 115
120 42 141
mas   academic 77 113 153 35 9 115 131
132
scholar   academic 47
imdb   internet movie 153 9 58 131 132
yelp   business review 153 9 131 132
wikisql  multiple fields eg state
college manufacturer167 54 158 156 87 142
48 51 125
paraphrasebench  medical 133
advising   university course 47
spider  138 different fields eg
car stadium country160 53 156 115 19 50 92
131 42 43 48 51 125
table 9 details of popular benchmarks
benchmark year queries tables domains covered
atis 108 1990 5871 25 single field
restaurant 127 2000 250 3 single field
geoquery 128 2001 880 7 single field
mas 77 2014 196 17 single field
scholar 62 2017 816 10 single field
imdb 153 2017 131 16 single field
yelp 153 2017 128 7 single field
wikisql 167 2017 80654 24241 multiple fields
paraphrasebench 133 2018 290 1 single field
advising 47 2018 4387 15 single field
spider 160 2018 10181 1020 multiple fields
queries and sorting queries the average length of nlqs and sqls in geoquery is about 8 and 16 words
respectively additionally each query operates on an average of one table although the queries are relatively
brief in length they are highly composable with nearly half of the sql containing at least one nested subquery
one of the english queries is as follows
q3what is the largest city in states that border california
ivmas 77 is generated from the microsoft academic search database which stores information such as
academic papers authors journals and conferences the source of nlqs in mas is the logical queries that are
capable of being articulated in the search interface of the microsoft academic search platform the fields of mas
and scholar are both academic in nature but exhibit distinct patterns one english query is as follows
q4return authors who have more papers than bob in vldb after 2000
vscholar 62 consists of 816 nlqs for academic database search that are annotated with sql the average
length of nlqs and sqls in scholar is approximately 7 and 29 words respectively each query operates on an
21
table 10 query categories and examples for paraphrasebench
category example queries
naive what is the average length of stay of patients where age is 80
syntactic where age is 80 what is the average length of stay of patients
morphological what is the averaged length of stay of patients where age equaled 80
lexical what is the mean length of stay of patients where age is 80 years
semantic what is the average length of stay of patients older than 80
missing information what is the average stay of patients who are 80
average of 3 tables iyer et al 62 provide a database for performing these queries which includes academic
articles journal details author information keywords citations and utilized datasets one of the english queries
is as follows
q5get all author having data set as dataset type
viimdb and yelp 153 are generated using data from the internet movie database and business review
database respectively the nlqs are obtained from coworkers of the authors of the paper 153 who are only
aware of the types of data available in the database and not the underlying database schema
vii wikisql 167 introduced in 2017 is a comprehensive and meticulously annotated collection of natural
language to sql mappings and currently represents the most extensive data set for nl2sql wikisql contains
sql table instances extracted from 24241 html tables on wikipedia and 80654 natural language queries each
accompanied by an sql wikisql comprises genuine data extracted from the web with queries involving a
multitude of tables but the queries do not involve complex operations such as group by and multitable union
queries the majority of questions in wikisql are between 8 and 15 words in length most sqls are between
8 and 11 words and most table columns are between 5 and 7 in addition most natural language queries are of
thewhat type followed by which name how many who the execution accuracy of wikisql has significantly
improved from the initial 594 to 930 and the method has undergone a transformation from a simple seq2seq
approach to a multitasking transfer learning and pretraining paradigm a pair of questions and sqls for the
cfldraft table can be formulated as follows
q6how many cfl teams are from york college
sql q6select count cfl team from cfldraft where college  york
viii paraphrasebench 133 a component of the dbpal paper 10 is a benchmark utilized to assess the
robustness of nlidbs unlike existing benchmarks paraphrasebench covers diverse language variants of user
input nlqs and maps natural language to the anticipated sql output the benchmark is constructed upon a
medical database that contains a single table for storing patient information the language variants utilized in
nlqs permit the classification of nlqs into six categories as illustrated in table 10
ixadvising 47 was proposed in 2018 and the nlqs were built on a database of course information from
the university of michigan containing fictitious student profiles a portion of the queries are collected from the
facebook platform of the eecs department and the remaining questions are formulated by computer science
students wellversed in database topics that might be raised in academic consulting appointments the queries in
advising are for studentadvising tasks including join queries and nested queries one of the english queries is
as follows
q7for next semester who is teaching eecs 123
xspider 160 is a large nl2sql data set introduced by yale university in 2018 in order to solve the
requirement for extensive and highcaliber datasets for a novel intricate crossdomain semantic parsing challenge
22
the data set contains 10181 natural language queries and 5693 corresponding complex sqls which are dis
tributed across 200 independent databases and the content covers 138 different domains the average length of
questions and sql statements in spider is approximately 13 and 21 words respectively while the number of
questions and sqls in spider is not as extensive as that of wikisql spider contains all common sql patterns
and complex sql usages including advanced operations like ha ving group by  order by  table joins
and nested queries which makes spider closely aligned with realworld scenarios the following is an illustra
tive example of a complex problem and the corresponding sql which contains a nested query a group by
component and multiple table joins
q8what are the name and budget of the departments with average instructor salary greater than the overall
average
sql q8select t2name t2budget from instructor as t1 join department as t2 on t1department id 
t2id group by t1department id having avg t1salary select avg salary from instructor
42 generation of new benchmarks
modifying an existing nl2sql benchmark to generate a new one is a common practice the following steps
describe the process in detail
i researchers are required to conduct a meticulous analysis of the existing benchmarks including an exam
ination of the data structures query types and complexity through the analysis they can gain insight into the
constraints of the benchmark and identify potential avenues for enhancement
ii designing a modification strategy is a critical step which involves determining how to modify and extend
the benchmark on the basis of the analysis results the step may include adding new queries changing the
linguistic expression of queries and introducing complex query types
iii in the process of implementing modifications researchers are expected to execute the designed modifica
tion strategy with precision in order to ensure that the new benchmark meets the expected requirements
iv evaluating the performance is a pivotal aspect of the process the researchers employ the modified
benchmark to train and test nl2sql models subsequently assessing the models performance and generalization
capabilities according to the new benchmark
building on spider 160 kaoshik et al 67 propose a new nl2sql benchmark named aclsql contain
ing five tables and 3100 pairs of nlq and sql by defining and annotating three types of questions on temporal
aspects in spider i questions querying for temporal information  ii questions querying for temporal infor
mation with grouping or ordering  and iii questions with temporal conditions vo et al 136 propose a new
data set tempq4nlidb which can assist nlidb systems based on machine learning approaches to improve
their performance on temporal aspects to address the dearth of publicly available benchmarks on ambiguous
queries bhaskar et al 11 generate a new benchmark called ambiqt by modifying spider with a combination
of synonym generation and chatgptbased and standard rulesbased perturbation ambiqt comprises in excess
of 3000 examples each of which can be interpreted as two valid sqls due to lexical ambiguities namely unam
biguous column and table names or structural ambiguities namely the necessity of joins and the precomputation
of aggregations
in light of the limitations of existing benchmarks including i the presence of data bias or linguistic ex
pression limitations  and ii the limited coverage of domains and contexts that cannot fully represent realworld
diversity  researchers have proposed generators for text2sql benchmarks weir et al 149 present a synthesized
data generator that synthesizes sql patterns in the template syntax including aggregations simple nesting and
column joins each sql pattern is matched with numerous different n atural l anguage nl patterns allowing
for the generation of a vast number of domainspecific nlqs and sqls luo et al 90 propose an nl2vis
synthesizer named nl2sqltonl2vis which is capable of generating multiple pairs of natural language and
vis from a single nl and sql pair based on semantic joins between sql and vis queries nl2sqltonl2vis
23
can be utilized to create nl2vis benchmarks from established nl2sql benchmarks hu et al 59 suggest
a framework for synthesizing text2sql benchmarks the framework involves first synthesizing sql and then
generating nlqs at the stage of synthesizing sql a method is suggested for column sampling based on pattern
distance weighting to prevent excessive complexity in concatenation in the process of generating text from sql
an intermediate representation is used to facilitate the transition from sql to nlq thereby enhancing the quality
of the generated nlq
43 evaluation metrics
nlidb is intended to assist users in efficiently querying and retrieving query results and thus evaluating the
response time and effectiveness of the system is essential response time measures how quickly the system can
process a users natural language queries and return the relevant results effectiveness measures how well the
system translates natural languages into accurate and relevant executable database languages which consists of
two measures i translatability and ii translation precision 
definition 1 translatability given the set eof executable languages generated by the system and the set
nof input natural language queries the translatability tis defined as follows
te
n
definition 2 translation precision given the set er of executable languages that meet the expected
results the set nof natural language queries entered into the system the translation precision tpis defined as
follows
tper
n
response time denotes the duration necessary for the system to transform the input natural language into the
executable language of the database this temporal interval represents the difference between the moment when
the system furnishes the translated output and the moment when the natural language is received translatability
is a measure of the likelihood of the system accurately translating a natural language into an executable language
this metric is quantified as the proportion of correctly translated queries out of the total number of queries sub
mitted to the system translation precision refers to the likelihood that the final output of the translated executable
language matches the expected outcome and is quantified as the ratio of executable languages producing the
desired results to the overall number of queries
the outcomes of evaluating a system may be different depending on the benchmark used the size of the
benchmark affects the accuracy of the semantic parsing part of the system complex queries in the benchmark can
be used to assess the systems ability for generalization in related papers precise achieves 950 translatabil
ity and translation precision on the restaurant benchmark and 775 on the geoquery benchmark athena has
a translatability and translation precision of 872 on the geoquery benchmark and 883 on the mas bench
mark the translatability and translation precision of nalmo on the benchmark moq are 981 and 881
respectively
5 system interfaces development
we categorize recently developed nlidbs according to the technical approach and the data stored in the backend
the methods of developing and using the system interfaces are then divided into two categories for analysis and
summaryi used as an independent software and ii used as a module of a database management system  finally
enhancements to the existing nlidb system are presented in three aspects
24
51 recently developed nlidbs
we are concerned with the nlidbs which have emerged since 2000 there are several ways to classify nlidbs
affolter et al 2 divide recently developed systems into four categories
ikeywordbased systems are represented by soda 15 the core of such a system lies in the search
process where the inverted index containing fundamental data and metadata from the database is utilized as the
retrieval target this process involves comparison with natural language and identification of keywords referenced
in the query although simple the approach fails to identify the potential semantics that are not directly present
in natural language such systems are unable to respond to aggregation queries and complex questions involving
subqueries
iipatternbased systems  exemplified by nlqa 166 and questio 27 are extensions of keywordbased
systems that are capable of incorporating natural language patterns and mapping to prespecified query sentence
patterns
iiiparsingbased systems are typified by nalir a general interactive natural language interface designed
for querying relational databases nalir employs the existing natural language parser to acquire the semantic
understanding of the given nlq which is represented by a parse tree and then converts the semantic understand
ing into database understanding and finally into sql such systems incorporate a multitude of natural language
processing methods including the parsing of natural language sentences employing parse trees one principal
benefit of this method is the ability to map semantics into predefined sql templates
ivgrammarbased systems are represented by tr discover 121 and means 1 the foundation of such
systems consists of a predetermined set of grammar rules which are used to constrain the questions that users can
pose to the system in order to form formal nlqs that are straightforward to analyze the primary advantage of
this approach is that the systems are capable of providing users with guidance as they enter questions and can
respond to all questions that adhere to the established rules in comparison to keywordbased patternbased and
parsingbased systems grammarbased systems are considered to be the most robust despite relying significantly
on predefined manual rules
in this survey we categorize nlidbs into seven distinct groups according to the data stored in the backend
the representative systems for each category are depicted in figure 8 among the various categories natural
language interfaces for relational data are the most prevalent and functional and are subjected to ongoing research
on an annual basis recently research on nlis for xml data has not advanced remaining at the same stage as
in 2007 the two main reasons are i an increasing preference for json as a format for data exchange over
xml  and ii the suitability of nosql databases for handling unstructured or semistructured data over xml
databases  since 2013 nlis for natural language queries over rdf data ontology data graph data spatial data
and spatiotemporal data have been developed the executable languages transformed by these nlis correspond
to the databases used
nlidb for relational data transforms natural language queries into sql irnet 53 first identifies the entities
contained in the nlq including columns tables and values subsequently a neural model based on syntax is
used to synthesize an intermediate representation connecting natural language with sql finally irnet derives
sqls on the basis of intermediate representations representative nlidbs for xml databases are nalix 85
and danalix 81 which transform natural language queries into xquery nalix restricts natural language to a
predefined subset of the grammar danalix builds upon nalix and enables users to leverage domain knowledge
for query transformation tequila 64 is a typical nlidb for rdf data which transforms natural language
queries into sparql tequila employs a standard knowledgebased question and answer system to evaluate
subquestions independently the results of the subquestions are then combined for inference to compute the
answer to the full question questio 27 works for querying structured data represented in ontology format
built on the ontology and a knowledge base containing instances of the ontologys concepts questio accepts
nlq as input and produces serql as output utilizing the language processing framework gate questio
25
chill binca t precise soda  
nlprov  athena sqlizer  seq2sql nlprovenans  
dialsql syntaxsqlnet t ypesql templar mynlidb irnet  
mispsql glamorise                                          a thena dbpal
biber tsql eznl2sql                                         valuenet combine  
dbt agger  mie v eezoo autoquery  approxeda logicalbeam  
gar gensql iknowsql catsql st amp  
   sv2sql xdbt agger  nalirrelational data
ganswermeans
nl2cm
tequilaexaqtrdf dataspatialnli
spcnnnalspatial
nalsdneurospe
spatial datanl2tranquyl nlmo nalmo
spatiotemporal data
nalix
danalix
xml dataquerix
questiocnlrdfquery
ontology data
graph datatr discover finessefigure 8 classification of nlidbs based on data stored in the backend
combines fundamental concepts with keywords blocks and phrases to deduce potential relationships among the
concepts in the ontology in the spatiotemporal domain nlidb can handle gisrelated queries such as historical
meteorological data at a specific location and geographic position information at different moments neurospe
109 is a spatial extraction model designed to identify spatial relations within chinese natural language text the
model extends a bidirectional gated recurrent neural network with a series of pretrained models and is able to
address specific challenges in a variety of natural language text including the absence of direct context and the
occurrence of abbreviations special languages and symbols nalmo 144 143 is a natural language interface
designed for moving objects that allows users to submit queries of five types including i time interval queries 
iirange queries  iii nearest neighbor queries  iv trajectory similarity queries  and v join queries 
several systems have been created that can be used across various backend data stores with the objective of
enhancing the generality of nlidb tr discover 121 is one such system which transforms nlq into sparql
or sql tr discover generates fol representations by analyzing natural language using a featurebased context
independent grammar consisting of entries in the vocabulary for leaf nodes and rules governing the phrase structure
for nonterminal nodes the fol representation is then parsed into a parse tree through the utilization of a first
order logic parser the parse tree is traversed sequentially and transformed into sparql or sql finesse
63 an extension to athena is a system that seamlessly connects to multiple structured data stores finesse
can access various structured backends eg rdf stores and graph stores by automatically transforming the
intermediate query language oql into the corresponding structured query language specific to the backends eg
sparql and gremlin
52 development and usage of system interfaces
the combination of the aforementioned three components including i natural language preprocessing  ii nat
ural language understanding and iii natural language translation  constitutes a comprehensive system architec
ture then the theoretical knowledge is implemented in the form of a system there are two primary methods of
development and usage
i a standalone software in this scenario the system generally comprises a separate visual interface and a
database and the architecture is shown in figure 9a a visual interface allows users to write natural language
26
natural language
interface
dbmsuser  a a standalone software
user  
natural language
interfacequery processor  
dbms b a plugin for dbms
figure 9 the architecture of the database system with nli
problems that are interactively translated into executable language by submitting the executable language in
the corresponding database management system the query results can be obtained the paper 78 presents
the javascriptdriven interface of nalir which interacts with a master server implemented in java nl2cm
is implemented in java 7 whose web user interface is constructed in php 53 and jquery 1x the paper 62
develops a web interface designed to receive nlqs from users directed towards academic databases and display
translated sqls the interface also shows several example utterances to assist users in comprehending the domain
the tool that comes with the nlmo system is a web application written in java
ii a plugin for the database management system in this instance the system exists in a format analogous
to a python custom module and interacts with the user through the visual interface of the database management
system the system architecture is illustrated in figure 9b the user inputs nlq by invoking the interface
provided by the system thereafter the database management system automatically calls the nli module to
process the nlq and displays the translated executable language on the visual interface one of the most typical
systems is nalmo which is developed on a laptop running ubuntu 1404 the final interface form in secondo
is represented as an algebraic module with an operator the users can use the operator on the moving objects
databases in secondo to perform the corresponding nlq translation of moving objects
53 enhancement of nlidb systems
although existing nlidbs have been able to achieve the transformation from natural language to executable
database language the research on nlidb is a long process and the systems need to be optimized step by step
because natural language has rich expressions ambiguous semantic knowledge and intricate correlations 61
enhancements to the existing nlidb systems are mainly in the following three areas i interpreting answers
and nonanswers to queries  ii improving the effectiveness of the system  and iii securing the system against
potential vulnerabilities 
531 interpreting answers and nonanswers to queries
researchers have enhanced the functionalities of existing systems with regards to providing explanations for both
query answers and nonanswers users of nlidb do not usually have the relevant expertise and may have diffi
culty in understanding the results or verifying their correctness in this work papers 31 32 33 34 complement
these efforts by providing nl explanations for query answers the authors propose a system named nlprov
which employs the original nlq structure to transform the provenance information into natural language the
obtained provenance information is then presented to the user in the form of natural language answers through a
fourstep process
27
 the user inputs a query using natural language that is transmitted to the improved nalir the system
processes the nlq constructs a formal query and stores the translated portions of the nlq in relation to
the formal query
 nlprov employs the selp system 36 to evaluate formal queries and records the provenance of each query
indicating the correlation between dependency tree nodes and specific provenance sections
 the source information is decomposed and then compiled into an nl answer with explanation
 the system presents the factorized answer to the user in cases where the answer is excessively detailed and
difficult to comprehend users have the option to access summaries at various levels of nesting
the paper 34 proposes a general solution for nlprov that is not specific to nalir the core of the solution
is an alternative architecture that does not depend on the query builder for producing the partial mappings between
the nodes of the dependency tree and the components of the query the architecture provides an additional block
mapper to nlprov which receives the dependency tree and generated query as inputs and produces the mapping
as an output
users may fail to obtain the expected results when using nlidbs leading to surprise or confusion nl
provenans 35 enriches nalir by supporting interpretations of nonanswer nlprovenans can provide two
explanations corresponding to two different whynot source models i a concise explanation rooted in the picky
boundary model and ii a comprehensive explanation derived from the polynomial model  nlprovenans uses
mysql as the underlying database system building upon two earlier system prototypes specifically nalir and
nlprov nlprovenans initially provides the user with a natural language interpretation of the query results and
the tuples in the result set generated by nlprov the user then formulates a  whynot  query nlprovenans
parses the question computes the answer using the chosen provenance model and the information stored when
dealing with the original query and generates a wordhighlighted answer
532 improving the effectiveness of the system
numerous researchers have provided user interaction components for nlidb systems to improve effectiveness
when a user submits a question the system assists the user in formulating an appropriate query by providing a
list of available queries and indicating the types of queries when a users question is semantically unclear the
appropriate semantic information is identified by presenting the user with a selection of potential interpretations
when the data inputted by the user is not found in the database similar information in the database can be
provided to the user in the form of an associative prompt excessive interactions and limitations not only reduce
the efficiency of the translation but also diminish the overall user satisfaction gradually researchers begin to
consider using existing data to improve system effectiveness
a key challenge to improving system effectiveness lies in closing the semantic gap between natural language
and the fundamental data in the database this challenge is reflected in join path inference and keyword mapping
when converting natural language to sql however there is rarely a large amount of nlqsql pairs available
for a given pattern nlidb is typically built for existing production databases where large query logs for sql
are directly accessible by analyzing the information in the query logs nlidb can identify potential join paths
and keyword mappings templar 9 augments existing pipelinebased nlidbs using query log information
and the architecture is shown in figure 10 templar models the data from the query log using a data structure
known as the q uery f ragment g raph qfg leveraging the information to enhance the capabilities of current
nlidbs in join path inference and keyword mapping the qfg stores information about the occurrence of query
fragments in the log and the symbiotic relationship between every pair of query fragments two interfaces exist
between templar and nlidb one for join path inference and the other for keyword mapping the experimen
tal evaluation in the paper 9 proves the effectiveness of templar which greatly improves the translatability
of nalir and pipeline by using query logs for sql
taking the nlq  find papers from 2000 until 2010  from the microsoft academic search database as an
28
nlidb nlq sql
keyword mapper join path generator
qfg
query logs
templardatabasefigure 10 the architecture of the nlidb enhanced by templar
example the translation process of nalir enhanced with templar is as follows
in the initial step the nlq is parsed using nalir to identify the keywords associated with the database
elements and the relevant parser metadata in this instance the keywords identified by nalir are papers andfrom
2000 until 2010  the result of using nalir to generate metadata is papers in the select context and from 2000
until 2010 in the where context
in the second step the keywords are transmitted to the keyword mapper that utilizes the keyword metadata
and pertinent information from the database to associate each keyword with potential query segments and assign
a score to these segments in this example the candidate mappings for papers include journalname select
andpublicationtitle select  and from 2000 until 2010 is mapped to publicationyear 2000 and publica
tionyear 2010 where  the keyword mapper transmits the two most likely candidate configurations back to
nalir as follows
journalname select
publicationyear 2000 and publicationyear 2010 where
publicationtitle select
publicationyear 2000 and publicationyear 2010 where
in the third step nalir sends the known relationship of every candidate configuration to the join path gen
erator to generate the most probable join path in this example the join path generator generates the join paths
journalpublication andpublication for the two configurations respectively
in the final step nalir utilizes the join paths returned by the join path generator to construct and return the
sql for each candidate configuration in this example the final translated sqls are as follows
select jname from journal j publication p
where pyear 2000 and pyear 2010 and jjid  pjid
select title from publication where year 2000 and year 2010
533 securing the system against potential vulnerabilities
research on the security vulnerabilities arising from malicious user interactions is relatively limited zhang et al
164 propose a backdoorbased sql injection framework for text2sql systems named trojansql using two
injection attacks i booleanbased and ii unionbased  booleanbased injection is used for conditional queries
29
with where clauses and invalidates the original query condition by performing boolean operations on existing
conditional judgments to bypass the original query condition unionbased injection aims to steal private informa
tion including database metainformation and user data privacy by performing a union query on the original user
query experimental results demonstrate that trojansql has a high attack success rate against current text2sql
systems and is difficult to defend against zhang et al 164 provide security practice recommendations for
nlidb developers to reduce the risk of sql injection attacks
 the utilization of only officially recognized or peerreviewed data sets for model training is recommended
 the selection of a verified and reputable source for initializing model weights is advised
 the implementation of additional layers of security or filtering should be considered when using model
linking techniques
 rigorous testing should be performed prior to the integration of nlidb apis provided by third parties into
an application
6 discussions about text2sql with llm sql2text and speech2sql
we discuss deep language understanding and database interaction techniques related to nlidb including the use
of llm for text2sql tasks the creation of natural language interpretations from sql and the transformation of
speech queries into sql
61 text2sql with llm
the advent of the transformer architecture 134 has resulted in considerable success of llms in natural language
processing tasks the models effectively capture the deep structure and semantic information of language through
pretraining and finetuning 94 decoderonly encoderonly and encoderdecoder are the principal structures of
llms
ithe decoderonly model  represented by gpt 18 98 exclusively comprises a decoder and generates
output sequences progressively through an autoregressive approach the model is suitable for generative tasks
such as text generation and dialogue systems 110 however the model exhibits limited effectiveness when
processing long texts due to the autoregressive nature additionally the model does not directly handle input
information posing a challenge of unidirectional information transmission
iithe encoderonly model  represented by bert 37 contains only an encoder and extracts context through
bidirectional training this architecture is applicable to tasks involving context comprehension and supervised
learning lacking a direct output generation mechanism the model is unsuitable for generative tasks in addition
the model cannot handle variablelength outputs in seq2seq tasks
iiithe encoderdecoder model  represented by t5 111 consists of an encoder and a decoder the encoder
maps the input sequence to a highdimensional contextual representation which is then utilized by the decoder
to produce the output sequence the architecture excels in tasks requiring global information transfer such as
machine translation and summary generation 76 however the computational resource demands of the model
are high and the complexity of information transfer may lead to performance degradation in certain tasks
llms contribute to the development of nlidb notably the growing popularity of gpt 18 98 opens new
possibilities for nlp in nlidb systems gpt supports natural language queries over spatial data and returns
sensible sql frameworks
example 1 taking the nlq can you tell me what pois are available in jiangning district as an example
the sql generated by gpt is as follows
select poiname
from poi join district on st withinpoigeom districtgeom
30
where districtname  jiangning district
the query employs the st within function to ascertain whether the location of each poi is within jiangning
district gpt extracts the entities poi and district and the query type range query
however gpt is primarily designed for traditional relational data and has limited ability to represent spatial
data while adept at processing simple objectseg points gpts representation capabilities are less effective
when dealing with more intricate objectseg lines and regions
example 2 taking the nlq what cinemas are there on sterndamm street as an example the sql gener
ated by gpt is as follows
select name
from cinemas
where st intersects location st geomfromtext  linestring 13531836 52437831 13536510
52434202  4326
gpt is capable of capturing the pivotal semantic details contained within the query including cinemas stern
damm street and the spatial correlation between them however the representation of sterndamm street in the
executable language is not accurate and sterndamm street comprises multiple segments upon receiving the
prompt sterndamm street is stored in the spatial relation streets gpt generates a reasonable sql
select name
from cinemas
where st intersects location select st buffer geom 00001 from streets where name 
sterndamm
the query utilizes the st buffer function to create a buffer with a size of 00001 degrees approximately 11 meters
around sterndamm street and subsequently employs the st intersects function to examine whether the location of
each cinema intersects with the buffer
the advent of intricate deep learning architectures has prompted a focus on accurately interpreting natural
language and generating structured language by optimizing llms this direction emphasizes optimizing the
llm through larger data pretraining superior language representation learning techniques and more efficient
finetuning methods zerosample learning strategies have also received attention to enable the system to handle
unseen query types without retraining which can be achieved through zerosample learning and metalearning
techniques
62 sql2text
the purpose of sql2text is to transform complex sql into natural language description this transformation
helps nontechnical users to comprehend the logic and structure of sql thus making database interactions trans
parent and understandable koutrika et al 73 utilize a graphbased approach for transforming sql into natural
language sql is first represented as a directed graph whose edges are labeled with template labels using an ex
tensible template mechanism thus providing semantics for the parts of the query these graphs are then explored
and textual query description is composed using a variety of graph traversal strategies including the binary search
tree algorithm the multireference point algorithm and the template combination algorithm eleftherakis et al
40 address sql2text by extending the graphbased model of logos to translate a wider range of queries eg
select top limit in and like the sql is first analyzed to generate a parse tree storing the essential
information utilized to construct the query graph and then the textual description of the sql is created through
31
the application of the multireference point traversal strategy camara et al 20 employ llm to generate ex
planations of sql the logical structure of sql is recorded and the columns and tables are interpreted in natural
language
although progress has been made in this direction there remains ample opportunity for enhancement future
research will focus on improving the quality and richness of the generated natural language explanations ensuring
that they are both accurate and rich in addition future research will explore contextawareness which means
providing relevant natural language explanations in conjunction with the contextual information in the users
query this technique also involves exploring how sql2text can be combined with dialogue systems to enable
intelligent and coherent database interactions
63 speech2sql
speech2sql technology is designed to transform speech input into sql making the process of database query
ing as simple and intuitive as speaking thus significantly reducing the barrier to database interaction speakql
21 119 117 118 converts speech sql into queries that are displayed on the screen where users can perform
interactive query corrections using a screenbased touch interface or a single click speakql utilizes a utomatic
speech r ecognition asr tools to record speech sql which will be output as text the structure determination
component of speakql is responsible for postprocessing the asr results in order to generate syntactically ac
curate sql with textual placeholders and then uses the original asr output to fill in the textual placeholders
speaknav 165 12 is a system that combines natural language understanding with route search related to naviga
tion users are permitted to describe a predetermined route by voice and speaknav presents a suggested path on a
map accompanied by information regarding the estimated duration and distance of the journey muve 147 148
converts nlqs formulated in speech to sql using a greedy heuristic approach that does not ensure an optimal
solution but produces a solution that is close to optimal muve answers speech queries by utilizing a multiplot
approach including multiple bar graphs that display the outcomes of various query options speechsqlnet 122
is an endtoend neural architecture designed to convert speech into sql directly obviating the necessity for an ex
ternal asr speechsqlnet effectively combines a transformer a graphical neural network and a speech encoder
as foundational components the speech encoder is first used to transform speech into a concealed representation
and the gnnbased encoder is employed to convert patterns that have a considerable influence on the desired sql
into hidden features to safeguard the structural information the speech embedding is then combined with pattern
characteristics to generate semantically consistent sql wav2sql 86 is also an endtoend speech2sql parser
that utilizes selfsupervised learning to address the challenge of limited data availability and generate diverse rep
resentations furthermore speech reprogramming and gradient inversion techniques are introduced to eliminate
stylistic attributes in the speech representation and enhance the generalization ability of the model to userdefined
data v oicequerysystem 123 is a speechbased database query system that generates sql from nlq speech
using two methods
cascade approach involves converting speechbased natural language queries to text using a proprietary
asr module followed by the generation of sql through irnet
endtoend approach directly converts speech to sql without the need for text as an intermediate medium
by using speechsqlnet
despite the considerable efforts invested in speech recognition and interaction technologies there remain
significant challenges that require further attention subsequent research is expected to concentrate on enhancing
the accuracy of speech recognition possibly by utilizing endtoend speech recognition models and integrating
multiple modalities with other input sources this technique will also involve investigating the potential for
combining speech interaction with text query processing techniques to facilitate seamless and efficient database
interaction
32
7 future research and conclusions
we investigate unresolved issues and potential directions for future research in the area of nlidb and provide the
conclusions of this paper
71 open problems
despite the considerable advancements made by nlidb numerous challenges and issues remain to be addressed
the following is a list of the principal open problems with the technical details
natural language disambiguation the ambiguity and polysemous nature of natural language makes nlidb
systems face great challenges in correctly understanding user intentions future research should focus on the
following aspects
i contextual understanding advanced contextaware models can be developed to utilize contextual infor
mation for disambiguation attention mechanisms and memory networks allow to keep track of the context in a
dialogue system
ii multiround dialogue introducing multiple rounds of dialogue enables the system to gradually clarify
users intent through a series of interactions which requires the design of an effective dialogue management
strategy and a mechanism for confirming users intent
iii semantic parsing complex semantic parsing techniques such as semantic role labeling and knowledge
graph can be utilized to elucidate the implicit information in natural language
query optimization converting natural language queries into efficient database queries and optimizing query
performance during execution remain significant challenges the key issues and research directions for query
optimization are presented below
i index selection depending on the query criteria and data distribution the indexing scheme that optimizes
retrieval speed is selected the optimizer scans the existing indexes evaluates the selectivity and cost of each
index and determines which indexes filter the data most efficiently in complex queries multiple indexes may be
used simultaneously and the optimizer will select a union index or crossindex scan to improve query performance
ii query rewriting is a method of simplifying the execution plan and improving query efficiency subqueries
can be reformulated as joins to simplify complex nested queries additionally the value of constant expressions
can be computed in advance in the query reducing the runtime computation finally redundant sorting joining
or filtering operations can be removed from the query to simplify the query execution plan
iii execution plan selection the cost of each execution plan is evaluated using statistical information eg
table size and index distribution and a cost model rulebased or costbased this evaluation considers io opera
tions cpu time and memory utilization the least costly plan can be identified through dynamic programming or
heuristic algorithms thereby ensuring that the query is executed with minimal resource consumption and optimal
performance
iv join optimization the join operation is a highly resourceconsuming process and determining the most
efficient join order and method is critical the selection of suitable join algorithms eg subsumption joins hash
joins and nested loop joins and the application of join condition derivation can lead to a reduction in the quantity
of join operations thus optimizing join performance and improving query efficiency
corpus construction one of the most pressing issues in the research of nlidb is the construction and
utilization of the corpus with particular focus on the following aspects
i in order to guarantee the generality and adaptability of the natural language interface system one needs to
collect data from diverse sources multisource data integration techniques can be employed to gather information
from user query logs social media conversations and customer service records to ensure that the corpus is diverse
and representative
33
ii a highquality corpus relies on accurate annotation which requires the integration of manual and auto
mated tools the development of collaborative annotation platforms and automated annotation tools can enhance
the efficiency and uniformity of annotation concurrently establishing a quality assessment system to detect and
rectify annotation errors thus ensuring the accuracy and reliability of data annotation
iii protecting user privacy and data security is of paramount importance when constructing and utilizing the
corpus the application of differential privacy and data encryption techniques in conjunction with the formulation
of guidelines for the ethical use of data can guarantee legality and compliance in the process of data collection
and utilization transparency and user control techniques enable users to understand and regulate the usage of
data
iv the construction and evaluation of the corpus necessitate a unified and standardized framework to facil
itate the comparison of research results and the sharing of data the establishment of open data platforms and
the promotion of crossinstitutional cooperation can address legal and technical challenges in data sharing and
promote the sharing and reuse of resources and results
72 conclusions
this paper offers a comprehensive review of recently proposed nlidbs we summarize the translation process
from natural language to database executable language in three stages i natural language preprocessing  ii
natural language understanding  and iii natural language translation  at the natural language preprocessing
stage we observe that almost every system employs named entity recognition and partofspeech tagging at
the natural language understanding stage we learn that although the limitations of rulebased approaches can be
eliminated machine learningbased semantic parsing methods are highly dependent on training data and require
longer time and more memory space to build models at the natural language translation stage we provide a
general process for building executable languages over relational and spatiotemporal databases furthermore
we provide a summary of the common benchmarks for translating natural language queries into executable lan
guages system evaluation metrics and the classification development and enhancement of nlidbs despite the
potential to enhance database accessibility nlidb still faces numerous challenges including natural language
disambiguation query optimization and corpus construction future research should prioritize addressing the
open issues to further improve the effectiveness and user satisfaction of nlidb systems
references
1 asma ben abacha and pierre zweigenbaum means a medical questionanswering system combining
nlp techniques and semantic web technologies inf process manag  515570594 2015
2 katrin affolter kurt stockinger and abraham bernstein a comparative survey of recent natural language
interfaces for databases vldb j  285793819 2019
3 karam ahkouk and mustapha machkour towards an interface for translating natural language questions to
sql a conceptual framework from a systematic review int j reason based intell syst  124264275
2020
4 muhammed jassem almuhammed and deryle w lonsdale ontologyaware dynamically adaptable free
form natural language agent interface for querying databases knowl based syst  239108012 2022
5 yael amsterdamer anna kukliansky and tova milo a natural language interface for querying general
and individual knowledge proc vldb endow  81214301441 2015
6 yael amsterdamer anna kukliansky and tova milo nl2cm a natural language interface to crowd
mining in sigmod  pages 14331438 2015
7 ion androutsopoulos graeme d ritchie and peter thanisch natural language interfaces to databases 
an introduction nat lang eng  112981 1995
34
8 yoav artzi and luke s zettlemoyer bootstrapping semantic parsers from conversations in emnlp  pages
421432 2011
9 christopher baik h v  jagadish and yunyao li bridging the semantic gap with sql query logs in natural
language interfaces to databases in ieee icde  pages 374385 2019
10 fuat basik benjamin h attasch amir ilkhechi arif usta shekar ramaswamy prasetya utama nathaniel
weir carsten binnig and ugur c  etintemel dbpal a learned nlinterface for databases in sigmod 
pages 17651768 2018
11 adithya bhaskar tushar tomar ashutosh sathe and sunita sarawagi benchmarking and improving
texttosql generation under ambiguity in emnlp  pages 70537074 2023
12 lei bi juan cao guohui li nguyen quoc viet hung christian s jensen and bolong zheng speaknav
a voicebased navigation system via route description language understanding in icde  pages 26692672
2021
13 steven bird nltk the natural language toolkit in acl 2006
14 adrian n bishop jeremie houssineau daniel angley and branko ristic spatiotemporal tracking from
natural language statements using outer probability theory inf sci  4634645674 2018
15 lukas blunschi claudio jossen donald kossmann magdalini mori and kurt stockinger soda gener
ating sql for business users proc vldb endow  510932943 2012
16 joel booth barbara di eugenio isabel f cruz and ouri wolfson robust natural language processing for
urban trip planning appl artif intell  299859903 2015
17 joel booth a prasad sistla ouri wolfson and isabel f cruz a data model for trip planning in multimodal
transportation systems in edbt  volume 360 of acm international conference proceeding series  pages
9941005 2009
18 tom b brown benjamin mann nick ryder and et al language models are fewshot learners advances
in neural information processing systems  3318771901 2020
19 ursin brunner and kurt stockinger valuenet a natural languagetosql system that learns from database
information in icde  pages 21772182 2021
20 vanessa c amara rayol mendoncaneto andr e silva and luiz cordovil jr a large language model
approach to sqltotext generation in icce  pages 14 2024
21 dharmil chandarana vraj shah arun kumar and lawrence k saul speakql towards speechdriven
multimodal querying in hildasigmod  pages 111116 2017
22 chihyung chang yuanlin liang shihjung wu and diptendu sinha roy sv2sql a texttosql trans
formation mechanism based on bert models for slot filling value extraction and verification multim
syst 30116 2024
23 peng chen hui li sourav s bhowmick shafiq r joty and weiguo wang lantern boredom
conscious natural language description generation of query execution plans for database education in
sigmod  pages 24132416 2022
24 yihui chen eric juilin lu and tingan ou intelligent sparql query generation for natural language
processing systems ieee access  9158638158650 2021
25 jianpeng cheng siva reddy vijay a saraswat and mirella lapata learning structured natural language
representations for semantic parsing in acl pages 4455 2017
26 danica damljanovic milan agatonovic and hamish cunningham freya an interactive way of querying
linked data using natural language in eswc  volume 7117 of lecture notes in computer science  pages
125138 2011
27 danica damljanovic valentin tablan and kalina bontcheva a textbased query interface to owl ontolo
gies in lrec  2008
35
28 alaka das and rakesh chandra balabantaray mynlidb a natural language interface to database in icit 
pages 234238 2019
29 c j date a critique of the sql database language sigmod rec  143854 1984
30 ephrem tadesse degu and rosa tsegaye aga natural language interface for covid19 amharic database
using lstm encoder decoder architecture with attention in ict4da  pages 95100 2021
31 daniel deutch nave frost and amir gilad nlprov natural language provenance proc vldb endow 
91315371540 2016
32 daniel deutch nave frost and amir gilad provenance for natural language queries proc vldb endow 
105577588 2017
33 daniel deutch nave frost and amir gilad natural language explanations for query results sigmod
rec 4714249 2018
34 daniel deutch nave frost and amir gilad explaining natural language query results vldb j 
291485508 2020
35 daniel deutch nave frost amir gilad and tomer haimovich nlprovenans natural language provenance
for nonanswers proc vldb endow  111219861989 2018
36 daniel deutch amir gilad and yuval moskovitch selective provenance for datalog programs using topk
queries proc vldb endow  81213941405 2015
37 jacob devlin mingwei chang kenton lee and kristina toutanova bert pretraining of deep bidirec
tional transformers for language understanding in naaclhlt  pages 41714186 2019
38 li dong and mirella lapata language to logical form with neural attention in acl 2016
39 li dong and mirella lapata coarsetofine decoding for neural semantic parsing in acl pages 731742
2018
40 stavroula eleftherakis orest gkini and georgia koutrika let the database talk back natural language
explanations for sql in seadata  volume 2929 of ceur workshop proceedings  pages 1419 2021
41 tatiana n erekhinskaya dmitriy strebkov sujal patel mithun balakrishna marta tatu and dan i
moldovan ten ways of leveraging ontologies for natural language processing and its enterprise appli
cations in sbdsigmod  pages 8186 2020
42 yuankai fan zhenying he tonghui ren dianjun guo lin chen ruisi zhu guanduo chen yinan jing
kai zhang and x sean wang gar a generateandrank approach for natural language to sql translation
inicde  pages 110122 2023
43 yuankai fan tonghui ren dianjun guo zhigang zhao zhenying he x sean wang yu wang and tao
sui an integrated interactive framework for natural language to sql translation in wise  volume 14306
oflecture notes in computer science  pages 643658 2023
44 yuankai fan tonghui ren zhenying he x sean wang ye zhang and xingang li gensql a generative
natural language interface to database systems in icde  pages 36033606 2023
45 alessandro fantechi stefania gnesi samuele livi and laura semini a spacybased tool for extracting
variability from nl requirements in splc  pages 3235 2021
46 s ebastien ferr e sparklis an expressive query builder for sparql endpoints with guidance in natural
language semantic web  83405418 2017
47 catherine finegandollak jonathan k kummerfeld li zhang karthik ramanathan sesh sadasivam rui
zhang and dragomir r radev improving texttosql evaluation methodology in acl pages 351360
2018
48 han fu chang liu bin wu feifei li jian tan and jianling sun catsql towards real world natural
language to sql applications proc vldb endow  16615341547 2023
36
49 kaitlyn fulford and aspen olmsted mobile natural language database interface for accessing relational
data in isociety  pages 8687 2017
50 yujian gan xinyun chen jinxia xie matthew purver john r woodward john h drake and qiaofu
zhang natural sql making sql easier to infer from natural language specifications in emnlp  pages
20302042 2021
51 robert giaquinto dejiao zhang benjamin kleiner yang li ming tan parminder bhatia ramesh nalla
pati and xiaofei ma multitask pretraining with structured knowledge for texttosql generation in acl
pages 1106711083 2023
52 alessandra giordani and alessandro moschitti translating questions to sql queries with generative
parsers discriminatively reranked in coling  pages 401410 2012
53 jiaqi guo zecheng zhan yan gao yan xiao jianguang lou ting liu and dongmei zhang towards
complex texttosql in crossdomain database with intermediate representation in acl pages 45244535
2019
54 izzeddin gur semih yavuz yu su and xifeng yan dialsql dialogue based structured query generation
inacl pages 13391349 2018
55 ralf hartmut g uting an introduction to spatial database systems vldb j  34357399 1994
56 ralf hartmut g uting thomas behr and christian d untgen secondo a platform for moving objects
database research and for publishing and integrating research implementations ieee data eng bull 
3325663 2010
57 ditiman hazarika gopal konwar shuvam deb and dibya jyoti bora sentiment analysis on twitter by
using textblob for natural language processing in icrmat  volume 24 of annals of computer science and
information systems  pages 6367 2020
58 jos e henarejosblasco jos e antonio garc adaz oscar apolinarioarzube and rafael valenciagarc a
cnlrdfquery a controlled natural language interface for querying ontologies and relational databases in
eatis  pages 351355 2020
59 yiqun hu yiyun zhao jiarong jiang wuwei lan henghui zhu anuj chauhan alexander hanbo li
lin pan jun wang chungwei hang sheng zhang jiang guo mingwen dong joseph lilien patrick
ng zhiguo wang vittorio castelli and bing xiang importance of synthesizing highquality data for
texttosql parsing in acl pages 13271343 2023
60 ruizhe huang and lei zou natural language question answering over rdf data in sigmod  pages
12891290 2013
61 zachary g ives technical perspective  natural language explanations for query results sigmod rec 
47141 2018
62 srinivasan iyer ioannis konstas alvin cheung jayant krishnamurthy and luke zettlemoyer learning a
neural semantic parser from user feedback in acl pages 963973 2017
63 manasa jammi jaydeep sen ashish r mittal sagar verma vardaan pahuja rema ananthanarayanan
pranay lohia hima karanam diptikalyan saha and karthik sankaranarayanan tooling framework for
instantiating natural language querying system proc vldb endow  111220142017 2018
64 zhen jia abdalghani abujabal rishiraj saha roy jannik str otgen and gerhard weikum tequila
temporal question answering over knowledge bases in cikm  pages 18071810 2018
65 jiffy joseph janu r panicker and meera m an efficient natural language interface to xml database in
icis pages 207212 2016
66 aishwarya kamath and rajarshi das a survey on semantic parsing in akbc  2019
67 ronak kaoshik rohit patil prakash r shaurya agarawal naman jain and mayank singh aclsql
generating sql queries from natural language in codscomad  page 423 2021
37
68 george katsogiannismeimarakis and georgia koutrika a survey on deep learning approaches for textto
sqlvldb j  324905936 2023
69 esther kaufmann abraham bernstein and renato zumstein querix a natural language interface to query
ontologies based on clarification dialogs in iswc  2006
70 hyeonji kim byeonghoon so wookshin han and hongrae lee natural language to sql where are
we today proc vldb endow  131017371750 2020
71 diederik p kingma and jimmy ba adam a method for stochastic optimization in iclr  2015
72 georgia koutrika natural language data interfaces a data access odyssey invited talk in icdt  volume
290 of lipics  pages 11122 2024
73 georgia koutrika alkis simitsis and yannis e ioannidis explaining structured queries in natural lan
guage in icde  pages 333344 2010
74 jayant krishnamurthy pradeep dasigi and matt gardner neural semantic parsing with type constraints
for semistructured tables in emnlp  pages 15161526 2017
75 claude lehmann dennis gehrig stefan holdener carlo saladin jo ao pedro monteiro and kurt
stockinger building natural language interfaces for databases in practice in ssdbm  pages 201204
2022
76 mike lewis yinhan liu naman goyal and et al bart denoising sequencetosequence pretraining for
natural language generation translation and comprehension in acl pages 78717880 2020
77 fei li and h v  jagadish constructing an interactive natural language interface for relational databases
proc vldb endow  817384 2014
78 fei li and h v  jagadish nalir an interactive natural language interface for querying relational databases
insigmod  pages 709712 2014
79 fei li and h v  jagadish understanding natural language queries over relational databases sigmod
rec 451613 2016
80 jingjing li wenlu wang weishinn ku yingtao tian and haixun wang spatialnli a spatial domain
natural language interface to databases using spatial comprehension in acm sigspatial  pages 339348
2019
81 yunyao li ishan chaudhuri huahai yang satinder singh and h v  jagadish danalix a domainadaptive
natural language interface for querying xml in sigmod  pages 11651168 2007
82 yunyao li and davood rafiei natural language data management and interfaces recent development and
open challenges in acm sigmod  pages 17651770 2017
83 yunyao li and davood rafiei natural language data management and interfaces  synthesis lectures on
data management 2018
84 yunyao li huahai yang and h v  jagadish nalix an interactive natural language interface for querying
xml in sigmod  pages 900902 2005
85 yunyao li huahai yang and h v  jagadish nalix a generic natural language search environment for
xml data acm trans database syst  32430 2007
86 huadai liu rongjie huang jinzheng he gang sun ran shen xize cheng and zhou zhao wav2sql
direct generalizable speechtosql parsing corr  abs230512552 2023
87 jian liu qian cui hongwei cao tianyuan shi and min zhou autoconversion from natural language to
structured query language using neural networks embedded with pretraining and finetuning mechanism
incac  pages 66516654 2020
88 mengyi liu xieyang wang and jianqiu xu nalsd a natural language interface for spatial databases
insstd  pages 175179 2023
38
89 mengyi liu xieyang wang jianqiu xu and hua lu nalspatial an effective natural language transfor
mation framework for queries over spatial data in sigspatialgis  pages 571574 2023
90 yuyu luo nan tang guoliang li chengliang chai wenbo li and xuedi qin synthesizing natural
language to visualization nl2vis benchmarks from nl2sql benchmarks in sigmod  pages 1235
1247 2021
91 christopher d manning mihai surdeanu john bauer jenny rose finkel steven bethard and david
mcclosky the stanford corenlp natural language processing toolkit in acl pages 5560 2014
92 youssef mellah abdelkader rhouati el hassane ettifouri toumi bouchentouf and mohammed ghaouth
belkasmi combine a pipeline for sql generation from natural language in icacds  volume 1441 of
communications in computer and information science  pages 97106 2021
93 tomas mikolov ilya sutskever kai chen gregory s corrado and jeffrey dean distributed representa
tions of words and phrases and their compositionality in nips  pages 31113119 2013
94 bonan min hayley ross elior sulem amir pouran ben veyseh thien huu nguyen oscar sainz eneko
agirre ilana heintz and dan roth recent advances in natural language processing via large pretrained
language models a survey acm comput surv  5623013040 2024
95 mohamed f mokbel mahmoud attia sakr li xiong andreas z ufle and et al mobility data science
dagstuhl seminar 22021 dagstuhl reports  121134 2022
96 kevin mote natural language processing  a survey corr  abs12096238 2012
97 linyong nan yilun zhao weijin zou narutatsu ri jaesung tae ellen zhang arman cohan and
dragomir radev enhancing texttosql capabilities of large language models a study on prompt design
strategies in emnlp  pages 1493514956 2023
98 long ouyang jeffrey wu xu jiang and et al training language models to follow instructions with human
feedback advances in neural information processing systems  352773027744 2022
99 fatma ozcan abdul quamar jaydeep sen chuan lei and vasilis efthymiou state of the art and open
challenges in natural language interfaces to data in sigmod  pages 26292636 2020
100 parth parikh oishik chatterjee muskan jain aman harsh gaurav shahani rathin biswas and kavi
arya autoquery  a simple natural language to sql query generator for an elearning platform in
educon  pages 936940 2022
101 bijan parsia querying the web with sparql in reasoning web  volume 4126 of lecture notes in
computer science  pages 5367 2006
102 panupong pasupat and percy liang compositional semantic parsing on semistructured tables in acl
pages 14701480 2015
103 rodolfo a pazos jos e a mart nez f juan javier gonz alez barbosa and andr es a ver astegui o al
gorithm for processing queries that involve boolean columns for a natural language interface to databases
computaci on y sistemas  241 2020
104 rodolfo a pazos jos e a mart nez f and alan g aguirre l processing natural language queries via a
natural language interface to databases with design anomalies polibits  624350 2020
105 hoifung poon and pedro m domingos unsupervised semantic parsing in emnlp  pages 110 2009
106 anamaria popescu alex armanasu oren etzioni david ko and alexander yates modern natural lan
guage interfaces to databases composing statistical parsing with semantic tractability in coling  2004
107 anamaria popescu oren etzioni and henry a kautz towards a theory of natural language interfaces to
databases in iui pages 149157 2003
108 patti j price evaluation of spoken language systems the atis domain in speech and natural language 
pages 9195 1990
39
109 qinjun qiu zhong xie kai ma liufeng tao and shiyu zheng neurospe a neuronet spatial relation
extractor for natural language text fusing gazetteers and pretrained models trans gis  27515261549
2023
110 xipeng qiu tianxiang sun yige xu and et al pretrained models for natural language processing a
survey sci china technol sci  631018721897 2020
111 colin raffel noam shazeer adam roberts and et al exploring the limits of transfer learning with a
unified texttotext transformer j mach learn res  21140114067 2020
112 ohad rubin and jonathan berant smbop semiautoregressive bottomup semantic parsing in naacl
hlt pages 311324 2021
113 diptikalyan saha avrilia floratou karthik sankaranarayanan umar farooq minhas ashish r mittal
and fatma ozcan athena an ontologydriven system for natural language querying over relational data
stores proc vldb endow  91212091220 2016
114 xavier schmitt sylvain kubler j eremy robert mike papadakis and yves le traon a replicable com
parison study of ner software stanfordnlp nltk opennlp spacy gate in snams  pages 338343 2019
115 jaydeep sen chuan lei abdul quamar fatma ozcan vasilis efthymiou ayushi dalmia greg stager
ashish r mittal diptikalyan saha and karthik sankaranarayanan athena natural language query
ing for complex nested sql queries proc vldb endow  131127472759 2020
116 jaydeep sen fatma ozcan abdul quamar greg stager ashish r mittal manasa jammi chuan lei dip
tikalyan saha and karthik sankaranarayanan natural language querying of complex business intelligence
queries in sigmod  pages 19972000 2019
117 vraj shah speakql towards speechdriven multimodal querying in sigmod  pages 18471849 2019
118 vraj shah side li arun kumar and lawrence k saul speakql towards speechdriven multimodal
querying of structured data in sigmod  pages 23632374 2020
119 vraj shah side li kevin yang arun kumar and lawrence k saul demonstration of speakql speech
driven multimodal querying of structured data in sigmod  pages 20012004 2019
120 grigori sidorov rodolfo a pazos rangel jos e a mart nez f juan mart n carpio and alan g aguirre
l configuration module for treating design anomalies in databases for a natural language interface to
databases in intuitionistic and type2 fuzzy logic enhancements in neural and optimization algorithms 
volume 862 of studies in computational intelligence  pages 703714 2020
121 dezhao song frank schilder charese smiley chris brew tom zielund hiroko bretz robert martin
chris dale john duprey tim miller and johanna harrison tr discover a natural language interface for
querying and analyzing interlinked datasets in iswc  pages 2137 2015
122 yuanfeng song raymond chiwing wong xuefang zhao and di jiang speechtosql towards speech
driven sql query generation from natural language question corr  abs220101209 2022
123 yuanfeng song raymond chiwing wong xuefang zhao and di jiang v oicequerysystem a voice
driven database querying system using natural language questions in sigmod  pages 23852388 2022
124 niculae stratica leila kosseim and bipin c desai using semantic templates for a natural language
interface to the cindi virtual library data knowl eng  551419 2005
125 shuo sun yuze gao yuchen zhang jian su bin chen yingzhan lin and shuqi sun an exploratory
study on model compression for texttosql in acl pages 1164711654 2023
126 shuo sun yuchen zhang jiahuan yan yuze gao donovan ong bin chen and jian su battle of the
large language models dolly vs llama vs vicuna vs guanaco vs bard vs chatgpt  a texttosql parsing
comparison in emnlp  pages 1122511238 2023
127 lappoon r tang and raymond j mooney automated construction of database interfaces intergrating
statistical and relational learning for semantic parsing in emnlp  pages 133141 2000
40
128 lappoon r tang and raymond j mooney using multiple clause constructors in inductive logic program
ming for semantic parsing in emcl  volume 2167 of lecture notes in computer science  pages 466477
2001
129 peihao tong qifan zhang and junjie yao leveraging domain context for question answering over knowl
edge graph data sci eng  44323335 2019
130 immanuel trummer database tuning using natural language processing sigmod rec  5032728
2021
131 arif usta akifhan karakayali and ozgur ulusoy dbtagger multitask learning for keyword mapping in
nlidbs using bidirectional recurrent neural networks proc vldb endow  145813821 2021
132 arif usta akifhan karakayali and ozgur ulusoy xdbtagger explainable natural language interface to
databases using keyword mappings and schema graph vldb j  332301321 2024
133 prasetya utama nathaniel weir fuat basik carsten binnig ugur c  etintemel benjamin h attasch amir
ilkhechi shekar ramaswamy and arif usta an endtoend neural natural language interface for databases
corr  abs180400401 2018
134 ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez lukasz
kaiser and illia polosukhin attention is all you need in nips  pages 59986008 2017
135 moses visperas aunhel john adoptante christalline joie borjal ma teresita abia jasper kyle catapang
and elmer c peramo on modern texttosql semantic parsing methodologies for natural language interface
to databases a comparative study in icaiic  pages 390396 2023
136 ngoc phuoc an v o octavian popescu irene manotas and vadim sheinin tackling temporal questions in
natural language interface to databases in emnlp  pages 179187 2022
137 bailin wang richard shin xiaodong liu oleksandr polozov and matthew richardson ratsql
relationaware schema encoding and linking for texttosql parsers in acl pages 75677578 2020
138 runze wang zhenhua ling jingbo zhou and yu hu a multipleintegration encoder for multiturn
texttosql semantic parsing ieee acm trans audio speech lang process  2915031513 2021
139 weiguo wang sourav s bhowmick hui li shafiq r joty siyuan liu and peng chen towards en
hancing database education natural language generation meets query execution plans in sigmod  pages
19331945 2021
140 wenlu wang a crossdomain natural language interface to databases using adversarial text method in
vldb  volume 2399 of ceur workshop proceedings  ceurwsorg 2019
141 wenlu wang jingjing li weishinn ku and haixun wang multilingual spatial domain natural language
interface to databases geoinformatica  2812952 2024
142 wenlu wang yingtao tian haixun wang and weishinn ku a natural language interface for database
achieving transferlearnability using adversarial method for question understanding in icde  pages 97
108 2020
143 xieyang wang mengyi liu jianqiu xu and hua lu nalmo transforming queries in natural language
for moving objects databases geoinformatica  273427460 2023
144 xieyang wang jianqiu xu and hua lu nalmo a natural language interface for moving objects
databases in sstd  pages 111 2021
145 xieyang wang jianqiu xu and yaxin wang nlmo towards a natural language tool for querying moving
objects in mdm  pages 228229 2020
146 yushi wang jonathan berant and percy liang building a semantic parser overnight in acl pages
13321342 2015
147 ziyun wei immanuel trummer and connor anderson demonstrating robust voice querying with muve
optimally visualizing results of phonetically similar queries in sigmod  pages 27982802 2021
41
148 ziyun wei immanuel trummer and connor anderson robust voice querying with muve optimally
visualizing results of phonetically similar queries proc vldb endow  141123972409 2021
149 nathaniel weir and prasetya utama bootstrapping an endtoend natural language interface for databases
insigmod  pages 18621864 2019
150 yuk wah wong and raymond j mooney learning for semantic parsing with statistical machine trans
lation in human language technology conference of the north american chapter of the association of
computational linguistics  2006
151 chunyang xiao marc dymetman and claire gardent sequencebased structured prediction for semantic
parsing in acl 2016
152 xiaojun xu chang liu and dawn song sqlnet generating structured queries from natural language
without reinforcement learning corr  abs171104436 2017
153 navid yaghmazadeh yuepeng wang isil dillig and thomas dillig sqlizer query synthesis from natural
language proc acm program lang  1oopsla6316326 2017
154 yuquan yang qifan zhang and junjie yao taskdriven neural natural language interface to database in
wise  volume 14306 of lecture notes in computer science  pages 659673 2023
155 zhilin yang zihang dai yiming yang jaime g carbonell ruslan salakhutdinov and quoc v  le xlnet
generalized autoregressive pretraining for language understanding in neurips  pages 57545764 2019
156 ziyu yao yu su huan sun and wentau yih modelbased interactive semantic parsing a unified
framework and a texttosql case study in emnlpijcnlp  pages 54465457 2019
157 pengcheng yin and graham neubig a syntactic neural model for generalpurpose code generation in
acl pages 440450 2017
158 tao yu zifan li zilin zhang rui zhang and dragomir r radev typesql knowledgebased typeaware
neural texttosql generation in naaclhlt  pages 588594 2018
159 tao yu michihiro yasunaga kai yang rui zhang dongxu wang zifan li and dragomir r radev
syntaxsqlnet syntax tree networks for complex and crossdomain texttosql task in emnlp  pages
16531663 2018
160 tao yu rui zhang kai yang michihiro yasunaga dongxu wang zifan li james ma irene li qingning
yao shanelle roman zilin zhang and dragomir r radev spider a largescale humanlabeled dataset
for complex and crossdomain semantic parsing and texttosql task in emnlp  pages 39113921 2018
161 john m zelle and raymond j mooney learning to parse database queries using inductive logic program
ming in aaai iaai  pages 10501055 1996
162 gideon zenz xuan zhou enrico minack wolf siberski and wolfgang nejdl from keywords to semantic
queries  incremental query construction on the semantic web j web semant  73166176 2009
163 luke s zettlemoyer and michael collins learning to map sentences to logical form structured classifi
cation with probabilistic categorial grammars in uai pages 658666 2005
164 jinchuan zhang yan zhou binyuan hui yaxin liu ziming li and songlin hu trojansql sql injection
against natural language interface to database in emnlp  pages 43444359 2023
165 bolong zheng lei bi juan cao hua chai jun fang lu chen yunjun gao xiaofang zhou and chris
tian s jensen speaknav v oicebased route description language understanding for template driven path
search proc vldb endow  141230563068 2021
166 weiguo zheng hong cheng lei zou jeffrey xu yu and kangfei zhao natural language ques
tionanswering let users talk with the knowledge graph in acm cikm  pages 217226 2017
167 victor zhong caiming xiong and richard socher seq2sql generating structured queries from natural
language using reinforcement learning corr  abs170900103 2017
168 lei zou ruizhe huang haixun wang jeffrey xu yu wenqiang he and dongyan zhao natural language
question answering over rdf a graph data driven approach in sigmod  pages 313324 2014
42","['2019mynlidbeznl2sql2008questio', 'frameworksseq2sql', '2024sv2sqliknowsql', '2017seq2sql', 'informationsegmentation', '1arxiv250302435v1', 'wav2sql', 'disambiguation', 'crossinstitutional', 'geodataregionname']",2
"Integrating AI Planning with Natural Language Processing: A Combination
  of Explicit and Tacit Knowledge","['Kebing Jin', 'Hankz Hankui Zhuo']",2022,http://arxiv.org/abs/2202.07138v2,"Integrating AI Planning with Natural Language Processing:
A Combination of Explicit and Tacit Knowledge
KEBING JIN and HANKZ HANKUI ZHUO∗,School of Computer Science and Engineering, Sun
Yat-sen University, China
Natural language processing (NLP) aims at investigating the interactions between agents and humans, pro-
cessing and analyzing large amounts of natural language data. Large-scale language models play an important
role in current natural language processing. However, the challenges of explainability and complexity come
along with the developments of language models. One way is to introduce logical relations and rules into
natural language processing models, such as making use of Automated Planning. Automated planning (AI
planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals
based on domain models. Recently, there have been plenty of works related to these two fields, which have
the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from
tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing
effectively improves the communication between human and intelligent agents. This paper outlines the
commons and relations between AI planning and natural language processing, argues that each of them can
effectively impact on the other one by five areas: (1) planning-based text understanding, (2) planning-based
natural language processing, (3) planning-based explainability, (4) text-based human-robot interaction, and
(5) applications. We also explore some potential future issues between AI planning and natural language
processing. To the best of our knowledge, this survey is the first work that addresses the deep connections
between AI planning and Natural language processing.
CCS Concepts: •Computing methodologies →Natural language processing ;Planning and schedul-
ing;Information extraction ;Natural language generation .
Additional Key Words and Phrases: AI planning, Natural language processing, Natural language understanding,
Human-robot interaction, Explainability
ACM Reference Format:
Kebing Jin and Hankz Hankui Zhuo. 2022. Integrating AI Planning with Natural Language Processing: A
Combination of Explicit and Tacit Knowledge. ACM Trans. Intell. Syst. Technol. 1, 1 (April 2022), 24 pages.
https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
Natural language processing (NLP) aims at investigating the interactions between agents and
humans, processing and analyzing large amounts of natural language data. In recent years, for
attaining better performance and handling large corpora, building large-scale language models
is an inevitable trend in real applications [ 62,78,126]. Despite the success of language models in
various domains, the explainability and complexity of language models have drawn intense research
interests recently. In order to make models explainable and lightweight, integrating models with
∗Corresponding author
Authors’ address: Kebing Jin, jinkb@mail2.sysu.edu.cn; Hankz Hankui Zhuo, zhuohank@mail.sysu.edu.cn, School of
Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China, 510006.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
©2022 Association for Computing Machinery.
2157-6904/2022/4-ART $15.00
https://doi.org/XXXXXXX.XXXXXXX
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.arXiv:2202.07138v2  [cs.AI]  13 Apr 2023
2 Jin et al.
symbolic planning has been demonstrated effective in various NLP tasks. Symbolic planning (AI
planning) is a branch of artificial intelligence that focuses on building symbolic domain models and
synthesizing plans to transit initial states to goals based on domain models. The plans are typically
for execution by intelligent agents, autonomous robots, and unmanned vehicles. Different from
classical control and classification problems, the solutions are complex and must be discovered and
optimized in multidimensional space. Generally, those approaches are mostly based on structured
data, which has a well-defined structure and logically explainable to humans.
Compared with structured data used in AI planning, natural language descriptions are often
complicated by omissions, inverted order, etc., resulting in difficulties in reasoning about language
descriptions. It is thus often hard to directly train neural models to generate available and correct
solutions, although deep learning has been widely used to handle unstructured data. Deep learning
methods do well in acquiring knowledge from data, capturing implied rules, and expressing them
by mathematical and neural models, which are tacit and unable to be directly shared with other
humans and agents. Different from deep learning methods that aim to learn tacit knowledge,
planning-based methods are better at capturing changes, formalizing them by rules, and generating
valid plans when handling structured data. Rules are already codified, namely explicit knowledge,
which can be clearly expressed and easily shared with others. Therefore, AI planning is one of the
considerable steps to understand implied rules and build domain models from large amount of texts
in natural language processing [32, 72].
On the other hand, unstructured data in real world is not disorderly but often a sequence based
on rules. As for a natural language description, there is a theme running through it, along with a
series of relevant events and a coherent text unfolds. Each sentence relates to the preceding texts
and influences following sentences, just like preconditions and effects of actions in AI planning. For
example, in a recipe about making a meatloaf shown in Figure 1(a), humans can easily understand it
and capture the main information including verbs, e.g., “Heat”, and objects, e.g., “butter” and “skillet”.
However, as for agents, when given a mass of data in the form of sentences, it is hard to directly build
models to reason about the implied rules and predict next moves. If we extract these information and
formalize them structurally, as shown in Figure 1(b), it is easier to construct models based on planning
methods for guiding future unseen tasks.
Besides using AI planning to help reason about implied rules in texts, the power of AI planning
about capturing implied relations and computing valid solutions is another effective way to improve
natural language processing, such as text summarization and machine translation. For example,
there have been planning-based text generation methods [ 57,119] extending a clear storyline
ordered in advance. Those methods first compute sequences composed of keywords, key phrases,
or contents as storylines, then use natural language processing techniques to extend storylines
to coherent texts. In the above-mentioned example, generating an available recipe in a correct order
shown in Figure 1(a) is hard. However, given some rules, such as domain models about the operations
of cooking, agents can compute plans toward achieving specified goals like a theme about making a
meatloaf, as shown in Figure 1(b). Agents can easily extend the plan and gain a valid recipe.
The integration of AI planning and natural language processing combines the best of tacit
knowledge learning from sentences and explicit knowledge in the form of rules. As discussed
in [52], it would be more effective to combine explicit and tacit knowledge rather than giving
up explicit knowledge and learning everything from tacit knowledge, which is the current trend.
Integrating AI planning and natural language processing allows human to communicate with
agents in a more comfortable way, and enables intelligent agents to explain themselves to human
in a human-understandable way. Natural language, as the most comfortable way to communicate
with humans, establishes a relationship between humans and intelligent agents. In recent years,
researchers have made efforts to connect with natural language and robots, such as by dialogue
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 3
Heat  butter in a large skillet .  Add the onions , garlic , celery and carrot . 
Cook the mixture over medium heat  for 5 minutes, stirring  frequently. Add 
the ketchup sauce  and the salt and pepper . Cook the mixture for another 
minute . Combine the meat , bread crumbs , eggs  and parsley in a mixing 
bowl . Add the cooked vegetables  from the skillet . Mix everything well 
together. Push the mixture into the baking loaf pan . Then put the loaf into 
the oven and bake for about  an hour . When the meatloaf is done, allow it 
to cool slightly, then slowly remove the loaf from the baking pan by cutting 
along the sides with a butter knife . Gently lift the meatloaf from the pan 
and place on serving plate . Cut into slices of approximately 3/4 inch thick . 
Heat(butter, skillet) → Add (onions, garlic, celery, carrot, skillet) → 
Cook(mixture, medium heat, 5 minutes) → stirring() → Add(ketchup sauce, 
salt, pepper, skillet) → Cook(mixture, medium heat, one minute) → 
Combine(meat, bread crumbs, eggs, parsley ,bowl) → Add(cooked 
vegetables, bowl) → Mix() → Push(mixture, loaf pan) → Put(loaf, oven) → 
Bake(an hour) →  Cool() → Remove(loaf) → Cut(sides, knife) → 
Lift(meatloaf, pan) → Place(meatloaf, plate) → Cut(meatloaf, 3/4 inch thick)(a) A recipe for making a meatloaf.
     (b) A trace extracted from (a).
Fig. 1. An example textual recipe about making a meatloaf.
systems [ 82,105] and natural language commands understanding [ 59,108]. On the other hand,
planning-based natural language models are based on structured data or implied rules, such as
predicted storylines, which allows human to partly understand the principles of models.
In this paper, we first introduce some background knowledge in AI planning and natural language
processing as well as their relations. Then we give a comprehensive overview of integrating AI
planning and natural language processing by four aspects and their challenges: planning-based text
understanding, planning-based natural language processing, planning-based explainability, and
text-based human-robot interaction. Their relations are shown in Figure 2. Firstly, planning-based
natural language understanding includes extracting actions from texts and learning domain models
from texts. Secondly, we introduce planning-based natural language processing by three tasks
integrated with AI planning, i.e., text generation, text summarization, and machine translation. Then
we discuss planning-based explainability. Next, we introduce text-based human-robot interaction by
extracting actions from natural language instructions, natural language command understanding,
and dialogue generation. Finally, we present current applications, several future directions and
conclude this paper. To the best of our knowledge, this survey is the first work that addresses the
deep connections between AI planning and NLP.
2 PLANNING DOMAIN DESCRIPTION LANGUAGE AND NLP
In this section, we introduce modeling knowledge in AI planning, backgrounds in natural language
processing (NLP), and relations between AI planning and NLP, including similarities, differences,
and language model-based planning.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
4 Jin et al.
Natural Language
Text
Make use of extracted rules 
to improve coherence and 
reasonability.
Human
RobotActions Extraction
Natural Language 
Command Understanding
Dialogue Systems
Human-robot 
InteractionAs a 
Medium 
ExplainabilityText Generation
Text Summarization
Machine Translation
Planning-based
Natural Language ProcessingAction traces Extraction
Domain Models Learning
Planning-based Natural 
Language UnderstandingExtract information, capture rules, 
and build domain models.
Learn implied rules, 
organize skeletons, 
and predict key 
information.
Give instructionsExecute 
instructions
Fig. 2. Relations between AI planning and Natural language processing
2.1 Planning domain description language
A planning problem is composed of a planning domain Dand an instance 𝑝, defined by planning
domain description language. With the development of AI planning, more and more extended
planning domain description languages [ 34,39,92] have been proposed. Taking PDDL (Planning
Domain Definition Language) [ 71] as an example, a planning domain Dis made up by several
action models. An action model is defined by a tuple of 𝐴=⟨𝑎,pre(𝑎),eff(𝑎)⟩, where𝑎is an action
name with zero or more types of parameters. An action is a grounding of an action model, each
of whose parameters is an object. pre(𝑎)is a set of preconditions requiring to be satisfied when
executing𝑎, each of which is a proposition or a numeric constraint. Similarly, eff(𝑎)is a set of effects,
an effect can be a topical proposition, added into or deleted from the state after executing 𝑎, or a
numeric updating, increasing or decreasing the value of variables according to specified functions.
An instance is defined by 𝑝=⟨𝑠0,𝑔,𝜉⟩, where𝑠0is a set of initial assignments by propositions
and variables, and 𝑔is a set of goals requiring to be achieved. 𝜉is an objective function guiding
planner to compute for a minimum cost or maximum reward. A planning problem is to compute
an available action sequence, which can transfer 𝑠0to a state containing desired goals 𝑔.
For example, parts of action models in the Rover domain are shown in Figure 3(a), where “(equipped_for
_imaging ?r)” is a proposition asking that a rover “?r” should equip with a camera for taking image
when executing action “Calibrate”. “( >= (energy ?r) 1)” is a numeric precondition requiring the energy
of rover “?r” should be larger than 1. Figure 3(b) and (c) show an initial state and goals, respectively.
An example valid plan, updating the initial state to a state achieving the goals, is shown in Figure 3(d),
where each action is a grounding action model with parameters.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 5
(
:
a
c
t
i
o
n
 
C
a
l
i
b
r
a
t
e
 
:
p
a
r
a
m
e
t
e
r
s
 
(
?
r
 
-
 
r
o
v
e
r
 
?
i
 
-
 
c
a
m
e
r
a
 
?
t
 
-
 
o
b
j
e
c
t
i
v
e
 
?
w
 
-
 
w
a
y
p
o
i
n
t
)
 
:
p
r
e
c
o
n
d
i
t
i
o
n
 
(
a
n
d
 
(
e
q
u
i
p
p
e
d
_
f
o
r
_
i
m
a
g
i
n
g
 
?
r
)
 
(
>
=
 
(
e
n
e
r
g
y
 
?
r
)
 
2
)
 
(
c
a
l
i
b
r
a
t
i
o
n
_
t
a
r
g
e
t
 
?
i
 
?
t
)
 
(
a
t
 
?
r
 
?
w
)
 
 
 
 
 
 
 
 
 
(
v
i
s
i
b
l
e
_
f
r
o
m
 
?
t
 
?
w
)
 
(
o
n
_
b
o
a
r
d
 
?
i
 
?
r
)
)
 
:
e
f
f
e
c
t
 
(
a
n
d
 
(
d
e
c
r
e
a
s
e
 
(
e
n
e
r
g
y
 
?
r
)
 
2
)
(
c
a
l
i
b
r
a
t
e
d
 
?
i
 
?
r
)
 
)
)
(
:
a
c
t
i
o
n
 
T
a
k
e
_
i
m
a
g
e
 
:
p
a
r
a
m
e
t
e
r
s
 
(
?
r
 
-
 
r
o
v
e
r
 
?
p
 
-
 
w
a
y
p
o
i
n
t
 
?
o
 
-
 
o
b
j
e
c
t
i
v
e
 
?
i
 
-
 
c
a
m
e
r
a
 
?
m
 
-
 
m
o
d
e
)
 
:
p
r
e
c
o
n
d
i
t
i
o
n
 
(
a
n
d
 
(
c
a
l
i
b
r
a
t
e
d
 
?
i
 
?
r
)
 
(
o
n
_
b
o
a
r
d
 
?
i
 
?
r
)
 
(
e
q
u
i
p
p
e
d
_
f
o
r
_
i
m
a
g
i
n
g
 
?
r
)
 
(
s
u
p
p
o
r
t
s
 
?
i
 
?
m
)
 
 
 
 
 
 
 
 
 
 
(
v
i
s
i
b
l
e
_
f
r
o
m
 
?
o
 
?
p
)
 
(
a
t
 
?
r
 
?
p
)
 
(
>
=
 
(
e
n
e
r
g
y
 
?
r
)
 
1
)
)
 
:
e
f
f
e
c
t
 
(
a
n
d
 
(
h
a
v
e
_
i
m
a
g
e
 
?
r
 
?
o
 
?
m
)
(
n
o
t
 
(
c
a
l
i
b
r
a
t
e
d
 
?
i
 
?
r
)
)
(
d
e
c
r
e
a
s
e
 
(
e
n
e
r
g
y
 
?
r
)
 
1
)
)
)
.
.
.
C
a
l
i
b
r
a
t
e
 
(
r
o
v
e
r
0
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1
 
w
a
y
p
o
i
n
t
3
)
 
→
 
T
a
k
e
_
i
m
a
g
e
 
(
r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3
 
o
b
j
e
c
t
i
v
e
1
 
c
a
m
e
r
a
0
 
h
i
g
h
_
r
e
s
)
 
→
 
C
o
m
m
u
n
i
c
a
t
e
_
i
m
a
g
e
_
d
a
t
a
 
(
r
o
v
e
r
0
 
c
a
m
e
r
a
 
o
b
j
e
c
t
i
v
e
1
 
h
i
g
h
_
r
e
s
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
0
)
 
→
 
S
a
m
p
l
e
_
r
o
c
k
 
(
r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e
 
w
a
y
p
o
i
n
t
3
)
 
→
 
D
r
o
p
 
(
r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e
)
 
→
 
C
o
m
m
u
n
i
c
a
t
e
_
r
o
c
k
_
d
a
t
a
 
(
r
o
v
e
r
0
 
c
a
m
e
r
a
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
0
)
 
→
 
N
a
v
i
g
a
t
e
 
(
r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
1
)
 
→
 
N
a
v
i
g
a
t
e
 
(
r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
1
 
w
a
y
p
o
i
n
t
2
)
 
→
 
S
a
m
p
l
e
_
s
o
i
l
 
(
r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e
 
w
a
y
p
o
i
n
t
2
)
 
→
 
C
o
m
m
u
n
i
c
a
t
e
_
s
o
i
l
_
d
a
t
a
 
(
r
o
v
e
r
0
 
c
a
m
e
r
a
 
w
a
y
p
o
i
n
t
2
 
w
a
y
p
o
i
n
t
2
 
w
a
y
p
o
i
n
t
0
)
(
:
i
n
i
t
(
e
q
u
i
p
p
e
d
_
f
o
r
_
i
m
a
g
i
n
g
 
r
o
v
e
r
0
)
 
(
c
a
l
i
b
r
a
t
i
o
n
_
t
a
r
g
e
t
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1
)
 
(
a
t
 
r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3
)
 
(
o
n
_
b
o
a
r
d
 
c
a
m
e
r
a
0
 
r
o
v
e
r
0
)
 
(
a
v
a
i
l
a
b
l
e
 
r
o
v
e
r
0
)
(
c
a
l
i
b
r
a
t
i
o
n
_
t
a
r
g
e
t
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1
)
 
(
s
u
p
p
o
r
t
s
 
c
a
m
e
r
a
0
 
c
o
l
o
u
r
)
(
s
u
p
p
o
r
t
s
 
c
a
m
e
r
a
0
 
h
i
g
h
_
r
e
s
)
 
(
i
n
_
s
u
n
 
w
a
y
p
o
i
n
t
0
)
 
(
=
 
(
e
n
e
r
g
y
 
r
o
v
e
r
0
)
 
5
0
)
.
.
.
.
 
)
(
:
g
o
a
l
 
(
a
n
d
(
c
o
m
m
u
n
i
c
a
t
e
d
_
s
o
i
l
_
d
a
t
a
 
w
a
y
p
o
i
n
t
2
)
(
c
o
m
m
u
n
i
c
a
t
e
d
_
r
o
c
k
_
d
a
t
a
 
w
a
y
p
o
i
n
t
3
)
(
c
o
m
m
u
n
i
c
a
t
e
d
_
i
m
a
g
e
_
d
a
t
a
 
o
b
j
e
c
t
i
v
e
1
 
h
i
g
h
_
r
e
s
)
)
)
(
a
)
 
A
c
t
i
o
n
 
m
o
d
e
l
s
.
(
b
)
 
I
n
i
t
i
a
l
 
s
t
a
t
e
.
(
c
)
 
G
o
a
l
s
.
(
d
)
 
A
n
 
e
x
a
m
p
l
e
 
p
l
a
n
 
f
o
r
 
t
h
e
 
p
l
a
n
n
i
n
g
 
p
r
o
b
l
e
m
.
Fig. 3. An example in the Rover domain, including action models, initial state, goals, and an available plan.
2.2 Natural language processing
Recently, natural language processing (NLP) [ 17,54,114] has attracted lots of attention, and it
builds a bridge between human and agents. Natural language processing is grand, including various
fields, such as natural language understanding (NLU)[ 81,107], natural language generation (NLG),
[30,37] machine translation[ 80], and spelling correction[ 43]. NLP has undergone several stages
of rule-based models, statistic-based models, and neural network models. Rule-based NLP [ 97] is
led by hand-crafted rule sets, whose main task is to understand natural language. It is, however,
difficult and time-consuming to build all hand-crafted rules, lacking of scalability. Statistic-based
NLP [ 65] makes use of probability distributions to generate proper words and sentences, promoting
the application of statistical machine learning methods based on large-scale corpora in natural
language processing. Nevertheless, statistic-based models is barely to capture long-term relations
and use information included in contexts. Recently, deep learning has been widely used in NLP
tasks[ 106], it is able to capture tacit knowledge implied in texts. However, deep learning is to fit
neural networks and predict based on statistics, it can not “understand” the real meaning in natural
language. In this paper, we focus on those NLP tasks related to AI planning. Compared with NLP
approaches totally based on deep learning, planning-based NLP methods are more curious about
implied logic and reasons of the solutions.
2.3 Relations between AI planning and natural language processing
In this section, we will sketch the relations between AI planning and natural language processing,
which is mentioned by [ 38,116,122]. We will first introduce the similarities between AI planning
and natural language processing, and then talk about their differences and deep relations.
We discuss the similarities between AI planning and natural language processing by two aspects.
First of all, AI planning and natural language processing both revolve around observations and
knowledge [ 38]. Planning tasks aim at either solving problems based on a current observation and
goals along with priori knowledge like action models, or constructing knowledge such as transition
functions based on sequential observations. Similarly, in natural language processing tasks, a text
can be regarded as a sequence of observations, each observation is a sentence describing a partially
observed state, where observations changes following implied rules. Secondly, they share two
major common problems in planning tasks and natural language processing tasks: consistency and
diversity. Both of plan traces and texts are cohesive descriptions and stringed by some rules and
goals. As for planning, the rules are action models and transition functions, which update current
states to next ones. The goals are sets of goal states or objective functions, guiding planners to attain
optimal solutions. As for natural language processing, the rules are implied in the organization of
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
6 Jin et al.
texts, such as transition connections or consequences. Their goals can be titles, themes, or topics.
On the other hand, in natural language processing, given goals, we can generate lots of coherent
texts composed of different events, similar to different plan traces computed for the same goal
states. Moreover, a sequence of events can be written as various stylized texts. As shown in Table
1, we enumerate some concepts in AI planning and natural language processing, which can have
some similarities. For example, objects, such as “rover0” and “objective1” in Figure 3, in planning
problems are similar to entities in texts, e.g., “skillet” and “onions” in Figure 1.
Table 1. Similar concepts between AI planning and natural language processing
AI planning Natural language texts
Objects Entities
States Sentences, sentiments, and intentions
Actions Events
Domain models Implied rules, transitions, and relations
Goals Topics, and themes
Plan traces Storylines, skeletons, and frameworks
Although AI planning and natural language processing have those commons, the difference
between them is that AI planning is good at generating explicit knowledge, such as domain models
[128–131], while natural language processing often learns tacit knowledge, such as training models
from natural language data. [ 52] argues that AI systems should be able to know when to take advice
and when to learn, to find a balance between explicit and tacit knowledge. Taking planning-based
text generation as an example, although texts are required to be coherent and with correct logic,
natural language processing is weak in computing available and valid events, which AI planning
is good at. And the integration of both allows agents to generate coherent texts by first using AI
planning to generate storylines and then learning text generator by natural language processing
techniques.
In a word, there are close ties between AI planning and natural language processing, due to
their different advantages of explicit and tacit knowledge. The combination allows each of them to
effectively impact on the other one.
2.4 Language Model-based Planning
Although AI planning can effectively capture rules from action sequences, it is hard for humans
without expert knowledge to construct structured plans. A natural and intuitive way is to use human
natural language to describe plans, asking language model-based planners to be able to handle
text sequences and predict the next moves [ 94,132]. Prior works mostly make use of pre-trained
language models (LMs) to understand abstract, high-level textual actions and learn actionable
knowledge for guiding planning [ 47,50,61]. Specifically, Huang et al. [ 46] use large language
models (LLMs) to generate natural language actions, they investigated actionable knowledge already
contained pre-trained LLMs. On the other hand, some works map natural language instructions
and high-level goals to actions and goals, and learn policy to make decisions [ 98]. For example, LID
[61] uses policies initialized with pre-trained LMs and fine-tunes policies for predicting actions,
validating that LMs are able to contain rich actionable knowledge. Language model-based planners
are mostly based on templated textual actions datasets, rather than complex natural language
instructions with various styles of descriptions. In the following sections, we introduce deep
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 7
connections between AI planning and natural language processing, to rise to the dual challenges
from rules and natural language.
3 PLANNING-BASED NATURAL LANGUAGE UNDERSTANDING
In this section, we introduce a comprehension overview of natural language understanding based on
AI planning. Natural language understanding aims at comprehending human language, including
sentiments, relations in contexts, topics, etc. Compared with learning relations from structured state
traces, learning relations between extracted events from texts are even more challenging. It asks
agents to reason about contexts, capture themes of sentences by selecting words to represent them,
compute causal relationships between the selected words. There are two major areas introduced in
the following section, which are both based on AI planning, to understand the texts and learn causal
relationships from texts. The first one is to extract action sequences from texts, which requires
agents to understand complex contexts from action descriptions. Moreover, it requires agents to be
capable of reasoning about connotations in texts, such as exclusion relations and optional relations
between actions. The other one is to first select words to represent the main ideas of sentences,
and then learn the rules implied in sentences and formalize them by readable domain models for
guiding agents to solve future unseen tasks and helping agents and people understand logical
relations between events.
3.1 Extracting actions from texts
There have been works on extracting action sequences from action descriptions [ 127]. The inputs
of the task mostly include some texts describing some actions and procedures, the outputs are
action sequences from the texts, each action is composed of a verb as action name and some objects.
Figure 4 shows an example in [ 32], where an input text is in left part of Figure 4, extracting action
traces are shown in the right part of Figure 4, the relations between actions are shown in the middle
of Figure 4. This task does not only need extract a word standing for an action of the sentence,
but also reason about contexts for completing omissions caused by pronouns. Early approaches
[55,70] mostly make use of specialized resources, such as semantic parsers and learned lexicons,
to reason about natural language route instructions. For example, MARCO [ 68] was proposed to
Cook the rice the day before, or use leftover rice in the refrigerator.  The important thing to remember is not to heat up the rice, but keep it cold.  In a bowl, add 1 tablespoon of oil to rice.  Use a spoon or your hands to work the oil into the rice, evenly coating the rice.  Transfer the rice to a colander and drain.  Combine eggs and salt in a small bowl and gently whisk until blended.  Heat 1 tablespoon oil in a wok.  Add whisked eggs and cumin seeds to wok.  Stir frequently, working the eggs to a scramble.  Heat the remaining oil in the wok.  If desired, you can recycle some of the oil that drained from the rice.  Add the garlic and onion to the wok.  Stir-fry together over high heat for about 5 minutes or until the onion looks transparent, but is not soft.  Add the rice, eggs, soy sauce, chili sauce, vinegar, and celery.  Mix together, continuing to stir-fry over high heat for 1-2 minutes while stirring frequently.  Spoon onto a plate and serve. Input Training TextMission StartCookUseKeep
HeatAddRecycleWork
ServeEX EXESESESESESOPExtracting Action Names and Action ArgumentsSome Possible Outputs
ES: essential OP: optional EX: exclusiveMake Egg Fried RiceMission EndCookriceUseleftover riceKeeprice, coldAddoilspoonUsehandsAction NamesAction ArgumentsESESESESEXEXx Cook (rice) Æ Keep (rice, cold) Æ Add (oil) Æ Use (spoon) Æ Work (oil, rice) Æ …  Æ Work (eggs) Æ Heat (oil) Æ … Æ Serve ()x Use (leftover rice) Æ Keep (rice, cold) Æ Add (oil) Æ Use (spoon) Æ Work (oil, rice) Æ …  Æ Work (eggs) Æ Heat (oil) Æ … Æ Serve ()x Use (leftover rice) Æ Keep (rice, cold) Æ Add (oil) Æ Use (hands) Æ Work (oil, rice) Æ …  Æ Work (eggs) Æ Heat (oil) Æ … Æ Serve ()x Use (leftover rice) Æ Keep (rice, cold) Æ Add (oil) Æ Use (hands) Æ Work (oil, rice) Æ …  Æ Work (eggs) Æ Recycle (oil) Æ Heat (oil) Æ … Æ Serve ()x ...Figure 1: Illustration of our action sequence extraction problemis unknown. We propose an approach calledEASDRL, whichstands forExtractingActionSequences from texts based onDeepReinforcementLearning. InEASDRL, we view textsassociated with actions as “states”, and associating words intexts with labels as “actions”, and then build deep Q-networksto extract action sequences from texts. We capture complexrelations among actions by considering previously extractedactions as parts of states for deciding the choice of next op-erations. In other words, once we know action “cook(rice)”has been extracted and included as parts of states, we willchoose to extract next action “keep(rice, cold)” instead of“use(leftover rice)” in the above-mentioned example.In the remainder of paper, we ﬁrst review previous workrelated to our approach. After that we give a formal deﬁnitionof our plan extraction problem and presentEASDRLin detail.We then evaluateEASDRLwith comparison to state-of-the-art approaches and conclude the paper with future work.2 Related WorkThere have been approaches related to our work besidesthe ones we mentioned in the introduction section. Map-ping route instructions[Macmahonet al., 2006]to action se-quences has aroused great interest in natural language pro-cessing community. Early approaches, such as[Chen andMooney, 2011; Kim and Mooney, 2013], largely depend onspecialized resources, i.e. semantic parsers, learned lexiconsand re-rankers. Recently, LSTM encoder-decoder structure[Meiet al., 2016]has been applied to this problem and getsdecent performance in processing single-sentence instruc-tions, however, it could not handle multi-sentence texts well.There is also a lot of work on learning STRIPS represen-tation actions[Pomarlanet al., 2017]from texts.[Silet al.,2010; Sil and Yates, 2011]learn sentence patterns and lexi-cons or use off-the-shelf toolkits, i.e., OpenNLP1and Stan-ford CoreNLP2.[Lindsayet al., 2017]also build action mod-els with the help of LOCM[Cresswellet al., 2009]after ex-tracting action sequences by using NLP tools. These tools aretrained for universal natural language processing tasks, theycannot solve the complex action sequence extraction prob-lem well, and their performance will be greatly affected byPOS-tagging and dependency parsing results. In this paperwe aim to build a model that learns to directly extract actionsequences without external tools.3 Problem DeﬁnitionOur training data can be deﬁned byΦ={⟨X,Y⟩}, whereX=⟨w1,w2,...,wN⟩is a sequence of words andY=⟨y1,y2,...,yN⟩is a sequence of annotations. Ifwiisnot an action name,yiis∅. Otherwise,yiis a tuple(ActType,{ExActId},{⟨ArgId, ExArgId⟩})to describetypeof the action name and its corresponding arguments.ActTypeindicates the type of actionaicorresponding towi,which can be one ofessential,optionalandexclusive. Thetypeessentialsuggests the corresponding actionaito beextracted,optionalsuggestsaithat can be “optionally” ex-tracted,exclusivesuggestsaithat is “exclusive” with otheractions indicated by the set{ExActId}(in other words, ei-theraior exactly one action in{ExActId}can be extracted).ExActIdis the index of the action exclusive withai. We de-note the size of{ExActId}byM, i.e.,|{ExActId}|=M.1https://opennlp.apache.org/2http://stanfordnlp.github.io/CoreNLP/Proceedings of the Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence (IJCAI-18)
4065
Fig. 4. An illustration of action sequence extraction problem in [32]
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
8 Jin et al.
map free-form natural language route instructions to action sequences, arising great interest in
natural language processing community. MARCO is able to model a sentence by an instruction,
e.g., “Turn to face the green hallway” can be modeled by “Turn(until=(object=Path, appear=Green,
side=Front, dist=0:))”. [ 22] presented a system along with a plan refinement algorithm to transform
natural language navigation instructions into executable formal plans. Generally, methods with
semantics parsers require high simplicity of the texts. Therefore, mostly approaches are based on
instructional texts or similar texts following some templates.
In recent years, learning methods, such as reinforcement learning and LSTM, have been widely
used in natural language processing, as well as extracting action sequences from natural language
texts, with the rapid development of artificial intelligence. For example, [ 13] proposed a reinforce-
ment learning approach for mapping natural language instructions in two domains, Windows
troubleshooting guides and game tutorials, to sequences of executable actions. It uses a reward
function to define the quality of the executed actions, and a policy gradient algorithm to estimate
the parameters of a log-linear model for action selection. The learner repeatedly constructs action
sequences for a set of documents, executes those actions, and observes the resulting reward. To
handle free natural language without restricted templates, EASDRL [ 32] was presented to extract
action sequences from texts, making use of deep reinforcement learning. It builds Q-networks
to learn policies of extracting actions and extract plans from the labeled texts. EASDRL regards
texts associated with actions as “states”, and associating words in texts with labels as “actions”.
During capturing relations, EASDRL considers previously extracted actions as parts of states for
deciding the choice of next operations. Therefore, EASDRL is able to reason about connotations in
texts, such as exclusion relations and optional relations between actions. Except for reinforcement
learning, there are more techniques used in extracting actions from texts. With the help of with long
short-term memory (LSTM) recurrent neural networks, Mei at al. [ 72] proposed a neural sequence-
to-sequence model to translate single-sentence natural language instructions to action sequences
based upon a representation of the observable world state. LSTMs are applicable to a number of
sequence learning problems, due to their ability to learn long-term dependencies, and they have
been shown to be effective in tasks existing sequences. The LSTM framework allows agents to
bidirectionally encode the navigational instruction sequence and decode the representation to an
action sequence, based on a representation of the current state.
3.2 Learning domain models from texts
Besides extracting action sequences from texts, another way to understand text is to learn the
implied relations from sentences. The input of the learning task is a set of texts, and the output
is a planning domain model composed of action models describing the relations by propositional
preconditions and effects following the syntax of planning domain description language, such as
PDDL [ 71]. Preconditions and effects make use of propositions to describe conditions that must be
satisfied when executing actions and results after executing them, respectively.
Learning domain models from instructional texts is a little different from narrative stories. In-
structional texts are simpler than narrative stories, and the words are domain-dependent. Narrative
stories are mostly third person synopses and they are always along with omission, which results in
complexity when parsing sentences. A general way to construct a domain model is first to extract
words and objects by parsing sentences for annotations (e.g., OpenNLP1and Stanford CoreNLP2),
and then learn causal relationships between them and formalize the relations by action models.
1https://opennlp.apache.org/
2http://stanfordnlp.github.io/CoreNLP/
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 9
To learn domain models from instructional texts, Sil and Yates [ 103] used text mining via a
search method to identify documents that contain words that represent target verbs or events.
Then they used inductive learning techniques to identify appropriate action preconditions and
effects. The method relies on handcrafted Pointwise Mutual Information to learn a SVM-based
classifier that scores preconditions for a given action. Branavan et al. [ 14] presented a reinforcement
learning framework to extract precondition and effects relations implied by the text, and used
these relations to compute action sequences for completing given tasks in the environment. Single
argument predicates are extracted from the text as states, and regarded as sub-goals to construct
hierarchical planning problems. Yordanova and Kirste [ 121] extracted verbs and objects from text
instructions based on part of speech (POS) tagging module, and discovered causal relations on the
basis of the order of appearance to build PDDL models. However, due to lacking of connections
between texts and world states and analyses between variable texts with the same meaning, it is
hard to directly construct domain models as learning action models from structured data. In this
paper, domain models are constructed according to some templates after parsing sentences. For
example, “If the apple is ripe, put the apple on the table. ” indicates that “ripe”, a state of an apple, is
a precondition of action “put”. Therefore, a precondition of action “put” is “(state-ripe)”. Although
the model is readable for human, it is kind of redundant and not easy to understand for agents
because of synonyms and polysemous words. Similarly, Lindsay et al. [ 64] assumed texts are in
restricted templates when describing actions. They generated sequences of actions by constructing
representations of sentences and cluster operators by computing similarity, and built PDDL domain
models with the help of a domain model acquisition tool.
Considering the power of AI planning about offering correct causality and flexible narrative
generation possibilities, constructing domain models has been used in narrative systems recently.
Hayton et al. [ 42] proposed an approach taking natural language sentences which summarise
the main elements of stories as inputs and generating action representations following PDDL,
a narrative planning domain model. To overcome difficulties in parsing narrative stories, they
presented two sets of rules to handle pronouns in stories. Then they used a template similar to [ 121]
to construct planning domains. Another specific difficulty for planning-based narrative systems
is that hand-crafted domain models require more narrative actions and types of narrative objects
compared to generated planning domains. The plentiful actions and objects let generated plan
traces and storyline be more interesting and they can be extended to enjoyable stories. To achieve
it, Porteous et al. [ 87] tried to anticipate the consequences of plan failure and the remedial actions
or objects needed, or described several potential alternatives. They extended narrative planning
domains by two types of principled mechanisms to operationalize narrative action and object
substitution during narrative plan authoring. An original domain model can be extended with the
addition generated by two mechanisms alternately.
3.3 Challenges and future prospects
In AI planning, rules implied in states and actions are enforcedly constrained by preconditions
and effects. Compared with AI planning, rules between events, such as concurrence, causality, and
progression, in natural language processing are more flexible, which often intricately correlate
with others. Moreover, the preconditions and effects are implied in natural language, which are
abstract and hard to be modeled by propositions. In the other hand, in natural language text, a event
can be written in different words, and a word owns various meanings. It therefore is difficult to
directly distinguish them by only parsers. Those challenges make it hard to extract detailed logical
relations implied in natural language, let along model implied relations by constructing structural
domain models. It might be interesting to dig out clear logical relations implied in natural language
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
10 Jin et al.
text, which can lay a foundation for natural language processing tasks, such as explainability and
controllable text generation.
4 PLANNING-BASED NATURAL LANGUAGE PROCESSING
In this section, we introduce three natural language tasks integrated with AI planning, including
text generation, text summarization, and machine translation. Planning-based natural language
processing tasks concern about reasonability and coherence, making use of the power of AI planning
about reasoning about rules and relations.
4.1 Planning-based text generation
One important field combined with AI planning is text generation, in which there have been
significant advances, recently. Text generation asks models to generate coherent and interesting
text based on preceding parts of the text, topics, titles, or themes, requiring agents to be capable
of generating valid and clear logical frameworks. AI planning is one of crucial steps to guide
models to generate well-organized long texts, owing to its power in learning domain models
and computing solutions for goal-driven tasks. In this section, we introduce planning-based text
generation methods with respect to the following two features:
•Symbolic planning text generation combines text generation with a classical planning
framework, taking prior knowledge, e.g., domain models formalized by planning domain
description language, as extra inputs.
•Neural planning text generation are neural generators combined learning with a skeleton
planning, to make up for the difficulties in building hand-crafted domain models.
4.1.1 Symbolic planning text generation. In order to generate coherent text with correct logic, it is
natural to give agents some prior knowledge about basic rules between events. On the other hand,
early rule-based researches [ 9,21,83] about natural language processing explore constructing
representations of texts and combine with hand-crafted rules. It, however, is hard and tedious to
enumerate all rules. Therefore, making use of AI planning to capture implied rules in the form of
domain models with symbolic representations and compute proper skeletons is a natural way, which
can overcome the difficulties of manually constructing rules [ 36,56,66]. For example, Porteous
et al. [ 86] proposed an approach injecting narrative control into plan generation through the use
of PDDL [ 71] state trajectory constraints, to express narrative control information within the
planning representation. They constructed constraint trees according to input domain models, and
injected control into automatically generated narratives system. With the help of constraints, the
approach decomposes problems into sets of smaller subproblems using the temporal orderings
described by the constraints, and solves subproblems incrementally by a planner. Intentional Partial
Order Causal Link (IPOCL) planning framework [ 90] is an extension of classical planning, it aims
at finding a sound and believable sequence of character actions that transforms an initial state
into a state arriving goals. IPOCL does not only create causally sound plot progression, but also
reasons about character intentionality by identifying possible character goals that explain their
actions and creating plans that explain why those characters commit to their goals. Compared to
IPOCL, CPOCL [ 115] preserves the conflicting subplans without damaging the causal soundness of
the overall story to generate interesting stories. CPOCL is an extension of IPOCL that explicitly
captures how characters can thwart one another in pursuit of their goals, which is the essence of
narrative conflicts. Making use of hand-crafted, well-defined domain models, symbolic planning
text generation methods have the ability to produce impressive results in limited domains.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 11
4.1.2 Neural planning text generation. However, it is often tedious or difficult to build domain mod-
els by hand due to the high requirements of manual efforts and domain knowledge. Automatically
learning domains and constructing storylines have significantly attracted researchers’ attention
recently [88, 104].
To automatically learn domain models for helping generate coherent and valid stories, Li et
al. [60] used a crowd-sourced corpus of stories to learn plot graphs that can then be used as
constrained search spaces for sequences of story events, instead of relying on priori domain
models. Specifically, the approach crowdsources a corpus of narrative examples of a new domain,
automatically constructs domain models capturing different possible, non-contradictory story
trajectories, and samples from the space of stories allowed by the domain model according to
some story quality criteria. During the plot graph learning, learning mutual exclusion relations
and optional events lets the generated story be coherent. C2PO [ 2] learns a branching story graph
structure that can be searched, and introduces soft causal relations as causal relations inferred
from commonsense reasoning. It creates a branching space of possible story continuations that
bridge between plot points that are automatically extracted from existing natural language plot
summaries.
Another way for constructing valid line of text is to construct storylines in advance, which can be
skeletons, or sequences of keywords, key phrases, or contents. Xu et al. [ 118] generated skeletons
composed of phrases learned by a reinforcement learning method, and then expanded skeletons
to complete and fluent sentences. Fan et al. [ 31] proposed a novel approach which first generates
plans in the form of predicate-argument structures, then generates stories with placeholder tokens
to indicate entities, and finally replaces tokens by entities based on the global story contexts. The
inputs of the task are short descriptions of scenes or events, and the approach outputs relevant
narrative stories following the inputs.
Instead of generating skeletons with detailed prompts, some approaches first plan out storylines,
which enable them to generate controllable stories with goals. [ 119] proposed a hierarchical
generation framework that first planned a controllable storyline composed of keywords towards a
goal (i.e., a title), and then generated a story based on the storyline. The RAKE algorithm [ 91] takes
each sentence as an input and combines several word frequency based and graph-based metrics to
weight the importance of the words. The approach regards the most important word as the keyword.
The storyline is planned out based on the title, previously generated sentences, and the previous
keywords in the storyline. In the experiments, they explore two strategies, dynamic schema and
static schema. Results show the static schema performs better than the other one because it plans
the storyline holistically, thus tends to generate more coherent and relevant stories. Similarly,
[57] made use of a related framework, which first plans out storyline composed of a sequence
of keywords and then generates the whole story, to handle stylized story generation. Stylized
story generation is to generate stories with specified style given a leading context. Keywords are
selected following some emotion-driven style, such as “fear”, “anger”, and “surprsie”. According
to the stylized keywords, the approach can generate generates the whole stylized story with the
guidance of the keywords. Yu et al. [ 123] followed Yao et al. [ 119] and used the RAKE algorithm to
extract keywords to train a generation model for conducting keyword planning given story titles
as inputs. Then the approach combines the story titles and the corresponding keywords of each
story as the inputs of the graph module to automatically generate a graph for each story. According
to the keywords, titles, story graphs, the approach encodes them into latent variables and further
decodes them to generate the corresponding stories.
Except for generating stories according to prompts or goals, DYPLOC [ 44], a dynamic planning
generation framework, takes a set of content items as inputs, each content item consists of a title, a
set of entities, and a set of core concepts. To organize unordered content items, DYPLOC introduces
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
12 Jin et al.
a plan scoring network, which learns to dynamically select and order contents based on what has
been produced previously while generating the outputs.
4.1.3 Challenges and future prospects. Recently, text generation [ 49,51,124] has gained lots
of attraction, aiming at letting intelligent agents express like humans. Numbers of methods to
generate coherent texts have been proposed in recent years. Generating logical and controllable
texts, however, is still a challenging task. AI planning is one of critical ways to enable agents to
generate logical and controllable texts. Compared with symbolic planning text generation methods
and neural planning text generation methods, the former is more capable of generating logical
storylines with goals, and the texts generated by the latter are more diverse and coherent. Specially,
symbolic planning methods can generate more explainable storylines, which is still challenging
for deep learning methods. In general, it would be interesting to combine both for generating
logical, controllable, and coherent text with diversity. Although there have been some approaches
[31,96,109] proposed, based on the syntax of plans or representation of structure in AI planning,
they use neural networks to predict unseen events instead of speculating based on logical relations
implied. We hold the opinion that, compared with only learning blackbox neural models with
implicit rules, appropriately combined with explicit logical relations would be a new attempt, which
maybe contribute to natural language processing tasks.
4.2 Planning-based Text Summarization
Text summarization is to extract important information from texts and generate new texts based
on those information in the form of summarizes. It requires agents to understand texts, filter
information from abundant descriptions and organize them to form summarizes, which is one of
the most researched areas among the NLP community. Text summarization can be categorized into
extractive and abstractive techniques. Extractive summarization aims at selecting subsets of words
or sentences from input articles to summarize them. Abstractive summarization takes articles as
inputs, tries to understand the texts and generate summarizes. In recent years, some researchers try
to integrate text summarization models with AI planning. The combination of AI planning and text
summarization is mostly based on deep learning abstractive summarization, making use of content
planning which describes or predicts skeletons of articles. Planning-based text summarization
methods first plan out skeletons of summarizies or compute probability distributions, and then
generate the whole sentences based on the skeletons or predictions. For example, Narayan et al.
[77] first computed plans in the form of entity chains, which are ordered sequences of entities, and
then generated summaries conditioned on the plans. Marfurt et al. [ 69] proposed an abstractive
summarization model implemented with a planning step, done by a hierarchical decoder, which first
plans out an outline for the next sentence in the form of sentence representations and generates
words according to the representations. Amplayo et al. [ 3] incorporated content planning in
unsupervised summarization and datasets creation. They predicted aspect and sentiment probability
distributions as content plans and generated sentences according to the predictions. During creating
datasets, they made use of the distributions parametrized by the content planner to control the
structures of created datasets.
In current planning-based text summarization approaches, content planning is based on deep
learning which learns models and probability distributions to predict. However, only fitting deep
learning models based on representations of sentences and words is hard to capture the relations
implied. We believe that it would be interesting and challenging to let content planning modules
understand relations implied in texts, which will allow content plans to be more coherent and
controllable. On the other hand, although some mainstream text summarization methods are not
based on AI planning, there are some commonalities between them. For example, tree-based and
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 13
graph-based text summarization approaches[ 4,8,58] first find the most important information from
the text and then use trees and graphs to create summaries. Those structures aim at representing the
relations between sentences, which is similar to the relations between actions in AI planning but at
a more abstract level. Secondly, some text summarization methods try to obtain important words
from sentences, such as verbs, objects, and subjects, to represent sentences semantically [ 1]. These
forms have similarities with the structured representations in AI planning such as propositions
and first-order predicates. Thirdly, ontology-based text summarization methods [ 74,117] collect
entities and their relationships, which reminds us of domain models in AI planning. We believe
that there is a vast scope for researchers to combine AI planning and text summarization.
4.3 Planning-based Machine Translation
Machine translation aims at automatically translating content from source language to another
target language, having a long history. One way to understand source texts and generate target
texts is to combine neural language models with planning phases, i.e., first generating skeletons,
and extending them by target languages. For example, Gülçehre et al. [ 41] integrated an auto-
encoder with a planning mechanism, the auto-encoder first encodes texts by sequences of vector
representations and decodes representations by generating target translation character-by-character.
Specifically, they first created plans ahead in the form of action matrices, which are sequences of
probability distributions, and made use of commitment plan vectors to govern whether to recompute
plans or use them. Then they computed soft alignments based on the plan and generated texts in
target language at each time-step. Shu and Nakayama [ 102] combined neural machine translation
with a planning phase, which first generates planner codes to disambiguate uncertain information
about the sentence structure and control the structure of output sentences. Bahdanau et al. [ 7]
used actor-critic methods from reinforcement learning (RL) to generate sequences. They showed
that sequences can be used in machine translation tasks, gaining better translation performance.
Those approaches first produce big pictures of output texts by planning, then generate complete
sentences conditioned on plans. They take advantages of capturing implied rules to generate more
accurate and coherent target texts.
In natural language texts, the transitions between sentences imply relations and rules. Machine
translation tasks do not only need to understand word-level structures of sentences, but also need
to capture sentence-level relationships. Only relying on word-by-word text generation is hard and
challenging to generate coherent and logical texts, especially when generating accurate transitions
between sentences. Current approaches to capture implied rules and generate plans are mostly based
on neural black-box models, lacking the explainability of making decisions. Previous researches
about rule-based translation are explainable, they are based on hand-crafted rules. Although those
rules are explicit and accurate, it is hard to manually write rules and the rules are not scalable.
Producing rules are time-consuming and tedious. However, it would be interesting if we regard it as
action models learning in planning community, which structurally formalize rules by preconditions
and effects. We believe that combining rule-based machine translation with planning and neural
machine translation may spark new ideas.
5 PLANNING-BASED EXPLAINABILITY
Nowadays, although deep learning approaches have been widely used in AI fields, human cannot
understand practical meaning inside black-box neural models. Differently, AI planning is able to
offer explicit knowledge, in the form of first-order logic, domain models, etc, implied in natural
language. Therefore, the combination of natural language and AI planning may enable AI systems
to be able to explain their reasoning to humans, which meets the needs for AI systems to work
synergistically with humans. Those systems require agents to be aware of the intentions, capabilities
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
14 Jin et al.
Lack 
explainability
Offer rules, 
storylines,
action sequences,
domain modelsNeural 
AI systems
Human
Planning-based
AI systemsHuman-
understandable 
symbolic interfaceGive feedbacks, 
such as rewards 
and punishments
Annotate, 
answer, or 
explainGive human-
understandable 
queriesQuery
Combine with
AI planning
Fig. 5. Two types of making neural AI systems be explainable: (1) integrating AI systems with planning
techniques; (2) making use of human-understandable interface.
and mental model of the human in the loop during its decision process. As shown in Figure 5,
besides extracting action sequences [ 32,68] and building domain models [ 14,64] mentioned
above, another way for making AI system explainable is to construct human-understandable
symbolic interfaces (cf. [ 53]). A human-understandable symbolic interface is not only developed
for its own computational efficiency, but also beneficial to humans. EXPAND system [ 40] and
SERLfD framework [ 125], respectively. EXPAND system accelerates Human-in-the-Loop deep
reinforcement learning by using human evaluative feedback and visual explanation. SERLfD uses
self-explanation to recognize valuable high-level relational features as an interpretation of why a
successful trajectory is successful, allowing SERLfD to guide itself and improve the efficiency.
6 TEXT-BASED HUMAN-ROBOT INTERACTION
The rapid developments of artificial intelligence let robots move out from industrial environments,
and enter the daily life of humans, such as homes and hospitals. It requires robots to be able to
respond quickly and effectively to rapidly-changing conditions and expectations. Language–based
communication is the most natural method for humans to communicate with others, so natural
language is a good candidate to be robot instruction for human-robot interaction. In this section,
we will introduce text-based human-robot interaction from three aspects: extracting actions from
natural language commands, natural language command understanding, and dialogue generation,
as shown in the Figure 6.
6.1 Extracting actions from natural language command
One of important tasks in text-based human-robot interaction is to extract actions from natural
language commands [ 48,79,85,111]. Extracting actions from natural language commands is
similar to action extraction in Section 3.1. Differently, extracting actions from natural language
commands is not only to capture important words to indicate sentences, but also to understand
implied rules and generate action sequences to guide robots to achieve tasks. Some approaches
make use of with language descriptions, then build models that map language commands to
action sequences. Tellex et al. [ 110] introduced a system, Generalized Grounding Graphs (G3),
taking a natural language command as input and outputting a plan for the robot. G3instantiates a
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 15
Human
RobotNatural language 
commandsNatural language 
commandsNatural language 
commandsAction 
sequences
Action models 
(understand 
implied 
intentions)
Planning-based 
dialogue systemsExtract actions 
Execute
Capture 
implied rules and 
intentions
Communicate
Generate 
utterancesGive feedbacksUnderstand new 
commands
Fig. 6. Relations of researches in human-robot interaction.
probabilistic graphical model for a particular natural language command according to hierarchical
and compositional semantic structure of the command. Cantrell et al. [ 20] presented a robotic
architecture equipping with a planner that uses newly discovered information to produce new and
updated plans, specifically information originating in spoken input produced by human operators.
The robot can learn action sequences with defined preconditions and effects from natural language
descriptions, and immediately apply this knowledge to improve planning. On the other hand, some
approaches [ 16,120] focus on temporal logic between natural language commands, aiming at
handling semantic disambiguation of natural language.
6.2 Natural Language Command Understanding
Another important task is to enable agents to understand natural language commands given by
humans, which requires agents to understand natural language commands and capture implied rules
[10,10,12,25,25,99], or learn new actions based on natural language commands and dialogues[ 35,
75,95,101]. To understand natural language commands, Thomason et al. [ 113] introduced a dialog
agent to understand human natural language commands through semantic parsing, actively resolve
ambiguities using a dialog manager, and incrementally learn from human-robot conversations. The
agent employs incremental learning of a semantic parser from conversations on a mobile robot.
It is implemented and tested both on a web interface with hundreds of users and on a mobile
robot over several days, tasked with understanding navigation and delivery requests through
natural language in an office environment. Brawer et al. [ 15] presented a framework for effectively
grounding situated and natural language to action selection during human-robot interaction. It
integrates verbal commands from a human partner with contextual information in the form of a
task model. The approach is capable of acquiring and deploying new task representations from
limited and natural language data sets, and without any prior domain knowledge of language
or the task itself. Moreover, understanding action models and predicting next actions are widely
researched for robotic tasks and navigation tasks with natural language commands [24, 26, 112].
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
16 Jin et al.
On the other hand, another challenge in natural language command understanding tasks is
to learn new actions when facing unknown natural language commands [ 6,100]. Cantrell et al.
[19] introduced an algorithm, to learn meanings of action verbs through dialogue-based natural
language descriptions and integrated it in the robot’s natural language subsystem. The algorithm
allows robots to perform the actions associated with the learned verb meanings right away without
any additional help or learning trials. Moreover, it allows human to interact with a robot to explain
new action words in natural language, and lets the robot be able to perform the new action and
store the procedural knowledge for future usage. Learning by Instruction Agent (LIA) [ 5] was
proposed to learn new commands by natural language interaction with human. When facing a
new natural language command that LIA does not understand, it prompts users to explain how
to achieve the command through a sequence of natural language steps. LIA interprets commands
using a semantic parser that maps each command to a logical form, which contains one or more of
functions and predicates.
Undoubtedly, letting agents understand natural language commands and infer about next actions
is an important but challenging task. An agent does not only need to capture rules implied in
utterances, but also need to distinguish sentences described in different ways. We believe that the
combination of planning-based natural language processing and human-robot interaction would
create something interesting for natural language commands understanding tasks.
6.3 Dialogue Systems
Dialogue systems [ 23,67] have been a bridge between human and robots, which interacts with
human in natural language. AI planning is one of crucial mechanisms used in dialogue systems
to recognize the intentions conveyed in dialogues [ 18,76]. Planning-based dialogue systems take
advantage of the power of capturing and expressing rules and use it to manage utterances or guide
the generation. Rules, plans and intentions offer proper logical forms which derive appropriate
communication acts in dialogue systems [ 28]. Plan-based model [ 27,93] were proposed to manage
the intentions and information implied in dialogues. Those models describe the common activities
and relations between utterances, and can be used in the following generation processes. However,
planning-based dialogue systems are still in early stages [ 28,84], which facing the challenges
of complex representations in open-domain, difficulties of manually constructing models and
limitations of scalability of dialogue models. Nevertheless, we believe that planning could be a
strong suit for dialogue systems by integrating with automatically domain models learning and
searching strategies, especially for controlled dialogue generation. Moreover, we are interested in
the explainability of planning-based dialogue systems, it would be interesting to know the reason
for intentions generation.
7 APPLICATIONS
In this section, we introduce some reality applications based on combinations of AI planning and
natural language processing. AI planning is widely used in reality management systems, such as
logistics management, workshop schedule, and reservoir operation. Moreover, natural language
processing (NLP) helps human communicate with agents, the combination of AI planning and NLP
enables applications to be found in many fields, such as emergency managements [ 11,29,29,33]
and urban planning [ 63,63,89]. For example, the Urban Redevelopment Authority (URA) Centre in
Singapore3deployed Robotic Process Automation and NLP to help conduct operations for resource
optimization. The combination allows routine tasks to make use of AI planning and NLP, such
as chatbots for public queries, which capture information from large datasets, analyze textual
3https://www.ura.gov.sg/Corporate/Resources/Ideas-and-Trends/AI-in-Urban-Planning
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 17
feedback, make planning decisions, and respond intelligently. On the other hand, the navigation
systems in daily use, such as Baidu Maps4and Google Maps5, combine making decisions and
NLP techniques, which plan out routes with different objectives according to goals, and generate
natural language suggestions to guide human. Moreover, agents learn from human commands and
navigation datasets, helping agents understand human behaviors [45, 73].
8 CONCLUSION
In this paper, we consider that AI planning and natural language processing have strong ties, and we
introduce recent works about four related tasks, i.e., planning-based text understanding, planning-
based natural language processing, planning-based explainability, and text-based human-robot
interaction. We first introduce backgrounds about AI planning and natural language processing
and discuss commons between them, as well as their abilities to generate explicit knowledge,
e.g., domain models, and learning from tacit knowledge, e.g., neural models. We then introduce
methods of planning-based text understanding by extracting action sequences from texts and
learning domain models from texts. Next, we give an overview of planning-based natural language
processing about text generation, text summarization, and machine translation. Then, we introduce
recent works in planning-based explainability and text-based human-robot interaction.
With this paper, we aim to provide a high-level view of AI planning and natural language
processing for further studies, about integrating them for a combination of explicit and tacit
knowledge. Combining learning from tacit knowledge and using explicit knowledge in a fully
principled way is an open problem, although there are non-negligible relations between AI planning
and natural language processing, allowing each of them can effectively impact the other one.
However, there is not enough communication between these two fields. While many advances have
been made in natural language processing by using AI planning algorithms, a significant amount
of research is still required to understand the implied knowledge hidden in texts. Meanwhile,
improving the ability to describe environments by domain models and solve large-scale planning
problems is also beneficial to understanding texts and generating coherent and interesting texts.
We believe that integrating AI planning and natural language processing, a complex combination of
explicit and tacit knowledge, is a promising research area, which can improve the communication
between human and intelligent agents.
REFERENCES
[1]S Alshaina, Ansamma John, and Aneesh G Nath. 2017. Multi-document abstractive summarization based on predicate
argument structure. In 2017 IEEE International Conference on Signal Processing, Informatics, Communication and Energy
Systems (SPICES) . IEEE, 1–6.
[2]Prithviraj Ammanabrolu, Wesley Cheung, William Broniec, and Mark O. Riedl. 2021. Automated Storytelling
via Causal, Commonsense Plot Ordering. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium
on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021 . 5859–5867. https:
//ojs.aaai.org/index.php/AAAI/article/view/16733
[3]Reinald Kim Amplayo, Stefanos Angelidis, and Mirella Lapata. 2021. Unsupervised Opinion Summarization with
Content Planning. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference
on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in
Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021 . 12489–12497. https://ojs.aaai.org/index.php/AAAI/
article/view/17481
[4]Mozhgan Nasr Azadani, Nasser Ghadiri, and Ensieh Davoodijam. 2018. Graph-based biomedical text summarization:
An itemset mining and sentence clustering approach. J. Biomed. Informatics 84 (2018), 42–58. https://doi.org/10.1016/
j.jbi.2018.06.005
4https://map.baidu.com/
5https://www.google.de/maps
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
18 Jin et al.
[5]Amos Azaria, Jayant Krishnamurthy, and Tom M. Mitchell. 2016. Instructable Intelligent Personal Agent. In Proceedings
of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA , Dale Schuurmans
and Michael P. Wellman (Eds.). 2681–2689. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12383
[6]Amos Azaria, Shashank Srivastava, Jayant Krishnamurthy, Igor Labutov, and Tom M. Mitchell. 2020. An agent for
learning new natural language commands. Auton. Agents Multi Agent Syst. 34, 1 (2020), 6. https://doi.org/10.1007/
s10458-019-09425-x
[7]Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C. Courville,
and Yoshua Bengio. 2017. An Actor-Critic Algorithm for Sequence Prediction. In 5th International Conference
on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings . https:
//openreview.net/forum?id=SJDaqqveg
[8]Siddhartha Banerjee, Prasenjit Mitra, and Kazunari Sugiyama. 2015. Multi-Document Abstractive Summarization
Using ILP Based Multi-Sentence Compression. In Proceedings of the Twenty-Fourth International Joint Conference on
Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015 , Qiang Yang and Michael J. Wooldridge
(Eds.). 1208–1214. http://ijcai.org/Abstract/15/174
[9]Robert Baud, Christian Lovis, Laurence Alpay, Anne-Marie Rassinoux, JR Scherrer, Anthony Nowlan, and Alan
Rector. 1993. Modelling for natural language understanding.. In Proceedings of the Annual Symposium on Computer
Application in Medical Care . American Medical Informatics Association, 289.
[10] Yonatan Bisk, Kevin J. Shih, Yejin Choi, and Daniel Marcu. 2018. Learning Interpretable Spatial Operations in a Rich
3D Blocks World. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th
innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in
Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 , Sheila A. McIlraith and Kilian Q.
Weinberger (Eds.). 5028–5036. https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17410
[11] Simon Blindheim, Sebastien Gros, and Tor Arne Johansen. 2020. Risk-based model predictive control for autonomous
ship emergency management. IFAC-PapersOnLine 53, 2 (2020), 14524–14531.
[12] Valts Blukis, Dipendra Kumar Misra, Ross A. Knepper, and Yoav Artzi. 2018. Mapping Navigation Instructions to
Continuous Control Actions with Position-Visitation Prediction. In 2nd Annual Conference on Robot Learning, CoRL
2018, Zürich, Switzerland, 29-31 October 2018, Proceedings (Proceedings of Machine Learning Research, Vol. 87) . 505–518.
http://proceedings.mlr.press/v87/blukis18a.html
[13] S. R. K. Branavan, Harr Chen, Luke S. Zettlemoyer, and Regina Barzilay. 2009. Reinforcement Learning for Mapping
Instructions to Actions. In ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational
Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009,
Singapore , Keh-Yih Su, Jian Su, and Janyce Wiebe (Eds.). 82–90. https://aclanthology.org/P09-1010/
[14] S. R. K. Branavan, Nate Kushman, Tao Lei, and Regina Barzilay. 2012. Learning High-Level Planning from Text. In
The 50th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, July 8-14,
2012, Jeju Island, Korea - Volume 1: Long Papers . 126–135. https://aclanthology.org/P12-1014/
[15] Jake Brawer, Olivier Mangin, Alessandro Roncone, Sarah Widder, and Brian Scassellati. 2018. Situated Human-
Robot Collaboration: predicting intent from grounded natural language. In 2018 IEEE/RSJ International Conference on
Intelligent Robots and Systems, IROS 2018, Madrid, Spain, October 1-5, 2018 . 827–833. https://doi.org/10.1109/IROS.
2018.8593942
[16] Igor Buzhinsky. 2019. Formalization of natural language requirements into temporal logics: a survey. In 17th
IEEE International Conference on Industrial Informatics, INDIN 2019, Helsinki, Finland, July 22-25, 2019 . 400–406.
https://doi.org/10.1109/INDIN41052.2019.8972130
[17] Erik Cambria and Bebo White. 2014. Jumping NLP curves: A review of natural language processing research. IEEE
Computational intelligence magazine 9, 2 (2014), 48–57.
[18] Guy Camilleri. 2002. Dialogue systems and planning. In International Conference on Text, Speech and Dialogue . Springer,
429–436.
[19] Rehj Cantrell, Paul W. Schermerhorn, and Matthias Scheutz. 2011. Learning actions from human-robot dialogues. In
20th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2011, Atlanta, Georgia,
USA, July 31 - August 3, 2011 , Henrik I. Christensen (Ed.). 125–130. https://doi.org/10.1109/ROMAN.2011.6005199
[20] Rehj Cantrell, Kartik Talamadupula, Paul W. Schermerhorn, J. Benton, Subbarao Kambhampati, and Matthias Scheutz.
2012. Tell me when and why to do it!: run-time planner model updates via natural language instruction. In HRI,
Holly A. Yanco, Aaron Steinfeld, Vanessa Evers, and Odest Chadwicke Jenkins (Eds.). 471–478. https://doi.org/10.
1145/2157689.2157840
[21] Nick Cercone and Gordon McCalla. 1986. Accessing knowledge through natural language. In Advances in Computers .
Vol. 25. Elsevier, 1–99.
[22] David L. Chen and Raymond J. Mooney. 2011. Learning to Interpret Natural Language Navigation Instructions from
Observations. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco,
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 19
California, USA, August 7-11, 2011 , Wolfram Burgard and Dan Roth (Eds.). http://www.aaai.org/ocs/index.php/AAAI/
AAAI11/paper/view/3701
[23] Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang. 2017. A Survey on Dialogue Systems: Recent Advances
and New Frontiers. SIGKDD Explor. 19, 2 (2017), 25–35. https://doi.org/10.1145/3166054.3166058
[24] Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, and Yoav Artzi. 2019. TOUCHDOWN: Nat-
ural Language Navigation and Spatial Reasoning in Visual Street Environments. In IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 . 12538–
12547. http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_TOUCHDOWN_Natural_Language_
Navigation_and_Spatial_Reasoning_in_Visual_Street_CVPR_2019_paper.html
[25] Haonan Chen, Hao Tan, Alan Kuntz, Mohit Bansal, and Ron Alterovitz. 2020. Enabling Robots to Understand
Incomplete Natural Language Instructions Using Commonsense Reasoning. In 2020 IEEE International Conference
on Robotics and Automation, ICRA 2020, Paris, France, May 31 - August 31, 2020 . 1963–1969. https://doi.org/10.1109/
ICRA40945.2020.9197315
[26] Ta-Chung Chi, Minmin Shen, Mihail Eric, Seokhwan Kim, and Dilek Hakkani-Tür. 2020. Just Ask: An Interactive
Learning Framework for Vision and Language Navigation. In The Thirty-Fourth AAAI Conference on Artificial
Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The
Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February
7-12, 2020 . 2459–2466. https://ojs.aaai.org/index.php/AAAI/article/view/5627
[27] Jennifer Chu-Carroll and Sandra Carberry. 1994. A plan-based model for response generation in collaborative
task-oriented dialogues. arXiv preprint cmp-lg/9405011 (1994).
[28] Philip R Cohen. 2020. Back to the future for dialogue research. In Proceedings of the AAAI Conference on Artificial
Intelligence , Vol. 34. 13514–13519.
[29] Daniel G Costa, João Paulo J Peixoto, Thiago C Jesus, Paulo Portugal, Francisco Vasques, Elivelton Rangel, and Maycon
Peixoto. 2022. A Survey of Emergencies Management Systems in Smart Cities. IEEE Access (2022).
[30] Chenhe Dong, Yinghui Li, Haifan Gong, Miaoxin Chen, Junxin Li, Ying Shen, and Min Yang. 2021. A Survey of
Natural Language Generation. arXiv preprint arXiv:2112.11739 (2021).
[31] Angela Fan, Mike Lewis, and Yann N. Dauphin. 2019. Strategies for Structuring Story Generation. In Proceedings
of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August
2, 2019, Volume 1: Long Papers , Anna Korhonen, David R. Traum, and Lluís Màrquez (Eds.). 2650–2660. https:
//doi.org/10.18653/v1/p19-1254
[32] Wenfeng Feng, Hankz Hankui Zhuo, and Subbarao Kambhampati. 2018. Extracting Action Sequences from Texts
Based on Deep Reinforcement Learning. In IJCAI . 4064–4070.
[33] Daniela Fogli and Giovanni Guida. 2013. Knowledge-centered design of decision support systems for emergency
management. Decision Support Systems 55, 1 (2013), 336–347.
[34] Maria Fox and Derek Long. 2002. PDDL+: Modeling continuous time dependent effects. In Proceedings of the 3rd
International NASA Workshop on Planning and Scheduling for Space , Vol. 4. 34.
[35] Tyler M. Frasca, Bradley Oosterveld, Meia Chita-Tegmark, and Matthias Scheutz. 2021. Enabling Fast Instruction-
Based Modification of Learned Robot Skills. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium
on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021 . 6075–6083. https:
//ojs.aaai.org/index.php/AAAI/article/view/16757
[36] Konstantina Garoufi. 2014. Planning-Based Models of Natural Language Generation. Lang. Linguistics Compass 8, 1
(2014), 1–10. https://doi.org/10.1111/lnc3.12053
[37] Albert Gatt and Emiel Krahmer. 2018. Survey of the state of the art in natural language generation: Core tasks,
applications and evaluation. Journal of Artificial Intelligence Research 61 (2018), 65–170.
[38] Christopher W. Geib and Mark Steedman. 2007. On Natural Language Processing and Plan Recognition. In IJCAI
2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12,
2007, Manuela M. Veloso (Ed.). 1612–1617. http://ijcai.org/Proceedings/07/Papers/260.pdf
[39] Alfonso Gerevini and Derek Long. 2005. Plan constraints and preferences in PDDL3 . Technical Report. Technical
Report 2005-08-07, Department of Electronics for Automation . . . .
[40] Lin Guan, Mudit Verma, Sihang Guo, Ruohan Zhang, and Subbarao Kambhampati. 2021. Widening the Pipeline in
Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation. Advances in
Neural Information Processing Systems 34 (2021).
[41] Çaglar Gülçehre, Francis Dutil, Adam Trischler, and Yoshua Bengio. 2017. Plan, Attend, Generate: Character-Level
Neural Machine Translation with Planning. In Proceedings of the 2nd Workshop on Representation Learning for NLP,
Rep4NLP@ACL 2017, Vancouver, Canada, August 3, 2017 , Phil Blunsom, Antoine Bordes, Kyunghyun Cho, Shay B.
Cohen, Chris Dyer, Edward Grefenstette, Karl Moritz Hermann, Laura Rimell, Jason Weston, and Scott Yih (Eds.).
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
20 Jin et al.
228–234. https://doi.org/10.18653/v1/w17-2627
[42] Thomas Hayton, Julie Porteous, João Fernando Ferreira, and Alan Lindsay. 2020. Narrative Planning Model Acquisition
from Text Summaries and Descriptions. In AAAI . 1709–1716.
[43] Daniel Hládek, Ján Staš, and Matúš Pleva. 2020. Survey of automatic spelling correction. Electronics 9, 10 (2020), 1670.
[44] Xinyu Hua, Ashwin Sreevatsa, and Lu Wang. 2021. DYPLOC: Dynamic Planning of Content Using Mixed Language
Models for Text Generation. In Proceedings of ACL . 6408–6423.
[45] Jizhou Huang, Haifeng Wang, Miao Fan, An Zhuo, Yibo Sun, and Ying Li. 2020. Understanding the Impact of
the COVID-19 Pandemic on Transportation-related Behaviors with Human Mobility Data. (2020), 3443–3450.
https://doi.org/10.1145/3394486.3412856
[46] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. 2022. Language Models as Zero-Shot Planners:
Extracting Actionable Knowledge for Embodied Agents. 162 (2022), 9118–9147. https://proceedings.mlr.press/v162/
huang22a.html
[47] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor
Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,
and Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning with Language Models. CoRR
abs/2207.05608 (2022). https://doi.org/10.48550/arXiv.2207.05608 arXiv:2207.05608
[48] Pham Ngoc Hung and Takashi Yoshimi. 2016. Extracting actions from instruction manual and testing their execution
in a robotic simulation. ASEAN Engineering Journal 6, 1 (2016), 47–58.
[49] Touseef Iqbal and Shaima Qureshi. 2020. The survey: Text generation models in deep learning. Journal of King Saud
University-Computer and Information Sciences (2020).
[50] Peter A. Jansen. 2020. Visually-Grounded Planning without Vision: Language Models Infer Detailed Plans from
High-level Instructions. EMNLP 2020 (2020), 4412–4417. https://doi.org/10.18653/v1/2020.findings-emnlp.395
[51] HanQi Jin, Yue Cao, TianMing Wang, XinYu Xing, and XiaoJun Wan. 2020. Recent advances of neural text generation:
Core tasks, datasets, models and challenges. Science China Technological Sciences 63, 10 (2020), 1990–2010.
[52] Subbarao Kambhampati. 2021. Polanyi’s revenge and AI’s new romance with tacit knowledge. Commun. ACM 64, 2
(2021), 31–32. https://doi.org/10.1145/3446369
[53] Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, and Lin Guan. 2021. Symbols as a Lingua
Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems. CoRR abs/2109.09904 (2021).
arXiv:2109.09904 https://arxiv.org/abs/2109.09904
[54] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. 2022. Natural language processing: State of the art,
current trends and challenges. Multimedia Tools and Applications (2022), 1–32.
[55] Joohyun Kim and Raymond J. Mooney. 2012. Unsupervised PCFG Induction for Grounded Language Learning with
Highly Ambiguous Supervision. In EMNLP-CoNLL , Jun’ichi Tsujii, James Henderson, and Marius Pasca (Eds.). 433–444.
https://aclanthology.org/D12-1040/
[56] Alexander Koller and Jörg Hoffmann. 2010. Waking Up a Sleeping Rabbit: On Natural-Language Sentence Generation
with FF. In Proceedings of the 20th International Conference on Automated Planning and Scheduling, ICAPS 2010, Toronto,
Ontario, Canada, May 12-16, 2010 , Ronen I. Brafman, Hector Geffner, Jörg Hoffmann, and Henry A. Kautz (Eds.).
AAAI, 238–241. http://www.aaai.org/ocs/index.php/ICAPS/ICAPS10/paper/view/1415
[57] Xiangzhe Kong, Jialiang Huang, Ziquan Tung, Jian Guan, and Minlie Huang. 2021. Stylized Story Generation with
Style-Guided Planning. In ACL-IJCNLP . 2430–2436.
[58] Litton J Kurisinkel, Yue Zhang, and Vasudeva Varma. 2017. Abstractive multi-document summarization by partial
tree extraction, recombination and linearization. In Proceedings of the Eighth International Joint Conference on Natural
Language Processing (Volume 1: Long Papers) . 812–821.
[59] Anastassia Küstenmacher and Paul G Plöger. 2021. Improving the Reliability of Service Robots by Symbolic Represen-
tation of Execution Specific Knowledge. In Robust and Reliable Autonomy in the Wild (R2AW) .
[60] Boyang Li, Stephen Lee-Urban, George Johnston, and Mark Riedl. 2013. Story Generation with Crowdsourced Plot
Graphs. In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, July 14-18, 2013, Bellevue,
Washington, USA , Marie desJardins and Michael L. Littman (Eds.). http://www.aaai.org/ocs/index.php/AAAI/AAAI13/
paper/view/6399
[61] Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek,
Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba, and Yuke Zhu. 2022. Pre-Trained Language
Models for Interactive Decision-Making. CoRR abs/2202.01771 (2022). arXiv:2202.01771 https://arxiv.org/abs/2202.
01771
[62] Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, and Ion Stoica. 2021. Terapipe:
Token-level pipeline parallelism for training large-scale language models. In International Conference on Machine
Learning . PMLR, 6543–6552.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 21
[63] Claudius Lieven, Bianca Lüders, Daniel Kulus, and Rosa Thoneick. 2021. Enabling digital co-creation in urban
planning and development. (2021), 415–430.
[64] Alan Lindsay, Jonathon Read, João F. Ferreira, Thomas Hayton, Julie Porteous, and Peter Gregory. 2017. Framer:
Planning Models from Natural Language Action Descriptions. In ICAPS . 434–442.
[65] Adam Lopez. 2008. Statistical Machine Translation. ACM Comput. Surv. 40, 3, Article 8 (aug 2008), 49 pages.
https://doi.org/10.1145/1380584.1380586
[66] Stephanie M Lukin and Marilyn A Walker. 2019. A narrative sentence planner and structurer for domain independent,
parameterizable storytelling. Dialogue & Discourse 10, 1 (2019), 34–86.
[67] Longxuan Ma, Mingda Li, Wei-Nan Zhang, Jiapeng Li, and Ting Liu. 2022. Unstructured Text Enhanced Open-Domain
Dialogue System: A Systematic Survey. ACM Trans. Inf. Syst. 40, 1 (2022), 9:1–9:44. https://doi.org/10.1145/3464377
[68] Matt MacMahon, Brian Stankiewicz, and Benjamin Kuipers. 2006. Walk the Talk: Connecting Language, Knowledge,
and Action in Route Instructions. In AAAI . 1475–1482. http://www.aaai.org/Library/AAAI/2006/aaai06-232.php
[69] Andreas Marfurt and James Henderson. 2021. Sentence-level Planning for Especially Abstractive Summarization. In
Proceedings of the Third Workshop on New Frontiers in Summarization . 1–14.
[70] Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010. Following directions using statistical machine translation. In
HRI, Pamela J. Hinds, Hiroshi Ishiguro, Takayuki Kanda, and Peter H. Kahn Jr. (Eds.). 251–258. https://doi.org/10.
1145/1734454.1734552
[71] Drew McDermott, Malik Ghallab, Adele E. Howe, Craig A. Knoblock, Ashwin Ram, Manuela M. Veloso, Daniel S.
Weld, and David E. Wilkins. 1998. PDDL-the planning domain definition language.
[72] Hongyuan Mei, Mohit Bansal, and Matthew R. Walter. 2016. Listen, Attend, and Walk: Neural Mapping of Navigational
Instructions to Action Sequences. In Thirtieth AAAI Conference on Artificial Intelligence , Dale Schuurmans and
Michael P. Wellman (Eds.). 2772–2778. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12522
[73] Shah Jahan Miah, Huy Quan Vu, and Damminda Alahakoon. 2022. A social media analytics perspective for human-
oriented smart city planning and management. Journal of the Association for Information Science and Technology 73, 1
(2022), 119–135.
[74] M Jishma Mohan, C Sunitha, Amal Ganesh, and A Jaya. 2016. A study on ontology based abstractive summarization.
Procedia Computer Science 87 (2016), 32–37.
[75] Shiwali Mohan and John E. Laird. 2014. Learning Goal-Oriented Hierarchical Tasks from Situated Interactive
Instruction. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Québec
City, Québec, Canada , Carla E. Brodley and Peter Stone (Eds.). 387–394. http://www.aaai.org/ocs/index.php/AAAI/
AAAI14/paper/view/8630
[76] Christian Muise, Tathagata Chakraborti, Shubham Agarwal, Ondrej Bajgar, Arunima Chaudhary, Luis A Lastras-
Montano, Josef Ondrej, Miroslav Vodolan, and Charlie Wiecha. 2019. Planning for goal-oriented dialogue systems.
arXiv preprint arXiv:1910.08137 (2019).
[77] Shashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo Simões, Vitaly Nikolaev, and Ryan McDonald. 2021. Planning with
learned entity prompts for abstractive summarization. Transactions of the Association for Computational Linguistics 9
(2021), 1475–1492.
[78] Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary, Vijay Korthikanti, Dmitri
Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, et al .2021. Efficient large-scale language model
training on gpu clusters using megatron-lm. In Proceedings of the International Conference for High Performance
Computing, Networking, Storage and Analysis . 1–15.
[79] Daniel Nyga and Michael Beetz. 2012. Everything robots always wanted to know about housework (but were afraid
to ask). In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems . IEEE, 243–250.
[80] MD Okpor. 2014. Machine translation approaches: issues and challenges. International Journal of Computer Science
Issues (IJCSI) 11, 5 (2014), 159.
[81] Daniel W Otter, Julian R Medina, and Jugal K Kalita. 2020. A survey of the usages of deep learning for natural
language processing. IEEE transactions on neural networks and learning systems 32, 2 (2020), 604–624.
[82] Vishal Pallagani and Biplav Srivastava. 2021. A Generic Dialog Agent for Information Retrieval Based on Automated
Planning Within a Reinforcement Learning Platform. Bridging the Gap Between AI Planning and Reinforcement
Learning (PRL) (2021).
[83] C. Raymond Perrault and James F. Allen. 1980. A Plan-Based Analysis of Indirect Speech Acts. Am. J. Comput.
Linguistics 6, 3-4 (1980), 167–182.
[84] Ronald PA Petrick and Mary Ellen Foster. 2016. Using general-purpose planning for action selection in human-robot
interaction. In 2016 AAAI Fall Symposium Series .
[85] Ngoc Hung Pham and Takashi Yoshimi. 2015. Extraction of actions and objects from instruction manual for executable
robot planning. In 2015 15th International Conference on Control, Automation and Systems (ICCAS) . IEEE, 881–885.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
22 Jin et al.
[86] Julie Porteous and Marc Cavazza. 2009. Controlling Narrative Generation with Planning Trajectories: The Role of
Constraints. In ICIDS 2009 (Lecture Notes in Computer Science, Vol. 5915) , Ido Iurgel, Nelson Zagalo, and Paolo Petta
(Eds.). 234–245. https://doi.org/10.1007/978-3-642-10643-9_28
[87] Julie Porteous, João F. Ferreira, Alan Lindsay, and Marc Cavazza. 2021. Automated narrative planning model extension.
Auton. Agents Multi Agent Syst. 35, 2 (2021), 19. https://doi.org/10.1007/s10458-021-09501-1
[88] Julie Porteous, João F Ferreira, Alan Lindsay, and Marc Cavazza. 2021. Automated narrative planning model extension.
Autonomous Agents and Multi-Agent Systems 35, 2 (2021), 1–29.
[89] Bernd Resch, Anja Summa, Peter Zeile, and Michael Strube. 2016. Citizen-centric urban planning through extracting
emotion information from twitter in an interdisciplinary space-time-linguistics algorithm. Urban Planning 1, 2 (2016),
114–127.
[90] Mark O. Riedl and Robert Michael Young. 2010. Narrative Planning: Balancing Plot and Character. J. Artif. Intell. Res.
39 (2010), 217–268. https://doi.org/10.1613/jair.2989
[91] Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley. 2010. Automatic keyword extraction from individual
documents. Text mining: applications and theory 1 (2010), 1–20.
[92] Scott Sanner et al .2010. Relational dynamic influence diagram language (rddl): Language description. Unpublished
ms. Australian National University 32 (2010), 27.
[93] Milene Santos Teixeira and Mauro Dragoni. 2022. A Review of Plan-Based Approaches for Dialogue Management.
Cognitive Computation (2022), 1–20.
[94] Buser Say. 2021. A Unified Framework for Planning with Learned Neural Network Transition Models. (2021),
5016–5024. https://ojs.aaai.org/index.php/AAAI/article/view/16635
[95] Matthias Scheutz, Evan A. Krause, Bradley Oosterveld, Tyler M. Frasca, and Robert Platt Jr. 2017. Spoken Instruction-
Based One-Shot Object and Action Learning in a Cognitive Robotic Architecture. In Proceedings of the 16th Conference
on Autonomous Agents and MultiAgent Systems, AAMAS 2017, São Paulo, Brazil, May 8-12, 2017 , Kate Larson, Michael
Winikoff, Sanmay Das, and Edmund H. Durfee (Eds.). 1378–1386. http://dl.acm.org/citation.cfm?id=3091315
[96] Lei Sha, Lili Mou, Tianyu Liu, Pascal Poupart, Sujian Li, Baobao Chang, and Zhifang Sui. 2018. Order-Planning Neural
Text Generation From Structured Data. In AAAI , Sheila A. McIlraith and Kilian Q. Weinberger (Eds.). 5414–5421.
[97] Khaled Shaalan et al .2010. Rule-based approach in Arabic natural language processing. The International Journal on
Information and Communication Technologies (IJICT) 3, 3 (2010), 11–19.
[98] Pratyusha Sharma, Antonio Torralba, and Jacob Andreas. 2022. Skill Induction and Planning with Latent Language.
(2022), 1713–1726. https://doi.org/10.18653/v1/2022.acl-long.120
[99] Lanbo She and Joyce Yue Chai. 2017. Interactive Learning of Grounded Verb Semantics towards Human-Robot
Communication. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017,
Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers , Regina Barzilay and Min-Yen Kan (Eds.). 1634–1644.
https://doi.org/10.18653/v1/P17-1150
[100] Lanbo She, Yu Cheng, Joyce Yue Chai, Yunyi Jia, Shaohua Yang, and Ning Xi. 2014. Teaching Robots New Actions
through Natural Language Instructions. In The 23rd IEEE International Symposium on Robot and Human Interactive
Communication, IEEE RO-MAN 2014, Edinburgh, UK, August 25-29, 2014 . 868–873. https://doi.org/10.1109/ROMAN.
2014.6926362
[101] Lanbo She, Shaohua Yang, Yu Cheng, Yunyi Jia, Joyce Yue Chai, and Ning Xi. 2014. Back to the Blocks World: Learning
New Actions through Situated Human-Robot Dialogue. In Proceedings of the SIGDIAL 2014 Conference, The 15th
Annual Meeting of the Special Interest Group on Discourse and Dialogue, 18-20 June 2014, Philadelphia, PA, USA . 89–97.
https://doi.org/10.3115/v1/w14-4313
[102] Raphael Shu and Hideki Nakayama. 2018. Discrete Structural Planning for Neural Machine Translation. CoRR
abs/1808.04525 (2018). arXiv:1808.04525 http://arxiv.org/abs/1808.04525
[103] Avirup Sil and Alexander Yates. 2011. Extracting STRIPS Representations of Actions and Events. In RANLP . 1–8.
[104] Nisha Simon and Christian Muise. 2022. TattleTale: Storytelling with Planning and Large Language Models. (2022).
[105] Sarath Sreedharan, Tathagata Chakraborti, Christian Muise, Yasaman Khazaeni, and Subbarao Kambhampati. 2020.
–d3wa+–a case study of xaip in a model acquisition task for dialogue planning. In Proceedings of the International
Conference on Automated Planning and Scheduling , Vol. 30. 488–497.
[106] Felix Stahlberg. 2020. Neural Machine Translation: A Review. J. Artif. Intell. Res. 69 (2020), 343–418. https:
//doi.org/10.1613/jair.1.12007
[107] Shane Storks, Qiaozi Gao, and Joyce Y Chai. 2019. Commonsense reasoning for natural language understanding: A
survey of benchmarks, resources, and approaches. arXiv preprint arXiv:1904.01172 (2019), 1–60.
[108] Gavin Suddrey, Ben Talbot, and Frederic Maire. 2022. Learning and executing re-usable behaviour trees from natural
language instruction. IEEE Robotics and Automation Letters (2022).
[109] Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J. Martin, Animesh Mehta, Brent Harrison, and Mark O. Riedl.
2019. Controllable Neural Story Plot Generation via Reward Shaping. In Proceedings of the Twenty-Eighth International
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge 23
Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019 , Sarit Kraus (Ed.). 5982–5988.
https://doi.org/10.24963/ijcai.2019/829
[110] Stefanie Tellex, Thomas Kollar, Steven Dickerson, Matthew R. Walter, Ashis Gopal Banerjee, Seth J. Teller, and
Nicholas Roy. 2011. Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.
InAAAI , Wolfram Burgard and Dan Roth (Eds.). http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3623
[111] Moritz Tenorth, Daniel Nyga, and Michael Beetz. 2010. Understanding and executing instructions for everyday
manipulation tasks from the World Wide Web. In IEEE International Conference on Robotics and Automation, ICRA
2010, Anchorage, Alaska, USA, 3-7 May 2010 . 1486–1491. https://doi.org/10.1109/ROBOT.2010.5509955
[112] Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer. 2019. Vision-and-Dialog Navigation. In 3rd
Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 - November 1, 2019, Proceedings (Proceedings
of Machine Learning Research, Vol. 100) , Leslie Pack Kaelbling, Danica Kragic, and Komei Sugiura (Eds.). 394–406.
http://proceedings.mlr.press/v100/thomason20a.html
[113] Jesse Thomason, Shiqi Zhang, Raymond J. Mooney, and Peter Stone. 2015. Learning to Interpret Natural Language
Commands through Human-Robot Dialog. In IJCAI 2015 , Qiang Yang and Michael J. Wooldridge (Eds.). 1923–1929.
http://ijcai.org/Abstract/15/273
[114] Amirsina Torfi, Rouzbeh A Shirvani, Yaser Keneshloo, Nader Tavaf, and Edward A Fox. 2020. Natural language
processing advancements by deep learning: A survey. arXiv preprint arXiv:2003.01200 (2020).
[115] Stephen G. Ware and Robert Michael Young. 2011. CPOCL: A Narrative Planner Supporting Conflict. In AIIDE , Vadim
Bulitko and Mark O. Riedl (Eds.). http://www.aaai.org/ocs/index.php/AIIDE/AIIDE11/paper/view/4058
[116] Robert Wilensky. 1981. Meta-Planning: Representing and Using Knowledge About Planning in Problem Solving and
Natural Language Understanding. Cogn. Sci. 5, 3 (1981), 197–233. https://doi.org/10.1207/s15516709cog0503_2
[117] Chuncheng Xiang, Tingsong Jiang, Baobao Chang, and Zhifang Sui. 2015. ERSOM: A Structural Ontology Matching
Approach Using Automatically Learned Entity Representation. In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015 , Lluís Màrquez, Chris
Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton (Eds.). 2419–2429. https://doi.org/10.18653/v1/d15-1289
[118] Jingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xiaoyan Cai, and Xu Sun. 2018. A Skeleton-Based Model for Promoting
Coherence Among Sentences in Narrative Story Generation. In EMNLP . 4306–4315. https://aclanthology.org/D18-
1462/
[119] Lili Yao, Nanyun Peng, Ralph M. Weischedel, Kevin Knight, Dongyan Zhao, and Rui Yan. 2019. Plan-and-Write:
Towards Better Automatic Storytelling. In AAAI . 7378–7385.
[120] Rongguang Ye, Qingchuan Xu, Jie Liu, Yang Hong, Chengfeng Sun, Wenzheng Chi, and Lining Sun. 2021. A Natural
Language Instruction Disambiguation Method for Robot Grasping. In IEEE International Conference on Robotics and
Biomimetics, ROBIO 2021, Sanya, China, December 27-31, 2021 . 601–606. https://doi.org/10.1109/ROBIO54168.2021.
9739456
[121] Kristina Y. Yordanova and Thomas Kirste. 2016. Learning Models of Human Behaviour from Textual Instructions. In
ICAART . 415–422.
[122] R Michael Young, Stephen G Ware, Brad A Cassell, and Justus Robertson. 2013. Plans and planning in narrative
generation: a review of plan-based approaches to the generation of story, discourse and interactivity in narratives.
Sprache und Datenverarbeitung, Special Issue on Formal and Computational Models of Narrative 37, 1-2 (2013), 41–64.
[123] Meng-Hsuan Yu, Juntao Li, Zhangming Chan, Rui Yan, and Dongyan Zhao. 2021. Content Learning with Structure-
Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling. In AAAI .
6021–6029.
[124] Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, and Meng Jiang. 2022. A survey of
knowledge-enhanced text generation. ACM Computing Surveys (CSUR) (2022).
[125] Yantian Zha, Lin Guan, and Subbarao Kambhampati. 2021. Learning from Ambiguous Demonstrations with Self-
Explanation Guided Reinforcement Learning. CoRR abs/2110.05286 (2021). arXiv:2110.05286 https://arxiv.org/abs/
2110.05286
[126] Zhengyan Zhang, Yuxian Gu, Xu Han, Shengqi Chen, Chaojun Xiao, Zhenbo Sun, Yuan Yao, Fanchao Qi, Jian Guan,
Pei Ke, et al. 2021. Cpm-2: Large-scale cost-effective pre-trained language models. AI Open 2 (2021), 216–224.
[127] Fengda Zhao, Zhikai Yang, Xianshan Li, Dingding Guo, and Haitao Li. 2021. Extract Executable Action Sequences
from Natural Language Instructions Based on DQN for Medical Service Robots. Int. J. Comput. Commun. Control 16,
2 (2021). https://doi.org/10.15837/ijccc.2021.2.4115
[128] Hankz Hankui Zhuo and Subbarao Kambhampati. 2013. Action-Model Acquisition from Noisy Plan Traces. In IJCAI .
2444–2450.
[129] Hankz Hankui Zhuo and Subbarao Kambhampati. 2017. Model-lite planning: Case-based vs. model-based approaches.
Artif. Intell. 246 (2017), 1–21. https://doi.org/10.1016/j.artint.2017.01.004
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
24 Jin et al.
[130] Hankz Hankui Zhuo, Héctor Muñoz-Avila, and Qiang Yang. 2014. Learning hierarchical task network domains from
partially observed plan traces. Artif. Intell. 212 (2014), 134–157.
[131] Hankz Hankui Zhuo and Qiang Yang. 2014. Action-model acquisition for planning via transfer learning. Artif. Intell.
212 (2014), 80–103. https://doi.org/10.1016/j.artint.2014.03.004
[132] Hankz Hankui Zhuo, Yantian Zha, Subbarao Kambhampati, and Xin Tian. 2020. Discovering Underlying Plans Based
on Shallow Models. ACM Trans. Intell. Syst. Technol. 11, 2 (2020), 18:1–18:30. https://doi.org/10.1145/3368270
Received xxxx; revised xxxx; accepted xxxx
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.","integrating ai planning with natural language processing
a combination of explicit and tacit knowledge
kebing jin and hankz hankui zhuoschool of computer science and engineering sun
yatsen university china
natural language processing nlp aims at investigating the interactions between agents and humans pro
cessing and analyzing large amounts of natural language data largescale language models play an important
role in current natural language processing however the challenges of explainability and complexity come
along with the developments of language models one way is to introduce logical relations and rules into
natural language processing models such as making use of automated planning automated planning ai
planning focuses on building symbolic domain models and synthesizing plans to transit initial states to goals
based on domain models recently there have been plenty of works related to these two fields which have
the abilities to generate explicit knowledge eg preconditions and effects of action models and learn from
tacit knowledge eg neural models respectively integrating ai planning and natural language processing
effectively improves the communication between human and intelligent agents this paper outlines the
commons and relations between ai planning and natural language processing argues that each of them can
effectively impact on the other one by five areas 1 planningbased text understanding 2 planningbased
natural language processing 3 planningbased explainability 4 textbased humanrobot interaction and
5 applications we also explore some potential future issues between ai planning and natural language
processing to the best of our knowledge this survey is the first work that addresses the deep connections
between ai planning and natural language processing
ccs concepts computing methodologies natural language processing planning and schedul
inginformation extraction natural language generation 
additional key words and phrases ai planning natural language processing natural language understanding
humanrobot interaction explainability
acm reference format
kebing jin and hankz hankui zhuo 2022 integrating ai planning with natural language processing a
combination of explicit and tacit knowledge acm trans intell syst technol 1 1 april 2022 24 pages
httpsdoiorgxxxxxxxxxxxxxx
1 introduction
natural language processing nlp aims at investigating the interactions between agents and
humans processing and analyzing large amounts of natural language data in recent years for
attaining better performance and handling large corpora building largescale language models
is an inevitable trend in real applications  6278126 despite the success of language models in
various domains the explainability and complexity of language models have drawn intense research
interests recently in order to make models explainable and lightweight integrating models with
corresponding author
authors address kebing jin jinkbmail2sysueducn hankz hankui zhuo zhuohankmailsysueducn school of
computer science and engineering sun yatsen university guangzhou china 510006
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page copyrights for components of this work owned by others than acm must be honored
abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires
prior specific permission andor a fee request permissions from permissionsacmorg
2022 association for computing machinery
2157690420224art 1500
httpsdoiorgxxxxxxxxxxxxxx
acm trans intell syst technol vol 1 no 1 article  publication date april 2022arxiv220207138v2  csai  13 apr 2023
2 jin et al
symbolic planning has been demonstrated effective in various nlp tasks symbolic planning ai
planning is a branch of artificial intelligence that focuses on building symbolic domain models and
synthesizing plans to transit initial states to goals based on domain models the plans are typically
for execution by intelligent agents autonomous robots and unmanned vehicles different from
classical control and classification problems the solutions are complex and must be discovered and
optimized in multidimensional space generally those approaches are mostly based on structured
data which has a welldefined structure and logically explainable to humans
compared with structured data used in ai planning natural language descriptions are often
complicated by omissions inverted order etc resulting in difficulties in reasoning about language
descriptions it is thus often hard to directly train neural models to generate available and correct
solutions although deep learning has been widely used to handle unstructured data deep learning
methods do well in acquiring knowledge from data capturing implied rules and expressing them
by mathematical and neural models which are tacit and unable to be directly shared with other
humans and agents different from deep learning methods that aim to learn tacit knowledge
planningbased methods are better at capturing changes formalizing them by rules and generating
valid plans when handling structured data rules are already codified namely explicit knowledge
which can be clearly expressed and easily shared with others therefore ai planning is one of the
considerable steps to understand implied rules and build domain models from large amount of texts
in natural language processing 32 72
on the other hand unstructured data in real world is not disorderly but often a sequence based
on rules as for a natural language description there is a theme running through it along with a
series of relevant events and a coherent text unfolds each sentence relates to the preceding texts
and influences following sentences just like preconditions and effects of actions in ai planning for
example in a recipe about making a meatloaf shown in figure 1a humans can easily understand it
and capture the main information including verbs eg heat and objects eg butter and skillet
however as for agents when given a mass of data in the form of sentences it is hard to directly build
models to reason about the implied rules and predict next moves if we extract these information and
formalize them structurally as shown in figure 1b it is easier to construct models based on planning
methods for guiding future unseen tasks
besides using ai planning to help reason about implied rules in texts the power of ai planning
about capturing implied relations and computing valid solutions is another effective way to improve
natural language processing such as text summarization and machine translation for example
there have been planningbased text generation methods  57119 extending a clear storyline
ordered in advance those methods first compute sequences composed of keywords key phrases
or contents as storylines then use natural language processing techniques to extend storylines
to coherent texts in the abovementioned example generating an available recipe in a correct order
shown in figure 1a is hard however given some rules such as domain models about the operations
of cooking agents can compute plans toward achieving specified goals like a theme about making a
meatloaf as shown in figure 1b agents can easily extend the plan and gain a valid recipe
the integration of ai planning and natural language processing combines the best of tacit
knowledge learning from sentences and explicit knowledge in the form of rules as discussed
in 52 it would be more effective to combine explicit and tacit knowledge rather than giving
up explicit knowledge and learning everything from tacit knowledge which is the current trend
integrating ai planning and natural language processing allows human to communicate with
agents in a more comfortable way and enables intelligent agents to explain themselves to human
in a humanunderstandable way natural language as the most comfortable way to communicate
with humans establishes a relationship between humans and intelligent agents in recent years
researchers have made efforts to connect with natural language and robots such as by dialogue
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 3
heat  butter in a large skillet   add the onions  garlic  celery and carrot  
cook the mixture over medium heat  for 5 minutes stirring  frequently add 
the ketchup sauce  and the salt and pepper  cook the mixture for another 
minute  combine the meat  bread crumbs  eggs  and parsley in a mixing 
bowl  add the cooked vegetables  from the skillet  mix everything well 
together push the mixture into the baking loaf pan  then put the loaf into 
the oven and bake for about  an hour  when the meatloaf is done allow it 
to cool slightly then slowly remove the loaf from the baking pan by cutting 
along the sides with a butter knife  gently lift the meatloaf from the pan 
and place on serving plate  cut into slices of approximately 34 inch thick  
heatbutter skillet  add onions garlic celery carrot skillet  
cookmixture medium heat 5 minutes  stirring  addketchup sauce 
salt pepper skillet  cookmixture medium heat one minute  
combinemeat bread crumbs eggs parsley bowl  addcooked 
vegetables bowl  mix  pushmixture loaf pan  putloaf oven  
bakean hour   cool  removeloaf  cutsides knife  
liftmeatloaf pan  placemeatloaf plate  cutmeatloaf 34 inch thicka a recipe for making a meatloaf
     b a trace extracted from a
fig 1 an example textual recipe about making a meatloaf
systems  82105 and natural language commands understanding  59108 on the other hand
planningbased natural language models are based on structured data or implied rules such as
predicted storylines which allows human to partly understand the principles of models
in this paper we first introduce some background knowledge in ai planning and natural language
processing as well as their relations then we give a comprehensive overview of integrating ai
planning and natural language processing by four aspects and their challenges planningbased text
understanding planningbased natural language processing planningbased explainability and
textbased humanrobot interaction their relations are shown in figure 2 firstly planningbased
natural language understanding includes extracting actions from texts and learning domain models
from texts secondly we introduce planningbased natural language processing by three tasks
integrated with ai planning ie text generation text summarization and machine translation then
we discuss planningbased explainability next we introduce textbased humanrobot interaction by
extracting actions from natural language instructions natural language command understanding
and dialogue generation finally we present current applications several future directions and
conclude this paper to the best of our knowledge this survey is the first work that addresses the
deep connections between ai planning and nlp
2 planning domain description language and nlp
in this section we introduce modeling knowledge in ai planning backgrounds in natural language
processing nlp and relations between ai planning and nlp including similarities differences
and language modelbased planning
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
4 jin et al
natural language
text
make use of extracted rules 
to improve coherence and 
reasonability
human
robotactions extraction
natural language 
command understanding
dialogue systems
humanrobot 
interactionas a 
medium 
explainabilitytext generation
text summarization
machine translation
planningbased
natural language processingaction traces extraction
domain models learning
planningbased natural 
language understandingextract information capture rules 
and build domain models
learn implied rules 
organize skeletons 
and predict key 
information
give instructionsexecute 
instructions
fig 2 relations between ai planning and natural language processing
21 planning domain description language
a planning problem is composed of a planning domain dand an instance  defined by planning
domain description language with the development of ai planning more and more extended
planning domain description languages  343992 have been proposed taking pddl planning
domain definition language  71 as an example a planning domain dis made up by several
action models an action model is defined by a tuple of preeff whereis an action
name with zero or more types of parameters an action is a grounding of an action model each
of whose parameters is an object preis a set of preconditions requiring to be satisfied when
executing each of which is a proposition or a numeric constraint similarly effis a set of effects
an effect can be a topical proposition added into or deleted from the state after executing  or a
numeric updating increasing or decreasing the value of variables according to specified functions
an instance is defined by 0 where0is a set of initial assignments by propositions
and variables and is a set of goals requiring to be achieved is an objective function guiding
planner to compute for a minimum cost or maximum reward a planning problem is to compute
an available action sequence which can transfer 0to a state containing desired goals 
for example parts of action models in the rover domain are shown in figure 3a where equippedfor
imaging r is a proposition asking that a rover r should equip with a camera for taking image
when executing action calibrate   energy r 1 is a numeric precondition requiring the energy
of rover r should be larger than 1 figure 3b and c show an initial state and goals respectively
an example valid plan updating the initial state to a state achieving the goals is shown in figure 3d
where each action is a grounding action model with parameters
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 5


a
c
t
i
o
n
 
c
a
l
i
b
r
a
t
e
 

p
a
r
a
m
e
t
e
r
s
 


r
 

 
r
o
v
e
r
 

i
 

 
c
a
m
e
r
a
 

t
 

 
o
b
j
e
c
t
i
v
e
 

w
 

 
w
a
y
p
o
i
n
t

 

p
r
e
c
o
n
d
i
t
i
o
n
 

a
n
d
 

e
q
u
i
p
p
e
d

f
o
r

i
m
a
g
i
n
g
 

r

 



 

e
n
e
r
g
y
 

r

 
2

 

c
a
l
i
b
r
a
t
i
o
n

t
a
r
g
e
t
 

i
 

t

 

a
t
 

r
 

w

 
 
 
 
 
 
 
 
 

v
i
s
i
b
l
e

f
r
o
m
 

t
 

w

 

o
n

b
o
a
r
d
 

i
 

r


 

e
f
f
e
c
t
 

a
n
d
 

d
e
c
r
e
a
s
e
 

e
n
e
r
g
y
 

r

 
2


c
a
l
i
b
r
a
t
e
d
 

i
 

r

 




a
c
t
i
o
n
 
t
a
k
e

i
m
a
g
e
 

p
a
r
a
m
e
t
e
r
s
 


r
 

 
r
o
v
e
r
 

p
 

 
w
a
y
p
o
i
n
t
 

o
 

 
o
b
j
e
c
t
i
v
e
 

i
 

 
c
a
m
e
r
a
 

m
 

 
m
o
d
e

 

p
r
e
c
o
n
d
i
t
i
o
n
 

a
n
d
 

c
a
l
i
b
r
a
t
e
d
 

i
 

r

 

o
n

b
o
a
r
d
 

i
 

r

 

e
q
u
i
p
p
e
d

f
o
r

i
m
a
g
i
n
g
 

r

 

s
u
p
p
o
r
t
s
 

i
 

m

 
 
 
 
 
 
 
 
 
 

v
i
s
i
b
l
e

f
r
o
m
 

o
 

p

 

a
t
 

r
 

p

 



 

e
n
e
r
g
y
 

r

 
1


 

e
f
f
e
c
t
 

a
n
d
 

h
a
v
e

i
m
a
g
e
 

r
 

o
 

m


n
o
t
 

c
a
l
i
b
r
a
t
e
d
 

i
 

r



d
e
c
r
e
a
s
e
 

e
n
e
r
g
y
 

r

 
1






c
a
l
i
b
r
a
t
e
 

r
o
v
e
r
0
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1
 
w
a
y
p
o
i
n
t
3

 

 
t
a
k
e

i
m
a
g
e
 

r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3
 
o
b
j
e
c
t
i
v
e
1
 
c
a
m
e
r
a
0
 
h
i
g
h

r
e
s

 

 
c
o
m
m
u
n
i
c
a
t
e

i
m
a
g
e

d
a
t
a
 

r
o
v
e
r
0
 
c
a
m
e
r
a
 
o
b
j
e
c
t
i
v
e
1
 
h
i
g
h

r
e
s
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
0

 

 
s
a
m
p
l
e

r
o
c
k
 

r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e
 
w
a
y
p
o
i
n
t
3

 

 
d
r
o
p
 

r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e

 

 
c
o
m
m
u
n
i
c
a
t
e

r
o
c
k

d
a
t
a
 

r
o
v
e
r
0
 
c
a
m
e
r
a
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
0

 

 
n
a
v
i
g
a
t
e
 

r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3
 
w
a
y
p
o
i
n
t
1

 

 
n
a
v
i
g
a
t
e
 

r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
1
 
w
a
y
p
o
i
n
t
2

 

 
s
a
m
p
l
e

s
o
i
l
 

r
o
v
e
r
0
 
r
o
v
e
r
0
s
t
o
r
e
 
w
a
y
p
o
i
n
t
2

 

 
c
o
m
m
u
n
i
c
a
t
e

s
o
i
l

d
a
t
a
 

r
o
v
e
r
0
 
c
a
m
e
r
a
 
w
a
y
p
o
i
n
t
2
 
w
a
y
p
o
i
n
t
2
 
w
a
y
p
o
i
n
t
0



i
n
i
t

e
q
u
i
p
p
e
d

f
o
r

i
m
a
g
i
n
g
 
r
o
v
e
r
0

 

c
a
l
i
b
r
a
t
i
o
n

t
a
r
g
e
t
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1

 

a
t
 
r
o
v
e
r
0
 
w
a
y
p
o
i
n
t
3

 

o
n

b
o
a
r
d
 
c
a
m
e
r
a
0
 
r
o
v
e
r
0

 

a
v
a
i
l
a
b
l
e
 
r
o
v
e
r
0


c
a
l
i
b
r
a
t
i
o
n

t
a
r
g
e
t
 
c
a
m
e
r
a
0
 
o
b
j
e
c
t
i
v
e
1

 

s
u
p
p
o
r
t
s
 
c
a
m
e
r
a
0
 
c
o
l
o
u
r


s
u
p
p
o
r
t
s
 
c
a
m
e
r
a
0
 
h
i
g
h

r
e
s

 

i
n

s
u
n
 
w
a
y
p
o
i
n
t
0

 


 

e
n
e
r
g
y
 
r
o
v
e
r
0

 
5
0





 



g
o
a
l
 

a
n
d

c
o
m
m
u
n
i
c
a
t
e
d

s
o
i
l

d
a
t
a
 
w
a
y
p
o
i
n
t
2


c
o
m
m
u
n
i
c
a
t
e
d

r
o
c
k

d
a
t
a
 
w
a
y
p
o
i
n
t
3


c
o
m
m
u
n
i
c
a
t
e
d

i
m
a
g
e

d
a
t
a
 
o
b
j
e
c
t
i
v
e
1
 
h
i
g
h

r
e
s




a

 
a
c
t
i
o
n
 
m
o
d
e
l
s


b

 
i
n
i
t
i
a
l
 
s
t
a
t
e


c

 
g
o
a
l
s


d

 
a
n
 
e
x
a
m
p
l
e
 
p
l
a
n
 
f
o
r
 
t
h
e
 
p
l
a
n
n
i
n
g
 
p
r
o
b
l
e
m

fig 3 an example in the rover domain including action models initial state goals and an available plan
22 natural language processing
recently natural language processing nlp  1754114 has attracted lots of attention and it
builds a bridge between human and agents natural language processing is grand including various
fields such as natural language understanding nlu 81107 natural language generation nlg
3037 machine translation 80 and spelling correction 43 nlp has undergone several stages
of rulebased models statisticbased models and neural network models rulebased nlp  97 is
led by handcrafted rule sets whose main task is to understand natural language it is however
difficult and timeconsuming to build all handcrafted rules lacking of scalability statisticbased
nlp  65 makes use of probability distributions to generate proper words and sentences promoting
the application of statistical machine learning methods based on largescale corpora in natural
language processing nevertheless statisticbased models is barely to capture longterm relations
and use information included in contexts recently deep learning has been widely used in nlp
tasks 106 it is able to capture tacit knowledge implied in texts however deep learning is to fit
neural networks and predict based on statistics it can not understand the real meaning in natural
language in this paper we focus on those nlp tasks related to ai planning compared with nlp
approaches totally based on deep learning planningbased nlp methods are more curious about
implied logic and reasons of the solutions
23 relations between ai planning and natural language processing
in this section we will sketch the relations between ai planning and natural language processing
which is mentioned by  38116122 we will first introduce the similarities between ai planning
and natural language processing and then talk about their differences and deep relations
we discuss the similarities between ai planning and natural language processing by two aspects
first of all ai planning and natural language processing both revolve around observations and
knowledge  38 planning tasks aim at either solving problems based on a current observation and
goals along with priori knowledge like action models or constructing knowledge such as transition
functions based on sequential observations similarly in natural language processing tasks a text
can be regarded as a sequence of observations each observation is a sentence describing a partially
observed state where observations changes following implied rules secondly they share two
major common problems in planning tasks and natural language processing tasks consistency and
diversity both of plan traces and texts are cohesive descriptions and stringed by some rules and
goals as for planning the rules are action models and transition functions which update current
states to next ones the goals are sets of goal states or objective functions guiding planners to attain
optimal solutions as for natural language processing the rules are implied in the organization of
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
6 jin et al
texts such as transition connections or consequences their goals can be titles themes or topics
on the other hand in natural language processing given goals we can generate lots of coherent
texts composed of different events similar to different plan traces computed for the same goal
states moreover a sequence of events can be written as various stylized texts as shown in table
1 we enumerate some concepts in ai planning and natural language processing which can have
some similarities for example objects such as rover0 and objective1 in figure 3 in planning
problems are similar to entities in texts eg skillet and onions in figure 1
table 1 similar concepts between ai planning and natural language processing
ai planning natural language texts
objects entities
states sentences sentiments and intentions
actions events
domain models implied rules transitions and relations
goals topics and themes
plan traces storylines skeletons and frameworks
although ai planning and natural language processing have those commons the difference
between them is that ai planning is good at generating explicit knowledge such as domain models
128131 while natural language processing often learns tacit knowledge such as training models
from natural language data  52 argues that ai systems should be able to know when to take advice
and when to learn to find a balance between explicit and tacit knowledge taking planningbased
text generation as an example although texts are required to be coherent and with correct logic
natural language processing is weak in computing available and valid events which ai planning
is good at and the integration of both allows agents to generate coherent texts by first using ai
planning to generate storylines and then learning text generator by natural language processing
techniques
in a word there are close ties between ai planning and natural language processing due to
their different advantages of explicit and tacit knowledge the combination allows each of them to
effectively impact on the other one
24 language modelbased planning
although ai planning can effectively capture rules from action sequences it is hard for humans
without expert knowledge to construct structured plans a natural and intuitive way is to use human
natural language to describe plans asking language modelbased planners to be able to handle
text sequences and predict the next moves  94132 prior works mostly make use of pretrained
language models lms to understand abstract highlevel textual actions and learn actionable
knowledge for guiding planning  475061 specifically huang et al  46 use large language
models llms to generate natural language actions they investigated actionable knowledge already
contained pretrained llms on the other hand some works map natural language instructions
and highlevel goals to actions and goals and learn policy to make decisions  98 for example lid
61 uses policies initialized with pretrained lms and finetunes policies for predicting actions
validating that lms are able to contain rich actionable knowledge language modelbased planners
are mostly based on templated textual actions datasets rather than complex natural language
instructions with various styles of descriptions in the following sections we introduce deep
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 7
connections between ai planning and natural language processing to rise to the dual challenges
from rules and natural language
3 planningbased natural language understanding
in this section we introduce a comprehension overview of natural language understanding based on
ai planning natural language understanding aims at comprehending human language including
sentiments relations in contexts topics etc compared with learning relations from structured state
traces learning relations between extracted events from texts are even more challenging it asks
agents to reason about contexts capture themes of sentences by selecting words to represent them
compute causal relationships between the selected words there are two major areas introduced in
the following section which are both based on ai planning to understand the texts and learn causal
relationships from texts the first one is to extract action sequences from texts which requires
agents to understand complex contexts from action descriptions moreover it requires agents to be
capable of reasoning about connotations in texts such as exclusion relations and optional relations
between actions the other one is to first select words to represent the main ideas of sentences
and then learn the rules implied in sentences and formalize them by readable domain models for
guiding agents to solve future unseen tasks and helping agents and people understand logical
relations between events
31 extracting actions from texts
there have been works on extracting action sequences from action descriptions  127 the inputs
of the task mostly include some texts describing some actions and procedures the outputs are
action sequences from the texts each action is composed of a verb as action name and some objects
figure 4 shows an example in  32 where an input text is in left part of figure 4 extracting action
traces are shown in the right part of figure 4 the relations between actions are shown in the middle
of figure 4 this task does not only need extract a word standing for an action of the sentence
but also reason about contexts for completing omissions caused by pronouns early approaches
5570 mostly make use of specialized resources such as semantic parsers and learned lexicons
to reason about natural language route instructions for example marco  68 was proposed to
cook the rice the day before or use leftover rice in the refrigerator  the important thing to remember is not to heat up the rice but keep it cold  in a bowl add 1 tablespoon of oil to rice  use a spoon or your hands to work the oil into the rice evenly coating the rice  transfer the rice to a colander and drain  combine eggs and salt in a small bowl and gently whisk until blended  heat 1 tablespoon oil in a wok  add whisked eggs and cumin seeds to wok  stir frequently working the eggs to a scramble  heat the remaining oil in the wok  if desired you can recycle some of the oil that drained from the rice  add the garlic and onion to the wok  stirfry together over high heat for about 5 minutes or until the onion looks transparent but is not soft  add the rice eggs soy sauce chili sauce vinegar and celery  mix together continuing to stirfry over high heat for 12 minutes while stirring frequently  spoon onto a plate and serve input training textmission startcookusekeep
heataddrecyclework
serveex exesesesesesopextracting action names and action argumentssome possible outputs
es essential op optional ex exclusivemake egg fried ricemission endcookriceuseleftover ricekeeprice coldaddoilspoonusehandsaction namesaction argumentsesesesesexexx cook rice  keep rice cold  add oil  use spoon  work oil rice     work eggs  heat oil    serve x use leftover rice  keep rice cold  add oil  use spoon  work oil rice     work eggs  heat oil    serve x use leftover rice  keep rice cold  add oil  use hands  work oil rice     work eggs  heat oil    serve x use leftover rice  keep rice cold  add oil  use hands  work oil rice     work eggs  recycle oil  heat oil    serve x figure 1 illustration of our action sequence extraction problemis unknown we propose an approach calledeasdrl whichstands forextractingactionsequences from texts based ondeepreinforcementlearning ineasdrl we view textsassociated with actions as states and associating words intexts with labels as actions and then build deep qnetworksto extract action sequences from texts we capture complexrelations among actions by considering previously extractedactions as parts of states for deciding the choice of next operations in other words once we know action cookricehas been extracted and included as parts of states we willchoose to extract next action keeprice cold instead ofuseleftover rice in the abovementioned examplein the remainder of paper we rst review previous workrelated to our approach after that we give a formal denitionof our plan extraction problem and presenteasdrlin detailwe then evaluateeasdrlwith comparison to stateoftheart approaches and conclude the paper with future work2 related workthere have been approaches related to our work besidesthe ones we mentioned in the introduction section mapping route instructionsmacmahonet al 2006to action sequences has aroused great interest in natural language processing community early approaches such aschen andmooney 2011 kim and mooney 2013 largely depend onspecialized resources ie semantic parsers learned lexiconsand rerankers recently lstm encoderdecoder structuremeiet al 2016has been applied to this problem and getsdecent performance in processing singlesentence instructions however it could not handle multisentence texts wellthere is also a lot of work on learning strips representation actionspomarlanet al 2017from textssilet al2010 sil and yates 2011learn sentence patterns and lexicons or use offtheshelf toolkits ie opennlp1and stanford corenlp2lindsayet al 2017also build action models with the help of locmcresswellet al 2009after extracting action sequences by using nlp tools these tools aretrained for universal natural language processing tasks theycannot solve the complex action sequence extraction problem well and their performance will be greatly affected bypostagging and dependency parsing results in this paperwe aim to build a model that learns to directly extract actionsequences without external tools3 problem denitionour training data can be dened byxy wherexw1w2wnis a sequence of words andyy1y2ynis a sequence of annotations ifwiisnot an action nameyiis otherwiseyiis a tupleacttypeexactidargid exargidto describetypeof the action name and its corresponding argumentsacttypeindicates the type of actionaicorresponding towiwhich can be one ofessentialoptionalandexclusive thetypeessentialsuggests the corresponding actionaito beextractedoptionalsuggestsaithat can be optionally extractedexclusivesuggestsaithat is exclusive with otheractions indicated by the setexactidin other words eitheraior exactly one action inexactidcan be extractedexactidis the index of the action exclusive withai we denote the size ofexactidbym ieexactidm1httpsopennlpapacheorg2httpstanfordnlpgithubiocorenlpproceedings of the twentyseventh international joint conference on articial intelligence ijcai18
4065
fig 4 an illustration of action sequence extraction problem in 32
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
8 jin et al
map freeform natural language route instructions to action sequences arising great interest in
natural language processing community marco is able to model a sentence by an instruction
eg turn to face the green hallway can be modeled by turnuntilobjectpath appeargreen
sidefront dist0  22 presented a system along with a plan refinement algorithm to transform
natural language navigation instructions into executable formal plans generally methods with
semantics parsers require high simplicity of the texts therefore mostly approaches are based on
instructional texts or similar texts following some templates
in recent years learning methods such as reinforcement learning and lstm have been widely
used in natural language processing as well as extracting action sequences from natural language
texts with the rapid development of artificial intelligence for example  13 proposed a reinforce
ment learning approach for mapping natural language instructions in two domains windows
troubleshooting guides and game tutorials to sequences of executable actions it uses a reward
function to define the quality of the executed actions and a policy gradient algorithm to estimate
the parameters of a loglinear model for action selection the learner repeatedly constructs action
sequences for a set of documents executes those actions and observes the resulting reward to
handle free natural language without restricted templates easdrl  32 was presented to extract
action sequences from texts making use of deep reinforcement learning it builds qnetworks
to learn policies of extracting actions and extract plans from the labeled texts easdrl regards
texts associated with actions as states and associating words in texts with labels as actions
during capturing relations easdrl considers previously extracted actions as parts of states for
deciding the choice of next operations therefore easdrl is able to reason about connotations in
texts such as exclusion relations and optional relations between actions except for reinforcement
learning there are more techniques used in extracting actions from texts with the help of with long
shortterm memory lstm recurrent neural networks mei at al  72 proposed a neural sequence
tosequence model to translate singlesentence natural language instructions to action sequences
based upon a representation of the observable world state lstms are applicable to a number of
sequence learning problems due to their ability to learn longterm dependencies and they have
been shown to be effective in tasks existing sequences the lstm framework allows agents to
bidirectionally encode the navigational instruction sequence and decode the representation to an
action sequence based on a representation of the current state
32 learning domain models from texts
besides extracting action sequences from texts another way to understand text is to learn the
implied relations from sentences the input of the learning task is a set of texts and the output
is a planning domain model composed of action models describing the relations by propositional
preconditions and effects following the syntax of planning domain description language such as
pddl  71 preconditions and effects make use of propositions to describe conditions that must be
satisfied when executing actions and results after executing them respectively
learning domain models from instructional texts is a little different from narrative stories in
structional texts are simpler than narrative stories and the words are domaindependent narrative
stories are mostly third person synopses and they are always along with omission which results in
complexity when parsing sentences a general way to construct a domain model is first to extract
words and objects by parsing sentences for annotations eg opennlp1and stanford corenlp2
and then learn causal relationships between them and formalize the relations by action models
1httpsopennlpapacheorg
2httpstanfordnlpgithubiocorenlp
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 9
to learn domain models from instructional texts sil and yates  103 used text mining via a
search method to identify documents that contain words that represent target verbs or events
then they used inductive learning techniques to identify appropriate action preconditions and
effects the method relies on handcrafted pointwise mutual information to learn a svmbased
classifier that scores preconditions for a given action branavan et al  14 presented a reinforcement
learning framework to extract precondition and effects relations implied by the text and used
these relations to compute action sequences for completing given tasks in the environment single
argument predicates are extracted from the text as states and regarded as subgoals to construct
hierarchical planning problems yordanova and kirste  121 extracted verbs and objects from text
instructions based on part of speech pos tagging module and discovered causal relations on the
basis of the order of appearance to build pddl models however due to lacking of connections
between texts and world states and analyses between variable texts with the same meaning it is
hard to directly construct domain models as learning action models from structured data in this
paper domain models are constructed according to some templates after parsing sentences for
example if the apple is ripe put the apple on the table  indicates that ripe a state of an apple is
a precondition of action put therefore a precondition of action put is stateripe although
the model is readable for human it is kind of redundant and not easy to understand for agents
because of synonyms and polysemous words similarly lindsay et al  64 assumed texts are in
restricted templates when describing actions they generated sequences of actions by constructing
representations of sentences and cluster operators by computing similarity and built pddl domain
models with the help of a domain model acquisition tool
considering the power of ai planning about offering correct causality and flexible narrative
generation possibilities constructing domain models has been used in narrative systems recently
hayton et al  42 proposed an approach taking natural language sentences which summarise
the main elements of stories as inputs and generating action representations following pddl
a narrative planning domain model to overcome difficulties in parsing narrative stories they
presented two sets of rules to handle pronouns in stories then they used a template similar to  121
to construct planning domains another specific difficulty for planningbased narrative systems
is that handcrafted domain models require more narrative actions and types of narrative objects
compared to generated planning domains the plentiful actions and objects let generated plan
traces and storyline be more interesting and they can be extended to enjoyable stories to achieve
it porteous et al  87 tried to anticipate the consequences of plan failure and the remedial actions
or objects needed or described several potential alternatives they extended narrative planning
domains by two types of principled mechanisms to operationalize narrative action and object
substitution during narrative plan authoring an original domain model can be extended with the
addition generated by two mechanisms alternately
33 challenges and future prospects
in ai planning rules implied in states and actions are enforcedly constrained by preconditions
and effects compared with ai planning rules between events such as concurrence causality and
progression in natural language processing are more flexible which often intricately correlate
with others moreover the preconditions and effects are implied in natural language which are
abstract and hard to be modeled by propositions in the other hand in natural language text a event
can be written in different words and a word owns various meanings it therefore is difficult to
directly distinguish them by only parsers those challenges make it hard to extract detailed logical
relations implied in natural language let along model implied relations by constructing structural
domain models it might be interesting to dig out clear logical relations implied in natural language
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
10 jin et al
text which can lay a foundation for natural language processing tasks such as explainability and
controllable text generation
4 planningbased natural language processing
in this section we introduce three natural language tasks integrated with ai planning including
text generation text summarization and machine translation planningbased natural language
processing tasks concern about reasonability and coherence making use of the power of ai planning
about reasoning about rules and relations
41 planningbased text generation
one important field combined with ai planning is text generation in which there have been
significant advances recently text generation asks models to generate coherent and interesting
text based on preceding parts of the text topics titles or themes requiring agents to be capable
of generating valid and clear logical frameworks ai planning is one of crucial steps to guide
models to generate wellorganized long texts owing to its power in learning domain models
and computing solutions for goaldriven tasks in this section we introduce planningbased text
generation methods with respect to the following two features
symbolic planning text generation combines text generation with a classical planning
framework taking prior knowledge eg domain models formalized by planning domain
description language as extra inputs
neural planning text generation are neural generators combined learning with a skeleton
planning to make up for the difficulties in building handcrafted domain models
411 symbolic planning text generation in order to generate coherent text with correct logic it is
natural to give agents some prior knowledge about basic rules between events on the other hand
early rulebased researches  92183 about natural language processing explore constructing
representations of texts and combine with handcrafted rules it however is hard and tedious to
enumerate all rules therefore making use of ai planning to capture implied rules in the form of
domain models with symbolic representations and compute proper skeletons is a natural way which
can overcome the difficulties of manually constructing rules  365666 for example porteous
et al  86 proposed an approach injecting narrative control into plan generation through the use
of pddl  71 state trajectory constraints to express narrative control information within the
planning representation they constructed constraint trees according to input domain models and
injected control into automatically generated narratives system with the help of constraints the
approach decomposes problems into sets of smaller subproblems using the temporal orderings
described by the constraints and solves subproblems incrementally by a planner intentional partial
order causal link ipocl planning framework  90 is an extension of classical planning it aims
at finding a sound and believable sequence of character actions that transforms an initial state
into a state arriving goals ipocl does not only create causally sound plot progression but also
reasons about character intentionality by identifying possible character goals that explain their
actions and creating plans that explain why those characters commit to their goals compared to
ipocl cpocl  115 preserves the conflicting subplans without damaging the causal soundness of
the overall story to generate interesting stories cpocl is an extension of ipocl that explicitly
captures how characters can thwart one another in pursuit of their goals which is the essence of
narrative conflicts making use of handcrafted welldefined domain models symbolic planning
text generation methods have the ability to produce impressive results in limited domains
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 11
412 neural planning text generation however it is often tedious or difficult to build domain mod
els by hand due to the high requirements of manual efforts and domain knowledge automatically
learning domains and constructing storylines have significantly attracted researchers attention
recently 88 104
to automatically learn domain models for helping generate coherent and valid stories li et
al 60 used a crowdsourced corpus of stories to learn plot graphs that can then be used as
constrained search spaces for sequences of story events instead of relying on priori domain
models specifically the approach crowdsources a corpus of narrative examples of a new domain
automatically constructs domain models capturing different possible noncontradictory story
trajectories and samples from the space of stories allowed by the domain model according to
some story quality criteria during the plot graph learning learning mutual exclusion relations
and optional events lets the generated story be coherent c2po  2 learns a branching story graph
structure that can be searched and introduces soft causal relations as causal relations inferred
from commonsense reasoning it creates a branching space of possible story continuations that
bridge between plot points that are automatically extracted from existing natural language plot
summaries
another way for constructing valid line of text is to construct storylines in advance which can be
skeletons or sequences of keywords key phrases or contents xu et al  118 generated skeletons
composed of phrases learned by a reinforcement learning method and then expanded skeletons
to complete and fluent sentences fan et al  31 proposed a novel approach which first generates
plans in the form of predicateargument structures then generates stories with placeholder tokens
to indicate entities and finally replaces tokens by entities based on the global story contexts the
inputs of the task are short descriptions of scenes or events and the approach outputs relevant
narrative stories following the inputs
instead of generating skeletons with detailed prompts some approaches first plan out storylines
which enable them to generate controllable stories with goals  119 proposed a hierarchical
generation framework that first planned a controllable storyline composed of keywords towards a
goal ie a title and then generated a story based on the storyline the rake algorithm  91 takes
each sentence as an input and combines several word frequency based and graphbased metrics to
weight the importance of the words the approach regards the most important word as the keyword
the storyline is planned out based on the title previously generated sentences and the previous
keywords in the storyline in the experiments they explore two strategies dynamic schema and
static schema results show the static schema performs better than the other one because it plans
the storyline holistically thus tends to generate more coherent and relevant stories similarly
57 made use of a related framework which first plans out storyline composed of a sequence
of keywords and then generates the whole story to handle stylized story generation stylized
story generation is to generate stories with specified style given a leading context keywords are
selected following some emotiondriven style such as fear anger and surprsie according
to the stylized keywords the approach can generate generates the whole stylized story with the
guidance of the keywords yu et al  123 followed yao et al  119 and used the rake algorithm to
extract keywords to train a generation model for conducting keyword planning given story titles
as inputs then the approach combines the story titles and the corresponding keywords of each
story as the inputs of the graph module to automatically generate a graph for each story according
to the keywords titles story graphs the approach encodes them into latent variables and further
decodes them to generate the corresponding stories
except for generating stories according to prompts or goals dyploc  44 a dynamic planning
generation framework takes a set of content items as inputs each content item consists of a title a
set of entities and a set of core concepts to organize unordered content items dyploc introduces
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
12 jin et al
a plan scoring network which learns to dynamically select and order contents based on what has
been produced previously while generating the outputs
413 challenges and future prospects recently text generation  4951124 has gained lots
of attraction aiming at letting intelligent agents express like humans numbers of methods to
generate coherent texts have been proposed in recent years generating logical and controllable
texts however is still a challenging task ai planning is one of critical ways to enable agents to
generate logical and controllable texts compared with symbolic planning text generation methods
and neural planning text generation methods the former is more capable of generating logical
storylines with goals and the texts generated by the latter are more diverse and coherent specially
symbolic planning methods can generate more explainable storylines which is still challenging
for deep learning methods in general it would be interesting to combine both for generating
logical controllable and coherent text with diversity although there have been some approaches
3196109 proposed based on the syntax of plans or representation of structure in ai planning
they use neural networks to predict unseen events instead of speculating based on logical relations
implied we hold the opinion that compared with only learning blackbox neural models with
implicit rules appropriately combined with explicit logical relations would be a new attempt which
maybe contribute to natural language processing tasks
42 planningbased text summarization
text summarization is to extract important information from texts and generate new texts based
on those information in the form of summarizes it requires agents to understand texts filter
information from abundant descriptions and organize them to form summarizes which is one of
the most researched areas among the nlp community text summarization can be categorized into
extractive and abstractive techniques extractive summarization aims at selecting subsets of words
or sentences from input articles to summarize them abstractive summarization takes articles as
inputs tries to understand the texts and generate summarizes in recent years some researchers try
to integrate text summarization models with ai planning the combination of ai planning and text
summarization is mostly based on deep learning abstractive summarization making use of content
planning which describes or predicts skeletons of articles planningbased text summarization
methods first plan out skeletons of summarizies or compute probability distributions and then
generate the whole sentences based on the skeletons or predictions for example narayan et al
77 first computed plans in the form of entity chains which are ordered sequences of entities and
then generated summaries conditioned on the plans marfurt et al  69 proposed an abstractive
summarization model implemented with a planning step done by a hierarchical decoder which first
plans out an outline for the next sentence in the form of sentence representations and generates
words according to the representations amplayo et al  3 incorporated content planning in
unsupervised summarization and datasets creation they predicted aspect and sentiment probability
distributions as content plans and generated sentences according to the predictions during creating
datasets they made use of the distributions parametrized by the content planner to control the
structures of created datasets
in current planningbased text summarization approaches content planning is based on deep
learning which learns models and probability distributions to predict however only fitting deep
learning models based on representations of sentences and words is hard to capture the relations
implied we believe that it would be interesting and challenging to let content planning modules
understand relations implied in texts which will allow content plans to be more coherent and
controllable on the other hand although some mainstream text summarization methods are not
based on ai planning there are some commonalities between them for example treebased and
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 13
graphbased text summarization approaches 4858 first find the most important information from
the text and then use trees and graphs to create summaries those structures aim at representing the
relations between sentences which is similar to the relations between actions in ai planning but at
a more abstract level secondly some text summarization methods try to obtain important words
from sentences such as verbs objects and subjects to represent sentences semantically  1 these
forms have similarities with the structured representations in ai planning such as propositions
and firstorder predicates thirdly ontologybased text summarization methods  74117 collect
entities and their relationships which reminds us of domain models in ai planning we believe
that there is a vast scope for researchers to combine ai planning and text summarization
43 planningbased machine translation
machine translation aims at automatically translating content from source language to another
target language having a long history one way to understand source texts and generate target
texts is to combine neural language models with planning phases ie first generating skeletons
and extending them by target languages for example glehre et al  41 integrated an auto
encoder with a planning mechanism the autoencoder first encodes texts by sequences of vector
representations and decodes representations by generating target translation characterbycharacter
specifically they first created plans ahead in the form of action matrices which are sequences of
probability distributions and made use of commitment plan vectors to govern whether to recompute
plans or use them then they computed soft alignments based on the plan and generated texts in
target language at each timestep shu and nakayama  102 combined neural machine translation
with a planning phase which first generates planner codes to disambiguate uncertain information
about the sentence structure and control the structure of output sentences bahdanau et al  7
used actorcritic methods from reinforcement learning rl to generate sequences they showed
that sequences can be used in machine translation tasks gaining better translation performance
those approaches first produce big pictures of output texts by planning then generate complete
sentences conditioned on plans they take advantages of capturing implied rules to generate more
accurate and coherent target texts
in natural language texts the transitions between sentences imply relations and rules machine
translation tasks do not only need to understand wordlevel structures of sentences but also need
to capture sentencelevel relationships only relying on wordbyword text generation is hard and
challenging to generate coherent and logical texts especially when generating accurate transitions
between sentences current approaches to capture implied rules and generate plans are mostly based
on neural blackbox models lacking the explainability of making decisions previous researches
about rulebased translation are explainable they are based on handcrafted rules although those
rules are explicit and accurate it is hard to manually write rules and the rules are not scalable
producing rules are timeconsuming and tedious however it would be interesting if we regard it as
action models learning in planning community which structurally formalize rules by preconditions
and effects we believe that combining rulebased machine translation with planning and neural
machine translation may spark new ideas
5 planningbased explainability
nowadays although deep learning approaches have been widely used in ai fields human cannot
understand practical meaning inside blackbox neural models differently ai planning is able to
offer explicit knowledge in the form of firstorder logic domain models etc implied in natural
language therefore the combination of natural language and ai planning may enable ai systems
to be able to explain their reasoning to humans which meets the needs for ai systems to work
synergistically with humans those systems require agents to be aware of the intentions capabilities
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
14 jin et al
lack 
explainability
offer rules 
storylines
action sequences
domain modelsneural 
ai systems
human
planningbased
ai systemshuman
understandable 
symbolic interfacegive feedbacks 
such as rewards 
and punishments
annotate 
answer or 
explaingive human
understandable 
queriesquery
combine with
ai planning
fig 5 two types of making neural ai systems be explainable 1 integrating ai systems with planning
techniques 2 making use of humanunderstandable interface
and mental model of the human in the loop during its decision process as shown in figure 5
besides extracting action sequences  3268 and building domain models  1464 mentioned
above another way for making ai system explainable is to construct humanunderstandable
symbolic interfaces cf  53 a humanunderstandable symbolic interface is not only developed
for its own computational efficiency but also beneficial to humans expand system  40 and
serlfd framework  125 respectively expand system accelerates humanintheloop deep
reinforcement learning by using human evaluative feedback and visual explanation serlfd uses
selfexplanation to recognize valuable highlevel relational features as an interpretation of why a
successful trajectory is successful allowing serlfd to guide itself and improve the efficiency
6 textbased humanrobot interaction
the rapid developments of artificial intelligence let robots move out from industrial environments
and enter the daily life of humans such as homes and hospitals it requires robots to be able to
respond quickly and effectively to rapidlychanging conditions and expectations languagebased
communication is the most natural method for humans to communicate with others so natural
language is a good candidate to be robot instruction for humanrobot interaction in this section
we will introduce textbased humanrobot interaction from three aspects extracting actions from
natural language commands natural language command understanding and dialogue generation
as shown in the figure 6
61 extracting actions from natural language command
one of important tasks in textbased humanrobot interaction is to extract actions from natural
language commands  487985111 extracting actions from natural language commands is
similar to action extraction in section 31 differently extracting actions from natural language
commands is not only to capture important words to indicate sentences but also to understand
implied rules and generate action sequences to guide robots to achieve tasks some approaches
make use of with language descriptions then build models that map language commands to
action sequences tellex et al  110 introduced a system generalized grounding graphs g3
taking a natural language command as input and outputting a plan for the robot g3instantiates a
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 15
human
robotnatural language 
commandsnatural language 
commandsnatural language 
commandsaction 
sequences
action models 
understand 
implied 
intentions
planningbased 
dialogue systemsextract actions 
execute
capture 
implied rules and 
intentions
communicate
generate 
utterancesgive feedbacksunderstand new 
commands
fig 6 relations of researches in humanrobot interaction
probabilistic graphical model for a particular natural language command according to hierarchical
and compositional semantic structure of the command cantrell et al  20 presented a robotic
architecture equipping with a planner that uses newly discovered information to produce new and
updated plans specifically information originating in spoken input produced by human operators
the robot can learn action sequences with defined preconditions and effects from natural language
descriptions and immediately apply this knowledge to improve planning on the other hand some
approaches  16120 focus on temporal logic between natural language commands aiming at
handling semantic disambiguation of natural language
62 natural language command understanding
another important task is to enable agents to understand natural language commands given by
humans which requires agents to understand natural language commands and capture implied rules
101012252599 or learn new actions based on natural language commands and dialogues 35
7595101 to understand natural language commands thomason et al  113 introduced a dialog
agent to understand human natural language commands through semantic parsing actively resolve
ambiguities using a dialog manager and incrementally learn from humanrobot conversations the
agent employs incremental learning of a semantic parser from conversations on a mobile robot
it is implemented and tested both on a web interface with hundreds of users and on a mobile
robot over several days tasked with understanding navigation and delivery requests through
natural language in an office environment brawer et al  15 presented a framework for effectively
grounding situated and natural language to action selection during humanrobot interaction it
integrates verbal commands from a human partner with contextual information in the form of a
task model the approach is capable of acquiring and deploying new task representations from
limited and natural language data sets and without any prior domain knowledge of language
or the task itself moreover understanding action models and predicting next actions are widely
researched for robotic tasks and navigation tasks with natural language commands 24 26 112
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
16 jin et al
on the other hand another challenge in natural language command understanding tasks is
to learn new actions when facing unknown natural language commands  6100 cantrell et al
19 introduced an algorithm to learn meanings of action verbs through dialoguebased natural
language descriptions and integrated it in the robots natural language subsystem the algorithm
allows robots to perform the actions associated with the learned verb meanings right away without
any additional help or learning trials moreover it allows human to interact with a robot to explain
new action words in natural language and lets the robot be able to perform the new action and
store the procedural knowledge for future usage learning by instruction agent lia  5 was
proposed to learn new commands by natural language interaction with human when facing a
new natural language command that lia does not understand it prompts users to explain how
to achieve the command through a sequence of natural language steps lia interprets commands
using a semantic parser that maps each command to a logical form which contains one or more of
functions and predicates
undoubtedly letting agents understand natural language commands and infer about next actions
is an important but challenging task an agent does not only need to capture rules implied in
utterances but also need to distinguish sentences described in different ways we believe that the
combination of planningbased natural language processing and humanrobot interaction would
create something interesting for natural language commands understanding tasks
63 dialogue systems
dialogue systems  2367 have been a bridge between human and robots which interacts with
human in natural language ai planning is one of crucial mechanisms used in dialogue systems
to recognize the intentions conveyed in dialogues  1876 planningbased dialogue systems take
advantage of the power of capturing and expressing rules and use it to manage utterances or guide
the generation rules plans and intentions offer proper logical forms which derive appropriate
communication acts in dialogue systems  28 planbased model  2793 were proposed to manage
the intentions and information implied in dialogues those models describe the common activities
and relations between utterances and can be used in the following generation processes however
planningbased dialogue systems are still in early stages  2884 which facing the challenges
of complex representations in opendomain difficulties of manually constructing models and
limitations of scalability of dialogue models nevertheless we believe that planning could be a
strong suit for dialogue systems by integrating with automatically domain models learning and
searching strategies especially for controlled dialogue generation moreover we are interested in
the explainability of planningbased dialogue systems it would be interesting to know the reason
for intentions generation
7 applications
in this section we introduce some reality applications based on combinations of ai planning and
natural language processing ai planning is widely used in reality management systems such as
logistics management workshop schedule and reservoir operation moreover natural language
processing nlp helps human communicate with agents the combination of ai planning and nlp
enables applications to be found in many fields such as emergency managements  11292933
and urban planning  636389 for example the urban redevelopment authority ura centre in
singapore3deployed robotic process automation and nlp to help conduct operations for resource
optimization the combination allows routine tasks to make use of ai planning and nlp such
as chatbots for public queries which capture information from large datasets analyze textual
3httpswwwuragovsgcorporateresourcesideasandtrendsaiinurbanplanning
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 17
feedback make planning decisions and respond intelligently on the other hand the navigation
systems in daily use such as baidu maps4and google maps5 combine making decisions and
nlp techniques which plan out routes with different objectives according to goals and generate
natural language suggestions to guide human moreover agents learn from human commands and
navigation datasets helping agents understand human behaviors 45 73
8 conclusion
in this paper we consider that ai planning and natural language processing have strong ties and we
introduce recent works about four related tasks ie planningbased text understanding planning
based natural language processing planningbased explainability and textbased humanrobot
interaction we first introduce backgrounds about ai planning and natural language processing
and discuss commons between them as well as their abilities to generate explicit knowledge
eg domain models and learning from tacit knowledge eg neural models we then introduce
methods of planningbased text understanding by extracting action sequences from texts and
learning domain models from texts next we give an overview of planningbased natural language
processing about text generation text summarization and machine translation then we introduce
recent works in planningbased explainability and textbased humanrobot interaction
with this paper we aim to provide a highlevel view of ai planning and natural language
processing for further studies about integrating them for a combination of explicit and tacit
knowledge combining learning from tacit knowledge and using explicit knowledge in a fully
principled way is an open problem although there are nonnegligible relations between ai planning
and natural language processing allowing each of them can effectively impact the other one
however there is not enough communication between these two fields while many advances have
been made in natural language processing by using ai planning algorithms a significant amount
of research is still required to understand the implied knowledge hidden in texts meanwhile
improving the ability to describe environments by domain models and solve largescale planning
problems is also beneficial to understanding texts and generating coherent and interesting texts
we believe that integrating ai planning and natural language processing a complex combination of
explicit and tacit knowledge is a promising research area which can improve the communication
between human and intelligent agents
references
1s alshaina ansamma john and aneesh g nath 2017 multidocument abstractive summarization based on predicate
argument structure in 2017 ieee international conference on signal processing informatics communication and energy
systems spices  ieee 16
2prithviraj ammanabrolu wesley cheung william broniec and mark o riedl 2021 automated storytelling
via causal commonsense plot ordering in thirtyfifth aaai conference on artificial intelligence aaai 2021
thirtythird conference on innovative applications of artificial intelligence iaai 2021 the eleventh symposium
on educational advances in artificial intelligence eaai 2021 virtual event february 29 2021  58595867 https
ojsaaaiorgindexphpaaaiarticleview16733
3reinald kim amplayo stefanos angelidis and mirella lapata 2021 unsupervised opinion summarization with
content planning in thirtyfifth aaai conference on artificial intelligence aaai 2021 thirtythird conference
on innovative applications of artificial intelligence iaai 2021 the eleventh symposium on educational advances in
artificial intelligence eaai 2021 virtual event february 29 2021  1248912497 httpsojsaaaiorgindexphpaaai
articleview17481
4mozhgan nasr azadani nasser ghadiri and ensieh davoodijam 2018 graphbased biomedical text summarization
an itemset mining and sentence clustering approach j biomed informatics 84 2018 4258 httpsdoiorg101016
jjbi201806005
4httpsmapbaiducom
5httpswwwgoogledemaps
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
18 jin et al
5amos azaria jayant krishnamurthy and tom m mitchell 2016 instructable intelligent personal agent in proceedings
of the thirtieth aaai conference on artificial intelligence february 1217 2016 phoenix arizona usa  dale schuurmans
and michael p wellman eds 26812689 httpwwwaaaiorgocsindexphpaaaiaaai16paperview12383
6amos azaria shashank srivastava jayant krishnamurthy igor labutov and tom m mitchell 2020 an agent for
learning new natural language commands auton agents multi agent syst 34 1 2020 6 httpsdoiorg101007
s1045801909425x
7dzmitry bahdanau philemon brakel kelvin xu anirudh goyal ryan lowe joelle pineau aaron c courville
and yoshua bengio 2017 an actorcritic algorithm for sequence prediction in 5th international conference
on learning representations iclr 2017 toulon france april 2426 2017 conference track proceedings  https
openreviewnetforumidsjdaqqveg
8siddhartha banerjee prasenjit mitra and kazunari sugiyama 2015 multidocument abstractive summarization
using ilp based multisentence compression in proceedings of the twentyfourth international joint conference on
artificial intelligence ijcai 2015 buenos aires argentina july 2531 2015  qiang yang and michael j wooldridge
eds 12081214 httpijcaiorgabstract15174
9robert baud christian lovis laurence alpay annemarie rassinoux jr scherrer anthony nowlan and alan
rector 1993 modelling for natural language understanding in proceedings of the annual symposium on computer
application in medical care  american medical informatics association 289
10 yonatan bisk kevin j shih yejin choi and daniel marcu 2018 learning interpretable spatial operations in a rich
3d blocks world in proceedings of the thirtysecond aaai conference on artificial intelligence aaai18 the 30th
innovative applications of artificial intelligence iaai18 and the 8th aaai symposium on educational advances in
artificial intelligence eaai18 new orleans louisiana usa february 27 2018  sheila a mcilraith and kilian q
weinberger eds 50285036 httpswwwaaaiorgocsindexphpaaaiaaai18paperview17410
11 simon blindheim sebastien gros and tor arne johansen 2020 riskbased model predictive control for autonomous
ship emergency management ifacpapersonline 53 2 2020 1452414531
12 valts blukis dipendra kumar misra ross a knepper and yoav artzi 2018 mapping navigation instructions to
continuous control actions with positionvisitation prediction in 2nd annual conference on robot learning corl
2018 zrich switzerland 2931 october 2018 proceedings proceedings of machine learning research vol 87  505518
httpproceedingsmlrpressv87blukis18ahtml
13 s r k branavan harr chen luke s zettlemoyer and regina barzilay 2009 reinforcement learning for mapping
instructions to actions in acl 2009 proceedings of the 47th annual meeting of the association for computational
linguistics and the 4th international joint conference on natural language processing of the afnlp 27 august 2009
singapore  kehyih su jian su and janyce wiebe eds 8290 httpsaclanthologyorgp091010
14 s r k branavan nate kushman tao lei and regina barzilay 2012 learning highlevel planning from text in
the 50th annual meeting of the association for computational linguistics proceedings of the conference july 814
2012 jeju island korea  volume 1 long papers  126135 httpsaclanthologyorgp121014
15 jake brawer olivier mangin alessandro roncone sarah widder and brian scassellati 2018 situated human
robot collaboration predicting intent from grounded natural language in 2018 ieeersj international conference on
intelligent robots and systems iros 2018 madrid spain october 15 2018  827833 httpsdoiorg101109iros
20188593942
16 igor buzhinsky 2019 formalization of natural language requirements into temporal logics a survey in 17th
ieee international conference on industrial informatics indin 2019 helsinki finland july 2225 2019  400406
httpsdoiorg101109indin4105220198972130
17 erik cambria and bebo white 2014 jumping nlp curves a review of natural language processing research ieee
computational intelligence magazine 9 2 2014 4857
18 guy camilleri 2002 dialogue systems and planning in international conference on text speech and dialogue  springer
429436
19 rehj cantrell paul w schermerhorn and matthias scheutz 2011 learning actions from humanrobot dialogues in
20th ieee international symposium on robot and human interactive communication roman 2011 atlanta georgia
usa july 31  august 3 2011  henrik i christensen ed 125130 httpsdoiorg101109roman20116005199
20 rehj cantrell kartik talamadupula paul w schermerhorn j benton subbarao kambhampati and matthias scheutz
2012 tell me when and why to do it runtime planner model updates via natural language instruction in hri
holly a yanco aaron steinfeld vanessa evers and odest chadwicke jenkins eds 471478 httpsdoiorg10
114521576892157840
21 nick cercone and gordon mccalla 1986 accessing knowledge through natural language in advances in computers 
vol 25 elsevier 199
22 david l chen and raymond j mooney 2011 learning to interpret natural language navigation instructions from
observations in proceedings of the twentyfifth aaai conference on artificial intelligence aaai 2011 san francisco
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 19
california usa august 711 2011  wolfram burgard and dan roth eds httpwwwaaaiorgocsindexphpaaai
aaai11paperview3701
23 hongshen chen xiaorui liu dawei yin and jiliang tang 2017 a survey on dialogue systems recent advances
and new frontiers sigkdd explor 19 2 2017 2535 httpsdoiorg10114531660543166058
24 howard chen alane suhr dipendra misra noah snavely and yoav artzi 2019 touchdown nat
ural language navigation and spatial reasoning in visual street environments in ieee conference on
computer vision and pattern recognition cvpr 2019 long beach ca usa june 1620 2019  12538
12547 httpopenaccessthecvfcomcontentcvpr2019htmlchentouchdownnaturallanguage
navigationandspatialreasoninginvisualstreetcvpr2019paperhtml
25 haonan chen hao tan alan kuntz mohit bansal and ron alterovitz 2020 enabling robots to understand
incomplete natural language instructions using commonsense reasoning in 2020 ieee international conference
on robotics and automation icra 2020 paris france may 31  august 31 2020  19631969 httpsdoiorg101109
icra4094520209197315
26 tachung chi minmin shen mihail eric seokhwan kim and dilek hakkanitr 2020 just ask an interactive
learning framework for vision and language navigation in the thirtyfourth aaai conference on artificial
intelligence aaai 2020 the thirtysecond innovative applications of artificial intelligence conference iaai 2020 the
tenth aaai symposium on educational advances in artificial intelligence eaai 2020 new york ny usa february
712 2020  24592466 httpsojsaaaiorgindexphpaaaiarticleview5627
27 jennifer chucarroll and sandra carberry 1994 a planbased model for response generation in collaborative
taskoriented dialogues arxiv preprint cmplg9405011 1994
28 philip r cohen 2020 back to the future for dialogue research in proceedings of the aaai conference on artificial
intelligence  vol 34 1351413519
29 daniel g costa joo paulo j peixoto thiago c jesus paulo portugal francisco vasques elivelton rangel and maycon
peixoto 2022 a survey of emergencies management systems in smart cities ieee access 2022
30 chenhe dong yinghui li haifan gong miaoxin chen junxin li ying shen and min yang 2021 a survey of
natural language generation arxiv preprint arxiv211211739 2021
31 angela fan mike lewis and yann n dauphin 2019 strategies for structuring story generation in proceedings
of the 57th conference of the association for computational linguistics acl 2019 florence italy july 28 august
2 2019 volume 1 long papers  anna korhonen david r traum and llus mrquez eds 26502660 https
doiorg1018653v1p191254
32 wenfeng feng hankz hankui zhuo and subbarao kambhampati 2018 extracting action sequences from texts
based on deep reinforcement learning in ijcai  40644070
33 daniela fogli and giovanni guida 2013 knowledgecentered design of decision support systems for emergency
management decision support systems 55 1 2013 336347
34 maria fox and derek long 2002 pddl modeling continuous time dependent effects in proceedings of the 3rd
international nasa workshop on planning and scheduling for space  vol 4 34
35 tyler m frasca bradley oosterveld meia chitategmark and matthias scheutz 2021 enabling fast instruction
based modification of learned robot skills in thirtyfifth aaai conference on artificial intelligence aaai 2021
thirtythird conference on innovative applications of artificial intelligence iaai 2021 the eleventh symposium
on educational advances in artificial intelligence eaai 2021 virtual event february 29 2021  60756083 https
ojsaaaiorgindexphpaaaiarticleview16757
36 konstantina garoufi 2014 planningbased models of natural language generation lang linguistics compass 8 1
2014 110 httpsdoiorg101111lnc312053
37 albert gatt and emiel krahmer 2018 survey of the state of the art in natural language generation core tasks
applications and evaluation journal of artificial intelligence research 61 2018 65170
38 christopher w geib and mark steedman 2007 on natural language processing and plan recognition in ijcai
2007 proceedings of the 20th international joint conference on artificial intelligence hyderabad india january 612
2007 manuela m veloso ed 16121617 httpijcaiorgproceedings07papers260pdf
39 alfonso gerevini and derek long 2005 plan constraints and preferences in pddl3  technical report technical
report 20050807 department of electronics for automation    
40 lin guan mudit verma sihang guo ruohan zhang and subbarao kambhampati 2021 widening the pipeline in
humanguided reinforcement learning with explanation and contextaware data augmentation advances in
neural information processing systems 34 2021
41 aglar glehre francis dutil adam trischler and yoshua bengio 2017 plan attend generate characterlevel
neural machine translation with planning in proceedings of the 2nd workshop on representation learning for nlp
rep4nlpacl 2017 vancouver canada august 3 2017  phil blunsom antoine bordes kyunghyun cho shay b
cohen chris dyer edward grefenstette karl moritz hermann laura rimell jason weston and scott yih eds
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
20 jin et al
228234 httpsdoiorg1018653v1w172627
42 thomas hayton julie porteous joo fernando ferreira and alan lindsay 2020 narrative planning model acquisition
from text summaries and descriptions in aaai  17091716
43 daniel hldek jn sta and mat pleva 2020 survey of automatic spelling correction electronics 9 10 2020 1670
44 xinyu hua ashwin sreevatsa and lu wang 2021 dyploc dynamic planning of content using mixed language
models for text generation in proceedings of acl  64086423
45 jizhou huang haifeng wang miao fan an zhuo yibo sun and ying li 2020 understanding the impact of
the covid19 pandemic on transportationrelated behaviors with human mobility data 2020 34433450
httpsdoiorg10114533944863412856
46 wenlong huang pieter abbeel deepak pathak and igor mordatch 2022 language models as zeroshot planners
extracting actionable knowledge for embodied agents 162 2022 91189147 httpsproceedingsmlrpressv162
huang22ahtml
47 wenlong huang fei xia ted xiao harris chan jacky liang pete florence andy zeng jonathan tompson igor
mordatch yevgen chebotar pierre sermanet noah brown tomas jackson linda luu sergey levine karol hausman
and brian ichter 2022 inner monologue embodied reasoning through planning with language models corr
abs220705608 2022 httpsdoiorg1048550arxiv220705608 arxiv220705608
48 pham ngoc hung and takashi yoshimi 2016 extracting actions from instruction manual and testing their execution
in a robotic simulation asean engineering journal 6 1 2016 4758
49 touseef iqbal and shaima qureshi 2020 the survey text generation models in deep learning journal of king saud
universitycomputer and information sciences 2020
50 peter a jansen 2020 visuallygrounded planning without vision language models infer detailed plans from
highlevel instructions emnlp 2020 2020 44124417 httpsdoiorg1018653v12020findingsemnlp395
51 hanqi jin yue cao tianming wang xinyu xing and xiaojun wan 2020 recent advances of neural text generation
core tasks datasets models and challenges science china technological sciences 63 10 2020 19902010
52 subbarao kambhampati 2021 polanyis revenge and ais new romance with tacit knowledge commun acm 64 2
2021 3132 httpsdoiorg1011453446369
53 subbarao kambhampati sarath sreedharan mudit verma yantian zha and lin guan 2021 symbols as a lingua
franca for bridging humanai chasm for explainable and advisable ai systems corr abs210909904 2021
arxiv210909904 httpsarxivorgabs210909904
54 diksha khurana aditya koli kiran khatter and sukhdev singh 2022 natural language processing state of the art
current trends and challenges multimedia tools and applications 2022 132
55 joohyun kim and raymond j mooney 2012 unsupervised pcfg induction for grounded language learning with
highly ambiguous supervision in emnlpconll  junichi tsujii james henderson and marius pasca eds 433444
httpsaclanthologyorgd121040
56 alexander koller and jrg hoffmann 2010 waking up a sleeping rabbit on naturallanguage sentence generation
with ff in proceedings of the 20th international conference on automated planning and scheduling icaps 2010 toronto
ontario canada may 1216 2010  ronen i brafman hector geffner jrg hoffmann and henry a kautz eds
aaai 238241 httpwwwaaaiorgocsindexphpicapsicaps10paperview1415
57 xiangzhe kong jialiang huang ziquan tung jian guan and minlie huang 2021 stylized story generation with
styleguided planning in aclijcnlp  24302436
58 litton j kurisinkel yue zhang and vasudeva varma 2017 abstractive multidocument summarization by partial
tree extraction recombination and linearization in proceedings of the eighth international joint conference on natural
language processing volume 1 long papers  812821
59 anastassia kstenmacher and paul g plger 2021 improving the reliability of service robots by symbolic represen
tation of execution specific knowledge in robust and reliable autonomy in the wild r2aw 
60 boyang li stephen leeurban george johnston and mark riedl 2013 story generation with crowdsourced plot
graphs in proceedings of the twentyseventh aaai conference on artificial intelligence july 1418 2013 bellevue
washington usa  marie desjardins and michael l littman eds httpwwwaaaiorgocsindexphpaaaiaaai13
paperview6399
61 shuang li xavier puig chris paxton yilun du clinton wang linxi fan tao chen dean huang ekin akyrek
anima anandkumar jacob andreas igor mordatch antonio torralba and yuke zhu 2022 pretrained language
models for interactive decisionmaking corr abs220201771 2022 arxiv220201771 httpsarxivorgabs2202
01771
62 zhuohan li siyuan zhuang shiyuan guo danyang zhuo hao zhang dawn song and ion stoica 2021 terapipe
tokenlevel pipeline parallelism for training largescale language models in international conference on machine
learning  pmlr 65436552
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 21
63 claudius lieven bianca lders daniel kulus and rosa thoneick 2021 enabling digital cocreation in urban
planning and development 2021 415430
64 alan lindsay jonathon read joo f ferreira thomas hayton julie porteous and peter gregory 2017 framer
planning models from natural language action descriptions in icaps  434442
65 adam lopez 2008 statistical machine translation acm comput surv 40 3 article 8 aug 2008 49 pages
httpsdoiorg10114513805841380586
66 stephanie m lukin and marilyn a walker 2019 a narrative sentence planner and structurer for domain independent
parameterizable storytelling dialogue  discourse 10 1 2019 3486
67 longxuan ma mingda li weinan zhang jiapeng li and ting liu 2022 unstructured text enhanced opendomain
dialogue system a systematic survey acm trans inf syst 40 1 2022 91944 httpsdoiorg1011453464377
68 matt macmahon brian stankiewicz and benjamin kuipers 2006 walk the talk connecting language knowledge
and action in route instructions in aaai  14751482 httpwwwaaaiorglibraryaaai2006aaai06232php
69 andreas marfurt and james henderson 2021 sentencelevel planning for especially abstractive summarization in
proceedings of the third workshop on new frontiers in summarization  114
70 cynthia matuszek dieter fox and karl koscher 2010 following directions using statistical machine translation in
hri pamela j hinds hiroshi ishiguro takayuki kanda and peter h kahn jr eds 251258 httpsdoiorg10
114517344541734552
71 drew mcdermott malik ghallab adele e howe craig a knoblock ashwin ram manuela m veloso daniel s
weld and david e wilkins 1998 pddlthe planning domain definition language
72 hongyuan mei mohit bansal and matthew r walter 2016 listen attend and walk neural mapping of navigational
instructions to action sequences in thirtieth aaai conference on artificial intelligence  dale schuurmans and
michael p wellman eds 27722778 httpwwwaaaiorgocsindexphpaaaiaaai16paperview12522
73 shah jahan miah huy quan vu and damminda alahakoon 2022 a social media analytics perspective for human
oriented smart city planning and management journal of the association for information science and technology 73 1
2022 119135
74 m jishma mohan c sunitha amal ganesh and a jaya 2016 a study on ontology based abstractive summarization
procedia computer science 87 2016 3237
75 shiwali mohan and john e laird 2014 learning goaloriented hierarchical tasks from situated interactive
instruction in proceedings of the twentyeighth aaai conference on artificial intelligence july 27 31 2014 qubec
city qubec canada  carla e brodley and peter stone eds 387394 httpwwwaaaiorgocsindexphpaaai
aaai14paperview8630
76 christian muise tathagata chakraborti shubham agarwal ondrej bajgar arunima chaudhary luis a lastras
montano josef ondrej miroslav vodolan and charlie wiecha 2019 planning for goaloriented dialogue systems
arxiv preprint arxiv191008137 2019
77 shashi narayan yao zhao joshua maynez gonalo simes vitaly nikolaev and ryan mcdonald 2021 planning with
learned entity prompts for abstractive summarization transactions of the association for computational linguistics 9
2021 14751492
78 deepak narayanan mohammad shoeybi jared casper patrick legresley mostofa patwary vijay korthikanti dmitri
vainbrand prethvi kashinkunti julie bernauer bryan catanzaro et al 2021 efficient largescale language model
training on gpu clusters using megatronlm in proceedings of the international conference for high performance
computing networking storage and analysis  115
79 daniel nyga and michael beetz 2012 everything robots always wanted to know about housework but were afraid
to ask in 2012 ieeersj international conference on intelligent robots and systems  ieee 243250
80 md okpor 2014 machine translation approaches issues and challenges international journal of computer science
issues ijcsi 11 5 2014 159
81 daniel w otter julian r medina and jugal k kalita 2020 a survey of the usages of deep learning for natural
language processing ieee transactions on neural networks and learning systems 32 2 2020 604624
82 vishal pallagani and biplav srivastava 2021 a generic dialog agent for information retrieval based on automated
planning within a reinforcement learning platform bridging the gap between ai planning and reinforcement
learning prl 2021
83 c raymond perrault and james f allen 1980 a planbased analysis of indirect speech acts am j comput
linguistics 6 34 1980 167182
84 ronald pa petrick and mary ellen foster 2016 using generalpurpose planning for action selection in humanrobot
interaction in 2016 aaai fall symposium series 
85 ngoc hung pham and takashi yoshimi 2015 extraction of actions and objects from instruction manual for executable
robot planning in 2015 15th international conference on control automation and systems iccas  ieee 881885
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
22 jin et al
86 julie porteous and marc cavazza 2009 controlling narrative generation with planning trajectories the role of
constraints in icids 2009 lecture notes in computer science vol 5915  ido iurgel nelson zagalo and paolo petta
eds 234245 httpsdoiorg101007978364210643928
87 julie porteous joo f ferreira alan lindsay and marc cavazza 2021 automated narrative planning model extension
auton agents multi agent syst 35 2 2021 19 httpsdoiorg101007s10458021095011
88 julie porteous joo f ferreira alan lindsay and marc cavazza 2021 automated narrative planning model extension
autonomous agents and multiagent systems 35 2 2021 129
89 bernd resch anja summa peter zeile and michael strube 2016 citizencentric urban planning through extracting
emotion information from twitter in an interdisciplinary spacetimelinguistics algorithm urban planning 1 2 2016
114127
90 mark o riedl and robert michael young 2010 narrative planning balancing plot and character j artif intell res
39 2010 217268 httpsdoiorg101613jair2989
91 stuart rose dave engel nick cramer and wendy cowley 2010 automatic keyword extraction from individual
documents text mining applications and theory 1 2010 120
92 scott sanner et al 2010 relational dynamic influence diagram language rddl language description unpublished
ms australian national university 32 2010 27
93 milene santos teixeira and mauro dragoni 2022 a review of planbased approaches for dialogue management
cognitive computation 2022 120
94 buser say 2021 a unified framework for planning with learned neural network transition models 2021
50165024 httpsojsaaaiorgindexphpaaaiarticleview16635
95 matthias scheutz evan a krause bradley oosterveld tyler m frasca and robert platt jr 2017 spoken instruction
based oneshot object and action learning in a cognitive robotic architecture in proceedings of the 16th conference
on autonomous agents and multiagent systems aamas 2017 so paulo brazil may 812 2017  kate larson michael
winikoff sanmay das and edmund h durfee eds 13781386 httpdlacmorgcitationcfmid3091315
96 lei sha lili mou tianyu liu pascal poupart sujian li baobao chang and zhifang sui 2018 orderplanning neural
text generation from structured data in aaai  sheila a mcilraith and kilian q weinberger eds 54145421
97 khaled shaalan et al 2010 rulebased approach in arabic natural language processing the international journal on
information and communication technologies ijict 3 3 2010 1119
98 pratyusha sharma antonio torralba and jacob andreas 2022 skill induction and planning with latent language
2022 17131726 httpsdoiorg1018653v12022acllong120
99 lanbo she and joyce yue chai 2017 interactive learning of grounded verb semantics towards humanrobot
communication in proceedings of the 55th annual meeting of the association for computational linguistics acl 2017
vancouver canada july 30  august 4 volume 1 long papers  regina barzilay and minyen kan eds 16341644
httpsdoiorg1018653v1p171150
100 lanbo she yu cheng joyce yue chai yunyi jia shaohua yang and ning xi 2014 teaching robots new actions
through natural language instructions in the 23rd ieee international symposium on robot and human interactive
communication ieee roman 2014 edinburgh uk august 2529 2014  868873 httpsdoiorg101109roman
20146926362
101 lanbo she shaohua yang yu cheng yunyi jia joyce yue chai and ning xi 2014 back to the blocks world learning
new actions through situated humanrobot dialogue in proceedings of the sigdial 2014 conference the 15th
annual meeting of the special interest group on discourse and dialogue 1820 june 2014 philadelphia pa usa  8997
httpsdoiorg103115v1w144313
102 raphael shu and hideki nakayama 2018 discrete structural planning for neural machine translation corr
abs180804525 2018 arxiv180804525 httparxivorgabs180804525
103 avirup sil and alexander yates 2011 extracting strips representations of actions and events in ranlp  18
104 nisha simon and christian muise 2022 tattletale storytelling with planning and large language models 2022
105 sarath sreedharan tathagata chakraborti christian muise yasaman khazaeni and subbarao kambhampati 2020
d3waa case study of xaip in a model acquisition task for dialogue planning in proceedings of the international
conference on automated planning and scheduling  vol 30 488497
106 felix stahlberg 2020 neural machine translation a review j artif intell res 69 2020 343418 https
doiorg101613jair112007
107 shane storks qiaozi gao and joyce y chai 2019 commonsense reasoning for natural language understanding a
survey of benchmarks resources and approaches arxiv preprint arxiv190401172 2019 160
108 gavin suddrey ben talbot and frederic maire 2022 learning and executing reusable behaviour trees from natural
language instruction ieee robotics and automation letters 2022
109 pradyumna tambwekar murtaza dhuliawala lara j martin animesh mehta brent harrison and mark o riedl
2019 controllable neural story plot generation via reward shaping in proceedings of the twentyeighth international
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
integrating ai planning with natural language processing a combination of explicit and tacit knowledge 23
joint conference on artificial intelligence ijcai 2019 macao china august 1016 2019  sarit kraus ed 59825988
httpsdoiorg1024963ijcai2019829
110 stefanie tellex thomas kollar steven dickerson matthew r walter ashis gopal banerjee seth j teller and
nicholas roy 2011 understanding natural language commands for robotic navigation and mobile manipulation
inaaai  wolfram burgard and dan roth eds httpwwwaaaiorgocsindexphpaaaiaaai11paperview3623
111 moritz tenorth daniel nyga and michael beetz 2010 understanding and executing instructions for everyday
manipulation tasks from the world wide web in ieee international conference on robotics and automation icra
2010 anchorage alaska usa 37 may 2010  14861491 httpsdoiorg101109robot20105509955
112 jesse thomason michael murray maya cakmak and luke zettlemoyer 2019 visionanddialog navigation in 3rd
annual conference on robot learning corl 2019 osaka japan october 30  november 1 2019 proceedings proceedings
of machine learning research vol 100  leslie pack kaelbling danica kragic and komei sugiura eds 394406
httpproceedingsmlrpressv100thomason20ahtml
113 jesse thomason shiqi zhang raymond j mooney and peter stone 2015 learning to interpret natural language
commands through humanrobot dialog in ijcai 2015  qiang yang and michael j wooldridge eds 19231929
httpijcaiorgabstract15273
114 amirsina torfi rouzbeh a shirvani yaser keneshloo nader tavaf and edward a fox 2020 natural language
processing advancements by deep learning a survey arxiv preprint arxiv200301200 2020
115 stephen g ware and robert michael young 2011 cpocl a narrative planner supporting conflict in aiide  vadim
bulitko and mark o riedl eds httpwwwaaaiorgocsindexphpaiideaiide11paperview4058
116 robert wilensky 1981 metaplanning representing and using knowledge about planning in problem solving and
natural language understanding cogn sci 5 3 1981 197233 httpsdoiorg101207s15516709cog05032
117 chuncheng xiang tingsong jiang baobao chang and zhifang sui 2015 ersom a structural ontology matching
approach using automatically learned entity representation in proceedings of the 2015 conference on empirical
methods in natural language processing emnlp 2015 lisbon portugal september 1721 2015  llus mrquez chris
callisonburch jian su daniele pighin and yuval marton eds 24192429 httpsdoiorg1018653v1d151289
118 jingjing xu xuancheng ren yi zhang qi zeng xiaoyan cai and xu sun 2018 a skeletonbased model for promoting
coherence among sentences in narrative story generation in emnlp  43064315 httpsaclanthologyorgd18
1462
119 lili yao nanyun peng ralph m weischedel kevin knight dongyan zhao and rui yan 2019 planandwrite
towards better automatic storytelling in aaai  73787385
120 rongguang ye qingchuan xu jie liu yang hong chengfeng sun wenzheng chi and lining sun 2021 a natural
language instruction disambiguation method for robot grasping in ieee international conference on robotics and
biomimetics robio 2021 sanya china december 2731 2021  601606 httpsdoiorg101109robio541682021
9739456
121 kristina y yordanova and thomas kirste 2016 learning models of human behaviour from textual instructions in
icaart  415422
122 r michael young stephen g ware brad a cassell and justus robertson 2013 plans and planning in narrative
generation a review of planbased approaches to the generation of story discourse and interactivity in narratives
sprache und datenverarbeitung special issue on formal and computational models of narrative 37 12 2013 4164
123 menghsuan yu juntao li zhangming chan rui yan and dongyan zhao 2021 content learning with structure
aware writing a graphinfused dual conditional variational autoencoder for automatic storytelling in aaai 
60216029
124 wenhao yu chenguang zhu zaitang li zhiting hu qingyun wang heng ji and meng jiang 2022 a survey of
knowledgeenhanced text generation acm computing surveys csur 2022
125 yantian zha lin guan and subbarao kambhampati 2021 learning from ambiguous demonstrations with self
explanation guided reinforcement learning corr abs211005286 2021 arxiv211005286 httpsarxivorgabs
211005286
126 zhengyan zhang yuxian gu xu han shengqi chen chaojun xiao zhenbo sun yuan yao fanchao qi jian guan
pei ke et al 2021 cpm2 largescale costeffective pretrained language models ai open 2 2021 216224
127 fengda zhao zhikai yang xianshan li dingding guo and haitao li 2021 extract executable action sequences
from natural language instructions based on dqn for medical service robots int j comput commun control 16
2 2021 httpsdoiorg1015837ijccc202124115
128 hankz hankui zhuo and subbarao kambhampati 2013 actionmodel acquisition from noisy plan traces in ijcai 
24442450
129 hankz hankui zhuo and subbarao kambhampati 2017 modellite planning casebased vs modelbased approaches
artif intell 246 2017 121 httpsdoiorg101016jartint201701004
acm trans intell syst technol vol 1 no 1 article  publication date april 2022
24 jin et al
130 hankz hankui zhuo hctor muozavila and qiang yang 2014 learning hierarchical task network domains from
partially observed plan traces artif intell 212 2014 134157
131 hankz hankui zhuo and qiang yang 2014 actionmodel acquisition for planning via transfer learning artif intell
212 2014 80103 httpsdoiorg101016jartint201403004
132 hankz hankui zhuo yantian zha subbarao kambhampati and xin tian 2020 discovering underlying plans based
on shallow models acm trans intell syst technol 11 2 2020 1811830 httpsdoiorg1011453368270
received xxxx revised xxxx accepted xxxx
acm trans intell syst technol vol 1 no 1 article  publication date april 2022","['arxiv210909904', 'arxiv220705608', 'arxiv190401172', 'arxiv180804525', 'arxiv220201771', 'arxiv191008137', 'arxiv200301200', 'httpsdoiorg101207s15516709cog05032', '2022arxiv220207138v2', 'httpsdoiorg1048550arxiv220705608']",1
Simple Natural Language Processing Tools for Danish,['Leon Derczynski'],2019,http://arxiv.org/abs/1906.11608v2,"arXiv:1906.11608v2  [cs.CL]  26 Jul 2019SIMPLE NATURAL LANGUAGE PROCESSING TOOLS
FOR DANISH
Leon Derczynski
Department of Computer Science
ITU Copenhagen
Denmark DK2300
ld@itu.dk
July 29, 2019
ABSTRACT
This technical note describes a set of baseline tools for aut omatic processing of Danish text. The
tools are machine-learning based, using natural language p rocessing models trained over previously
annotated documents. They are maintained at ITU Copenhagen and will always be freely available.
Keywords natural language processing ·Danish·open access
1 Introduction
Danish, a language with few resources for automatic process ing, is spoken by six million people, largely concentrated
in the Scandinavian country of Denmark. At the NLP (natural l anguage processing) group at ITU Copenhagen, one
of our foci is Nordic and Danish languages. Thus, we aim to inc lude local languages in our NLP research whenever
possible, and to provide tools for others working on these la nguages. Despite a modest number of researcher in the
country, there has been a gap in usable Danish NLP tools that a re available to the wider community. As in every
time that new technology is not effectively mediated to thos e who can use it, this restriction stymies the impact and
development NLP in Denmark. To bridge this artiﬁcial lacuna , a basic set of easy-to-run utilities that build on existing
datasets and open tools has been developed at ITU, which this note introduces.
The tools are available at https://nlp.itu.dk/resources/ .
2 daner: Named Entity Recognition
Named entity recognition means ﬁnding words in text that ref er to things by a speciﬁc name. This could be e.g. using
“Nanna"" to refer to a speciﬁc individual, instead of “them"" o r “she"" or “the person""; or referring to “Moscow"" instead
of “the nearest city"". The important thing is that one mentio ns a name speciﬁcally. Named entity recognition (NER)
ﬁnds those names. In the case of daner , names of Locations, Organisation and Persons are tagged.
Thedaner tool wraps the CoreNLP [1] named entity recognition compone nt [2], using the DKIE data [3] developed
as part of the GATE tool [4], which is derived from the UD part o f the Copenhagen Dependency Treebank [5], itself
including data from the Danish Dependency Treebank [6]. Fur ther ad-hoc data is added as required, from newswire
and other sources. The data overall comprises 20K tokens fro m the CDT (largely 1990s newswire), 3K tokens from
non-newswire Danish, and 10K tokens from post-2015 newswir e. The mode performs best over Danish newswire
text. The data is annotated for three classes, person (PER), location (LOC), and organisation (ORG). Tags are in BIO
format.
The tool recognises names of people, of organisations, and o f locations. It performs automatic tokenization, and
outputs in slashed-tag format. For example:
En/O stor/O reform/O skal/O derfor/O blandt/O andet/O styr ke/O tilliden/O til/O politikere/O
og/O medier/O ,/O genopbygge/O tilliden/O til/O Skat/O og/ O mindske/O de/O økonomiske/O
forskelle/O i/O Danmark/B-LOC ./O
Here, “Danmark"" is tagged as a location. The Bindicates that “Danmark"" is the ﬁrst token in the location na me (the
beginning ).
Additional data is added to an internal repository that is al so used to train daner ; some of this data has copyright
restrictions, and so cannot be distributed, though the aggr egated statistical representation in daner ’s model is free
from that restriction, and so can be downloaded by anyone.
The NER model is conﬁgured to use contextual features, inclu ding n-grams up to 5-grams, and to use type sequences
and word shape features.
daner uses Brown clusters induced over large Danish-language cor pus. These are created using the Generalised
Brown formulation [7], which offers more ﬂexibility in use t han the classical version – speciﬁcally, one clustering run
can be used to generate clusterings of any size. For daner , 2500 clusters1are induced from a clustering with window
size of 5000, over a set of 134M Danish tokens. These 134M toke ns are taken from Danish Wikipedia and Danish
content from the Common Crawl corpus ﬁltered through the Fas tText language ID [9], both using June 2019 data. The
clusters are used inside the model, but also available separ ately athttp://itu.dk/~leod/dansk-brown.tar.bz2 .
3 dapipe: Tokenization, Part-of-speech tagging, and Depen dency Parsing
Another utility in the toolkit, dapipe , provides three functions: breaking text ﬁles into words an d sentences, ﬁnding
what class each word is through PoS tagging, and determining one part of the syntax that links a sentence’s words
together, through dependency parsing.
Deﬁning where words and sentences start and stop is very impo rtant if we are going to do NLP. These processes are
both called tokenization. dapipe uses the Universal dependencies method for tokenizing, bre aking text into sentences
and words.
The next step is to give a “part of speech"" to each word. This wo uld be something like a noun (substantiv), verb
(verbum), or preposition (præposition). This tells us the f unction each particular word has. dapipe works generally
well, though for social media text, I recommend structbilty ,2which is more resilient [10, 11] to the unusual words
and noise found in this colloquial setting [12].
Once the words and their classes are known, one may continue b y parsing the words in the sentence. The dapipe
tool uses the Universal Dependencies schema3for this, ﬁnding the main grammatical relations between eac h word to
construct a dependency tree that links every word in the sent ence together.
All these tasks are achieved by using UDPipe [13] based on the universal dependencies [14] data for Danish. Sample
output follows.
leon@blade:~/dapipe$ ./dapipe dktest.txt
...
# text = Derfor presser EU-siden hårdt på, for at amerikanern e ikke saboterer aftalen, der
blandt andet lader udenlandske observatører inspicere ira nske atomanlæg.
1 Derfor derfor ADV _ _ 2 advmod _ _
2 presser presse VERB _ Mood=Ind|Tense=Pres|VerbForm=Fin |Voice=Act 0 root _ _
3 EU-siden EU-sid NOUN _ Definite=Def|Gender=Com|Number= Sing 2 nsubj _ _
4 hårdt hårdt ADV _ Degree=Pos 2 advmod _ _
5 på på ADP _ AdpType=Prep 4 case _ SpaceAfter=No
6 ,,PUNCT _ _ 2 punct _ _
7 for for ADP _ AdpType=Prep 11 mark _ _
8 at at SCONJ _ _ 11 mark _ _
9 amerikanerne amerikaner NOUN _ Definite=Def|Gender=Com |Number=Plur 11 nsubj _ _
10 ikke ikke ADV _ _ 11 advmod _ _
11 saboterer sabotere VERB _ Mood=Ind|Tense=Pres|VerbFor m=Fin|Voice=Act 2 advcl _ _
1A size that works well for NER in English [8]
2Seehttps://github.com/bplank/bilstm-aux
3Seehttps://universaldependencies.org/introduction.html
2
12 aftalen aftale NOUN _ Definite=Def|Gender=Com|Number= Sing 11 obj _ SpaceAfter=No
13 ,,PUNCT _ _ 12 punct _ _
14 der der PRON _ PartType=Inf 17 nsubj _ _
15 blandt blandt ADP _ AdpType=Prep 17 advmod _ _
16 andet anden PRON _ Gender=Neut|Number=Sing|PronType=I nd 15 fixed _ _
17 lader lade VERB _ Mood=Ind|Tense=Pres|VerbForm=Fin|Vo ice=Act 12 acl:relcl _ _
18 udenlandske udenlandsk ADJ _ Degree=Pos|Number=Plur 19 amod _ _
19 observatører observatør NOUN _ Definite=Ind|Gender=Co m|Number=Plur 17 obj _ _
20 inspicere inspicere ADV _ Degree=Cmp 21 advmod _ _
21 iranske iransk ADJ _ Degree=Pos|Number=Plur 22 amod _ _
22 atomanlæg atomanlæg NOUN _ Definite=Ind|Gender=Neut|N umber=Plur 17 obj _ SpaceAfter=No
23 . . PUNCT _ _ 2 punct _ SpacesAfter=\n
4 Summary
This note describes a free toolkit for basic natural languag e processing. The two tools daner anddapipe are built on
freely-available resources and maintaned at ITU Copenhage n.
Feedback, requests, and so on can be addressed to the ITU NLP r esearch group: http://nlp.itu.dk/
References
[1] Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. The
Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd annual meeting of the Association
for Computational Linguistics , pages 55–60. Association for Computational Linguistics, 2014.
[2] Jenny Rose Finkel, Trond Grenager, and Christopher Mann ing. Incorporating non-local information into infor-
mation extraction systems by Gibbs sampling. In Proceedings of the 43rd annual meeting on association for
computational linguistics , pages 363–370. Association for Computational Linguistic s, 2005.
[3] Leon Derczynski and Kenneth S Bøgh. DKIE: Open source inf ormation extraction for Danish. In Proceedings
of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational
Linguistics , pages 61–64. Association for Computational Linguistics, 2014.
[4] Hamish Cunningham, Diana Maynard, Kalina Bontcheva, Va lentin Tablan, Niraj Aswani, Ian Roberts, Genevieve
Gorrell, Adam Funk, Angus Roberts, Danica Damljanovic, Leo n Derczynski, et al. Developing language pro-
cessing components with GATE version 8.0 . University of Shefﬁeld Department of Computer Science, 20 12.
[5] Anders Johannsen, Héctor Martínez Alonso, and Barbara P lank. Universal dependencies for danish. In Proc.
International Workshop on Treebanks and Linguistic Theori es, page 157, 2015.
[6] Matthias T Kromann, Line Mikkelsen, and Stine Kern Lynge . Danish dependency treebank. In Proc. Interna-
tional Workshop on Treebanks and Linguistic Theories , pages 217–220, 2003.
[7] Leon Derczynski and Sean Chester. Generalised brown clu stering and roll-up feature generation. In Proc. AAAI
Conference on Artiﬁcial Intelligence , 2016.
[8] Leon Derczynski, Sean Chester, and Kenneth S Bøgh. Tune y our brown clustering, please. In Proc. Interna-
tional Conference Recent Advances in Natural Language Proc essing, RANLP , volume 2015, pages 110–117.
Association for Computational Linguistics, 2015.
[9] Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tom as Mikolov. Bag of tricks for efﬁcient text classiﬁca-
tion. arXiv preprint arXiv:1607.01759 , 2016.
[10] Barbara Plank and Željko Agi ´c. Distant supervision from disparate sources for low-reso urce part-of-speech
tagging. In Proceedings of the 2018 Conference on Empirical Methods in N atural Language Processing , pages
614–620. Association for Computational Linguistics, 2018 .
[11] Barbara Plank, Anders Søgaard, and Yoav Goldberg. Mult ilingual Part-of-Speech Tagging with Bidirectional
Long Short-Term Memory Models and Auxiliary Loss. In ACL 2016, arXiv preprint arXiv:1604.05529 , 2016.
[12] Leon Derczynski, Diana Maynard, Giuseppe Rizzo, Marie ke Van Erp, Genevieve Gorrell, Raphaël Troncy, Jo-
hann Petrak, and Kalina Bontcheva. Analysis of named entity recognition and linking for tweets. Information
Processing & Management , 51(2):32–49, 2015.
[13] Milan Straka, Jan Hajic, and Jana Straková. UDPipe: Tra inable Pipeline for Processing CoNLL-U Files Perform-
ing Tokenization, Morphological Analysis, POS Tagging and Parsing. In Proc. LREC , 2016.
3
[14] Joakim Nivre, Marie-Catherine De Marneffe, Filip Gint er, Yoav Goldberg, Jan Hajic, Christopher D Manning,
Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveir a, et al. Universal dependencies v1: A multilin-
gual treebank collection. In Proceedings of the Tenth International Conference on Langu age Resources and
Evaluation (LREC 2016) , pages 1659–1666, 2016.
4","arxiv190611608v2  cscl  26 jul 2019simple natural language processing tools
for danish
leon derczynski
department of computer science
itu copenhagen
denmark dk2300
lditudk
july 29 2019
abstract
this technical note describes a set of baseline tools for aut omatic processing of danish text the
tools are machinelearning based using natural language p rocessing models trained over previously
annotated documents they are maintained at itu copenhagen and will always be freely available
keywords natural language processing danishopen access
1 introduction
danish a language with few resources for automatic process ing is spoken by six million people largely concentrated
in the scandinavian country of denmark at the nlp natural l anguage processing group at itu copenhagen one
of our foci is nordic and danish languages thus we aim to inc lude local languages in our nlp research whenever
possible and to provide tools for others working on these la nguages despite a modest number of researcher in the
country there has been a gap in usable danish nlp tools that a re available to the wider community as in every
time that new technology is not effectively mediated to thos e who can use it this restriction stymies the impact and
development nlp in denmark to bridge this articial lacuna  a basic set of easytorun utilities that build on existing
datasets and open tools has been developed at itu which this note introduces
the tools are available at httpsnlpitudkresources 
2 daner named entity recognition
named entity recognition means nding words in text that ref er to things by a specic name this could be eg using
nanna to refer to a specic individual instead of them o r she or the person or referring to moscow instead
of the nearest city the important thing is that one mentio ns a name specically named entity recognition ner
nds those names in the case of daner  names of locations organisation and persons are tagged
thedaner tool wraps the corenlp 1 named entity recognition compone nt 2 using the dkie data 3 developed
as part of the gate tool 4 which is derived from the ud part o f the copenhagen dependency treebank 5 itself
including data from the danish dependency treebank 6 fur ther adhoc data is added as required from newswire
and other sources the data overall comprises 20k tokens fro m the cdt largely 1990s newswire 3k tokens from
nonnewswire danish and 10k tokens from post2015 newswir e the mode performs best over danish newswire
text the data is annotated for three classes person per location loc and organisation org tags are in bio
format
the tool recognises names of people of organisations and o f locations it performs automatic tokenization and
outputs in slashedtag format for example
eno storo reformo skalo derforo blandto andeto styr keo tillideno tilo politikereo
ogo mediero o genopbyggeo tillideno tilo skato og o mindskeo deo konomiskeo
forskelleo io danmarkbloc o
here danmark is tagged as a location the bindicates that danmark is the rst token in the location na me the
beginning 
additional data is added to an internal repository that is al so used to train daner  some of this data has copyright
restrictions and so cannot be distributed though the aggr egated statistical representation in daner s model is free
from that restriction and so can be downloaded by anyone
the ner model is congured to use contextual features inclu ding ngrams up to 5grams and to use type sequences
and word shape features
daner uses brown clusters induced over large danishlanguage cor pus these are created using the generalised
brown formulation 7 which offers more exibility in use t han the classical version  specically one clustering run
can be used to generate clusterings of any size for daner  2500 clusters1are induced from a clustering with window
size of 5000 over a set of 134m danish tokens these 134m toke ns are taken from danish wikipedia and danish
content from the common crawl corpus ltered through the fas ttext language id 9 both using june 2019 data the
clusters are used inside the model but also available separ ately athttpitudkleoddanskbrowntarbz2 
3 dapipe tokenization partofspeech tagging and depen dency parsing
another utility in the toolkit dapipe  provides three functions breaking text les into words an d sentences nding
what class each word is through pos tagging and determining one part of the syntax that links a sentences words
together through dependency parsing
dening where words and sentences start and stop is very impo rtant if we are going to do nlp these processes are
both called tokenization dapipe uses the universal dependencies method for tokenizing bre aking text into sentences
and words
the next step is to give a part of speech to each word this wo uld be something like a noun substantiv verb
verbum or preposition prposition this tells us the f unction each particular word has dapipe works generally
well though for social media text i recommend structbilty 2which is more resilient 10 11 to the unusual words
and noise found in this colloquial setting 12
once the words and their classes are known one may continue b y parsing the words in the sentence the dapipe
tool uses the universal dependencies schema3for this nding the main grammatical relations between eac h word to
construct a dependency tree that links every word in the sent ence together
all these tasks are achieved by using udpipe 13 based on the universal dependencies 14 data for danish sample
output follows
leonbladedapipe dapipe dktesttxt

 text  derfor presser eusiden hrdt p for at amerikanern e ikke saboterer aftalen der
blandt andet lader udenlandske observatrer inspicere ira nske atomanlg
1 derfor derfor adv   2 advmod  
2 presser presse verb  moodindtensepresverbformfin voiceact 0 root  
3 eusiden eusid noun  definitedefgendercomnumber sing 2 nsubj  
4 hrdt hrdt adv  degreepos 2 advmod  
5 p p adp  adptypeprep 4 case  spaceafterno
6 punct   2 punct  
7 for for adp  adptypeprep 11 mark  
8 at at sconj   11 mark  
9 amerikanerne amerikaner noun  definitedefgendercom numberplur 11 nsubj  
10 ikke ikke adv   11 advmod  
11 saboterer sabotere verb  moodindtensepresverbfor mfinvoiceact 2 advcl  
1a size that works well for ner in english 8
2seehttpsgithubcombplankbilstmaux
3seehttpsuniversaldependenciesorgintroductionhtml
2
12 aftalen aftale noun  definitedefgendercomnumber sing 11 obj  spaceafterno
13 punct   12 punct  
14 der der pron  parttypeinf 17 nsubj  
15 blandt blandt adp  adptypeprep 17 advmod  
16 andet anden pron  genderneutnumbersingprontypei nd 15 fixed  
17 lader lade verb  moodindtensepresverbformfinvo iceact 12 aclrelcl  
18 udenlandske udenlandsk adj  degreeposnumberplur 19 amod  
19 observatrer observatr noun  definiteindgenderco mnumberplur 17 obj  
20 inspicere inspicere adv  degreecmp 21 advmod  
21 iranske iransk adj  degreeposnumberplur 22 amod  
22 atomanlg atomanlg noun  definiteindgenderneutn umberplur 17 obj  spaceafterno
23   punct   2 punct  spacesaftern
4 summary
this note describes a free toolkit for basic natural languag e processing the two tools daner anddapipe are built on
freelyavailable resources and maintaned at itu copenhage n
feedback requests and so on can be addressed to the itu nlp r esearch group httpnlpitudk
references
1 christopher manning mihai surdeanu john bauer jenny finkel steven bethard and david mcclosky the
stanford corenlp natural language processing toolkit in proceedings of 52nd annual meeting of the association
for computational linguistics  pages 5560 association for computational linguistics 2014
2 jenny rose finkel trond grenager and christopher mann ing incorporating nonlocal information into infor
mation extraction systems by gibbs sampling in proceedings of the 43rd annual meeting on association for
computational linguistics  pages 363370 association for computational linguistic s 2005
3 leon derczynski and kenneth s bgh dkie open source inf ormation extraction for danish in proceedings
of the demonstrations at the 14th conference of the european chapter of the association for computational
linguistics  pages 6164 association for computational linguistics 2014
4 hamish cunningham diana maynard kalina bontcheva va lentin tablan niraj aswani ian roberts genevieve
gorrell adam funk angus roberts danica damljanovic leo n derczynski et al developing language pro
cessing components with gate version 80  university of shefeld department of computer science 20 12
5 anders johannsen hctor martnez alonso and barbara p lank universal dependencies for danish in proc
international workshop on treebanks and linguistic theori es page 157 2015
6 matthias t kromann line mikkelsen and stine kern lynge  danish dependency treebank in proc interna
tional workshop on treebanks and linguistic theories  pages 217220 2003
7 leon derczynski and sean chester generalised brown clu stering and rollup feature generation in proc aaai
conference on articial intelligence  2016
8 leon derczynski sean chester and kenneth s bgh tune y our brown clustering please in proc interna
tional conference recent advances in natural language proc essing ranlp  volume 2015 pages 110117
association for computational linguistics 2015
9 armand joulin edouard grave piotr bojanowski and tom as mikolov bag of tricks for efcient text classica
tion arxiv preprint arxiv160701759  2016
10 barbara plank and eljko agi c distant supervision from disparate sources for lowreso urce partofspeech
tagging in proceedings of the 2018 conference on empirical methods in n atural language processing  pages
614620 association for computational linguistics 2018 
11 barbara plank anders sgaard and yoav goldberg mult ilingual partofspeech tagging with bidirectional
long shortterm memory models and auxiliary loss in acl 2016 arxiv preprint arxiv160405529  2016
12 leon derczynski diana maynard giuseppe rizzo marie ke van erp genevieve gorrell raphal troncy jo
hann petrak and kalina bontcheva analysis of named entity recognition and linking for tweets information
processing  management  5123249 2015
13 milan straka jan hajic and jana strakov udpipe tra inable pipeline for processing conllu files perform
ing tokenization morphological analysis pos tagging and parsing in proc lrec  2016
3
14 joakim nivre mariecatherine de marneffe filip gint er yoav goldberg jan hajic christopher d manning
ryan mcdonald slav petrov sampo pyysalo natalia silveir a et al universal dependencies v1 a multilin
gual treebank collection in proceedings of the tenth international conference on langu age resources and
evaluation lrec 2016  pages 16591666 2016
4","['athttpitudkleoddanskbrowntarbz2', '3seehttpsuniversaldependenciesorgintroductionhtml', 'genderneutnumbersingprontypei', 'arxiv190611608v2', '2seehttpsgithubcombplankbilstmaux', 'degreeposnumberplur', 'moodindtensepresverbformfin', 'httpsnlpitudkresources', 'definiteindgenderneutn', 'definitedefgendercomnumber']",0
Natural Language Generation,"['Emiel van Miltenburg', 'Chenghua Lin']",2025,http://arxiv.org/abs/2503.16728v2,"Natural Language Generation
Emiel van Miltenburg,aand Chenghua Linb
aTilburg University, Department of Cognition and Communication, Tilburg, The Netherlands
bUniversity of Manchester, Department of Computer Science, Manchester, UK
1 Introduction
The term Natural Language Generation (NLG), in its broadest def-
inition, refers to the study of systems that verbalize some form
of information through natural language. That information could
be stored in a large database or knowledge graph (in data-to-text
applications), but NLG researchers may also study summarisation
(text-to-text ) or image captioning ( image-to-text ), for example. As a
subfield of Natural Language Processing, NLG is closely related to
other sub-disciplines such as Machine Translation (MT) and Dialog
Systems. Some NLG researchers exclude MT from their definition
of the field, since there is no content selection involved where the
system has to determine what to say . Conversely, dialog systems
do not typically fall under the header of Natural Language Genera-
tion since NLG is just one component of dialog systems (the others
being Natural Language Understanding and Dialog Management).
However, with the rise of Large Language Models (LLMs), di ffer-
ent subfields of Natural Language Processing have converged on
similar methodologies for the production of natural language and
the evaluation of automatically generated text.
1.1 Relation to linguistics
Historically, NLG research has had close ties with pragmatics and
psycholinguistics. The reason for this is that automatically gen-
erated text should generally be as fluent and natural as possible.
However, there are often many di fferent ways to communicate the
same message. How to best formulate that message depends on the
context.1By studying human language production, we can better
understand how people formulate their utterances in di fferent situ-
ations. Psycholinguistic models of speech production (e.g. Levelt
1989) also have clear parallels with classical NLG pipelines (see
§3.1). All these models can be divided into two stages: conceptu-
alisation ( what to say ) and formulation ( how to say it ).
2 Applications
NLG technology promises to automate or streamline writing tasks
in many di fferent domains. We discuss three examples below.
2.1 NLG and business
The commercial potential of NLG has long been recognized; the
first company to commercialize NLG was founded in 1990 and
several di fferent companies have followed in their footsteps (Dale,
2020). Robert Dale marks 2012 as the year when NLG entered the
mainstream media conscious, with the publication of a Wired arti-
cle on automated journalism. Following the release of ChatGPT,
a full decade later (November 30, 2022), we have now seen how
automatic text generation has become fully mainstream, with dif-
1We can perhaps best see this in the literature on referring expression generation,
see Krahmer & van Deemter (2012).ferent companies o ffering the general public paid subscriptions to
Large Language Models via user-friendly interfaces.
NLG techniques have traditionally been used to convert tabular
data into text. For example, generating financial reports,2or gener-
ating product titles and descriptions based on product specifications
(Mathur et al., 2017; Zou et al., 2023). Following the rise of Chat-
GPT, we are now seeing an explosion of interest to use language
models for all sorts of purposes, including content generation (writ-
ing informative texts), and the generation of email responses (see
Tafesse & Wien 2024; Tafesse & Wood 2024 for more discussion).
2.2 NLG and journalism
Like with business applications, NLG techniques have traditionally
been used in journalism to produce data-driven articles to report on
topics such as weather reports, sports matches, earthquakes, and
elections. These articles are relatively formulaic, making it easier
to develop templates where relevant values (such as the magnitude
of an earthquake) can be inserted (Gatt & Krahmer, 2018). Nowa-
days, journalists use generative AI throughout the reporting pro-
cess (news gathering, news production, news verification, distribu-
tion, and moderation) for a much wider array of articles (Cools
& Diakopoulos, 2024). Still, classical rule- and template-based
approaches remain the most reliable solution for standalone text
generation, since they do not su ffer from hallucination (see §5.1).
Moreover, as Reiter (2025, Chapter 6) notes, rule-based systems
may be easier to modify (e.g. make small changes to the output)
and maintain.
2.3 NLG in a medical context
There is a long history of Natural Language Generation in health-
care (see Cawsey et al. 1997 for an early survey). Applications
range from medical report generation (presenting relevant clin-
ical data to di fferent audiences, e.g. Gatt et al. 2009) to clini-
cal note generation (summarising doctor-patient interactions; e.g.
Ben Abacha et al. 2023) and personalised decision support tools
(e.g. Hommes et al. 2019). Challenges in the medical field in-
clude working with potentially unreliable sensor data (van Deemter
& Reiter, 2018), and involving di fferent stakeholders (doctors, pa-
tients, nurses) who often di ffer in background knowledge, reading
level, technical ability, and socio-economic status. Medical NLG
research is usually carried out in interdisciplinary teams, with ex-
perts not only assessing the quality of the output, but also looking
at the potentially harmful impact that systems may have on their
users (e.g. Balloccu et al. 2024).
2Ehud Reiter (2018) notes that all major NLG companies are involved in financial
reporting, because the sector is large and use cases are similar between di ffer-
ent organisations, making it easier to capitalise on NLG technology than in areas
where more customisation is needed.
1arXiv:2503.16728v2  [cs.CL]  25 Mar 2025
2 Natural Language Generation
3 Approaches
This section provides a brief overview of the di fferent approaches
to Natural Language Generation, focusing on the evolution from
the classical NLG pipeline, through end-to-end approaches, to the
use of (more general) large language models. (For an overview of
all NLG approaches before LLMs, see Gatt & Krahmer 2018).
3.1 The classical NLG pipeline
In the classical NLG pipeline, text generation proceeds in di fferent
stages. Here are the steps proposed by Reiter & Dale (2000):
•Content determination : deciding what information should be
communicated.
•Document structuring : deciding how to group and order dif-
ferent chunks of information.
•Lexicalisation : deciding what words, phrases, or syntactic con-
structions to use.
•Referring expression generation : deciding what words or
phrases should be used for di fferent named entities.
•Aggregation : deciding how to map the di fferent information
chunks to sentences and paragraphs.
•Realisation : converting the abstract representation of the text-
to-be-generated into a real text.
These steps can be handled by di fferent modules that may either
use (often hand-written) rules, Machine Learning, or both. The
initial steps of the pipeline are context-dependent, but the final stage
(realisation) is universal. As such, di fferent projects may re-use the
same realiser .3
3.2 End-to-end generation
End-to-end generation drastically simplifies the problem of nat-
ural language generation by directly mapping data to text. All
steps are implicitly handled by the same model that is developed
using a data-driven approach (see Castro Ferreira et al. 2019 for
a discussion). Popular challenges that can be resolved through
this approach are the E2E dataset (Novikova et al., 2017) and the
WebNLG challenge (e.g. Cripwell et al. 2023).4Taking WebNLG
as an example, the goal is to render a set of RDF triples in natural
language. Recent years have seen the focus shift away from En-
glish (as this problem has more or less been solved) and towards
low-resource languages.
3.3 Using Large Language Models
Large Language Models (LLMs), such as ChatGPT (Ouyang et
al., 2022) and LLaMA (Touvron et al., 2023), typically adopt
transformer-based architectures (Vaswani et al., 2017), which rely
on self-attention mechanisms to capture long-range contextual de-
pendencies in text. The training of LLMs generally follows a two-
stage training pipeline. The first stage, known as pre-training , is an
unsupervised process in which models are trained on vast amounts
of unlabelled textual data containing billions or even trillions of
tokens from diverse sources such as web pages, books, and ency-
clopaedias. This stage allows LLMs to acquire and encode gen-
eral linguistic and world knowledge. The second stage, known as
3Among existing realisers, S imple NLG (Gatt & Reiter, 2009) is a popular choice
that has been translated into several di fferent languages.
4Although note that these challenges do not require any signal analysis or content
determination.Supervised Fine-Tuning (SFT), involves further training the model
on labelled datasets containing explicit instruction-output pairs.
SFT aims to enhance the model’s ability to understand and follow
human-provided instructions, ensuring its responses are more rele-
vant, specific, and aligned with user expectations. Techniques such
as reinforcement learning from human feedback (RLHF) and direct
preference optimisation (DPO) can further refine the model’s out-
puts, improving its safety, helpfulness, and alignment with human
preferences (Xu et al., 2024).
Once trained, LLMs generate text through prompting, where
users provide textual inputs that may include explicit instructions,
context, or examples to guide the model’s responses. Prompting
enables LLMs to perform a wide range of tasks, such as sum-
marisation, translation, question answering, and creative writing,
without requiring additional task-specific fine-tuning. Advanced
prompting techniques, such as chain-of-thought prompting that in-
troduces intermediate reasoning steps within the prompt, can fur-
ther enhance the model’s performance on complex reasoning and
generation tasks (see Liu et al. (2023) for a survey).
4 Evaluation
Evaluating the quality of automatically generated text remains a
fundamental challenge in natural language processing (NLP). As
text generation models continue to improve, the di fficulty of eval-
uating their outputs has also increased. In many cases, evaluating
generated text is now as challenging as generating it. This di fficulty
arises due to the inherent variability in natural language—multiple
outputs can be equally valid despite di ffering in lexical choice,
structure, or even semantics. For instance, in machine transla-
tion, multiple translations of a given sentence may convey the same
meaning while varying in word choice and phrasing. The challenge
becomes even more pronounced in open-domain dialogue genera-
tion, where a single input may lead to many plausible responses
with di fferent semantics, i.e. the “one-to-many” problem (Zhao et
al., 2023, 2024). Similarly, summarisation often involves subjec-
tivity, as multiple summaries can be correct depending on the focus
and interpretation of the content. Additionally, certain text gen-
eration tasks, such as humour or metaphor, require evaluators to
account for demographic and cultural di fferences, further compli-
cating the assessment process (Loakman et al., 2023; Wang et al.,
2024). We can rougly distinguish two kinds of evaluation: using
human evaluation studies, or through automatic metrics (see Ce-
likyilmaz et al. 2020 for a survey).
4.1 Human evaluation
In human evaluation studies, participants answer questions about
one or more texts (van der Lee et al., 2021). A common approach
is to rate the quality of generated texts on a five-point scale (Amidei
et al., 2019). There is a wide array of di fferent dimensions that may
be relevant to assess the quality of a text, for example: fluency, cor-
rectness, completeness , and appropriateness (see Belz et al. 2020
for a general taxonomy). For quality dimensions that relate to in-
trinsic properties of the texts, human evaluation studies are similar
to traditional experiments that one may also encounter in other sub-
fields of linguistics. For quality dimensions that are more closely
related to the use of an NLG system in context, techniques from the
field of human-computer interaction (such as contextual interviews,
Natural Language Generation 3
think-aloud tasks, or usability surveys) may be used. Finally, au-
thors may also choose to carry out an error analysis , where authors
identify and categorise instances where something went wrong in
the generated text (van Miltenburg et al., 2021).
4.2 Automatic evaluation
While human evaluation remains the gold standard in NLG re-
search, it can be costly and time-consuming. Therefore, di fferent
researchers have developed di fferent ways to assess the output of
NLG systems along di fferent dimensions (e.g. fluency, grammati-
cality, correctness ). Celikyilmaz et al. (2020) distinguish two kinds
of automatic evaluation:
1.Untrained automatic metrics compare generated texts with a
set of reference texts, through di fferent similarity measures.
2.Machine-learned metrics are based on machine-learned mod-
els, and serve as automatic equivalents to human judges.
Recent years have seen rapid developments in the second cate-
gory, with the LLM-as-a-judge paradigm quickly gaining popular-
ity after showing impressive results on di fferent benchmarks (e.g.
Zheng et al. 2023). For an overview of currently used tasks and
evaluation measures, readers are referred to the recurring GEM
shared task (e.g. Mille et al. 2024), which is the most comprehen-
sive community e ffort to assess NLG models on a wide array of
different tasks.5
5 Challenges
5.1 Factuality versus fluency?
There is an interesting tension between factuality and fluency of
automatically generated texts. Generally speaking, traditional rule-
based approaches result in texts that are factually correct but not
always fluent, while neural approaches tend to produce texts that
are fluent but not always factually correct.6This is related to the
problem of hallucination (see Huang et al. 2025 for a survey). It is
currently unclear how to guarantee that NLG output is both fluent
and100% factual.
5.2 Long Text Generation
Traditionally, most text generation tasks have focused on produc-
ing relatively short outputs, such as weather reports or summaries
that span a few dozen to a few hundred words. However, there is
growing interest in developing models capable of generating much
longer texts, often extending to thousands of words. For example,
recent e fforts such as AI Scientist (Lu et al., 2024) have demon-
strated the ability to generate entire scientific papers. By incorpo-
rating structured scientific knowledge (e.g., experimental results),
this framework can draft papers that adhere to domain-specific re-
quirements, integrating relevant citations and conforming to disci-
plinary norms. Similarly, LongWriter (Bai et al., 2024) addresses
long-text generation across various domains, including academic
5For an indication of the popularity of current metrics, see Schmidtova et al. 2024.
But note that single metrics are always reductive; no individual metric can fully
capture all di fferent quality dimensions.
6Though see van Deemter & Reiter 2018, where the authors show how all types
of NLG systems may deviate from the truth in their outputs. To some extent this
is unavoidable in situations where the system also has to carry out signal analysis
(i.e. interpreting the input, with a risk of misinterpretation) and content selection
(meaning that the system cannot provide ‘the whole truth’).publications and monographs. It employs hierarchical attention
mechanisms and fine-tuning strategies to maintain thematic consis-
tency and produce structured arguments across extended outputs.
Despite notable advancements, achieving coherence and structure
in long-form content generation remains a significant challenge.
This challenge stems from key issues such as the scarcity of high-
quality long-form text data in the supervised fine-tuning phase,
which limits the model’s ability to learn e ffective writing patterns.
Moreover, the alignment phase based on RLHF or DPO introduces
complexities in reward modeling and evaluation, where assessing
attributes like narrative flow, logical consistency, and thematic co-
herence becomes increasingly di fficult as the text lengthens.
5.3 Evaluation
NLG evaluation is a hotly debated topic. Earlier studies found that
there is a widespread confusion about the terminology that is used
to refer to di fferent quality dimensions (Howcroft et al., 2020). Hu-
man evaluations may always not be reproducible (Belz et al., 2023),
which may be partly due to past reporting standards (Howcroft et
al., 2020; Shimorina & Belz, 2022; Gehrmann et al., 2023), but we
also have to consider the inherent di fficulty of quantifying the ob-
jective quality of a text (if such a thing even exists). More research
is needed to deepen our understanding of (the interaction between)
different quality dimensions that are involved in the process of text
appreciation (van Miltenburg et al., 2020).
5.4 Reproducibility
An open challenge in NLG research is how to ensure reproducible
results. In other words: being able to obtain the same results as
those reported in earlier studies. Although this holds for both the
output generated by NLG software and the results of the evaluation
procedure, most attention has gone to the repeatability of human
evaluation studies (Belz et al., 2023).
5.5 Ethics: the social impact of NLG
As NLG technology is both increasingly powerful andincreasingly
widespread, we also have to contend with the real-world implica-
tions of our work. A recent survey (van Miltenburg, 2025) provides
an overview of dual use issues that can arise from our research, and
Solaiman et al. (2024) o ffer a broad taxonomy of areas that may
be impacted by generative AI systems. Handling these issues re-
quires continuous e ffort from both individual researchers and the
community as a whole.
6 Conclusion
This article provided an overview of the field of Natural Language
Generation. Due to space constraints, we have focused on the ap-
plication side of the field (i.e. building and evaluating systems that
convert data to text). Readers who would like to learn more about
this topic can read the survey by Gatt & Krahmer (2018) or the
recent book by Reiter (2025).
NLG researchers have always found inspiration in the way hu-
mans produce language. Although we have not focused on this
topic, we encourage readers to also explore the more cognitively
oriented work that studies human language production in context,
and work that compares human and automatic language production.
4 Natural Language Generation
Acknowledgments
See Also: article title article title
Bibliography
Amidei, J., Piwek, P ., & Willis, A. (2019, October–November). The use
of rating and Likert scales in natural language generation human
evaluation tasks: A review and some recommendations. In K. van
Deemter, C. Lin, & H. Takamura (Eds.), Proceedings of the 12th
international conference on natural language generation (pp. 397–
402). Tokyo, Japan: Association for Computational Linguistics.
Retrieved from https://aclanthology.org/W19-8648/ doi: 10.18653/
v1/W19-8648.
Bai, Y ., Zhang, J., Lv, X., Zheng, L., Zhu, S., Hou, L., . . . Li, J. (2024).
Longwriter: Unleashing 10,000+ word generation from long con-
text llms. Retrieved from https://arxiv.org/abs/2408.07055
Balloccu, S., Reiter, E., Li, K. J.-H., Sargsyan, R., Kumar, V., Re-
forgiato, D., . . . Dusek, O. (2024, November). Ask the ex-
perts: sourcing a high-quality nutrition counseling dataset through
human-AI collaboration. In Y . Al-Onaizan, M. Bansal, & Y.-
N. Chen (Eds.), Findings of the association for computational
linguistics: Emnlp 2024 (pp. 11519–11545). Miami, Florida,
USA: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2024.findings-emnlp.674/ doi: 10.18653/
v1/2024.findings-emnlp.674.
Belz, A., Mille, S., & Howcroft, D. M. (2020, December). Disen-
tangling the properties of human evaluation methods: A clas-
sification system to support comparability, meta-evaluation and
reproducibility testing. In B. Davis, Y . Graham, J. Kelleher, &
Y . Sripada (Eds.), Proceedings of the 13th international confer-
ence on natural language generation (pp. 183–194). Dublin, Ire-
land: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2020.inlg-1.24/ doi: 10.18653/v1/2020
.inlg-1.24.
Belz, A., Thomson, C., Reiter, E., & Mille, S. (2023, July). Non-
repeatable experiments and non-reproducible results: The re-
producibility crisis in human evaluation in NLP. In A. Rogers,
J. Boyd-Graber, & N. Okazaki (Eds.), Findings of the associ-
ation for computational linguistics: Acl 2023 (pp. 3676–3687).
Toronto, Canada: Association for Computational Linguistics. Re-
trieved from https://aclanthology.org/2023.findings-acl.226/ doi:
10.18653/v1/2023.findings-acl.226.
Ben Abacha, A., Yim, W.-w., Michalopoulos, G., & Lin, T. (2023, July).
An investigation of evaluation methods in automatic medical note
generation. In A. Rogers, J. Boyd-Graber, & N. Okazaki (Eds.),
Findings of the association for computational linguistics: Acl 2023
(pp. 2575–2588). Toronto, Canada: Association for Computational
Linguistics. Retrieved from https://aclanthology.org/2023.findings-
acl.161/ doi: 10.18653/v1/2023.findings-acl.161.
Castro Ferreira, T., van der Lee, C., van Miltenburg, E., & Krah-
mer, E. (2019, November). Neural data-to-text generation: A
comparison between pipeline and end-to-end architectures. In
K. Inui, J. Jiang, V. Ng, & X. Wan (Eds.), Proceedings of the
2019 conference on empirical methods in natural language pro-
cessing and the 9th international joint conference on natural lan-
guage processing (emnlp-ijcnlp) (pp. 552–562). Hong Kong,
China: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/D19-1052/ doi: 10.18653/v1/D19-1052.
Cawsey, A. J., Webber, B. L., & Jones, R. B. (1997, 11). Nat-
ural language generation in health care. Journal of the Amer-
ican Medical Informatics Association ,4(6), 473-482. Retrieved
from https://doi.org/10.1136/jamia.1997.0040473 doi: 10.1136/
jamia.1997.0040473.
Celikyilmaz, A., Clark, E., & Gao, J. (2020). Evaluation of text gen-
eration: A survey. CoRR ,abs/2006.14799 (), . Retrieved from
https://arxiv.org/abs/2006.14799
Cools, H., & Diakopoulos, N. (2024). Uses of generative ai in
the newsroom: Mapping journalists’ perceptions of perils and
possibilities. Journalism Practice ,0(0), 1–19. Retrieved fromhttps://doi.org/10.1080/17512786.2024.2394558 doi: 10.1080/
17512786.2024.2394558.
Cripwell, L., Belz, A., Gardent, C., Gatt, A., Borg, C., Borg, M., . . .
Soto Martinez, W. (2023, September). The 2023 WebNLG shared
task on low resource languages. overview and evaluation results
(WebNLG 2023). In A. Gatt et al. (Eds.), Proceedings of the work-
shop on multimodal, multilingual natural language generation and
multilingual webnlg challenge (mm-nlg 2023) (pp. 55–66). Prague,
Czech Republic: Association for Computational Linguistics. Re-
trieved from https://aclanthology.org/2023.mmnlg-1.6/
Dale, R. (2020). Natural language generation: The commercial state
of the art in 2020. Natural Language Engineering ,26(4), 481–487.
doi: 10.1017/S135132492000025X.
Gatt, A., & Krahmer, E. (2018, January). Survey of the state of the
art in natural language generation: core tasks, applications and
evaluation. J. Artif. Int. Res. ,61(1), 65–170.
Gatt, A., Portet, F ., Reiter, E., Hunter, J., Mahamood, S., Moncur, W.,
& Sripada, S. (2009). From data to text in the neonatal intensive
care unit: Using nlg technology for decision support and informa-
tion management. Ai Communications ,22(3), 153–186.
Gatt, A., & Reiter, E. (2009, March). SimpleNLG: A realisa-
tion engine for practical applications. In E. Krahmer & M. The-
une (Eds.), Proceedings of the 12th European workshop on nat-
ural language generation (ENLG 2009) (pp. 90–93). Athens,
Greece: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/W09-0613/
Gehrmann, S., Clark, E., & Sellam, T. (2023, May). Repairing the
cracked foundation: A survey of obstacles in evaluation practices
for generated text. Journal of Artificial Intelligence Research ,77(),
103–166. Retrieved from http://dx.doi.org/10.1613/jair.1.13715
doi: 10.1613/jair.1.13715.
Hommes, S., van der Lee, C., Clouth, F ., Vermunt, J., Verbeek, X.,
& Krahmer, E. (2019, October–November). A personalized data-
to-text support tool for cancer patients. In K. van Deemter, C. Lin,
& H. Takamura (Eds.), Proceedings of the 12th international con-
ference on natural language generation (pp. 443–452). Tokyo,
Japan: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/W19-8656/ doi: 10.18653/v1/W19-8656.
Howcroft, D. M., Belz, A., Clinciu, M.-A., Gkatzia, D., Hasan, S. A.,
Mahamood, S., . . . Rieser, V. (2020, December). Twenty years
of confusion in human evaluation: NLG needs evaluation sheets
and standardised definitions. In B. Davis, Y . Graham, J. Kelleher,
& Y . Sripada (Eds.), Proceedings of the 13th international confer-
ence on natural language generation (pp. 169–182). Dublin, Ire-
land: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2020.inlg-1.23/ doi: 10.18653/v1/2020
.inlg-1.23.
Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., . . .
Liu, T. (2025, January). A survey on hallucination in large
language models: Principles, taxonomy, challenges, and open
questions. ACM Trans. Inf. Syst. ,43(2), . Retrieved from
https://doi.org/10.1145/3703155 doi: 10.1145/3703155.
Krahmer, E., & van Deemter, K. (2012, March). Computational gen-
eration of referring expressions: A survey. Computational Linguis-
tics,38(1), 173–218. Retrieved from https://aclanthology.org/J12-
1006/ doi: 10.1162/COLI a00088.
Levelt, W. J. M. (1989). Speaking: From inten-
tion to articulation . The MIT Press. Retrieved from
http://dx.doi.org/10.7551/mitpress/6393.001.0001 doi:
10.7551/mitpress/6393.001.0001.
Liu, P ., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023).
Pre-train, prompt, and predict: A systematic survey of prompting
methods in natural language processing. ACM Comput. Surv. ,
55(9), . Retrieved from https://doi.org/10.1145/3560815 doi:
10.1145/3560815.
Loakman, T., Maladry, A., & Lin, C. (2023). The iron(ic) melting pot:
Reviewing human evaluation in humour, irony and sarcasm gener-
ation. In H. Bouamor, J. Pino, & K. Bali (Eds.), Findings of the asso-
ciation for computational linguistics: Emnlp 2023 (pp. 6676–6689).
Retrieved from https://aclanthology.org/2023.findings-emnlp.444/
doi: 10.18653/v1/2023.findings-emnlp.444.
Lu, C., Lu, C., Lange, R. T., Foerster, J., Clune, J., & Ha, D. (2024).
The ai scientist: Towards fully automated open-ended scientific
Natural Language Generation 5
discovery. Retrieved from https://arxiv.org/abs/2408.06292
Mathur, P ., Ueffing, N., & Leusch, G. (2017, September). Gen-
erating titles for millions of browse pages on an e-commerce
site. In J. M. Alonso, A. Bugar ´ın, & E. Reiter (Eds.), Pro-
ceedings of the 10th international conference on natural lan-
guage generation (pp. 158–167). Santiago de Compostela,
Spain: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/W17-3525/ doi: 10.18653/v1/W17-3525.
Mille, S., Sedoc, J., Liu, Y ., Clark, E., Axelsson, A. J., Clinciu,
M. A., . . . Zhang, L. (2024, September). The 2024 GEM shared
task on multilingual data-to-text generation and summarization:
Overview and preliminary results. In S. Mille & M.-A. Clinciu
(Eds.), Proceedings of the 17th international natural language gen-
eration conference: Generation challenges (pp. 17–38). Tokyo,
Japan: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2024.inlg-genchal.2/
Novikova, J., Du ˇsek, O., & Rieser, V. (2017, August). The E2E
dataset: New challenges for end-to-end generation. In K. Joki-
nen, M. Stede, D. DeVault, & A. Louis (Eds.), Proceedings of the
18th annual SIGdial meeting on discourse and dialogue (pp. 201–
206). Saarbr ¨ucken, Germany: Association for Computational Lin-
guistics. Retrieved from https://aclanthology.org/W17-5525/ doi:
10.18653/v1/W17-5525.
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin,
P ., . . . Lowe, R. (2022). Training language models to follow in-
structions with human feedback. In Proceedings of the 36th in-
ternational conference on neural information processing systems.
Red Hook, NY , USA: Curran Associates Inc.
Reiter, E. (2018). Where is nlg most successful
commercially? (Published on Ehud Reiter’s blog:
https://ehudreiter.com/2018/10/30/most-successful-commercial-nlg/ )
Reiter, E. (2025). Natural language generation . Springer Nature
Switzerland. Retrieved from http://dx.doi.org/10.1007/978-3-031-
68582-8 doi: 10.1007/978-3-031-68582-8.
Reiter, E., & Dale, R. (2000). Building natural language generation
systems . Cambridge University Press.
Schmidtova, P ., Mahamood, S., Balloccu, S., Dusek, O., Gatt,
A., Gkatzia, D., . . . Sivaprasad, A. (2024, September). Au-
tomatic metrics in natural language generation: A survey of
current evaluation practices. In S. Mahamood, N. L. Minh,
& D. Ippolito (Eds.), Proceedings of the 17th international nat-
ural language generation conference (pp. 557–583). Tokyo,
Japan: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2024.inlg-main.44/
Shimorina, A., & Belz, A. (2022, May). The human evaluation
datasheet: A template for recording details of human evalua-
tion experiments in NLP. In A. Belz, M. Popovi ´c, E. Reiter, &
A. Shimorina (Eds.), Proceedings of the 2nd workshop on hu-
man evaluation of nlp systems (humeval) (pp. 54–75). Dublin,
Ireland: Association for Computational Linguistics. Retrieved
from https://aclanthology.org/2022.humeval-1.6/ doi: 10.18653/
v1/2022.humeval-1.6.
Solaiman, I., Talat, Z., Agnew, W., Ahmad, L., Baker, D., Blodgett,
S. L., . . . Subramonian, A. (2024). Evaluating the social impact
of generative ai systems in systems and society. Retrieved from
https://arxiv.org/abs/2306.05949 (Forthcoming in Hacker, Engel,
Hammer, Mittelstadt (eds), Oxford Handbook on the Foundations
and Regulation of Generative AI. Oxford University Press)
Tafesse, W., & Wien, A. (2024). Chatgpt’s applications in marketing:
a topic modeling approach. Marketing Intelligence & Planning ,
42(4), 666–683.
Tafesse, W., & Wood, B. (2024). Hey chatgpt: an examination of
chatgpt prompts in marketing. Journal of Marketing Analytics ,
12(4), 790-805. Retrieved from http://dx.doi.org/10.1057/s41270-
023-00284-w doi: 10.1057/s41270-023-00284-w.
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-
A., Lacroix, T., . . . Lample, G. (2023). Llama: Open
and efficient foundation language models. Retrieved from
https://arxiv.org/abs/2302.13971
van der Lee, C., Gatt, A., van Miltenburg, E., & Krahmer,
E. (2021). Human evaluation of automatically generated
text: Current trends and best practice guidelines. Com-puter Speech & Language ,67(), 101151. Retrieved from
https://www.sciencedirect.com/science/article/pii/S088523082030084X
doi: https://doi.org/10.1016/j.csl.2020.101151.
van Deemter, K., & Reiter, E. (2018, 11). 420lying
and computational linguistics. In The oxford hand-
book of lying. Oxford University Press. Retrieved from
https://doi.org/10.1093/oxfordhb/9780198736578.013.32 doi:
10.1093/oxfordhb/9780198736578.013.32.
van Miltenburg, E. (2025). Dual use issues in the
field of natural language generation. Retrieved from
https://arxiv.org/abs/2501.06636
van Miltenburg, E., Clinciu, M., Du ˇsek, O., Gkatzia, D., Inglis, S.,
Lepp ¨anen, L., . . . Wen, L. (2021, August). Underreporting of er-
rors in NLG output, and what to do about it. In A. Belz, A. Fan,
E. Reiter, & Y . Sripada (Eds.), Proceedings of the 14th interna-
tional conference on natural language generation (pp. 140–153).
Aberdeen, Scotland, UK: Association for Computational Linguis-
tics. Retrieved from https://aclanthology.org/2021.inlg-1.14/ doi:
10.18653/v1/2021.inlg-1.14.
van Miltenburg, E., Lu, W.-T., Krahmer, E., Gatt, A., Chen, G., Li,
L., & van Deemter, K. (2020, December). Gradations of error
severity in automatic image descriptions. In B. Davis, Y . Gra-
ham, J. Kelleher, & Y . Sripada (Eds.), Proceedings of the 13th
international conference on natural language generation (pp. 398–
411). Dublin, Ireland: Association for Computational Linguis-
tics. Retrieved from https://aclanthology.org/2020.inlg-1.45/ doi:
10.18653/v1/2020.inlg-1.45.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L.,
Gomez, A. N., . . . Polosukhin, I. (2017). Attention is all you need.
In I. Guyon et al. (Eds.), Advances in neural information process-
ing systems (Vol. 30). Curran Associates, Inc. Retrieved from
https://proceedings.neurips.cc/paper files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-
Paper.pdf
Wang, S., Zhang, G., Wu, H., Loakman, T., Huang, W., & Lin,
C. (2024, November). MMTE: Corpus and metrics for eval-
uating machine translation quality of metaphorical language.
In Y . Al-Onaizan, M. Bansal, & Y.-N. Chen (Eds.), Proceed-
ings of the 2024 conference on empirical methods in natu-
ral language processing (pp. 11343–11358). Miami, Florida,
USA: Association for Computational Linguistics. Retrieved from
https://aclanthology.org/2024.emnlp-main.634/ doi: 10.18653/v1/
2024.emnlp-main.634.
Xu, S., Fu, W., Gao, J., Y e, W., Liu, W., Mei, Z., . . . Wu, Y . (2024).
Is dpo superior to ppo for llm alignment? a comprehensive study.
InProceedings of the 41st international conference on machine
learning.
Zhao, K., Y ang, B., Lin, C., Rong, W., Villavicencio, A., & Cui, X.
(2023). Evaluating open-domain dialogues in latent space with
next sentence prediction and mutual information. In Proceedings
of the 61st annual meeting of the association for computational
linguistics (volume 1: Long papers) (pp. 562–574). Retrieved from
https://aclanthology.org/2023.acl-long.33/ doi: 10.18653/v1/2023
.acl-long.33.
Zhao, K., Y ang, B., Tang, C., Lin, C., & Zhan, L. (2024). SLIDE: A
framework integrating small and large language models for open-
domain dialogues evaluation. In L.-W. Ku, A. Martins, & V. Sriku-
mar (Eds.), Findings of the association for computational linguis-
tics: Acl 2024 (pp. 15421–15435). doi: 10.18653/v1/2024.findings
-acl.911.
Zheng, L., Chiang, W.-L., Sheng, Y ., Zhuang, S., Wu, Z., Zhuang,
Y ., . . . Stoica, I. (2023). Judging llm-as-a-judge with mt-bench and
chatbot arena. In Proceedings of the 37th international conference
on neural information processing systems. Red Hook, NY , USA:
Curran Associates Inc.
Zou, Y ., Zhang, X., Zhou, J., Diao, S., Chen, J., Ding, Z., . . . et al.
(2023). Automatic product copywriting for e-commerce. AI Maga-
zine,44(1), 41–53.","natural language generation
emiel van miltenburgaand chenghua linb
atilburg university department of cognition and communication tilburg the netherlands
buniversity of manchester department of computer science manchester uk
1 introduction
the term natural language generation nlg in its broadest def
inition refers to the study of systems that verbalize some form
of information through natural language that information could
be stored in a large database or knowledge graph in datatotext
applications but nlg researchers may also study summarisation
texttotext  or image captioning  imagetotext  for example as a
subfield of natural language processing nlg is closely related to
other subdisciplines such as machine translation mt and dialog
systems some nlg researchers exclude mt from their definition
of the field since there is no content selection involved where the
system has to determine what to say  conversely dialog systems
do not typically fall under the header of natural language genera
tion since nlg is just one component of dialog systems the others
being natural language understanding and dialog management
however with the rise of large language models llms di ffer
ent subfields of natural language processing have converged on
similar methodologies for the production of natural language and
the evaluation of automatically generated text
11 relation to linguistics
historically nlg research has had close ties with pragmatics and
psycholinguistics the reason for this is that automatically gen
erated text should generally be as fluent and natural as possible
however there are often many di fferent ways to communicate the
same message how to best formulate that message depends on the
context1by studying human language production we can better
understand how people formulate their utterances in di fferent situ
ations psycholinguistic models of speech production eg levelt
1989 also have clear parallels with classical nlg pipelines see
31 all these models can be divided into two stages conceptu
alisation  what to say  and formulation  how to say it 
2 applications
nlg technology promises to automate or streamline writing tasks
in many di fferent domains we discuss three examples below
21 nlg and business
the commercial potential of nlg has long been recognized the
first company to commercialize nlg was founded in 1990 and
several di fferent companies have followed in their footsteps dale
2020 robert dale marks 2012 as the year when nlg entered the
mainstream media conscious with the publication of a wired arti
cle on automated journalism following the release of chatgpt
a full decade later november 30 2022 we have now seen how
automatic text generation has become fully mainstream with dif
1we can perhaps best see this in the literature on referring expression generation
see krahmer  van deemter 2012ferent companies o ffering the general public paid subscriptions to
large language models via userfriendly interfaces
nlg techniques have traditionally been used to convert tabular
data into text for example generating financial reports2or gener
ating product titles and descriptions based on product specifications
mathur et al 2017 zou et al 2023 following the rise of chat
gpt we are now seeing an explosion of interest to use language
models for all sorts of purposes including content generation writ
ing informative texts and the generation of email responses see
tafesse  wien 2024 tafesse  wood 2024 for more discussion
22 nlg and journalism
like with business applications nlg techniques have traditionally
been used in journalism to produce datadriven articles to report on
topics such as weather reports sports matches earthquakes and
elections these articles are relatively formulaic making it easier
to develop templates where relevant values such as the magnitude
of an earthquake can be inserted gatt  krahmer 2018 nowa
days journalists use generative ai throughout the reporting pro
cess news gathering news production news verification distribu
tion and moderation for a much wider array of articles cools
 diakopoulos 2024 still classical rule and templatebased
approaches remain the most reliable solution for standalone text
generation since they do not su ffer from hallucination see 51
moreover as reiter 2025 chapter 6 notes rulebased systems
may be easier to modify eg make small changes to the output
and maintain
23 nlg in a medical context
there is a long history of natural language generation in health
care see cawsey et al 1997 for an early survey applications
range from medical report generation presenting relevant clin
ical data to di fferent audiences eg gatt et al 2009 to clini
cal note generation summarising doctorpatient interactions eg
ben abacha et al 2023 and personalised decision support tools
eg hommes et al 2019 challenges in the medical field in
clude working with potentially unreliable sensor data van deemter
 reiter 2018 and involving di fferent stakeholders doctors pa
tients nurses who often di ffer in background knowledge reading
level technical ability and socioeconomic status medical nlg
research is usually carried out in interdisciplinary teams with ex
perts not only assessing the quality of the output but also looking
at the potentially harmful impact that systems may have on their
users eg balloccu et al 2024
2ehud reiter 2018 notes that all major nlg companies are involved in financial
reporting because the sector is large and use cases are similar between di ffer
ent organisations making it easier to capitalise on nlg technology than in areas
where more customisation is needed
1arxiv250316728v2  cscl  25 mar 2025
2 natural language generation
3 approaches
this section provides a brief overview of the di fferent approaches
to natural language generation focusing on the evolution from
the classical nlg pipeline through endtoend approaches to the
use of more general large language models for an overview of
all nlg approaches before llms see gatt  krahmer 2018
31 the classical nlg pipeline
in the classical nlg pipeline text generation proceeds in di fferent
stages here are the steps proposed by reiter  dale 2000
content determination  deciding what information should be
communicated
document structuring  deciding how to group and order dif
ferent chunks of information
lexicalisation  deciding what words phrases or syntactic con
structions to use
referring expression generation  deciding what words or
phrases should be used for di fferent named entities
aggregation  deciding how to map the di fferent information
chunks to sentences and paragraphs
realisation  converting the abstract representation of the text
tobegenerated into a real text
these steps can be handled by di fferent modules that may either
use often handwritten rules machine learning or both the
initial steps of the pipeline are contextdependent but the final stage
realisation is universal as such di fferent projects may reuse the
same realiser 3
32 endtoend generation
endtoend generation drastically simplifies the problem of nat
ural language generation by directly mapping data to text all
steps are implicitly handled by the same model that is developed
using a datadriven approach see castro ferreira et al 2019 for
a discussion popular challenges that can be resolved through
this approach are the e2e dataset novikova et al 2017 and the
webnlg challenge eg cripwell et al 20234taking webnlg
as an example the goal is to render a set of rdf triples in natural
language recent years have seen the focus shift away from en
glish as this problem has more or less been solved and towards
lowresource languages
33 using large language models
large language models llms such as chatgpt ouyang et
al 2022 and llama touvron et al 2023 typically adopt
transformerbased architectures vaswani et al 2017 which rely
on selfattention mechanisms to capture longrange contextual de
pendencies in text the training of llms generally follows a two
stage training pipeline the first stage known as pretraining  is an
unsupervised process in which models are trained on vast amounts
of unlabelled textual data containing billions or even trillions of
tokens from diverse sources such as web pages books and ency
clopaedias this stage allows llms to acquire and encode gen
eral linguistic and world knowledge the second stage known as
3among existing realisers s imple nlg gatt  reiter 2009 is a popular choice
that has been translated into several di fferent languages
4although note that these challenges do not require any signal analysis or content
determinationsupervised finetuning sft involves further training the model
on labelled datasets containing explicit instructionoutput pairs
sft aims to enhance the models ability to understand and follow
humanprovided instructions ensuring its responses are more rele
vant specific and aligned with user expectations techniques such
as reinforcement learning from human feedback rlhf and direct
preference optimisation dpo can further refine the models out
puts improving its safety helpfulness and alignment with human
preferences xu et al 2024
once trained llms generate text through prompting where
users provide textual inputs that may include explicit instructions
context or examples to guide the models responses prompting
enables llms to perform a wide range of tasks such as sum
marisation translation question answering and creative writing
without requiring additional taskspecific finetuning advanced
prompting techniques such as chainofthought prompting that in
troduces intermediate reasoning steps within the prompt can fur
ther enhance the models performance on complex reasoning and
generation tasks see liu et al 2023 for a survey
4 evaluation
evaluating the quality of automatically generated text remains a
fundamental challenge in natural language processing nlp as
text generation models continue to improve the di fficulty of eval
uating their outputs has also increased in many cases evaluating
generated text is now as challenging as generating it this di fficulty
arises due to the inherent variability in natural languagemultiple
outputs can be equally valid despite di ffering in lexical choice
structure or even semantics for instance in machine transla
tion multiple translations of a given sentence may convey the same
meaning while varying in word choice and phrasing the challenge
becomes even more pronounced in opendomain dialogue genera
tion where a single input may lead to many plausible responses
with di fferent semantics ie the onetomany problem zhao et
al 2023 2024 similarly summarisation often involves subjec
tivity as multiple summaries can be correct depending on the focus
and interpretation of the content additionally certain text gen
eration tasks such as humour or metaphor require evaluators to
account for demographic and cultural di fferences further compli
cating the assessment process loakman et al 2023 wang et al
2024 we can rougly distinguish two kinds of evaluation using
human evaluation studies or through automatic metrics see ce
likyilmaz et al 2020 for a survey
41 human evaluation
in human evaluation studies participants answer questions about
one or more texts van der lee et al 2021 a common approach
is to rate the quality of generated texts on a fivepoint scale amidei
et al 2019 there is a wide array of di fferent dimensions that may
be relevant to assess the quality of a text for example fluency cor
rectness completeness  and appropriateness see belz et al 2020
for a general taxonomy for quality dimensions that relate to in
trinsic properties of the texts human evaluation studies are similar
to traditional experiments that one may also encounter in other sub
fields of linguistics for quality dimensions that are more closely
related to the use of an nlg system in context techniques from the
field of humancomputer interaction such as contextual interviews
natural language generation 3
thinkaloud tasks or usability surveys may be used finally au
thors may also choose to carry out an error analysis  where authors
identify and categorise instances where something went wrong in
the generated text van miltenburg et al 2021
42 automatic evaluation
while human evaluation remains the gold standard in nlg re
search it can be costly and timeconsuming therefore di fferent
researchers have developed di fferent ways to assess the output of
nlg systems along di fferent dimensions eg fluency grammati
cality correctness  celikyilmaz et al 2020 distinguish two kinds
of automatic evaluation
1untrained automatic metrics compare generated texts with a
set of reference texts through di fferent similarity measures
2machinelearned metrics are based on machinelearned mod
els and serve as automatic equivalents to human judges
recent years have seen rapid developments in the second cate
gory with the llmasajudge paradigm quickly gaining popular
ity after showing impressive results on di fferent benchmarks eg
zheng et al 2023 for an overview of currently used tasks and
evaluation measures readers are referred to the recurring gem
shared task eg mille et al 2024 which is the most comprehen
sive community e ffort to assess nlg models on a wide array of
different tasks5
5 challenges
51 factuality versus fluency
there is an interesting tension between factuality and fluency of
automatically generated texts generally speaking traditional rule
based approaches result in texts that are factually correct but not
always fluent while neural approaches tend to produce texts that
are fluent but not always factually correct6this is related to the
problem of hallucination see huang et al 2025 for a survey it is
currently unclear how to guarantee that nlg output is both fluent
and100 factual
52 long text generation
traditionally most text generation tasks have focused on produc
ing relatively short outputs such as weather reports or summaries
that span a few dozen to a few hundred words however there is
growing interest in developing models capable of generating much
longer texts often extending to thousands of words for example
recent e fforts such as ai scientist lu et al 2024 have demon
strated the ability to generate entire scientific papers by incorpo
rating structured scientific knowledge eg experimental results
this framework can draft papers that adhere to domainspecific re
quirements integrating relevant citations and conforming to disci
plinary norms similarly longwriter bai et al 2024 addresses
longtext generation across various domains including academic
5for an indication of the popularity of current metrics see schmidtova et al 2024
but note that single metrics are always reductive no individual metric can fully
capture all di fferent quality dimensions
6though see van deemter  reiter 2018 where the authors show how all types
of nlg systems may deviate from the truth in their outputs to some extent this
is unavoidable in situations where the system also has to carry out signal analysis
ie interpreting the input with a risk of misinterpretation and content selection
meaning that the system cannot provide the whole truthpublications and monographs it employs hierarchical attention
mechanisms and finetuning strategies to maintain thematic consis
tency and produce structured arguments across extended outputs
despite notable advancements achieving coherence and structure
in longform content generation remains a significant challenge
this challenge stems from key issues such as the scarcity of high
quality longform text data in the supervised finetuning phase
which limits the models ability to learn e ffective writing patterns
moreover the alignment phase based on rlhf or dpo introduces
complexities in reward modeling and evaluation where assessing
attributes like narrative flow logical consistency and thematic co
herence becomes increasingly di fficult as the text lengthens
53 evaluation
nlg evaluation is a hotly debated topic earlier studies found that
there is a widespread confusion about the terminology that is used
to refer to di fferent quality dimensions howcroft et al 2020 hu
man evaluations may always not be reproducible belz et al 2023
which may be partly due to past reporting standards howcroft et
al 2020 shimorina  belz 2022 gehrmann et al 2023 but we
also have to consider the inherent di fficulty of quantifying the ob
jective quality of a text if such a thing even exists more research
is needed to deepen our understanding of the interaction between
different quality dimensions that are involved in the process of text
appreciation van miltenburg et al 2020
54 reproducibility
an open challenge in nlg research is how to ensure reproducible
results in other words being able to obtain the same results as
those reported in earlier studies although this holds for both the
output generated by nlg software and the results of the evaluation
procedure most attention has gone to the repeatability of human
evaluation studies belz et al 2023
55 ethics the social impact of nlg
as nlg technology is both increasingly powerful andincreasingly
widespread we also have to contend with the realworld implica
tions of our work a recent survey van miltenburg 2025 provides
an overview of dual use issues that can arise from our research and
solaiman et al 2024 o ffer a broad taxonomy of areas that may
be impacted by generative ai systems handling these issues re
quires continuous e ffort from both individual researchers and the
community as a whole
6 conclusion
this article provided an overview of the field of natural language
generation due to space constraints we have focused on the ap
plication side of the field ie building and evaluating systems that
convert data to text readers who would like to learn more about
this topic can read the survey by gatt  krahmer 2018 or the
recent book by reiter 2025
nlg researchers have always found inspiration in the way hu
mans produce language although we have not focused on this
topic we encourage readers to also explore the more cognitively
oriented work that studies human language production in context
and work that compares human and automatic language production
4 natural language generation
acknowledgments
see also article title article title
bibliography
amidei j piwek p   willis a 2019 octobernovember the use
of rating and likert scales in natural language generation human
evaluation tasks a review and some recommendations in k van
deemter c lin  h takamura eds proceedings of the 12th
international conference on natural language generation pp 397
402 tokyo japan association for computational linguistics
retrieved from httpsaclanthologyorgw198648 doi 1018653
v1w198648
bai y  zhang j lv x zheng l zhu s hou l    li j 2024
longwriter unleashing 10000 word generation from long con
text llms retrieved from httpsarxivorgabs240807055
balloccu s reiter e li k jh sargsyan r kumar v re
forgiato d    dusek o 2024 november ask the ex
perts sourcing a highquality nutrition counseling dataset through
humanai collaboration in y  alonaizan m bansal  y
n chen eds findings of the association for computational
linguistics emnlp 2024 pp 1151911545 miami florida
usa association for computational linguistics retrieved from
httpsaclanthologyorg2024findingsemnlp674 doi 1018653
v12024findingsemnlp674
belz a mille s  howcroft d m 2020 december disen
tangling the properties of human evaluation methods a clas
sification system to support comparability metaevaluation and
reproducibility testing in b davis y  graham j kelleher 
y  sripada eds proceedings of the 13th international confer
ence on natural language generation pp 183194 dublin ire
land association for computational linguistics retrieved from
httpsaclanthologyorg2020inlg124 doi 1018653v12020
inlg124
belz a thomson c reiter e  mille s 2023 july non
repeatable experiments and nonreproducible results the re
producibility crisis in human evaluation in nlp in a rogers
j boydgraber  n okazaki eds findings of the associ
ation for computational linguistics acl 2023 pp 36763687
toronto canada association for computational linguistics re
trieved from httpsaclanthologyorg2023findingsacl226 doi
1018653v12023findingsacl226
ben abacha a yim ww michalopoulos g  lin t 2023 july
an investigation of evaluation methods in automatic medical note
generation in a rogers j boydgraber  n okazaki eds
findings of the association for computational linguistics acl 2023
pp 25752588 toronto canada association for computational
linguistics retrieved from httpsaclanthologyorg2023findings
acl161 doi 1018653v12023findingsacl161
castro ferreira t van der lee c van miltenburg e  krah
mer e 2019 november neural datatotext generation a
comparison between pipeline and endtoend architectures in
k inui j jiang v ng  x wan eds proceedings of the
2019 conference on empirical methods in natural language pro
cessing and the 9th international joint conference on natural lan
guage processing emnlpijcnlp pp 552562 hong kong
china association for computational linguistics retrieved from
httpsaclanthologyorgd191052 doi 1018653v1d191052
cawsey a j webber b l  jones r b 1997 11 nat
ural language generation in health care journal of the amer
ican medical informatics association 46 473482 retrieved
from httpsdoiorg101136jamia19970040473 doi 101136
jamia19970040473
celikyilmaz a clark e  gao j 2020 evaluation of text gen
eration a survey corr abs200614799   retrieved from
httpsarxivorgabs200614799
cools h  diakopoulos n 2024 uses of generative ai in
the newsroom mapping journalists perceptions of perils and
possibilities journalism practice 00 119 retrieved fromhttpsdoiorg1010801751278620242394558 doi 101080
1751278620242394558
cripwell l belz a gardent c gatt a borg c borg m   
soto martinez w 2023 september the 2023 webnlg shared
task on low resource languages overview and evaluation results
webnlg 2023 in a gatt et al eds proceedings of the work
shop on multimodal multilingual natural language generation and
multilingual webnlg challenge mmnlg 2023 pp 5566 prague
czech republic association for computational linguistics re
trieved from httpsaclanthologyorg2023mmnlg16
dale r 2020 natural language generation the commercial state
of the art in 2020 natural language engineering 264 481487
doi 101017s135132492000025x
gatt a  krahmer e 2018 january survey of the state of the
art in natural language generation core tasks applications and
evaluation j artif int res 611 65170
gatt a portet f  reiter e hunter j mahamood s moncur w
 sripada s 2009 from data to text in the neonatal intensive
care unit using nlg technology for decision support and informa
tion management ai communications 223 153186
gatt a  reiter e 2009 march simplenlg a realisa
tion engine for practical applications in e krahmer  m the
une eds proceedings of the 12th european workshop on nat
ural language generation enlg 2009 pp 9093 athens
greece association for computational linguistics retrieved from
httpsaclanthologyorgw090613
gehrmann s clark e  sellam t 2023 may repairing the
cracked foundation a survey of obstacles in evaluation practices
for generated text journal of artificial intelligence research 77
103166 retrieved from httpdxdoiorg101613jair113715
doi 101613jair113715
hommes s van der lee c clouth f  vermunt j verbeek x
 krahmer e 2019 octobernovember a personalized data
totext support tool for cancer patients in k van deemter c lin
 h takamura eds proceedings of the 12th international con
ference on natural language generation pp 443452 tokyo
japan association for computational linguistics retrieved from
httpsaclanthologyorgw198656 doi 1018653v1w198656
howcroft d m belz a clinciu ma gkatzia d hasan s a
mahamood s    rieser v 2020 december twenty years
of confusion in human evaluation nlg needs evaluation sheets
and standardised definitions in b davis y  graham j kelleher
 y  sripada eds proceedings of the 13th international confer
ence on natural language generation pp 169182 dublin ire
land association for computational linguistics retrieved from
httpsaclanthologyorg2020inlg123 doi 1018653v12020
inlg123
huang l yu w ma w zhong w feng z wang h   
liu t 2025 january a survey on hallucination in large
language models principles taxonomy challenges and open
questions acm trans inf syst 432  retrieved from
httpsdoiorg1011453703155 doi 1011453703155
krahmer e  van deemter k 2012 march computational gen
eration of referring expressions a survey computational linguis
tics381 173218 retrieved from httpsaclanthologyorgj12
1006 doi 101162coli a00088
levelt w j m 1989 speaking from inten
tion to articulation  the mit press retrieved from
httpdxdoiorg107551mitpress63930010001 doi
107551mitpress63930010001
liu p  yuan w fu j jiang z hayashi h  neubig g 2023
pretrain prompt and predict a systematic survey of prompting
methods in natural language processing acm comput surv 
559  retrieved from httpsdoiorg1011453560815 doi
1011453560815
loakman t maladry a  lin c 2023 the ironic melting pot
reviewing human evaluation in humour irony and sarcasm gener
ation in h bouamor j pino  k bali eds findings of the asso
ciation for computational linguistics emnlp 2023 pp 66766689
retrieved from httpsaclanthologyorg2023findingsemnlp444
doi 1018653v12023findingsemnlp444
lu c lu c lange r t foerster j clune j  ha d 2024
the ai scientist towards fully automated openended scientific
natural language generation 5
discovery retrieved from httpsarxivorgabs240806292
mathur p  ueffing n  leusch g 2017 september gen
erating titles for millions of browse pages on an ecommerce
site in j m alonso a bugar n  e reiter eds pro
ceedings of the 10th international conference on natural lan
guage generation pp 158167 santiago de compostela
spain association for computational linguistics retrieved from
httpsaclanthologyorgw173525 doi 1018653v1w173525
mille s sedoc j liu y  clark e axelsson a j clinciu
m a    zhang l 2024 september the 2024 gem shared
task on multilingual datatotext generation and summarization
overview and preliminary results in s mille  ma clinciu
eds proceedings of the 17th international natural language gen
eration conference generation challenges pp 1738 tokyo
japan association for computational linguistics retrieved from
httpsaclanthologyorg2024inlggenchal2
novikova j du sek o  rieser v 2017 august the e2e
dataset new challenges for endtoend generation in k joki
nen m stede d devault  a louis eds proceedings of the
18th annual sigdial meeting on discourse and dialogue pp 201
206 saarbr ucken germany association for computational lin
guistics retrieved from httpsaclanthologyorgw175525 doi
1018653v1w175525
ouyang l wu j jiang x almeida d wainwright c l mishkin
p     lowe r 2022 training language models to follow in
structions with human feedback in proceedings of the 36th in
ternational conference on neural information processing systems
red hook ny  usa curran associates inc
reiter e 2018 where is nlg most successful
commercially published on ehud reiters blog
httpsehudreitercom20181030mostsuccessfulcommercialnlg 
reiter e 2025 natural language generation  springer nature
switzerland retrieved from httpdxdoiorg1010079783031
685828 doi 1010079783031685828
reiter e  dale r 2000 building natural language generation
systems  cambridge university press
schmidtova p  mahamood s balloccu s dusek o gatt
a gkatzia d    sivaprasad a 2024 september au
tomatic metrics in natural language generation a survey of
current evaluation practices in s mahamood n l minh
 d ippolito eds proceedings of the 17th international nat
ural language generation conference pp 557583 tokyo
japan association for computational linguistics retrieved from
httpsaclanthologyorg2024inlgmain44
shimorina a  belz a 2022 may the human evaluation
datasheet a template for recording details of human evalua
tion experiments in nlp in a belz m popovi c e reiter 
a shimorina eds proceedings of the 2nd workshop on hu
man evaluation of nlp systems humeval pp 5475 dublin
ireland association for computational linguistics retrieved
from httpsaclanthologyorg2022humeval16 doi 1018653
v12022humeval16
solaiman i talat z agnew w ahmad l baker d blodgett
s l    subramonian a 2024 evaluating the social impact
of generative ai systems in systems and society retrieved from
httpsarxivorgabs230605949 forthcoming in hacker engel
hammer mittelstadt eds oxford handbook on the foundations
and regulation of generative ai oxford university press
tafesse w  wien a 2024 chatgpts applications in marketing
a topic modeling approach marketing intelligence  planning 
424 666683
tafesse w  wood b 2024 hey chatgpt an examination of
chatgpt prompts in marketing journal of marketing analytics 
124 790805 retrieved from httpdxdoiorg101057s41270
02300284w doi 101057s4127002300284w
touvron h lavril t izacard g martinet x lachaux m
a lacroix t    lample g 2023 llama open
and efficient foundation language models retrieved from
httpsarxivorgabs230213971
van der lee c gatt a van miltenburg e  krahmer
e 2021 human evaluation of automatically generated
text current trends and best practice guidelines computer speech  language 67 101151 retrieved from
httpswwwsciencedirectcomsciencearticlepiis088523082030084x
doi httpsdoiorg101016jcsl2020101151
van deemter k  reiter e 2018 11 420lying
and computational linguistics in the oxford hand
book of lying oxford university press retrieved from
httpsdoiorg101093oxfordhb978019873657801332 doi
101093oxfordhb978019873657801332
van miltenburg e 2025 dual use issues in the
field of natural language generation retrieved from
httpsarxivorgabs250106636
van miltenburg e clinciu m du sek o gkatzia d inglis s
lepp anen l    wen l 2021 august underreporting of er
rors in nlg output and what to do about it in a belz a fan
e reiter  y  sripada eds proceedings of the 14th interna
tional conference on natural language generation pp 140153
aberdeen scotland uk association for computational linguis
tics retrieved from httpsaclanthologyorg2021inlg114 doi
1018653v12021inlg114
van miltenburg e lu wt krahmer e gatt a chen g li
l  van deemter k 2020 december gradations of error
severity in automatic image descriptions in b davis y  gra
ham j kelleher  y  sripada eds proceedings of the 13th
international conference on natural language generation pp 398
411 dublin ireland association for computational linguis
tics retrieved from httpsaclanthologyorg2020inlg145 doi
1018653v12020inlg145
vaswani a shazeer n parmar n uszkoreit j jones l
gomez a n    polosukhin i 2017 attention is all you need
in i guyon et al eds advances in neural information process
ing systems vol 30 curran associates inc retrieved from
httpsproceedingsneuripsccpaper filespaper2017file3f5ee243547dee91fbd053c1c4a845aa
paperpdf
wang s zhang g wu h loakman t huang w  lin
c 2024 november mmte corpus and metrics for eval
uating machine translation quality of metaphorical language
in y  alonaizan m bansal  yn chen eds proceed
ings of the 2024 conference on empirical methods in natu
ral language processing pp 1134311358 miami florida
usa association for computational linguistics retrieved from
httpsaclanthologyorg2024emnlpmain634 doi 1018653v1
2024emnlpmain634
xu s fu w gao j y e w liu w mei z    wu y  2024
is dpo superior to ppo for llm alignment a comprehensive study
inproceedings of the 41st international conference on machine
learning
zhao k y ang b lin c rong w villavicencio a  cui x
2023 evaluating opendomain dialogues in latent space with
next sentence prediction and mutual information in proceedings
of the 61st annual meeting of the association for computational
linguistics volume 1 long papers pp 562574 retrieved from
httpsaclanthologyorg2023acllong33 doi 1018653v12023
acllong33
zhao k y ang b tang c lin c  zhan l 2024 slide a
framework integrating small and large language models for open
domain dialogues evaluation in lw ku a martins  v sriku
mar eds findings of the association for computational linguis
tics acl 2024 pp 1542115435 doi 1018653v12024findings
acl911
zheng l chiang wl sheng y  zhuang s wu z zhuang
y     stoica i 2023 judging llmasajudge with mtbench and
chatbot arena in proceedings of the 37th international conference
on neural information processing systems red hook ny  usa
curran associates inc
zou y  zhang x zhou j diao s chen j ding z    et al
2023 automatic product copywriting for ecommerce ai maga
zine441 4153","['v12024findingsemnlp674', '1018653v12024findings', 'httpsarxivorgabs230213971', '1arxiv250316728v2', 'httpsaclanthologyorg2024findingsemnlp674', '1018653v12020inlg145', '1018653v12021inlg114', 'httpsaclanthologyorg2023findingsemnlp444', 'httpsaclanthologyorg2020inlg145', 'httpsaclanthologyorg2021inlg114']",1
Towards the Study of Morphological Processing of the Tangkhul Language,"['Mirinso Shadang', 'Navanath Saharia', 'Thoudam Doren Singh']",2020,http://arxiv.org/abs/2006.16212v1,"arXiv:2006.16212v1  [cs.CL]  29 Jun 2020Towards the Study of Morphological Processing of the Tangkh ul
Language
Mirinso Shadang Navanath Saharia Thoudam Doren Singh
Indian Institute of Information Technology Manipur
Imphal, India - 795002
{mirinso, nsaharia }@iiitmanipur.ac.in,thoudam.doren@gmail.com
Abstract
There is no or little work on natural lan-
guage processing of Tangkhul language.
The current work is a humble beginning of
morphological processing of this language
using an unsupervised approach. We use
a small corpus collected from different
sources of text books, short stories and ar-
ticles of other topics. Based on the exper-
iments carried out, the morpheme identiﬁ-
cation task using morphessor gives reason-
able and interesting output despite using a
small corpus.
1 Introduction
The name Tangkhul (also known as Hao or Ihao
especially in older literature) refers to an ethnic
group which live in the hill of Ukhrul district and
Kamjong district of Manipur State, India, and con-
tiguous parts of Nagaland (another state of India)
and Burma. The Tangkhuls are quite diversiﬁed
linguistically, and culturally. The speech vari-
eties of most Tangkhul villages are not mutually
intelligible with those of neighbouring villages.
Even the similarities are large enough to facili-
tate the rapid learning of one anothers languages.
However, it is clear that the Tangkhul languages
are closely related to one-another and form a dis-
tinct subgroup within the Tibeto-Burman family.
Tangkhul is an ethnic group whose language varies
from village to village. It has long been noted that
Tangkhul is a group of languages, rather than a
single language (Brown 1837), however, almost
all of the available descriptions of Tangkhul lan-
guages have concentrated on a single varietythe
language of Ukhrul town, which has come to serve
as a lingua franca for the whole Tangkhul tribe.
Even if the Tangkhul language serve as a com-
mon language for the whole Tangkhul region, butthe accent of speech (way of speaking Tangkhul)
varies from geographical area. Tangkhul region is
mainly divided into four major part i.e. East (zing-
sho), west (zingtun), North (ato), South (azay).
There are more than 100 language spoken in the
various villages of Tangkhul diaspora, since all
the villages of Tangkhul region (Ukhrul district
& Kamjong district) has their own native lan-
guage, the pronunciation of the common language
(Tangkhul) is highly varying.
The most obvious working deﬁnition of the
Tangkhul language is the family of Tibeto-Burman
languages spoken by members of the Tangkhul
tribe. This deﬁnition is complicated by a num-
ber of factors, and is clearly inadequate (as will
be seen), since some of the languages spoken as a
mother-tongue by ethnic Tangkhuls are not mem-
bers of the family being discussed here and be-
cause it is possible that there are members of other
Naga tribes speaking languages that belong in the
Tangkhul group. Thus, while ethnicity can be
taken as neither a necessary nor a sufﬁcient cri-
terion for membership in the Tangkhul family it is
nevertheless a useful starting point for a discussion
of this group of languages.
Morphological processing of a language is the
beginning of NLP work of that particular lan-
guage. There are reports on morphological pro-
cessing work for many other major Indian lan-
guages. But, Tangkhul language in particular
which falls under resource constrained and less
privileged category with no or little work on natu-
ral language processing till date. In this light, we
attempt to collect small corpus and start the ini-
tial steps towards morphological processing of this
language. The morphological analysis of this lan-
guage is found to be slightly complex being agglu-
tinative ( Mortensen ,2003 ) one.
2 Related Work
The Tibeto-Burman languages of India are
still lacking the basic language processing
tools of required quality. Among the re-
ported work on Tibeto-Burman languages,
Bodo ( Sarmah ,2004 ), Mizo ( Pakray et al. ,
2015 ), Kok-borok ( Debbarma et al. ,2012 ) and
Manipuri ( Singh and Bandyopadhyay ,2008 ) are
main. Almost all the reported work used apriori
knowledge of the language either in the form of
dictionary or in the form of preparing label data
for training. Being a resource less language, we
preferred unsupervised learning approach for the
considered language.
2.1 Language morphology and syntax
Tankhul has two distinct tones - high and low,
mainly with the utterances associated with the let-
ter t, d, r, m, and f. For examples
1. High (Kajuiya)
Chanhan Kasho (open) Khaikao (dry ﬁsh)
Khalen (trap)
2. Low (Khanema) kachang (month) kachui
(high) mashit (closeness) ashee (blood)
Adjective of Tangkhul displays a hybrid mor-
phology, as it always occurs semantically some-
where between verbs and nouns.
Like other morphologically rich neighbour
languages ( Majumder et al. ,2007 ;Saharia et al. ,
2014 ), Tangkhul also has a strong tendency to
form sequence of afﬁxes to prepend/append to the
root.
In fact, many of the preﬁxes found in Tangkhul
language behaves morphologically as if they are
part of the root. While it is possible to assign
independent historical origins to these elements,
from a synchronic standpoint the factors that iden-
tify them are phonological and not morphological.
As will be seen, it is often not possible to assign
a consistent meaning or grammatical function to
these preﬁxes, which will be referred to here as
lexical preﬁxes ( Mortensen ,2003 ).
2.2 Word Formation
The formation of words in a language is one the
topic, which still attracts the researchers most.
The two main class of word formation are inﬂec-
tion and derivation. Derivation is divided into
again two classes - afﬁxation and compounding.Compounding is divided into three classes - en-
docentric compound, exocentric compound and
co-ordinate compound. Endocentric compound
is again divided into right headed compound and
left-headed compound. In the right-headed com-
pound, it may have many constituents such as
‘noun + noun’ and ‘noun + derived noun’, but
‘noun + noun’ is more used than the other one in
Tangkhul ( Ahum ,1997 ).
There are three types of verb roots in Tangkhul-
simple, complex and compound. A simple root
is irreducible ’core element’ obtained by drop-
ping all the afﬁxes. A root may be monosyl-
labic or bisyllabic. For example: lei ( exist/have ),
vao ( shout ), and malai ( forget ). Though Tangkhul
verbs are close class, few verbs are derived from
’nominal’ roots. For example: /pha/ /ra/. Table 1
tabulated few case markers of Tanghul language.
There are two broad types of modiﬁers- adjec-
tival and adverbials. Adjectives, as a word class,
are quite different from nouns and verbs. In the
case of Tangkhul language, the exact relationship
between adjectives on the one hand, and other
categories like nouns, verbs and adverbs on the
other, has been one of the disputed issues in lin-
guistics. In Tangkhul language there is no distinc-
tion between verbs and adjectives in the sense that
they are derived from roots, and function as adjec-
tives or verbs with (a) appropriate afﬁxation and
(b) appropriate occurrence in a sentence ( Ahum ,
1997 ). Expressives (which are aplenty in the lan-
guage and which most often have adverbial and
adjectival functions) can be compounded with a
number of roots to form compound adjectival. In
the process of compounding expressive tend to be-
have like intensiﬁers or modiﬁers. The following
are some of the most commonly used adjectives
formed by compounding roots and expressive.
2.3 Compounding and reduplication
There are some compound modiﬁers in the
Tangkhul, which are further reduplicated to denote
modiﬁed or completely changed meaning. In the
process of reduplication, the last syllable of the
compound root is partially reduplicated by replac-
ing its initial consonant. The following are some
of the most commonly used reduplicated com-
pound adjectives. For example: Root + Root +
Reduplicate
•them-reak-sek = them ( skill)- reak ( pretend )-
Proceeding of Regional International Conference on Natura l Language Processing (regICON) 2017, 3rd and 4th
November 2017, IIIT Senapati, Manipur, India
Case marker Sufﬁx Example
Locative case marker -li, -wui Manipur-li (in Manipur)
Genitive case marker -chi - Avi-chi (his)
Nominative case marker -na khipa-na (who)
Table 1: Few case markers with example
sek ( redu)
Approximate English meaning: pretending to
be very skillful or learned
•Khon-zar-tar = Khon ( sound )- zar( dense )- tar
(redu)
Approximate English meaning: very noisy.
3 Corpus preparation and preprocessing
As the existence of the language is very rare in
web, we have manually collected/typed few texts
for our experiment. The current version of the
corpus contains 21713 words, out of which 7362
are unique words (include inﬂections). The arti-
cles or segment of articles in the corpus can be
categoried into biography (4 numbers), short story
(6 numbers), essay (11 numbers), drama (2 num-
bers) and letter (1 number) with average (approx-
imately) 904 words per article. The ﬁrst ten fre-
quent words in the corpus are tabulated in Table 2.
Sr No. Word Meaning frequency
1 eina with 708
2 hi this 367
3 chi that 358
4 kala and 336
5 da 184
6 haowa 130
7 kaji that 122
8 ˜ akha one 122
9 ˜ awui his 120
10 chili there 110
Table 2: Ten most frequent words in the corpus.
For our experiment, we use Morfessor
(Creutz and Lagus ,2005 ) version 1.01, an un-
supervised language independent morphology
learning package to discover the regularities
behind the word formation process. This leaning
approach discovers the primitive morphological
units such as root/base/stem2, sufﬁx and preﬁx
1http://www.http://morpho.aalto.ﬁ/projects/morpho; Ac -
cess date: 30 August, 2017.
2Though, there are differences in the concept of root, baseof the utterances of a language. As it is based on
words or utterance of the language and its fre-
quency, most of the time, the tool discovers preﬁx
(in sequence), stem and sufﬁx (in sequence).
During experiment, we found that, a word may
have maximum seven different morpheme, mostly
sequence of afﬁxes. The morpheme frequency
with example is tabulated in Table 3. We also
found that The corpus contains a good number of
borrowed words from English and neighbouring
languages.
The following examples shows the morphologi-
cal richness of the considered language segmented
using Morfessor.
maphaning ( not thinking ) = ma ( no) + phaning
(thinking )
maphaninsali = ma + pha + nin + sa + li
map˜ amsangmara = ma + p˜ a + m + sa + ng + mara
khamashash˜ ali = kha + ma + sha + sh + ˜ ali
kakhararkhangazai = ka + kharar + kha + nga +
zai
˜ ach˜ ahonthangcham = ˜ a + ch˜ a + hon + thang +
cham
The following are few examples, the Morfessor
segmented correctly.
a + cham + ˜ aram
˜ a + lung + th + ung + li
˜ a + ng + ˜ a + ng + nao + li
a + ri + shang + li
Table 4tabulated few words incorrectly segmented
by Morfessor.
Interestingly, during segmentation, based on the
evidence in the corpus, the tool is splitting the
following English words used as loan words in
Tangkhul (Table 5).
In the context of loan words, another interesting
example we found is acid + p ˜a + va . Though the
root (the ﬁrst morpheme) is a valid loan word, the
context actually was indicating the root aship ˜ava
(means wife).
and stem, for this experiment we are using these terms inter-
changeably to indicate stem
Proceeding of Regional International Conference on Natura l Language Processing (regICON) 2017, 3rd and 4th
November 2017, IIIT Senapati, Manipur, India
Words with no afﬁx 1772 Example: khana
Words with one afﬁx 3600 Example: advocate+la
Words with two afﬁxes 1487 Example: ˜ a+thingreira+wui
Words with three afﬁxes 410 Example: kajui+kha+nem
Words with four afﬁxes 78 Example: +lung+th+ung+li
Words with ﬁve afﬁxes 12 Example: la+ng+da+ng+l˜ a+na
Words with Six afﬁxes 3 Example: kha+nga+p+eo+bing+li+la
Table 3: Afﬁx frequency distribution in the corpus
Wrong (By Morfessor) Correct
˜ a + k˜ a + khare + wui ˜ a + k˜ a + kha + re + wui
˜ a + mathen + pai + ra ˜ a + ma + then + pai + ra
˜ a + ngas˜ am + khuiya ˜ a + nga + s˜ am + khui + ya
Table 4: Incorrect segmentation of words
acqui + red Wrong
activ + ities Wrong
activ + ity Wrong
administra + tion + wui Wrong
Table 5: Segmentation of loan words
4 Conclusion
The demand for localization through electronic
content has made the globe a smaller place and
any digital divide in this regard has to be reduced
through the inclusion of more naturally occur-
ring languages through the information technol-
ogy revolution. Towards this direction, the present
task is a step to bring Tangkhul into the language
technology revolution. In the present work, we
reported the morphological processing work of
Tangkhul using an unsupervised approach. We
found the result of the experiment to be reasonably
good as compared to the size of the corpus used
in the work. Our future direction includes more
experiment on this by including language speciﬁc
rules and other semi-supervised approaches.
References
Victor Ahum. 1997. Tangkhul-Naga Grammar: A
Study of Word Formation . Ph.D. thesis.
Mathias Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using morfessor 1.0. Technical
report.
Khumbar Debbarma, Braja Gopal Patra, Swapan
Debbarma, Lalita Kumari, and Bipul ShyamPurkayastha. 2012. Morphological analysis of kok-
borok for universal networking language dictio-
nary. In Recent Advances in Information Technol-
ogy (RAIT), 2012 1st International Conference on .
IEEE, pages 474–477.
Prasenjit Majumder, Mandar Mitra, Swapan K Parui,
Gobinda Kole, Pabitra Mitra, and Kalyankumar
Datta. 2007. Yass: Yet another sufﬁx stripper.
ACM transactions on information systems (TOIS)
25(4):18.
David Mortensen. 2003. Comparative tangkhul. Uni-
versity of California, Berkeley .
Partha Pakray, Arunagshu Pal, Goutam Majumder, and
Alexander Gelbukh. 2015. Resource building and
parts-of-speech (pos) tagging for the mizo language.
InArtiﬁcial Intelligence (MICAI), 2015 Fourteenth
Mexican International Conference on . IEEE, pages
3–7.
Navanath Saharia, Utpal Sharma, and Jugal Kalita.
2014. Stemming resource-poor indian languages.
ACM Transactions on Asian Language Information
Processing (TALIP) 13(3):14.
Priyankoo Sarmah. 2004. Some aspects of the tonal
phonology of Bodo . Ph.D. thesis, English and For-
eign Languages University, Hyderabad.
Thoudam Doren Singh and Sivaji Bandyopadhyay.
2008. Morphology driven manipuri pos tagger. In
IJCNLP . pages 91–98.
Proceeding of Regional International Conference on Natura l Language Processing (regICON) 2017, 3rd and 4th
November 2017, IIIT Senapati, Manipur, India","arxiv200616212v1  cscl  29 jun 2020towards the study of morphological processing of the tangkh ul
language
mirinso shadang navanath saharia thoudam doren singh
indian institute of information technology manipur
imphal india  795002
mirinso nsaharia iiitmanipuracinthoudamdorengmailcom
abstract
there is no or little work on natural lan
guage processing of tangkhul language
the current work is a humble beginning of
morphological processing of this language
using an unsupervised approach we use
a small corpus collected from different
sources of text books short stories and ar
ticles of other topics based on the exper
iments carried out the morpheme identi
cation task using morphessor gives reason
able and interesting output despite using a
small corpus
1 introduction
the name tangkhul also known as hao or ihao
especially in older literature refers to an ethnic
group which live in the hill of ukhrul district and
kamjong district of manipur state india and con
tiguous parts of nagaland another state of india
and burma the tangkhuls are quite diversied
linguistically and culturally the speech vari
eties of most tangkhul villages are not mutually
intelligible with those of neighbouring villages
even the similarities are large enough to facili
tate the rapid learning of one anothers languages
however it is clear that the tangkhul languages
are closely related to oneanother and form a dis
tinct subgroup within the tibetoburman family
tangkhul is an ethnic group whose language varies
from village to village it has long been noted that
tangkhul is a group of languages rather than a
single language brown 1837 however almost
all of the available descriptions of tangkhul lan
guages have concentrated on a single varietythe
language of ukhrul town which has come to serve
as a lingua franca for the whole tangkhul tribe
even if the tangkhul language serve as a com
mon language for the whole tangkhul region butthe accent of speech way of speaking tangkhul
varies from geographical area tangkhul region is
mainly divided into four major part ie east zing
sho west zingtun north ato south azay
there are more than 100 language spoken in the
various villages of tangkhul diaspora since all
the villages of tangkhul region ukhrul district
 kamjong district has their own native lan
guage the pronunciation of the common language
tangkhul is highly varying
the most obvious working denition of the
tangkhul language is the family of tibetoburman
languages spoken by members of the tangkhul
tribe this denition is complicated by a num
ber of factors and is clearly inadequate as will
be seen since some of the languages spoken as a
mothertongue by ethnic tangkhuls are not mem
bers of the family being discussed here and be
cause it is possible that there are members of other
naga tribes speaking languages that belong in the
tangkhul group thus while ethnicity can be
taken as neither a necessary nor a sufcient cri
terion for membership in the tangkhul family it is
nevertheless a useful starting point for a discussion
of this group of languages
morphological processing of a language is the
beginning of nlp work of that particular lan
guage there are reports on morphological pro
cessing work for many other major indian lan
guages but tangkhul language in particular
which falls under resource constrained and less
privileged category with no or little work on natu
ral language processing till date in this light we
attempt to collect small corpus and start the ini
tial steps towards morphological processing of this
language the morphological analysis of this lan
guage is found to be slightly complex being agglu
tinative  mortensen 2003  one
2 related work
the tibetoburman languages of india are
still lacking the basic language processing
tools of required quality among the re
ported work on tibetoburman languages
bodo  sarmah 2004  mizo  pakray et al 
2015  kokborok  debbarma et al 2012  and
manipuri  singh and bandyopadhyay 2008  are
main almost all the reported work used apriori
knowledge of the language either in the form of
dictionary or in the form of preparing label data
for training being a resource less language we
preferred unsupervised learning approach for the
considered language
21 language morphology and syntax
tankhul has two distinct tones  high and low
mainly with the utterances associated with the let
ter t d r m and f for examples
1 high kajuiya
chanhan kasho open khaikao dry sh
khalen trap
2 low khanema kachang month kachui
high mashit closeness ashee blood
adjective of tangkhul displays a hybrid mor
phology as it always occurs semantically some
where between verbs and nouns
like other morphologically rich neighbour
languages  majumder et al 2007 saharia et al 
2014  tangkhul also has a strong tendency to
form sequence of afxes to prependappend to the
root
in fact many of the prexes found in tangkhul
language behaves morphologically as if they are
part of the root while it is possible to assign
independent historical origins to these elements
from a synchronic standpoint the factors that iden
tify them are phonological and not morphological
as will be seen it is often not possible to assign
a consistent meaning or grammatical function to
these prexes which will be referred to here as
lexical prexes  mortensen 2003 
22 word formation
the formation of words in a language is one the
topic which still attracts the researchers most
the two main class of word formation are inec
tion and derivation derivation is divided into
again two classes  afxation and compoundingcompounding is divided into three classes  en
docentric compound exocentric compound and
coordinate compound endocentric compound
is again divided into right headed compound and
leftheaded compound in the rightheaded com
pound it may have many constituents such as
noun  noun and noun  derived noun but
noun  noun is more used than the other one in
tangkhul  ahum 1997 
there are three types of verb roots in tangkhul
simple complex and compound a simple root
is irreducible core element obtained by drop
ping all the afxes a root may be monosyl
labic or bisyllabic for example lei  existhave 
vao  shout  and malai  forget  though tangkhul
verbs are close class few verbs are derived from
nominal roots for example pha ra table 1
tabulated few case markers of tanghul language
there are two broad types of modiers adjec
tival and adverbials adjectives as a word class
are quite different from nouns and verbs in the
case of tangkhul language the exact relationship
between adjectives on the one hand and other
categories like nouns verbs and adverbs on the
other has been one of the disputed issues in lin
guistics in tangkhul language there is no distinc
tion between verbs and adjectives in the sense that
they are derived from roots and function as adjec
tives or verbs with a appropriate afxation and
b appropriate occurrence in a sentence  ahum 
1997  expressives which are aplenty in the lan
guage and which most often have adverbial and
adjectival functions can be compounded with a
number of roots to form compound adjectival in
the process of compounding expressive tend to be
have like intensiers or modiers the following
are some of the most commonly used adjectives
formed by compounding roots and expressive
23 compounding and reduplication
there are some compound modiers in the
tangkhul which are further reduplicated to denote
modied or completely changed meaning in the
process of reduplication the last syllable of the
compound root is partially reduplicated by replac
ing its initial consonant the following are some
of the most commonly used reduplicated com
pound adjectives for example root  root 
reduplicate
themreaksek  them  skill reak  pretend 
proceeding of regional international conference on natura l language processing regicon 2017 3rd and 4th
november 2017 iiit senapati manipur india
case marker sufx example
locative case marker li wui manipurli in manipur
genitive case marker chi  avichi his
nominative case marker na khipana who
table 1 few case markers with example
sek  redu
approximate english meaning pretending to
be very skillful or learned
khonzartar  khon  sound  zar dense  tar
redu
approximate english meaning very noisy
3 corpus preparation and preprocessing
as the existence of the language is very rare in
web we have manually collectedtyped few texts
for our experiment the current version of the
corpus contains 21713 words out of which 7362
are unique words include inections the arti
cles or segment of articles in the corpus can be
categoried into biography 4 numbers short story
6 numbers essay 11 numbers drama 2 num
bers and letter 1 number with average approx
imately 904 words per article the rst ten fre
quent words in the corpus are tabulated in table 2
sr no word meaning frequency
1 eina with 708
2 hi this 367
3 chi that 358
4 kala and 336
5 da 184
6 haowa 130
7 kaji that 122
8  akha one 122
9  awui his 120
10 chili there 110
table 2 ten most frequent words in the corpus
for our experiment we use morfessor
creutz and lagus 2005  version 101 an un
supervised language independent morphology
learning package to discover the regularities
behind the word formation process this leaning
approach discovers the primitive morphological
units such as rootbasestem2 sufx and prex
1httpwwwhttpmorphoaaltoprojectsmorpho ac 
cess date 30 august 2017
2though there are differences in the concept of root baseof the utterances of a language as it is based on
words or utterance of the language and its fre
quency most of the time the tool discovers prex
in sequence stem and sufx in sequence
during experiment we found that a word may
have maximum seven different morpheme mostly
sequence of afxes the morpheme frequency
with example is tabulated in table 3 we also
found that the corpus contains a good number of
borrowed words from english and neighbouring
languages
the following examples shows the morphologi
cal richness of the considered language segmented
using morfessor
maphaning  not thinking   ma  no  phaning
thinking 
maphaninsali  ma  pha  nin  sa  li
map amsangmara  ma  p a  m  sa  ng  mara
khamashash ali  kha  ma  sha  sh   ali
kakhararkhangazai  ka  kharar  kha  nga 
zai
 ach ahonthangcham   a  ch a  hon  thang 
cham
the following are few examples the morfessor
segmented correctly
a  cham   aram
 a  lung  th  ung  li
 a  ng   a  ng  nao  li
a  ri  shang  li
table 4tabulated few words incorrectly segmented
by morfessor
interestingly during segmentation based on the
evidence in the corpus the tool is splitting the
following english words used as loan words in
tangkhul table 5
in the context of loan words another interesting
example we found is acid  p a  va  though the
root the rst morpheme is a valid loan word the
context actually was indicating the root aship ava
means wife
and stem for this experiment we are using these terms inter
changeably to indicate stem
proceeding of regional international conference on natura l language processing regicon 2017 3rd and 4th
november 2017 iiit senapati manipur india
words with no afx 1772 example khana
words with one afx 3600 example advocatela
words with two afxes 1487 example  athingreirawui
words with three afxes 410 example kajuikhanem
words with four afxes 78 example lungthungli
words with ve afxes 12 example langdangl ana
words with six afxes 3 example khangapeobinglila
table 3 afx frequency distribution in the corpus
wrong by morfessor correct
 a  k a  khare  wui  a  k a  kha  re  wui
 a  mathen  pai  ra  a  ma  then  pai  ra
 a  ngas am  khuiya  a  nga  s am  khui  ya
table 4 incorrect segmentation of words
acqui  red wrong
activ  ities wrong
activ  ity wrong
administra  tion  wui wrong
table 5 segmentation of loan words
4 conclusion
the demand for localization through electronic
content has made the globe a smaller place and
any digital divide in this regard has to be reduced
through the inclusion of more naturally occur
ring languages through the information technol
ogy revolution towards this direction the present
task is a step to bring tangkhul into the language
technology revolution in the present work we
reported the morphological processing work of
tangkhul using an unsupervised approach we
found the result of the experiment to be reasonably
good as compared to the size of the corpus used
in the work our future direction includes more
experiment on this by including language specic
rules and other semisupervised approaches
references
victor ahum 1997 tangkhulnaga grammar a
study of word formation  phd thesis
mathias creutz and krista lagus 2005 unsupervised
morpheme segmentation and morphology induction
from text corpora using morfessor 10 technical
report
khumbar debbarma braja gopal patra swapan
debbarma lalita kumari and bipul shyampurkayastha 2012 morphological analysis of kok
borok for universal networking language dictio
nary in recent advances in information technol
ogy rait 2012 1st international conference on 
ieee pages 474477
prasenjit majumder mandar mitra swapan k parui
gobinda kole pabitra mitra and kalyankumar
datta 2007 yass yet another sufx stripper
acm transactions on information systems tois
25418
david mortensen 2003 comparative tangkhul uni
versity of california berkeley 
partha pakray arunagshu pal goutam majumder and
alexander gelbukh 2015 resource building and
partsofspeech pos tagging for the mizo language
inarticial intelligence micai 2015 fourteenth
mexican international conference on  ieee pages
37
navanath saharia utpal sharma and jugal kalita
2014 stemming resourcepoor indian languages
acm transactions on asian language information
processing talip 13314
priyankoo sarmah 2004 some aspects of the tonal
phonology of bodo  phd thesis english and for
eign languages university hyderabad
thoudam doren singh and sivaji bandyopadhyay
2008 morphology driven manipuri pos tagger in
ijcnlp  pages 9198
proceeding of regional international conference on natura l language processing regicon 2017 3rd and 4th
november 2017 iiit senapati manipur india","['1httpwwwhttpmorphoaaltoprojectsmorpho', 'ahonthangcham', 'arxiv200616212v1', 'compoundingcompounding', 'tibetoburman', 'maphaninsali', 'khangapeobinglila', 'khonzartar', 'kakhararkhangazai', 'khaikao']",3
A Primer on Neural Network Models for Natural Language Processing,['Yoav Goldberg'],2015,http://arxiv.org/abs/1510.00726v1,"A Primer on Neural Network Models
for Natural Language Processing
Yoav Goldberg
Draft as of October 6, 2015.
The most up-to-date version of this manuscript is available at http://www.cs.biu.
ac.il/ ˜yogo/nnlp.pdf . Major updates will be published on arxiv periodically.
I welcome any comments you may have regarding the content and presentation. If you
spot a missing reference or have relevant work you'd like to see mentioned, do let me know.
first.last@gmail
Abstract
Over the past few years, neural networks have re-emerged as powerful machine-learning
models, yielding state-of-the-art results in elds such as image recognition and speech
processing. More recently, neural network models started to be applied also to textual
natural language signals, again with very promising results. This tutorial surveys neural
network models from the perspective of natural language processing research, in an attempt
to bring natural-language researchers up to speed with the neural techniques. The tutorial
covers input encoding for natural language tasks, feed-forward networks, convolutional
networks, recurrent networks and recursive networks, as well as the computation graph
abstraction for automatic gradient computation.
1. Introduction
For a long time, core NLP techniques were dominated by machine-learning approaches that
used linear models such as support vector machines or logistic regression, trained over very
high dimensional yet very sparse feature vectors.
Recently, the eld has seen some success in switching from such linear models over
sparse inputs to non-linear neural-network models over dense inputs. While most of the
neural network techniques are easy to apply, sometimes as almost drop-in replacements of
the old linear classiers, there is in many cases a strong barrier of entry. In this tutorial I
attempt to provide NLP practitioners (as well as newcomers) with the basic background,
jargon, tools and methodology that will allow them to understand the principles behind
the neural network models and apply them to their own work. This tutorial is expected
to be self-contained, while presenting the dierent approaches under a unied notation and
framework. It repeats a lot of material which is available elsewhere. It also points to
external sources for more advanced topics when appropriate.
This primer is not intended as a comprehensive resource for those that will go on and
develop the next advances in neural-network machinery (though it may serve as a good entry
point). Rather, it is aimed at those readers who are interested in taking the existing, useful
technology and applying it in useful and creative ways to their favourite NLP problems. For
more in-depth, general discussion of neural networks, the theory behind them, advanced
1arXiv:1510.00726v1  [cs.CL]  2 Oct 2015
optimization methods and other advanced topics, the reader is referred to other existing
resources. In particular, the book by Bengio et al (2015) is highly recommended.
Scope The focus is on applications of neural networks to language processing tasks. How-
ever, some subareas of language processing with neural networks were decidedly left out of
scope of this tutorial. These include the vast literature of language modeling and acoustic
modeling, the use of neural networks for machine translation, and multi-modal applications
combining language and other signals such as images and videos (e.g. caption generation).
Caching methods for ecient runtime performance, methods for ecient training with large
output vocabularies and attention models are also not discussed. Word embeddings are dis-
cussed only to the extent that is needed to understand in order to use them as inputs for
other models. Other unsupervised approaches, including autoencoders and recursive au-
toencoders, also fall out of scope. While some applications of neural networks for language
modeling and machine translation are mentioned in the text, their treatment is by no means
comprehensive.
A Note on Terminology The word \feature"" is used to refer to a concrete, linguistic
input such as a word, a sux, or a part-of-speech tag. For example, in a rst-order part-
of-speech tagger, the features might be \current word, previous word, next word, previous
part of speech"". The term \input vector"" is used to refer to the actual input that is fed
to the neural-network classier. Similarly, \input vector entry"" refers to a specic value
of the input. This is in contrast to a lot of the neural networks literature in which the
word \feature"" is overloaded between the two uses, and is used primarily to refer to an
input-vector entry.
Mathematical Notation I use bold upper case letters to represent matrices ( X,Y,
Z), and bold lower-case letters to represent vectors ( b). When there are series of related
matrices and vectors (for example, where each matrix corresponds to a dierent layer in
the network), superscript indices are used ( W1,W2). For the rare cases in which we want
indicate the power of a matrix or a vector, a pair of brackets is added around the item to
be exponentiated: ( W)2;(W3)2. Unless otherwise stated, vectors are assumed to be row
vectors. We use [ v1;v2] to denote vector concatenation.
2
2. Neural Network Architectures
Neural networks are powerful learning models. We will discuss two kinds of neural network
architectures, that can be mixed and matched { feed-forward networks and Recurrent /
Recursive networks. Feed-forward networks include networks with fully connected layers,
such as the multi-layer perceptron, as well as networks with convolutional and pooling
layers. All of the networks act as classiers, but each with dierent strengths.
Fully connected feed-forward neural networks (Section 4) are non-linear learners that
can, for the most part, be used as a drop-in replacement wherever a linear learner is used.
This includes binary and multiclass classication problems, as well as more complex struc-
tured prediction problems (Section 8). The non-linearity of the network, as well as the
ability to easily integrate pre-trained word embeddings, often lead to superior classication
accuracy. A series of works (Chen & Manning, 2014; Weiss, Alberti, Collins, & Petrov,
2015; Pei, Ge, & Chang, 2015; Durrett & Klein, 2015) managed to obtain improved syntac-
tic parsing results by simply replacing the linear model of a parser with a fully connected
feed-forward network. Straight-forward applications of a feed-forward network as a classi-
er replacement (usually coupled with the use of pre-trained word vectors) provide benets
also for CCG supertagging (Lewis & Steedman, 2014), dialog state tracking (Henderson,
Thomson, & Young, 2013), pre-ordering for statistical machine translation (de Gispert,
Iglesias, & Byrne, 2015) and language modeling (Bengio, Ducharme, Vincent, & Janvin,
2003; Vaswani, Zhao, Fossum, & Chiang, 2013). Iyyer et al (2015) demonstrate that multi-
layer feed-forward networks can provide competitive results on sentiment classication and
factoid question answering.
Networks with convolutional and pooling layers (Section 9) are useful for classication
tasks in which we expect to nd strong local clues regarding class membership, but these
clues can appear in dierent places in the input. For example, in a document classication
task, a single key phrase (or an ngram) can help in determining the topic of the document
(Johnson & Zhang, 2015). We would like to learn that certain sequences of words are good
indicators of the topic, and do not necessarily care where they appear in the document.
Convolutional and pooling layers allow the model to learn to nd such local indicators,
regardless of their position. Convolutional and pooling architecture show promising results
on many tasks, including document classication (Johnson & Zhang, 2015), short-text cat-
egorization (Wang, Xu, Xu, Liu, Zhang, Wang, & Hao, 2015a), sentiment classication
(Kalchbrenner, Grefenstette, & Blunsom, 2014; Kim, 2014), relation type classication be-
tween entities (Zeng, Liu, Lai, Zhou, & Zhao, 2014; dos Santos, Xiang, & Zhou, 2015), event
detection (Chen, Xu, Liu, Zeng, & Zhao, 2015; Nguyen & Grishman, 2015), paraphrase iden-
tication (Yin & Sch utze, 2015) semantic role labeling (Collobert, Weston, Bottou, Karlen,
Kavukcuoglu, & Kuksa, 2011), question answering (Dong, Wei, Zhou, & Xu, 2015), predict-
ing box-oce revenues of movies based on critic reviews (Bitvai & Cohn, 2015) modeling
text interestingness (Gao, Pantel, Gamon, He, & Deng, 2014), and modeling the relation
between character-sequences and part-of-speech tags (Santos & Zadrozny, 2014).
In natural language we often work with structured data of arbitrary sizes, such as
sequences and trees. We would like to be able to capture regularities in such structures,
or to model similarities between such structures. In many cases, this means encoding
the structure as a xed width vector, which we can then pass on to another statistical
3
learner for further processing. While convolutional and pooling architectures allow us to
encode arbitrary large items as xed size vectors capturing their most salient features,
they do so by sacricing most of the structural information. Recurrent (Section 10) and
recursive (Section 12) architectures, on the other hand, allow us to work with sequences
and trees while preserving a lot of the structural information. Recurrent networks (Elman,
1990) are designed to model sequences, while recursive networks (Goller & K uchler, 1996)
are generalizations of recurrent networks that can handle trees. We will also discuss an
extension of recurrent networks that allow them to model stacks (Dyer, Ballesteros, Ling,
Matthews, & Smith, 2015; Watanabe & Sumita, 2015).
Recurrent models have been shown to produce very strong results for language model-
ing, including (Mikolov, Kara at, Burget, Cernocky, & Khudanpur, 2010; Mikolov, Kom-
brink, Luk a s Burget, Cernocky, & Khudanpur, 2011; Mikolov, 2012; Duh, Neubig, Sudoh,
& Tsukada, 2013; Adel, Vu, & Schultz, 2013; Auli, Galley, Quirk, & Zweig, 2013; Auli &
Gao, 2014); as well as for sequence tagging (Irsoy & Cardie, 2014; Xu, Auli, & Clark, 2015;
Ling, Dyer, Black, Trancoso, Fermandez, Amir, Marujo, & Luis, 2015b), machine transla-
tion (Sundermeyer, Alkhouli, Wuebker, & Ney, 2014; Tamura, Watanabe, & Sumita, 2014;
Sutskever, Vinyals, & Le, 2014; Cho, van Merrienboer, Gulcehre, Bahdanau, Bougares,
Schwenk, & Bengio, 2014b), dependency parsing (Dyer et al., 2015; Watanabe & Sumita,
2015), sentiment analysis (Wang, Liu, SUN, Wang, & Wang, 2015b), noisy text normal-
ization (Chrupala, 2014), dialog state tracking (Mrk si c, O S eaghdha, Thomson, Gasic, Su,
Vandyke, Wen, & Young, 2015), response generation (Sordoni, Galley, Auli, Brockett, Ji,
Mitchell, Nie, Gao, & Dolan, 2015), and modeling the relation between character sequences
and part-of-speech tags (Ling et al., 2015b).
Recursive models were shown to produce state-of-the-art or near state-of-the-art re-
sults for constituency (Socher, Bauer, Manning, & Andrew Y., 2013) and dependency (Le
& Zuidema, 2014; Zhu, Qiu, Chen, & Huang, 2015a) parse re-ranking, discourse parsing
(Li, Li, & Hovy, 2014), semantic relation classication (Hashimoto, Miwa, Tsuruoka, &
Chikayama, 2013; Liu, Wei, Li, Ji, Zhou, & WANG, 2015), political ideology detection
based on parse trees (Iyyer, Enns, Boyd-Graber, & Resnik, 2014b), sentiment classication
(Socher, Perelygin, Wu, Chuang, Manning, Ng, & Potts, 2013; Hermann & Blunsom, 2013),
target-dependent sentiment classication (Dong, Wei, Tan, Tang, Zhou, & Xu, 2014) and
question answering (Iyyer, Boyd-Graber, Claudino, Socher, & Daum e III, 2014a).
4
3. Feature Representation
Before discussing the network structure in more depth, it is important to pay attention
to how features are represented. For now, we can think of a feed-forward neural network
as a function NN(x) that takes as input a dindimensional vector xand produces a dout
dimensional output vector. The function is often used as a classier , assigning the input
xa degree of membership in one or more of doutclasses. The function can be complex,
and is almost always non-linear. Common structures of this function will be discussed
in Section 4. Here, we focus on the input, x. When dealing with natural language, the
input xencodes features such as words, part-of-speech tags or other linguistic information.
Perhaps the biggest jump when moving from sparse-input linear models to neural-network
based models is to stop representing each feature as a unique dimension (the so called
one-hot representation) and representing them instead as dense vectors. That is, each core
feature is embedded into addimensional space, and represented as a vector in that space.1
The embeddings (the vector representation of each core feature) can then be trained like
the other parameter of the function NN. Figure 1 shows the two approaches to feature
representation.
The feature embeddings (the values of the vector entries for each feature) are treated
asmodel parameters that need to be trained together with the other components of the
network. Methods of training (or obtaining) the feature embeddings will be discussed later.
For now, consider the feature embeddings as given.
The general structure for an NLP classication system based on a feed-forward neural
network is thus:
1. Extract a set of core linguistic features f1;:::;fkthat are relevant for predicting the
output class.
2. For each feature fiof interest, retrieve the corresponding vector v(fi).
3. Combine the vectors (either by concatenation, summation or a combination of both)
into an input vector x.
4. Feed xinto a non-linear classier (feed-forward neural network).
The biggest change in the input, then, is the move from sparse representations in which
each feature is its own dimension, to a dense representation in which each feature is mapped
to a vector. Another dierence is that we extract only core features and not feature com-
binations. We will elaborate on both these changes briey.
Dense Vectors vs. One-hot Representations What are the benets of representing
our features as vectors instead of as unique IDs? Should we always represent features as
dense vectors? Let's consider the two kinds of representations:
One Hot Each feature is its own dimension.
Dimensionality of one-hot vector is same as number of distinct features.
1. Dierent feature types may be embedded into dierent spaces. For example, one may represent word
features using 100 dimensions, and part-of-speech features using 20 dimensions.
5
Figure 1: Sparse vs. dense feature representations . Two encodings of the informa-
tion: current word is \dog""; previous word is \the""; previous pos-tag is \DET"" .
(a) Sparse feature vector. Each dimension represents a feature. Feature combi-
nations receive their own dimensions. Feature values are binary. Dimensionality
is very high. (b) Dense, embeddings-based feature vector. Each core feature is
represented as a vector. Each feature corresponds to several input vector en-
tries. No explicit encoding of feature combinations. Dimensionality is low. The
feature-to-vector mappings come from an embedding table.
Features are completely independent from one another. The feature \word is
`dog' "" is as dis-similar to \word is `thinking' "" than it is to \word is `cat' "".
Dense Each feature is a d-dimensional vector.
Dimensionality of vector is d.
Similar features will have similar vectors { information is shared between similar
features.
One benet of using dense and low-dimensional vectors is computational: the majority
of neural network toolkits do not play well with very high-dimensional, sparse vectors.
However, this is just a technical obstacle, which can be resolved with some engineering
eort.
The main benet of the dense representations is in generalization power: if we believe
some features may provide similar clues, it is worthwhile to provide a representation that
is able to capture these similarities. For example, assume we have observed the word `dog'
many times during training, but only observed the word `cat' a handful of times, or not at
6
all. If each of the words is associated with its own dimension, occurrences of `dog' will not
tell us anything about the occurrences of `cat'. However, in the dense vectors representation
the learned vector for `dog' may be similar to the learned vector from `cat', allowing the
model to share statistical strength between the two events. This argument assumes that
\good"" vectors are somehow given to us. Section 5 describes ways of obtaining such vector
representations.
In cases where we have relatively few distinct features in the category, and we believe
there are no correlations between the dierent features, we may use the one-hot representa-
tion. However, if we believe there are going to be correlations between the dierent features
in the group (for example, for part-of-speech tags, we may believe that the dierent verb
inections VBandVBZ may behave similarly as far as our task is concerned) it may be
worthwhile to let the network gure out the correlations and gain some statistical strength
by sharing the parameters. It may be the case that under some circumstances, when the
feature space is relatively small and the training data is plentiful, or when we do not wish to
share statistical information between distinct words, there are gains to be made from using
the one-hot representations. However, this is still an open research question, and there are
no strong evidence to either side. The majority of work (pioneered by (Collobert & Weston,
2008; Collobert et al., 2011; Chen & Manning, 2014)) advocate the use of dense, trainable
embedding vectors for all features. For work using neural network architecture with sparse
vector encodings see (Johnson & Zhang, 2015).
Finally, it is important to note that representing features as dense vectors is an integral
part of the neural network framework, and that consequentially the dierences between
using sparse and dense feature representations are subtler than they may appear at rst.
In fact, using sparse, one-hot vectors as input when training a neural network amounts
to dedicating the rst layer of the network to learning a dense embedding vector for each
feature based on the training data. We touch on this in Section 4.4.
Variable Number of Features: Continuous Bag of Words Feed-forward networks
assume a xed dimensional input. This can easily accommodate the case of a feature-
extraction function that extracts a xed number of features: each feature is represented
as a vector, and the vectors are concatenated. This way, each region of the resulting
input vector corresponds to a dierent feature. However, in some cases the number of
features is not known in advance (for example, in document classication it is common
that each word in the sentence is a feature). We thus need to represent an unbounded
number of features using a xed size vector. One way of achieving this is through a so-
called continuous bag of words (CBOW) representation (Mikolov, Chen, Corrado, & Dean,
2013). The CBOW is very similar to the traditional bag-of-words representation in which
we discard order information, and works by either summing or averaging the embedding
vectors of the corresponding features:2
2. Note that if the v(fi)s were one-hot vectors rather than dense feature representations, the CBOW and
WCBOW equations above would reduce to the traditional (weighted) bag-of-words representations,
which is in turn equivalent to a sparse feature-vector representation in which each binary indicator
feature corresponds to a unique \word"".
7
CBOW (f1;:::;fk) =1
kkX
i=1v(fi)
A simple variation on the CBOW representation is weighted CBOW, in which dierent
vectors receive dierent weights:
WCBOW (f1;:::;fk) =1Pk
i=1aikX
i=1aiv(fi)
Here, each feature fihas an associated weight ai, indicating the relative importance of
the feature. For example, in a document classication task, a feature fimay correspond to
a word in the document, and the associated weight aicould be the word's TF-IDF score.
Distance and Position Features The linear distance in between two words in a sentence
may serve as an informative feature. For example, in an event extraction task3we may be
given a trigger word and a candidate argument word, and asked to predict if the argument
word is indeed an argument of the trigger. The distance (or relative position) between the
trigger and the argument is a strong signal for this prediction task. In the \traditional"" NLP
setup, distances are usually encoded by binning the distances into several groups (i.e. 1, 2,
3, 4, 5{10, 10+) and associating each bin with a one-hot vector. In a neural architecture,
where the input vector is not composed of binary indicator features, it may seem natural to
allocate a single input vector entry to the distance feature, where the numeric value of that
entry is the distance. However, this approach is not taken in practice. Instead, distance
features are encoded similarly to the other feature types: each bin is associated with a
d-dimensional vector, and these distance-embedding vectors are then trained as regular
parameters in the network (Zeng et al., 2014; dos Santos et al., 2015; Zhu et al., 2015a;
Nguyen & Grishman, 2015).
Feature Combinations Note that the feature extraction stage in the neural-network
settings deals only with extraction of core features. This is in contrast to the traditional
linear-model-based NLP systems in which the feature designer had to manually specify not
only the core features of interests but also interactions between them (e.g., introducing not
only a feature stating \word is X"" and a feature stating \tag is Y"" but also combined feature
stating \word is X and tag is Y"" or sometimes even \word is X, tag is Y and previous word
is Z""). The combination features are crucial in linear models because they introduce more
dimensions to the input, transforming it into a space where the data-points are closer to
being linearly separable. On the other hand, the space of possible combinations is very
large, and the feature designer has to spend a lot of time coming up with an eective
set of feature combinations. One of the promises of the non-linear neural network models
is that one needs to dene only the core features. The non-linearity of the classier, as
dened by the network structure, is expected to take care of nding the indicative feature
combinations, alleviating the need for feature combination engineering.
3. The event extraction task involves identication of events from a predened set of event types. For
example identication of \purchase"" events or \terror-attack"" events. Each event type can be triggered
by various triggering words (commonly verbs), and has several slots (arguments) that needs to be lled
(i.e. who purchased? what was purchased? at what amount?).
8
Kernel methods (Shawe-Taylor & Cristianini, 2004), and in particular polynomial kernels
(Kudo & Matsumoto, 2003), also allow the feature designer to specify only core features,
leaving the feature combination aspect to the learning algorithm. In contrast to neural-
network models, kernels methods are convex, admitting exact solutions to the optimization
problem. However, the classication eciency in kernel methods scales linearly with the
size of the training data, making them too slow for most practical purposes, and not suitable
for training with large datasets. On the other hand, neural network classication eciency
scales linearly with the size of the network, regardless of the training data size.
Dimensionality How many dimensions should we allocate for each feature? Unfortu-
nately, there are no theoretical bounds or even established best-practices in this space.
Clearly, the dimensionality should grow with the number of the members in the class (you
probably want to assign more dimensions to word embeddings than to part-of-speech embed-
dings) but how much is enough? In current research, the dimensionality of word-embedding
vectors range between about 50 to a few hundreds, and, in some extreme cases, thousands.
Since the dimensionality of the vectors has a direct eect on memory requirements and
processing time, a good rule of thumb would be to experiment with a few dierent sizes,
and choose a good trade-o between speed and task accuracy.
Vector Sharing Consider a case where you have a few features that share the same
vocabulary. For example, when assigning a part-of-speech to a given word, we may have a
set of features considering the previous word, and a set of features considering the next word.
When building the input to the classier, we will concatenate the vector representation of
the previous word to the vector representation of the next word. The classier will then
be able to distinguish the two dierent indicators, and treat them dierently. But should
the two features share the same vectors? Should the vector for \dog:previous-word"" be the
same as the vector of \dog:next-word""? Or should we assign them two distinct vectors?
This, again, is mostly an empirical question. If you believe words behave dierently when
they appear in dierent positions (e.g., word X behaves like word Y when in the previous
position, but X behaves like Z when in the next position) then it may be a good idea to
use two dierent vocabularies and assign a dierent set of vectors for each feature type.
However, if you believe the words behave similarly in both locations, then something may
be gained by using a shared vocabulary for both feature types.
Network's Output For multi-class classication problems with kclasses, the network's
output is a k-dimensional vector in which every dimension represents the strength of a
particular output class. That is, the output remains as in the traditional linear models {
scalar scores to items in a discrete set. However, as we will see in Section 4, there is a dk
matrix associated with the output layer. The columns of this matrix can be thought of as
ddimensional embeddings of the output classes. The vector similarities between the vector
representations of the kclasses indicate the model's learned similarities between the output
classes.
Historical Note Representing words as dense vectors for input to a neural network was
introduced by Bengio et al (Bengio et al., 2003) in the context of neural language modeling.
It was introduced to NLP tasks in the pioneering work of Collobert, Weston and colleagues
9
(2008, 2011). Using embeddings for representing not only words but arbitrary features was
popularized following Chen and Manning (2014).
10
4. Feed-forward Neural Networks
A Brain-inspired metaphor As the name suggest, neural-networks are inspired by the
brain's computation mechanism, which consists of computation units called neurons. In the
metaphor, a neuron is a computational unit that has scalar inputs and outputs. Each input
has an associated weight. The neuron multiplies each input by its weight, and then sums4
them, applies a non-linear function to the result, and passes it to its output. The neurons
are connected to each other, forming a network: the output of a neuron may feed into the
inputs of one or more neurons. Such networks were shown to be very capable computational
devices. If the weights are set correctly, a neural network with enough neurons and a non-
linear activation function can approximate a very wide range of mathematical functions (we
will be more precise about this later).
x1x2x3x4 Input layerRRRRRR Hidden
layerRRRRR Hidden
layery1y2y3Output
layer
Figure 2: Feed-forward neural network with two hidden layers.
A typical feed-forward neural network may be drawn as in Figure 2. Each circle is a
neuron, with incoming arrows being the neuron's inputs and outgoing arrows being the neu-
ron's outputs. Each arrow carries a weight, reecting its importance (not shown). Neurons
are arranged in layers, reecting the ow of information. The bottom layer has no incom-
ing arrows, and is the input to the network. The top-most layer has no outgoing arrows,
and is the output of the network. The other layers are considered \hidden"". The sigmoid
shape inside the neurons in the middle layers represent a non-linear function (typically a
1=(1 +e","a primer on neural network models
for natural language processing
yoav goldberg
draft as of october 6 2015
the most uptodate version of this manuscript is available at httpwwwcsbiu
acil yogonnlppdf  major updates will be published on arxiv periodically
i welcome any comments you may have regarding the content and presentation if you
spot a missing reference or have relevant work youd like to see mentioned do let me know
firstlastgmail
abstract
over the past few years neural networks have reemerged as powerful machinelearning
models yielding stateoftheart results in elds such as image recognition and speech
processing more recently neural network models started to be applied also to textual
natural language signals again with very promising results this tutorial surveys neural
network models from the perspective of natural language processing research in an attempt
to bring naturallanguage researchers up to speed with the neural techniques the tutorial
covers input encoding for natural language tasks feedforward networks convolutional
networks recurrent networks and recursive networks as well as the computation graph
abstraction for automatic gradient computation
1 introduction
for a long time core nlp techniques were dominated by machinelearning approaches that
used linear models such as support vector machines or logistic regression trained over very
high dimensional yet very sparse feature vectors
recently the eld has seen some success in switching from such linear models over
sparse inputs to nonlinear neuralnetwork models over dense inputs while most of the
neural network techniques are easy to apply sometimes as almost dropin replacements of
the old linear classiers there is in many cases a strong barrier of entry in this tutorial i
attempt to provide nlp practitioners as well as newcomers with the basic background
jargon tools and methodology that will allow them to understand the principles behind
the neural network models and apply them to their own work this tutorial is expected
to be selfcontained while presenting the dierent approaches under a unied notation and
framework it repeats a lot of material which is available elsewhere it also points to
external sources for more advanced topics when appropriate
this primer is not intended as a comprehensive resource for those that will go on and
develop the next advances in neuralnetwork machinery though it may serve as a good entry
point rather it is aimed at those readers who are interested in taking the existing useful
technology and applying it in useful and creative ways to their favourite nlp problems for
more indepth general discussion of neural networks the theory behind them advanced
1arxiv151000726v1  cscl  2 oct 2015
optimization methods and other advanced topics the reader is referred to other existing
resources in particular the book by bengio et al 2015 is highly recommended
scope the focus is on applications of neural networks to language processing tasks how
ever some subareas of language processing with neural networks were decidedly left out of
scope of this tutorial these include the vast literature of language modeling and acoustic
modeling the use of neural networks for machine translation and multimodal applications
combining language and other signals such as images and videos eg caption generation
caching methods for ecient runtime performance methods for ecient training with large
output vocabularies and attention models are also not discussed word embeddings are dis
cussed only to the extent that is needed to understand in order to use them as inputs for
other models other unsupervised approaches including autoencoders and recursive au
toencoders also fall out of scope while some applications of neural networks for language
modeling and machine translation are mentioned in the text their treatment is by no means
comprehensive
a note on terminology the word feature is used to refer to a concrete linguistic
input such as a word a sux or a partofspeech tag for example in a rstorder part
ofspeech tagger the features might be current word previous word next word previous
part of speech the term input vector is used to refer to the actual input that is fed
to the neuralnetwork classier similarly input vector entry refers to a specic value
of the input this is in contrast to a lot of the neural networks literature in which the
word feature is overloaded between the two uses and is used primarily to refer to an
inputvector entry
mathematical notation i use bold upper case letters to represent matrices  xy
z and bold lowercase letters to represent vectors  b when there are series of related
matrices and vectors for example where each matrix corresponds to a dierent layer in
the network superscript indices are used  w1w2 for the rare cases in which we want
indicate the power of a matrix or a vector a pair of brackets is added around the item to
be exponentiated  w2w32 unless otherwise stated vectors are assumed to be row
vectors we use  v1v2 to denote vector concatenation
2
2 neural network architectures
neural networks are powerful learning models we will discuss two kinds of neural network
architectures that can be mixed and matched  feedforward networks and recurrent 
recursive networks feedforward networks include networks with fully connected layers
such as the multilayer perceptron as well as networks with convolutional and pooling
layers all of the networks act as classiers but each with dierent strengths
fully connected feedforward neural networks section 4 are nonlinear learners that
can for the most part be used as a dropin replacement wherever a linear learner is used
this includes binary and multiclass classication problems as well as more complex struc
tured prediction problems section 8 the nonlinearity of the network as well as the
ability to easily integrate pretrained word embeddings often lead to superior classication
accuracy a series of works chen  manning 2014 weiss alberti collins  petrov
2015 pei ge  chang 2015 durrett  klein 2015 managed to obtain improved syntac
tic parsing results by simply replacing the linear model of a parser with a fully connected
feedforward network straightforward applications of a feedforward network as a classi
er replacement usually coupled with the use of pretrained word vectors provide benets
also for ccg supertagging lewis  steedman 2014 dialog state tracking henderson
thomson  young 2013 preordering for statistical machine translation de gispert
iglesias  byrne 2015 and language modeling bengio ducharme vincent  janvin
2003 vaswani zhao fossum  chiang 2013 iyyer et al 2015 demonstrate that multi
layer feedforward networks can provide competitive results on sentiment classication and
factoid question answering
networks with convolutional and pooling layers section 9 are useful for classication
tasks in which we expect to nd strong local clues regarding class membership but these
clues can appear in dierent places in the input for example in a document classication
task a single key phrase or an ngram can help in determining the topic of the document
johnson  zhang 2015 we would like to learn that certain sequences of words are good
indicators of the topic and do not necessarily care where they appear in the document
convolutional and pooling layers allow the model to learn to nd such local indicators
regardless of their position convolutional and pooling architecture show promising results
on many tasks including document classication johnson  zhang 2015 shorttext cat
egorization wang xu xu liu zhang wang  hao 2015a sentiment classication
kalchbrenner grefenstette  blunsom 2014 kim 2014 relation type classication be
tween entities zeng liu lai zhou  zhao 2014 dos santos xiang  zhou 2015 event
detection chen xu liu zeng  zhao 2015 nguyen  grishman 2015 paraphrase iden
tication yin  sch utze 2015 semantic role labeling collobert weston bottou karlen
kavukcuoglu  kuksa 2011 question answering dong wei zhou  xu 2015 predict
ing boxoce revenues of movies based on critic reviews bitvai  cohn 2015 modeling
text interestingness gao pantel gamon he  deng 2014 and modeling the relation
between charactersequences and partofspeech tags santos  zadrozny 2014
in natural language we often work with structured data of arbitrary sizes such as
sequences and trees we would like to be able to capture regularities in such structures
or to model similarities between such structures in many cases this means encoding
the structure as a xed width vector which we can then pass on to another statistical
3
learner for further processing while convolutional and pooling architectures allow us to
encode arbitrary large items as xed size vectors capturing their most salient features
they do so by sacricing most of the structural information recurrent section 10 and
recursive section 12 architectures on the other hand allow us to work with sequences
and trees while preserving a lot of the structural information recurrent networks elman
1990 are designed to model sequences while recursive networks goller  k uchler 1996
are generalizations of recurrent networks that can handle trees we will also discuss an
extension of recurrent networks that allow them to model stacks dyer ballesteros ling
matthews  smith 2015 watanabe  sumita 2015
recurrent models have been shown to produce very strong results for language model
ing including mikolov kara at burget cernocky  khudanpur 2010 mikolov kom
brink luk a s burget cernocky  khudanpur 2011 mikolov 2012 duh neubig sudoh
 tsukada 2013 adel vu  schultz 2013 auli galley quirk  zweig 2013 auli 
gao 2014 as well as for sequence tagging irsoy  cardie 2014 xu auli  clark 2015
ling dyer black trancoso fermandez amir marujo  luis 2015b machine transla
tion sundermeyer alkhouli wuebker  ney 2014 tamura watanabe  sumita 2014
sutskever vinyals  le 2014 cho van merrienboer gulcehre bahdanau bougares
schwenk  bengio 2014b dependency parsing dyer et al 2015 watanabe  sumita
2015 sentiment analysis wang liu sun wang  wang 2015b noisy text normal
ization chrupala 2014 dialog state tracking mrk si c o s eaghdha thomson gasic su
vandyke wen  young 2015 response generation sordoni galley auli brockett ji
mitchell nie gao  dolan 2015 and modeling the relation between character sequences
and partofspeech tags ling et al 2015b
recursive models were shown to produce stateoftheart or near stateoftheart re
sults for constituency socher bauer manning  andrew y 2013 and dependency le
 zuidema 2014 zhu qiu chen  huang 2015a parse reranking discourse parsing
li li  hovy 2014 semantic relation classication hashimoto miwa tsuruoka 
chikayama 2013 liu wei li ji zhou  wang 2015 political ideology detection
based on parse trees iyyer enns boydgraber  resnik 2014b sentiment classication
socher perelygin wu chuang manning ng  potts 2013 hermann  blunsom 2013
targetdependent sentiment classication dong wei tan tang zhou  xu 2014 and
question answering iyyer boydgraber claudino socher  daum e iii 2014a
4
3 feature representation
before discussing the network structure in more depth it is important to pay attention
to how features are represented for now we can think of a feedforward neural network
as a function nnx that takes as input a dindimensional vector xand produces a dout
dimensional output vector the function is often used as a classier  assigning the input
xa degree of membership in one or more of doutclasses the function can be complex
and is almost always nonlinear common structures of this function will be discussed
in section 4 here we focus on the input x when dealing with natural language the
input xencodes features such as words partofspeech tags or other linguistic information
perhaps the biggest jump when moving from sparseinput linear models to neuralnetwork
based models is to stop representing each feature as a unique dimension the so called
onehot representation and representing them instead as dense vectors that is each core
feature is embedded into addimensional space and represented as a vector in that space1
the embeddings the vector representation of each core feature can then be trained like
the other parameter of the function nn figure 1 shows the two approaches to feature
representation
the feature embeddings the values of the vector entries for each feature are treated
asmodel parameters that need to be trained together with the other components of the
network methods of training or obtaining the feature embeddings will be discussed later
for now consider the feature embeddings as given
the general structure for an nlp classication system based on a feedforward neural
network is thus
1 extract a set of core linguistic features f1fkthat are relevant for predicting the
output class
2 for each feature fiof interest retrieve the corresponding vector vfi
3 combine the vectors either by concatenation summation or a combination of both
into an input vector x
4 feed xinto a nonlinear classier feedforward neural network
the biggest change in the input then is the move from sparse representations in which
each feature is its own dimension to a dense representation in which each feature is mapped
to a vector another dierence is that we extract only core features and not feature com
binations we will elaborate on both these changes briey
dense vectors vs onehot representations what are the benets of representing
our features as vectors instead of as unique ids should we always represent features as
dense vectors lets consider the two kinds of representations
one hot each feature is its own dimension
dimensionality of onehot vector is same as number of distinct features
1 dierent feature types may be embedded into dierent spaces for example one may represent word
features using 100 dimensions and partofspeech features using 20 dimensions
5
figure 1 sparse vs dense feature representations  two encodings of the informa
tion current word is dog previous word is the previous postag is det 
a sparse feature vector each dimension represents a feature feature combi
nations receive their own dimensions feature values are binary dimensionality
is very high b dense embeddingsbased feature vector each core feature is
represented as a vector each feature corresponds to several input vector en
tries no explicit encoding of feature combinations dimensionality is low the
featuretovector mappings come from an embedding table
features are completely independent from one another the feature word is
dog  is as dissimilar to word is thinking  than it is to word is cat 
dense each feature is a ddimensional vector
dimensionality of vector is d
similar features will have similar vectors  information is shared between similar
features
one benet of using dense and lowdimensional vectors is computational the majority
of neural network toolkits do not play well with very highdimensional sparse vectors
however this is just a technical obstacle which can be resolved with some engineering
eort
the main benet of the dense representations is in generalization power if we believe
some features may provide similar clues it is worthwhile to provide a representation that
is able to capture these similarities for example assume we have observed the word dog
many times during training but only observed the word cat a handful of times or not at
6
all if each of the words is associated with its own dimension occurrences of dog will not
tell us anything about the occurrences of cat however in the dense vectors representation
the learned vector for dog may be similar to the learned vector from cat allowing the
model to share statistical strength between the two events this argument assumes that
good vectors are somehow given to us section 5 describes ways of obtaining such vector
representations
in cases where we have relatively few distinct features in the category and we believe
there are no correlations between the dierent features we may use the onehot representa
tion however if we believe there are going to be correlations between the dierent features
in the group for example for partofspeech tags we may believe that the dierent verb
inections vbandvbz may behave similarly as far as our task is concerned it may be
worthwhile to let the network gure out the correlations and gain some statistical strength
by sharing the parameters it may be the case that under some circumstances when the
feature space is relatively small and the training data is plentiful or when we do not wish to
share statistical information between distinct words there are gains to be made from using
the onehot representations however this is still an open research question and there are
no strong evidence to either side the majority of work pioneered by collobert  weston
2008 collobert et al 2011 chen  manning 2014 advocate the use of dense trainable
embedding vectors for all features for work using neural network architecture with sparse
vector encodings see johnson  zhang 2015
finally it is important to note that representing features as dense vectors is an integral
part of the neural network framework and that consequentially the dierences between
using sparse and dense feature representations are subtler than they may appear at rst
in fact using sparse onehot vectors as input when training a neural network amounts
to dedicating the rst layer of the network to learning a dense embedding vector for each
feature based on the training data we touch on this in section 44
variable number of features continuous bag of words feedforward networks
assume a xed dimensional input this can easily accommodate the case of a feature
extraction function that extracts a xed number of features each feature is represented
as a vector and the vectors are concatenated this way each region of the resulting
input vector corresponds to a dierent feature however in some cases the number of
features is not known in advance for example in document classication it is common
that each word in the sentence is a feature we thus need to represent an unbounded
number of features using a xed size vector one way of achieving this is through a so
called continuous bag of words cbow representation mikolov chen corrado  dean
2013 the cbow is very similar to the traditional bagofwords representation in which
we discard order information and works by either summing or averaging the embedding
vectors of the corresponding features2
2 note that if the vfis were onehot vectors rather than dense feature representations the cbow and
wcbow equations above would reduce to the traditional weighted bagofwords representations
which is in turn equivalent to a sparse featurevector representation in which each binary indicator
feature corresponds to a unique word
7
cbow f1fk 1
kkx
i1vfi
a simple variation on the cbow representation is weighted cbow in which dierent
vectors receive dierent weights
wcbow f1fk 1pk
i1aikx
i1aivfi
here each feature fihas an associated weight ai indicating the relative importance of
the feature for example in a document classication task a feature fimay correspond to
a word in the document and the associated weight aicould be the words tfidf score
distance and position features the linear distance in between two words in a sentence
may serve as an informative feature for example in an event extraction task3we may be
given a trigger word and a candidate argument word and asked to predict if the argument
word is indeed an argument of the trigger the distance or relative position between the
trigger and the argument is a strong signal for this prediction task in the traditional nlp
setup distances are usually encoded by binning the distances into several groups ie 1 2
3 4 510 10 and associating each bin with a onehot vector in a neural architecture
where the input vector is not composed of binary indicator features it may seem natural to
allocate a single input vector entry to the distance feature where the numeric value of that
entry is the distance however this approach is not taken in practice instead distance
features are encoded similarly to the other feature types each bin is associated with a
ddimensional vector and these distanceembedding vectors are then trained as regular
parameters in the network zeng et al 2014 dos santos et al 2015 zhu et al 2015a
nguyen  grishman 2015
feature combinations note that the feature extraction stage in the neuralnetwork
settings deals only with extraction of core features this is in contrast to the traditional
linearmodelbased nlp systems in which the feature designer had to manually specify not
only the core features of interests but also interactions between them eg introducing not
only a feature stating word is x and a feature stating tag is y but also combined feature
stating word is x and tag is y or sometimes even word is x tag is y and previous word
is z the combination features are crucial in linear models because they introduce more
dimensions to the input transforming it into a space where the datapoints are closer to
being linearly separable on the other hand the space of possible combinations is very
large and the feature designer has to spend a lot of time coming up with an eective
set of feature combinations one of the promises of the nonlinear neural network models
is that one needs to dene only the core features the nonlinearity of the classier as
dened by the network structure is expected to take care of nding the indicative feature
combinations alleviating the need for feature combination engineering
3 the event extraction task involves identication of events from a predened set of event types for
example identication of purchase events or terrorattack events each event type can be triggered
by various triggering words commonly verbs and has several slots arguments that needs to be lled
ie who purchased what was purchased at what amount
8
kernel methods shawetaylor  cristianini 2004 and in particular polynomial kernels
kudo  matsumoto 2003 also allow the feature designer to specify only core features
leaving the feature combination aspect to the learning algorithm in contrast to neural
network models kernels methods are convex admitting exact solutions to the optimization
problem however the classication eciency in kernel methods scales linearly with the
size of the training data making them too slow for most practical purposes and not suitable
for training with large datasets on the other hand neural network classication eciency
scales linearly with the size of the network regardless of the training data size
dimensionality how many dimensions should we allocate for each feature unfortu
nately there are no theoretical bounds or even established bestpractices in this space
clearly the dimensionality should grow with the number of the members in the class you
probably want to assign more dimensions to word embeddings than to partofspeech embed
dings but how much is enough in current research the dimensionality of wordembedding
vectors range between about 50 to a few hundreds and in some extreme cases thousands
since the dimensionality of the vectors has a direct eect on memory requirements and
processing time a good rule of thumb would be to experiment with a few dierent sizes
and choose a good tradeo between speed and task accuracy
vector sharing consider a case where you have a few features that share the same
vocabulary for example when assigning a partofspeech to a given word we may have a
set of features considering the previous word and a set of features considering the next word
when building the input to the classier we will concatenate the vector representation of
the previous word to the vector representation of the next word the classier will then
be able to distinguish the two dierent indicators and treat them dierently but should
the two features share the same vectors should the vector for dogpreviousword be the
same as the vector of dognextword or should we assign them two distinct vectors
this again is mostly an empirical question if you believe words behave dierently when
they appear in dierent positions eg word x behaves like word y when in the previous
position but x behaves like z when in the next position then it may be a good idea to
use two dierent vocabularies and assign a dierent set of vectors for each feature type
however if you believe the words behave similarly in both locations then something may
be gained by using a shared vocabulary for both feature types
networks output for multiclass classication problems with kclasses the networks
output is a kdimensional vector in which every dimension represents the strength of a
particular output class that is the output remains as in the traditional linear models 
scalar scores to items in a discrete set however as we will see in section 4 there is a dk
matrix associated with the output layer the columns of this matrix can be thought of as
ddimensional embeddings of the output classes the vector similarities between the vector
representations of the kclasses indicate the models learned similarities between the output
classes
historical note representing words as dense vectors for input to a neural network was
introduced by bengio et al bengio et al 2003 in the context of neural language modeling
it was introduced to nlp tasks in the pioneering work of collobert weston and colleagues
9
2008 2011 using embeddings for representing not only words but arbitrary features was
popularized following chen and manning 2014
10
4 feedforward neural networks
a braininspired metaphor as the name suggest neuralnetworks are inspired by the
brains computation mechanism which consists of computation units called neurons in the
metaphor a neuron is a computational unit that has scalar inputs and outputs each input
has an associated weight the neuron multiplies each input by its weight and then sums4
them applies a nonlinear function to the result and passes it to its output the neurons
are connected to each other forming a network the output of a neuron may feed into the
inputs of one or more neurons such networks were shown to be very capable computational
devices if the weights are set correctly a neural network with enough neurons and a non
linear activation function can approximate a very wide range of mathematical functions we
will be more precise about this later
x1x2x3x4 input layerrrrrrr hidden
layerrrrrr hidden
layery1y2y3output
layer
figure 2 feedforward neural network with two hidden layers
a typical feedforward neural network may be drawn as in figure 2 each circle is a
neuron with incoming arrows being the neurons inputs and outgoing arrows being the neu
rons outputs each arrow carries a weight reecting its importance not shown neurons
are arranged in layers reecting the ow of information the bottom layer has no incom
ing arrows and is the input to the network the topmost layer has no outgoing arrows
and is the output of the network the other layers are considered hidden the sigmoid
shape inside the neurons in the middle layers represent a nonlinear function typically a
11 e","['1arxiv151000726v1', 'linearmodelbased', 'embeddings', 'toolkits', 'vocabularies', 'wordembedding', 'embeddingsbased', 'x1x2x3x4', 'layery1y2y3output', 'distanceembedding']",1
Natural Language Understanding with Distributed Representation,['Kyunghyun Cho'],2015,http://arxiv.org/abs/1511.07916v1,"Natural Language Understanding with
Distributed Representation
Kyunghyun Cho
Courant Institute of Mathematical Sciences and
Center for Data Science,
New York University
November 26, 2015arXiv:1511.07916v1  [cs.CL]  24 Nov 2015
Abstract
This is a lecture note for the course DS-GA 3001 hNatural Language Understanding
with Distributed Representation iat the Center for Data Science1, New York University
in Fall, 2015. As the name of the course suggests, this lecture note introduces readers
to a neural network based approach to natural language understanding/processing. In
order to make it as self-contained as possible, I spend much time on describing basics of
machine learning and neural networks, only after which how they are used for natural
languages is introduced. On the language front, I almost solely focus on language
modelling and machine translation, two of which I personally ﬁnd most fascinating
and most fundamental to natural language understanding.
After about a month of lectures and about 40 pages of writing this lecture note, I
found this fascinating note [47] by Yoav Goldberg on neural network models for natural
language processing. This note deals with wider topics on natural language processing
with distributed representations in more details, and I highly recommend you to read it
(hopefully along with this lecture note.) I seriously wish Yoav had written it earlier so
that I could’ve simply used his excellent note for my course.
This lecture note had been written quite hastily as the course progressed, meaning
that I could spare only about 100 hours in total for this note. This is my lame excuse
for likely many mistakes in this lecture note, and I kindly ask for your understanding
in advance. Again, how grateful I would’ve been had I found Yoav’s note earlier.
I am planning to update this lecture note gradually over time, hoping that I will
be able to convince the Center for Data Science to let me teach the same course next
year. The latest version will always be available both in pdf and in latex source code
from https://github.com/nyu-dl/NLP_DL_Lecture_Note . The arXiv
version will be updated whenever a major revision is made.
I thank all the students and non-students who took2this course and David Rosen-
berg for feedback.
1http://cds.nyu.edu/
2In fact, they are still taking the course as of 24 Nov 2015. They have two guest lectures and a ﬁnal exam
left until the end of the course.
Contents
1 Introduction 5
1.1 Route we will nottake . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.1.1 What is Language? . . . . . . . . . . . . . . . . . . . . . . . 5
1.1.2 Language Understanding . . . . . . . . . . . . . . . . . . . . 6
1.2 Road we willtake . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.2.1 Language as a Function . . . . . . . . . . . . . . . . . . . . 8
1.2.2 Language Understanding as a Function Approximation . . . . 8
2 Function Approximation as Supervised Learning 11
2.1 Function Approximation: Parametric Approach . . . . . . . . . . . . 11
2.1.1 Expected Cost Function . . . . . . . . . . . . . . . . . . . . 11
2.1.2 Empirical Cost Function . . . . . . . . . . . . . . . . . . . . 12
2.2 Learning as Optimization . . . . . . . . . . . . . . . . . . . . . . . . 13
2.2.1 Gradient-based Local Iterative Optimization . . . . . . . . . . 13
2.2.2 Stochastic Gradient Descent . . . . . . . . . . . . . . . . . . 14
2.3 When do we stop learning? . . . . . . . . . . . . . . . . . . . . . . . 16
2.3.1 Early Stopping . . . . . . . . . . . . . . . . . . . . . . . . . 16
2.3.2 Model Selection . . . . . . . . . . . . . . . . . . . . . . . . 18
2.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.5 Linear Regression for Non-Linear Functions . . . . . . . . . . . . . . 20
2.5.1 Feature Extraction . . . . . . . . . . . . . . . . . . . . . . . 20
3 Neural Networks and Backpropagation Algorithm 22
3.1 Conditional Distribution Approximation . . . . . . . . . . . . . . . . 22
3.1.1 Why do we want to do this? . . . . . . . . . . . . . . . . . . 24
3.1.2 Other Distributions . . . . . . . . . . . . . . . . . . . . . . . 25
3.2 Feature Extraction is also a Function . . . . . . . . . . . . . . . . . . 25
3.3 Multilayer Perceptron . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.3.1 Example: Binary classiﬁcation with a single hidden unit . . . 27
3.3.2 Example: Binary classiﬁcation with more than one hidden units 29
3.4 Automating Backpropagation . . . . . . . . . . . . . . . . . . . . . . 31
3.4.1 What if a Function is notDifferentiable? . . . . . . . . . . . 32
2
4 Recurrent Neural Networks and Gated Recurrent Units 35
4.1 Recurrent Neural Networks . . . . . . . . . . . . . . . . . . . . . . . 35
4.1.1 Fixed-Size Output y. . . . . . . . . . . . . . . . . . . . . . 37
4.1.2 Multiple Child Nodes and Derivatives . . . . . . . . . . . . . 38
4.1.3 Example: Sentiment Analysis . . . . . . . . . . . . . . . . . 39
4.1.4 Variable-Length Output y:jxj=jyj. . . . . . . . . . . . . . 40
4.2 Gated Recurrent Units . . . . . . . . . . . . . . . . . . . . . . . . . 43
4.2.1 Making Simple Recurrent Neural Networks Realistic . . . . . 43
4.2.2 Gated Recurrent Units . . . . . . . . . . . . . . . . . . . . . 44
4.2.3 Long Short-Term Memory . . . . . . . . . . . . . . . . . . . 46
4.3 Why not Rectiﬁers? . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
4.3.1 Rectiﬁers Explode . . . . . . . . . . . . . . . . . . . . . . . 47
4.3.2 Is tanh a Blessing? . . . . . . . . . . . . . . . . . . . . . . . 49
4.3.3 Are We Doomed? . . . . . . . . . . . . . . . . . . . . . . . . 52
4.3.4 Gated Recurrent Units Address Vanishing Gradient . . . . . . 53
5 Neural Language Models 55
5.1 Language Modeling: First Step . . . . . . . . . . . . . . . . . . . . . 55
5.1.1 What if those linguistic structures do exist . . . . . . . . . . . 56
5.1.2 Quick Note on Linguistic Units . . . . . . . . . . . . . . . . 57
5.2 Statistical Language Modeling . . . . . . . . . . . . . . . . . . . . . 58
5.2.1 Data Sparsity/Scarcity . . . . . . . . . . . . . . . . . . . . . 59
5.3 n-Gram Language Model . . . . . . . . . . . . . . . . . . . . . . . . 61
5.3.1 Smoothing and Back-Off . . . . . . . . . . . . . . . . . . . . 62
5.3.2 Lack of Generalization . . . . . . . . . . . . . . . . . . . . . 65
5.4 Neural Language Model . . . . . . . . . . . . . . . . . . . . . . . . 66
5.4.1 How does Neural Language Model Generalize to Unseen n-
Grams? – Distributional Hypothesis . . . . . . . . . . . . . . 68
5.4.2 Continuous Bag-of-Words Language Model:
Maximum Pseudo–Likelihood Approach . . . . . . . . . . . 71
5.4.3 Semi-Supervised Learning with Pretrained Word Embeddings 74
5.5 Recurrent Language Model . . . . . . . . . . . . . . . . . . . . . . . 76
5.6 How do n-gram language model, neural language model and RNN-LM
compare? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
6 Neural Machine Translation 82
6.1 Statistical Approach to Machine Translation . . . . . . . . . . . . . . 82
6.1.1 Parallel Corpora: Training Data for Machine Translation . . . 84
6.1.2 Automatic Evaluation Metric . . . . . . . . . . . . . . . . . . 87
6.2 Neural Machine Translation:
Simple Encoder-Decoder Model . . . . . . . . . . . . . . . . . . . . 90
6.2.1 Sampling vs. Decoding . . . . . . . . . . . . . . . . . . . . . 91
6.3 Attention-based Neural Machine Translation . . . . . . . . . . . . . . 97
6.3.1 What does the Attention Mechanism do? . . . . . . . . . . . 101
6.4 Warren Weaver’s Memorandum . . . . . . . . . . . . . . . . . . . . 103
3
7 Final Words 107
7.1 Multimedia Description Generation as Translation . . . . . . . . . . . 107
7.2 Language Understanding with World Knowledge . . . . . . . . . . . 109
7.3 Larger-Context Language Understanding:
Beyond Sentences and Beyond Words . . . . . . . . . . . . . . . . . 112
7.4 Warning and Summary . . . . . . . . . . . . . . . . . . . . . . . . . 113
4
Chapter 1
Introduction
This lecture is going to be the only one where I discuss some philosophical, meaning
nonpractical, arguments, because according to Chris Manning and Hinrich Schuetze,
“even practically-minded people have to confront the issue of what prior knowledge to
try to build into their model ” [77].
1.1 Route we will nottake
1.1.1 What is Language?
The very ﬁrst question we must ask ourselves before starting this course is the ques-
tion of what natural language is. Of course, the rest of this course does not in any
way require us to know what natural language is, but it is a philosophical question I
recommend everyone, including myself, to ponder upon once a while.
When I start talking about languages with anyone, there is a single person who
never misses to be mentioned, that is Noam Chomsky. His view has greatly inﬂuenced
the modern linguistics, and although many linguists I have talked to claim that their
work and ﬁeld have long moved on from Chomsky’s, I can feel his shadow all over
them.
My ﬁrst encounter with Chomsky was at the classroom of <Automata >from my
early undergrad years. I was not the most attentive student back then, and all I can
remember is Chomsky’s hierarchy and how it has shaped our view on languages, in this
context, programming/computer languages. A large part of the course was dedicated
to explaining which class of languages emerges given a set of constraints on a set of
generating rules , or production rules.
For instance, if we are given a set of generating rules that do not depend on the con-
text/meaning of non-terminal symbols (context-free grammar, CFG), we get a context-
free language. If we put a bit of constraints to CFG that each generating rule is such
that a non-terminal symbol is replaced by either a terminal symbol, a terminal symbol
by a non-terminal symbol or an empty symbol, then we get a regular grammar. Sim-
ilarly to CFG, we get a regular language from the regular grammar, and the regular
5
language is a subset of the context-free language.
What Chomsky believes is that this kind of approach applies also to human lan-
guages, or natural languages. There exists a set of generating rules that generates a
natural language. But, then, the obvious question to follow is where those generating
rules are. Where are they stored? How are they stored? Do we have separate generating
rules for different languages?
1.1.2 Language Understanding
Understanding Human Language Those questions are interesting, but out of scope
for this course. Those questions are the ones linguists try to answer. Generative linguis-
tics aims at ﬁguring out what those rules are, how they are combined to form a valid
sentence, how they are adapted to different languages and so on. We will leave these to
linguists and continue on to our journey of building a machine that understands human
languages .
Natural Language Understanding So, let’s put these questions aside and trust Chom-
sky that we, humans, are specially designed to store those generating rules somewhere
in the brain [30, 21]. Or, better yet, let’s trust Chomsky that there’s a universal gram-
marbuilt in our brain. In other words, let’s say we were born with this set of generating
rules for natural languages, and while growing, we have adapted this universal gram-
mar toward our native tongue (language variation).
When we decide to speak of something (whatever that is and however implausi-
ble that is), our brain quickly picks up a sequence of some of those generating rules
and starts generating a sentence accordingly. Of course, those rules do not generate a
sentence directly, but generates a sequence of control signals to move our muscles to
make sound. When heard by other people who understand your language, the sound
becomes a sentence.
In our case, we are more interested in a machine hearing that sound, or a sentence
from here on. When a machine heard this sentence, what would/should a language un-
derstanding machine do to understand a language, or more simply a sentence? Again,
we are assuming that this sentence was generated from applying a sequence of the
existing generating rules.
Under our assumption, a natural ﬁrst step that comes to my mind is to ﬁgure out
that sequence of the generating rules which led to the sentence. Once the sequence is
found, or in a fancier term, inferred, the next step will be to ﬁgure out what kind of
mental state of the speaker led to those generating rules.
Let’s take an example sentence “ Our company is training workers ” (from Sec. 1.3
of [77]), which is a horrible choice, because this was used as an example of ambiguity
in parsing. Regardless, a speaker obviously has an awesome image of her company
which trains its workers and wants to tell a machine about this. This mental state is
used to select the following generating rules (assuming a phrase structure grammar)1:
(ROOT
1Stanford Parser: http://nlp.stanford.edu:8080/parser
6
(S
(NP (PRP$ Our) (NN company))
(VP (VBZ is)
(VP (VBG training)
(NP (NNS workers))))))
pa
1.3 The Ambiguity of Language: Why NLP Is Diﬃcult 17
Philosophically, this brings us close to the position adopted in the later
writings of Wittgenstein (that is, Wittgenstein 1968), where the mean-
ing of a word is deﬁned by the circumstances of its use (a use theory of use theory of
meaning meaning )–s e et h eq u o t a t i o n sa tt h eb e g i n n i n go ft h ec h a p t e r .U n d e rt h i s
conception, much of Statistical NLPresearch directly tackles questions of
meaning.
1.3 The Ambiguity of Language: Why NLP Is Di ﬃcult
AnNLP system needs to determine something of the structure of text –
normally at least enough that it can answer “Who did what to whom?”
Conventional parsing systems try to answer this question only in terms
of possible structures that could be deemed grammatical for some choice
of words of a certain category. For example, given a reasonable grammar,
as t a n d a r d NLP system will say that sentence (1.10) has 3 syntactic anal-
yses, often called parses :
(1.10) Our company is training workers.
The three di ﬀering parses might be represented as in (1.11):
(1.11) a. S
NP
Our companyVP
Aux
isVP
V
trainingNP
workers
b. S
NP
Our companyVP
V
isNP
VP
V
trainingNP
workers
Figure 1.1: A parse of “ Our company is training workers ”
The machine hears the sentence “ Our company is training workers ” and infers
the parse in Fig. 1.1. Then, we can make a simple set of rules (again!) to let the
machine answer questions about this sentence, kinds of questions that imply that the
machine has understood the sentence (language). For instance, given a question “ Who
is training workers? ”, the machine can answer by noticing that the question is asking
for the subject of the verb phrase “ is training ” acted on the object “ workers ” and that
the subject is “ Our company ”.
Side Note: Bayesian Language Understanding This generative view of languages
ﬁts quite well with Bayesian modelling (see, e.g., [84].) There exists a hidden mecha-
nism, or a set of generating rules and a rule governing their composition, which can be
modelled as a latent variable Z. Given these rules, a language or a sentence Xis gen-
erated according to the conditional distribution P(XjZ). Then, understanding language
(by humans) is equivalent to computing the posterior distribution over all possible sets
of generating rules and their compositional rules (i.e., P(ZjX).) This answers the ques-
tion of what is the most likely mechanism underlying the observed language.
Furthermore, from the perspective of machines, Bayesian approach is attractive. In
this case, we assume to know theset of rules in advance and let the latent variable Z
denote the speciﬁc conﬁguration (use) of those rules. Given this sequence of applying
the rules, a sentence Xis generated via the conditional distribution P(XjZ). Machine
understanding of language is equivalent to inferring the posterior distribution over Z
given X.
For more details about Bayesian approaches (in the context of machine learning),
please, refer to [13] or take the course DS-GA 1005 Inference and Representation by
Prof. David Sontag.
7
Understanding vs. Using What’s clear from this example is that in this generative
view of languages, there is a clear separation between understanding and using. In-
ferring the generating rules from a given sentence is understanding , and answering a
question based on this understanding, using , is a separate activity. Understanding part
is done when the underlying (true) structure has been determined regardless of how
this understanding be used.
To put it in a slightly different wording, language understanding does not require its
use, or downstream tasks. In this road that we will nottake in this course, understanding
exists as it is, regardless of what the understood insight/knowledge will be used for.
And, this is the reason why we do not walk down this road.
1.2 Road we willtake
1.2.1 Language as a Function
In this course, we will view a natural/human language as “ a system intended to com-
municate ideas from a speaker to a hearer ” [110]. What this means is that we do not
view a language as a separate entity that exists on its own. Rather, we view a whole
system or behaviour of communication as a language. Furthermore, this view dictates
that we must take into account the world surrounding a speaker and a hearer in order
to understand language.
Under this view of language, language or rather its usage become somewhat similar
to action or behaviour. Speaking of something is equivalent to acting on a listener, as
both of them inﬂuence the listener in one way or another. The purpose of language
is then to inﬂuence another by efﬁciently communicate one’s will or intention.2This
hints at how language came to be (or may have come to be): (evolution) language
has evolved to facilitate the exchange of ideas among people (learning) humans learn
language by being either encouraged or punished for the use of language. This latter
view on how language came to be is similar in spirit to the behaviourism of B. F.
Skinner (“ necessary mediation of reinforcement by another organism ” [97].)
This is a radical departure from the generative view of human language, where
language existed on its own and its understanding does not necessarily require the
existence of the outside world nor the existence of a listener. It is no wonder why
Chomsky was so harsh in criticizing Skinner’s work in [30]. This departure, as I see
it, is the departure toward a functional view of language. Language is a function of
communication .
1.2.2 Language Understanding as a Function Approximation
Let’s make a large jump here such that we consider this function as a mathematical
function. This function (called language) takes as input the state of the surrounding
world, the speaker’s speech, either written, spoken or signed and the listener’s mental
2Chomsky does not agree: “ it is wrong to think of human use of language as characteristically informa-
tive, in fact or in intention. ” [31].
8
state3Inside the function, the listener’s mental state is updated to incorporate the new
idea from the speaker’s speech. The function then returns a response by the listener
(which may include “no response” as well) and a set of non-verbal action sequences
(what would be the action sequence if the speaker insulted the listener?).
In this case, language understanding, both from humans’ and machines’ perspec-
tive, boils down to ﬁguring out the internal working of this function. In other words, we
understand language by learning the internal mechanism of the function. Furthermore,
this view suggests that the underlying structures of language are heavily dependent on
the surrounding environment (context) as well as on the target task. The former (con-
text dependence) is quite clear, as the function takes as input the context, but the latter
may be confusing now. Hopefully, this will become clearer later in the course.
How can we approximate this function? How can we ﬁgure out the internal working
mechanism of this function? What tools do we have?
Language Understanding by Machine Learning This functional view of languages
suddenly makes machine learning a very appealing tool for understanding human lan-
guages. After all, function approximation is thecore of machine learning. Classiﬁca-
tion is a classical example of function approximation, clustering is a function approxi-
mation where the target is not given, generative modeling learns a function that returns
a probability of an input, and so on.
When we approximate a function in machine learning, the prime ingredient is data.
We are given data which was either generated from this function (unsupervised learn-
ing) or well ﬁt this function (supervised learning), based on which we adjust our ap-
proximation to the function, often iteratively, to best ﬁt the data. But, I must note here
that it does not matter how well the approximated function ﬁts the data it was ﬁtted to,
but matters how well this approximation ﬁts unseen data.4
In language understanding, this means that we collect a large data set of input and
output pairs (or conversations together with the recording of the surrounding environ-
ment) and ﬁt some arbitrary function to well predict the output given an input. We
probably want to evaluate this approximation in a novel conversation. If this function
makes a conversation just like a person, voil `a, we made a machine that passed the
Turing test. Simple, right?
Problem Unfortunately, as soon as we try to do this, we run into a big problem. This
problem is not from machine learning nor languages, but the deﬁnition of this function
of language.
Properly approximating this function requires us to either simulate or record the
whole world (in fact, the whole universe.) For, this function takes as input and main-
tains as internal state the surrounding world (context) and the mental state of the in-
dividual (speaker.) This is unavoidable, if we wanted to very well approximate this
function as a whole.
It is unclear, however, whether we want to approximate the full function. For a
human to survive, yes, it is likely that the full function is needed. But, if our goal is
3We assume here that a such thing exists however it is represented in our brain.
4This is a matter of generalization, and we will talk about this more throughout the course.
9
restricted to a certain task (such as translation, language modelling, and so on), we may
not want to approximate this function fully. We probably want to approximate only a
subset of this whole function. For instance, if our goal is to understand the process
of translation from one language to another, we can perhaps ignore all but the speech
input to the function and all but the speech output from the function, because often a
(trained) person can translate a sentence in one language to another without knowing
the whole context.
This latter approach to language understanding–approximating a partial function
of languages– will be at the core of this course. We will talk about various language
tasks that are a part of this whole function of language. These tasks will include, but
are not limited to, language modelling, machine translation, image/video description
generation and question answering. For these tasks and potentially more, we will study
how to use machine learning, or more speciﬁcally deep learning, to solve these tasks
by approximating sub-functions of language.
10
Chapter 2
Function Approximation as
Supervised Learning
Throughout this course, we will extensively use artiﬁcial neural networks1to approx-
imate (a part of) the function of natural language. This makes it necessary for us to
study the basics of neural networks ﬁrst, and this lecture and a couple of subsequent
ones are designed to serve this purpose.
2.1 Function Approximation: Parametric Approach
2.1.1 Expected Cost Function
Let us start by deﬁning a data distribution pdata.pdatais deﬁned over a pair of input
and output vectors, x2Idandy2Ok, respectively. IandOare respectively sets of
all possible input and output values, such as R,f0;1gandf0;1;:::; Lg. This data
distribution is not known to us.
The goal is to ﬁnd a relationship between xandy. More speciﬁcally, we are in-
terested in ﬁnding a function f:Rd!Okthat generates the output ygiven its corre-
sponding input x. The very ﬁrst thing we should do is to put some constraints on the
function fto make our search for the correct fa bit less impossible. In this lecture,
and throughout the course, I will consider only a parametric function f, in which case
the function is fully speciﬁed with a set of parameters q.
Next, we must deﬁne a way to measure how well the function fapproximates
the underlying mechanism of generation ( x!y). Let’s denote by ˆythe output of the
function with a particular set qof parameters and a given input x:
ˆy=fq(x)
1From here on, I will simply drop artiﬁcial and call them neural networks. Whenever I say “neural
network”, it refers to artiﬁcial neural networks.
11
How well fapproximates the true generating function is equivalent to how far ˆyis from
the correct output y. Let’s use D(ˆy;y)for now call this distance2between ˆyandy
It is clear that we want to ﬁnd qthat minimizes D(ˆy;y)for every pair in the space
(RRdOk). But, wait, every pair equally likely? Probably not, for we do not care how
well fqapproximates the true function, when a pair of input xand output yis unlikely,
meaning we do not care how bad the approximation is, if pdata(x;y)is small. However,
this is a bit difﬁcult to take into account, as we must decided on the threshold below
which we consider any pair irrelevant.
Hence, we weight the distance between the approximated ˆyand the correct yof
each pair (x;y)in the space by its probability p(x;y). Mathematically saying, we want
to ﬁnd
argmin
qZ
xZ
ypdata(x;y)D(ˆy;y)dxdy;
where the integralRshould be replaced with the summation åif any of xandyis
discrete.
We call this quantity being minimized with respect to the parameters qa cost func-
tionC(q). This is equivalent to computing the expected distance between the predicted
output ˆyand the correct one y:
C(q) =Z
xZ
ypdata(x;y)D(ˆy;y)dxdy; (2.1)
=E(x;y)pdata[D(ˆy;y)] (2.2)
This is often called an expected loss or risk, and minimizing this cost function is re-
ferred to as expected risk minimization [105].
Unfortunately C(q)cannot be (exactly) computed for a number of reasons. The
most important reason among them is simply that we don’t know what the data distri-
bution pdatais. Even if we have access to pdata, we can exactly compute C(q)only with
heavy assumptions on both the data distribution and the distance function.3
2.1.2 Empirical Cost Function
This does not mean that we are doomed from the beginning. Instead of the full-blown
description of the data distribution pdata, we will assume that someone miraculously
gave us a ﬁnite set of pairs drawn from the data distribution. We will call this a training
set:

(x1;y1);:::;(xN;yN)	
:
As we have access to the samples from the data distribution, we can use Monte
Carlo method to approximate the expected cost function C(q)such that
C(q)˜C(q) =1
NN
å
n=1D(ˆyn;yn): (2.3)
2Note that we do not require this distance to satisfy the triangular inequality, meaning that it does not
have to be a distance. However, I will just call it distance for now.
3Why?
12
We call this approximate ˜C(q)of the expected cost function, an empirical cost function
(or empirical risk or empirical loss.)
Because empirical cost function is readily computable, we will mainly work with
the empirical cost function not with the expected cost function. However, keep in mind
that at the end of the day, the goal is to ﬁnd a set of parameters that minimizes the
expected cost.
2.2 Learning as Optimization
We often call this process of ﬁnding a good set of parameters that minimizes the ex-
pected cost learning . This term is used from the perspective of a machine which imple-
ments the function fq, as it learns to approximate the true generating function ffrom
training data.
From what I have described so far, it may have become clear even without me men-
tioning that learning is optimization . We have a clearly deﬁned function (the empirical
cost function ˜C) which needs to be minimized with respect to its input q.
2.2.1 Gradient-based Local Iterative Optimization
There are many optimization algorithms one can use to ﬁnd a set of parameters that
minimizes ˜C. Sometimes, you can even ﬁnd the optimal set of parameters in a closed
form equation.4In most cases, because there is no known closed-form solution, it is
typical to use an iterative optimization algorithm (see [42] for in-depth discussion on
optimization.)
By an iterative optimization, I mean an algorithm which reﬁnes its estimate of the
optimal set of parameters little by little until the values of the parameters converge to
the optimal (expected) cost function. Also, it is worthwhile to note that most iterative
optimization algorithms are local , in the sense that they do not require us to evaluate
the whole parameter space, but only a small subset along the path from the starting
point to the convergence point.5
Here I will describe the simplest one among those local iterative optimization algo-
rithms, called gradient descent (GD) algorithm. As the name suggests, this algorithm
depends entirely on the gradient of the cost function.6
4One such example is a linear regression where
fq=fWg(x) =Wx
D(ˆy;y) =1
2kˆy","natural language understanding with
distributed representation
kyunghyun cho
courant institute of mathematical sciences and
center for data science
new york university
november 26 2015arxiv151107916v1  cscl  24 nov 2015
abstract
this is a lecture note for the course dsga 3001 hnatural language understanding
with distributed representation iat the center for data science1 new york university
in fall 2015 as the name of the course suggests this lecture note introduces readers
to a neural network based approach to natural language understandingprocessing in
order to make it as selfcontained as possible i spend much time on describing basics of
machine learning and neural networks only after which how they are used for natural
languages is introduced on the language front i almost solely focus on language
modelling and machine translation two of which i personally nd most fascinating
and most fundamental to natural language understanding
after about a month of lectures and about 40 pages of writing this lecture note i
found this fascinating note 47 by yoav goldberg on neural network models for natural
language processing this note deals with wider topics on natural language processing
with distributed representations in more details and i highly recommend you to read it
hopefully along with this lecture note i seriously wish yoav had written it earlier so
that i couldve simply used his excellent note for my course
this lecture note had been written quite hastily as the course progressed meaning
that i could spare only about 100 hours in total for this note this is my lame excuse
for likely many mistakes in this lecture note and i kindly ask for your understanding
in advance again how grateful i wouldve been had i found yoavs note earlier
i am planning to update this lecture note gradually over time hoping that i will
be able to convince the center for data science to let me teach the same course next
year the latest version will always be available both in pdf and in latex source code
from httpsgithubcomnyudlnlpdllecturenote  the arxiv
version will be updated whenever a major revision is made
i thank all the students and nonstudents who took2this course and david rosen
berg for feedback
1httpcdsnyuedu
2in fact they are still taking the course as of 24 nov 2015 they have two guest lectures and a nal exam
left until the end of the course
contents
1 introduction 5
11 route we will nottake                          5
111 what is language                        5
112 language understanding                     6
12 road we willtake                             8
121 language as a function                     8
122 language understanding as a function approximation     8
2 function approximation as supervised learning 11
21 function approximation parametric approach             11
211 expected cost function                     11
212 empirical cost function                     12
22 learning as optimization                         13
221 gradientbased local iterative optimization           13
222 stochastic gradient descent                   14
23 when do we stop learning                        16
231 early stopping                          16
232 model selection                         18
24 evaluation                                 19
25 linear regression for nonlinear functions               20
251 feature extraction                        20
3 neural networks and backpropagation algorithm 22
31 conditional distribution approximation                 22
311 why do we want to do this                   24
312 other distributions                        25
32 feature extraction is also a function                   25
33 multilayer perceptron                           26
331 example binary classication with a single hidden unit    27
332 example binary classication with more than one hidden units 29
34 automating backpropagation                       31
341 what if a function is notdifferentiable            32
2
4 recurrent neural networks and gated recurrent units 35
41 recurrent neural networks                        35
411 fixedsize output y                      37
412 multiple child nodes and derivatives              38
413 example sentiment analysis                  39
414 variablelength output yjxjjyj              40
42 gated recurrent units                          43
421 making simple recurrent neural networks realistic      43
422 gated recurrent units                      44
423 long shortterm memory                    46
43 why not rectiers                            47
431 rectiers explode                        47
432 is tanh a blessing                        49
433 are we doomed                         52
434 gated recurrent units address vanishing gradient       53
5 neural language models 55
51 language modeling first step                      55
511 what if those linguistic structures do exist            56
512 quick note on linguistic units                 57
52 statistical language modeling                      58
521 data sparsityscarcity                      59
53 ngram language model                         61
531 smoothing and backoff                     62
532 lack of generalization                      65
54 neural language model                         66
541 how does neural language model generalize to unseen n
grams  distributional hypothesis               68
542 continuous bagofwords language model
maximum pseudolikelihood approach            71
543 semisupervised learning with pretrained word embeddings 74
55 recurrent language model                        76
56 how do ngram language model neural language model and rnnlm
compare                                 79
6 neural machine translation 82
61 statistical approach to machine translation               82
611 parallel corpora training data for machine translation    84
612 automatic evaluation metric                   87
62 neural machine translation
simple encoderdecoder model                     90
621 sampling vs decoding                      91
63 attentionbased neural machine translation               97
631 what does the attention mechanism do            101
64 warren weavers memorandum                     103
3
7 final words 107
71 multimedia description generation as translation            107
72 language understanding with world knowledge            109
73 largercontext language understanding
beyond sentences and beyond words                  112
74 warning and summary                          113
4
chapter 1
introduction
this lecture is going to be the only one where i discuss some philosophical meaning
nonpractical arguments because according to chris manning and hinrich schuetze
even practicallyminded people have to confront the issue of what prior knowledge to
try to build into their model  77
11 route we will nottake
111 what is language
the very rst question we must ask ourselves before starting this course is the ques
tion of what natural language is of course the rest of this course does not in any
way require us to know what natural language is but it is a philosophical question i
recommend everyone including myself to ponder upon once a while
when i start talking about languages with anyone there is a single person who
never misses to be mentioned that is noam chomsky his view has greatly inuenced
the modern linguistics and although many linguists i have talked to claim that their
work and eld have long moved on from chomskys i can feel his shadow all over
them
my rst encounter with chomsky was at the classroom of automata from my
early undergrad years i was not the most attentive student back then and all i can
remember is chomskys hierarchy and how it has shaped our view on languages in this
context programmingcomputer languages a large part of the course was dedicated
to explaining which class of languages emerges given a set of constraints on a set of
generating rules  or production rules
for instance if we are given a set of generating rules that do not depend on the con
textmeaning of nonterminal symbols contextfree grammar cfg we get a context
free language if we put a bit of constraints to cfg that each generating rule is such
that a nonterminal symbol is replaced by either a terminal symbol a terminal symbol
by a nonterminal symbol or an empty symbol then we get a regular grammar sim
ilarly to cfg we get a regular language from the regular grammar and the regular
5
language is a subset of the contextfree language
what chomsky believes is that this kind of approach applies also to human lan
guages or natural languages there exists a set of generating rules that generates a
natural language but then the obvious question to follow is where those generating
rules are where are they stored how are they stored do we have separate generating
rules for different languages
112 language understanding
understanding human language those questions are interesting but out of scope
for this course those questions are the ones linguists try to answer generative linguis
tics aims at guring out what those rules are how they are combined to form a valid
sentence how they are adapted to different languages and so on we will leave these to
linguists and continue on to our journey of building a machine that understands human
languages 
natural language understanding so lets put these questions aside and trust chom
sky that we humans are specially designed to store those generating rules somewhere
in the brain 30 21 or better yet lets trust chomsky that theres a universal gram
marbuilt in our brain in other words lets say we were born with this set of generating
rules for natural languages and while growing we have adapted this universal gram
mar toward our native tongue language variation
when we decide to speak of something whatever that is and however implausi
ble that is our brain quickly picks up a sequence of some of those generating rules
and starts generating a sentence accordingly of course those rules do not generate a
sentence directly but generates a sequence of control signals to move our muscles to
make sound when heard by other people who understand your language the sound
becomes a sentence
in our case we are more interested in a machine hearing that sound or a sentence
from here on when a machine heard this sentence what wouldshould a language un
derstanding machine do to understand a language or more simply a sentence again
we are assuming that this sentence was generated from applying a sequence of the
existing generating rules
under our assumption a natural rst step that comes to my mind is to gure out
that sequence of the generating rules which led to the sentence once the sequence is
found or in a fancier term inferred the next step will be to gure out what kind of
mental state of the speaker led to those generating rules
lets take an example sentence  our company is training workers  from sec 13
of 77 which is a horrible choice because this was used as an example of ambiguity
in parsing regardless a speaker obviously has an awesome image of her company
which trains its workers and wants to tell a machine about this this mental state is
used to select the following generating rules assuming a phrase structure grammar1
root
1stanford parser httpnlpstanfordedu8080parser
6
s
np prp our nn company
vp vbz is
vp vbg training
np nns workers
pa
13 the ambiguity of language why nlp is dicult 17
philosophically this brings us close to the position adopted in the later
writings of wittgenstein that is wittgenstein 1968 where the mean
ing of a word is dened by the circumstances of its use a use theory of use theory of
meaning meaning s e et h eq u o t a t i o n sa tt h eb e g i n n i n go ft h ec h a p t e r u n d e rt h i s
conception much of statistical nlpresearch directly tackles questions of
meaning
13 the ambiguity of language why nlp is di cult
annlp system needs to determine something of the structure of text 
normally at least enough that it can answer who did what to whom
conventional parsing systems try to answer this question only in terms
of possible structures that could be deemed grammatical for some choice
of words of a certain category for example given a reasonable grammar
as t a n d a r d nlp system will say that sentence 110 has 3 syntactic anal
yses often called parses 
110 our company is training workers
the three di ering parses might be represented as in 111
111 a s
np
our companyvp
aux
isvp
v
trainingnp
workers
b s
np
our companyvp
v
isnp
vp
v
trainingnp
workers
figure 11 a parse of  our company is training workers 
the machine hears the sentence  our company is training workers  and infers
the parse in fig 11 then we can make a simple set of rules again to let the
machine answer questions about this sentence kinds of questions that imply that the
machine has understood the sentence language for instance given a question  who
is training workers  the machine can answer by noticing that the question is asking
for the subject of the verb phrase  is training  acted on the object  workers  and that
the subject is  our company 
side note bayesian language understanding this generative view of languages
ts quite well with bayesian modelling see eg 84 there exists a hidden mecha
nism or a set of generating rules and a rule governing their composition which can be
modelled as a latent variable z given these rules a language or a sentence xis gen
erated according to the conditional distribution pxjz then understanding language
by humans is equivalent to computing the posterior distribution over all possible sets
of generating rules and their compositional rules ie pzjx this answers the ques
tion of what is the most likely mechanism underlying the observed language
furthermore from the perspective of machines bayesian approach is attractive in
this case we assume to know theset of rules in advance and let the latent variable z
denote the specic conguration use of those rules given this sequence of applying
the rules a sentence xis generated via the conditional distribution pxjz machine
understanding of language is equivalent to inferring the posterior distribution over z
given x
for more details about bayesian approaches in the context of machine learning
please refer to 13 or take the course dsga 1005 inference and representation by
prof david sontag
7
understanding vs using whats clear from this example is that in this generative
view of languages there is a clear separation between understanding and using in
ferring the generating rules from a given sentence is understanding  and answering a
question based on this understanding using  is a separate activity understanding part
is done when the underlying true structure has been determined regardless of how
this understanding be used
to put it in a slightly different wording language understanding does not require its
use or downstream tasks in this road that we will nottake in this course understanding
exists as it is regardless of what the understood insightknowledge will be used for
and this is the reason why we do not walk down this road
12 road we willtake
121 language as a function
in this course we will view a naturalhuman language as  a system intended to com
municate ideas from a speaker to a hearer  110 what this means is that we do not
view a language as a separate entity that exists on its own rather we view a whole
system or behaviour of communication as a language furthermore this view dictates
that we must take into account the world surrounding a speaker and a hearer in order
to understand language
under this view of language language or rather its usage become somewhat similar
to action or behaviour speaking of something is equivalent to acting on a listener as
both of them inuence the listener in one way or another the purpose of language
is then to inuence another by efciently communicate ones will or intention2this
hints at how language came to be or may have come to be evolution language
has evolved to facilitate the exchange of ideas among people learning humans learn
language by being either encouraged or punished for the use of language this latter
view on how language came to be is similar in spirit to the behaviourism of b f
skinner  necessary mediation of reinforcement by another organism  97
this is a radical departure from the generative view of human language where
language existed on its own and its understanding does not necessarily require the
existence of the outside world nor the existence of a listener it is no wonder why
chomsky was so harsh in criticizing skinners work in 30 this departure as i see
it is the departure toward a functional view of language language is a function of
communication 
122 language understanding as a function approximation
lets make a large jump here such that we consider this function as a mathematical
function this function called language takes as input the state of the surrounding
world the speakers speech either written spoken or signed and the listeners mental
2chomsky does not agree  it is wrong to think of human use of language as characteristically informa
tive in fact or in intention  31
8
state3inside the function the listeners mental state is updated to incorporate the new
idea from the speakers speech the function then returns a response by the listener
which may include no response as well and a set of nonverbal action sequences
what would be the action sequence if the speaker insulted the listener
in this case language understanding both from humans and machines perspec
tive boils down to guring out the internal working of this function in other words we
understand language by learning the internal mechanism of the function furthermore
this view suggests that the underlying structures of language are heavily dependent on
the surrounding environment context as well as on the target task the former con
text dependence is quite clear as the function takes as input the context but the latter
may be confusing now hopefully this will become clearer later in the course
how can we approximate this function how can we gure out the internal working
mechanism of this function what tools do we have
language understanding by machine learning this functional view of languages
suddenly makes machine learning a very appealing tool for understanding human lan
guages after all function approximation is thecore of machine learning classica
tion is a classical example of function approximation clustering is a function approxi
mation where the target is not given generative modeling learns a function that returns
a probability of an input and so on
when we approximate a function in machine learning the prime ingredient is data
we are given data which was either generated from this function unsupervised learn
ing or well t this function supervised learning based on which we adjust our ap
proximation to the function often iteratively to best t the data but i must note here
that it does not matter how well the approximated function ts the data it was tted to
but matters how well this approximation ts unseen data4
in language understanding this means that we collect a large data set of input and
output pairs or conversations together with the recording of the surrounding environ
ment and t some arbitrary function to well predict the output given an input we
probably want to evaluate this approximation in a novel conversation if this function
makes a conversation just like a person voil a we made a machine that passed the
turing test simple right
problem unfortunately as soon as we try to do this we run into a big problem this
problem is not from machine learning nor languages but the denition of this function
of language
properly approximating this function requires us to either simulate or record the
whole world in fact the whole universe for this function takes as input and main
tains as internal state the surrounding world context and the mental state of the in
dividual speaker this is unavoidable if we wanted to very well approximate this
function as a whole
it is unclear however whether we want to approximate the full function for a
human to survive yes it is likely that the full function is needed but if our goal is
3we assume here that a such thing exists however it is represented in our brain
4this is a matter of generalization and we will talk about this more throughout the course
9
restricted to a certain task such as translation language modelling and so on we may
not want to approximate this function fully we probably want to approximate only a
subset of this whole function for instance if our goal is to understand the process
of translation from one language to another we can perhaps ignore all but the speech
input to the function and all but the speech output from the function because often a
trained person can translate a sentence in one language to another without knowing
the whole context
this latter approach to language understandingapproximating a partial function
of languages will be at the core of this course we will talk about various language
tasks that are a part of this whole function of language these tasks will include but
are not limited to language modelling machine translation imagevideo description
generation and question answering for these tasks and potentially more we will study
how to use machine learning or more specically deep learning to solve these tasks
by approximating subfunctions of language
10
chapter 2
function approximation as
supervised learning
throughout this course we will extensively use articial neural networks1to approx
imate a part of the function of natural language this makes it necessary for us to
study the basics of neural networks rst and this lecture and a couple of subsequent
ones are designed to serve this purpose
21 function approximation parametric approach
211 expected cost function
let us start by dening a data distribution pdatapdatais dened over a pair of input
and output vectors x2idandy2ok respectively iandoare respectively sets of
all possible input and output values such as rf01gandf01 lg this data
distribution is not known to us
the goal is to nd a relationship between xandy more specically we are in
terested in nding a function frdokthat generates the output ygiven its corre
sponding input x the very rst thing we should do is to put some constraints on the
function fto make our search for the correct fa bit less impossible in this lecture
and throughout the course i will consider only a parametric function f in which case
the function is fully specied with a set of parameters q
next we must dene a way to measure how well the function fapproximates
the underlying mechanism of generation  xy lets denote by ythe output of the
function with a particular set qof parameters and a given input x
yfqx
1from here on i will simply drop articial and call them neural networks whenever i say neural
network it refers to articial neural networks
11
how well fapproximates the true generating function is equivalent to how far yis from
the correct output y lets use dyyfor now call this distance2between yandy
it is clear that we want to nd qthat minimizes dyyfor every pair in the space
rrdok but wait every pair equally likely probably not for we do not care how
well fqapproximates the true function when a pair of input xand output yis unlikely
meaning we do not care how bad the approximation is if pdataxyis small however
this is a bit difcult to take into account as we must decided on the threshold below
which we consider any pair irrelevant
hence we weight the distance between the approximated yand the correct yof
each pair xyin the space by its probability pxy mathematically saying we want
to nd
argmin
qz
xz
ypdataxydyydxdy
where the integralrshould be replaced with the summation if any of xandyis
discrete
we call this quantity being minimized with respect to the parameters qa cost func
tioncq this is equivalent to computing the expected distance between the predicted
output yand the correct one y
cq z
xz
ypdataxydyydxdy 21
exypdatadyy 22
this is often called an expected loss or risk and minimizing this cost function is re
ferred to as expected risk minimization 105
unfortunately cqcannot be exactly computed for a number of reasons the
most important reason among them is simply that we dont know what the data distri
bution pdatais even if we have access to pdata we can exactly compute cqonly with
heavy assumptions on both the data distribution and the distance function3
212 empirical cost function
this does not mean that we are doomed from the beginning instead of the fullblown
description of the data distribution pdata we will assume that someone miraculously
gave us a nite set of pairs drawn from the data distribution we will call this a training
set

x1y1xnyn	

as we have access to the samples from the data distribution we can use monte
carlo method to approximate the expected cost function cqsuch that
cqcq 1
nn

n1dynyn 23
2note that we do not require this distance to satisfy the triangular inequality meaning that it does not
have to be a distance however i will just call it distance for now
3why
12
we call this approximate cqof the expected cost function an empirical cost function
or empirical risk or empirical loss
because empirical cost function is readily computable we will mainly work with
the empirical cost function not with the expected cost function however keep in mind
that at the end of the day the goal is to nd a set of parameters that minimizes the
expected cost
22 learning as optimization
we often call this process of nding a good set of parameters that minimizes the ex
pected cost learning  this term is used from the perspective of a machine which imple
ments the function fq as it learns to approximate the true generating function ffrom
training data
from what i have described so far it may have become clear even without me men
tioning that learning is optimization  we have a clearly dened function the empirical
cost function c which needs to be minimized with respect to its input q
221 gradientbased local iterative optimization
there are many optimization algorithms one can use to nd a set of parameters that
minimizes c sometimes you can even nd the optimal set of parameters in a closed
form equation4in most cases because there is no known closedform solution it is
typical to use an iterative optimization algorithm see 42 for indepth discussion on
optimization
by an iterative optimization i mean an algorithm which renes its estimate of the
optimal set of parameters little by little until the values of the parameters converge to
the optimal expected cost function also it is worthwhile to note that most iterative
optimization algorithms are local  in the sense that they do not require us to evaluate
the whole parameter space but only a small subset along the path from the starting
point to the convergence point5
here i will describe the simplest one among those local iterative optimization algo
rithms called gradient descent gd algorithm as the name suggests this algorithm
depends entirely on the gradient of the cost function6
4one such example is a linear regression where
fqfwgx wx
dyy 1
2ky","['2015arxiv151107916v1', 'httpnlpstanfordedu8080parser', 'insightknowledge', 'httpsgithubcomnyudlnlpdllecturenote', 'textmeaning', 'x2idandy2ok', 'understandingapproximating', 'understandingprocessing', 'distance2between', '1httpcdsnyuedu']",1
Deploying Technology to Save Endangered Languages,"['Hilaria Cruz', 'Joseph Waring']",2019,http://arxiv.org/abs/1908.08971v2,"1   Using technology to save endangered languages1 How linguists and computer scientists came together in a retreat to explore ways to advance automatic speech recognition for endangered languages Hilaria Cruz and Joseph Waring   Abstract In August 2018 a retreat in Quechee, Vermont, brought together computer scientists specializing in natural language processing, linguists, native speakers, and endangered language activists under one roof. During the retreat, participants discussed ways to utilize the latest advances in Automatic Speech Recognition, especially neural networks, to transcribe endangered languages and tackle the difficulties of transcribing natural language, addressing what is known as “the bottle neck” of language transcription. In a relaxed environment where work was mixed with fun, everyone who participated became friends quickly and interacted with collegiality, exhibiting great potential for future collaborations. 1.0 Background Automatic Speech Recognition (ASR) is a burgeoning technology with near limitless potential. Voice recognition, which was once considered science fiction, is now commonplace: Alexa, Siri, and OK Google live on countertops and bedside tables in our homes. Nevertheless, this technology has been limited to major, dominant languages such as English, German, and Spanish.   In the 19th and 20th centuries, nation states sought to stamp out linguistic and cultural diversity, setting language decline in rapid motion all over the world. Most of the world's 7,000 languages will fall out of use by the end of this century if language loss continues at its current rate, limiting humanity’s ability “to appreciate the full creative capacities of the human mind” (Mithun 1998:189).  The rapid development of ASR technologies, especially of neural networks, could expedite the transcription, translation, and linguistic annotation of endangered languages, providing resources for research, revitalization, and promotion. Before this can be achieved, linguists and computational scientists must overcome several technological and methodological obstacles.  Traditional ASR models, such as Markov chains, forced alignment, and hidden Markov models, require vast quantities of training data to get a model running (Michaud et al. 2018). Most endangered languages lack large corpora, alphabets, or speakers for data elicitation. A great number of these languages only have a few speakers left. Manual transcription and annotation of                                                 1 We are grateful to the Neukom Foundation, the Linguistics Program, and the Native American Program at Dartmouth College for supporting the retreat. Likewise, many thanks to Michael Abramov and Oliver Adams for comments on this paper.  
2  speech is time-consuming. As a native speaker of Chatino, it takes me on average 30 minutes to transcribe one minute of text. For non-native speakers, the process could take much longer.   Speakers of minority languages frequently forgo literacy in their native languages to become competent in the dominant language of their nation state, which makes it difficult to obtain corpora for ASR models of minority languages. The first author was literate in Spanish and English long before she could read and write Chatino, which did not have a working alphabet until the author was forty years old.   Researchers of dominant languages, such as Spanish, do not face the same problem. For instance, Carlos Hernandez Mena, a computer scientist from UNAM who participated in the retreat related that he uses students doing their compulsory social service to transcribe and edit data that Carlos downloads from Youtube (Hernández Mena & Herrera 2017). This workflow has allowed him to acquire massive corpora of Mexican Spanish. Researchers of endangered languages do not have this same privilege.  In contrast, transcription of endangered languages is a long and roundabout process: a field linguist, usually with Western training, collaborates with a language consultant; they listen and discuss the sounds of the language together; the linguist makes notes and formulates questions; and the language consultant repeats those sounds over and over again.  Because of these obstacles, cross-disciplinary dialogue between linguists and computer scientists is a necessity. Computer scientists developing ASR models often do not understand the many difficulties that field linguists face: conflict-ridden locales, malaria outbreaks, or a severe lack of remaining language consultants. On the other hand, linguists are frequently unaware of the ASR technologies available to them.  High-tech industries do not develop ASR models for lesser-studied languages because they are not deemed profitable, while computational linguists often cite pressure to get university tenure as a reason to forgo research on minority languages. What has been written about tools for “low resource languages” in the literature of computer science focuses on the needs and desires of Western linguists, with little mention of native speakers and their role in the advancement of these tools. Collaborative conversations have not taken place in part because native speakers lack the influence, the funding, and the connections to convene researchers with a common vision. Most conversations about ASR take place in formal settings, such as conferences, workshops, and forums, and are not well attended by native speakers.   The need to automate the transcription of Chatino became more urgent for the first author when she began to transcribe audio recordings that Lynn Hou, an Assistant professor of Linguistics at the University of California Santa Barbara, made in San Juan Quiahije by working with families of deaf children. Lina is deaf and relies on transcription of any spoken language she encounters.   The author endeavored to provide Lina with careful annotations of the Chatino materials she collected so that she could have reliable data to analyze. The task was extremely time-consuming and laborious. The author found herself typing the same words over and over again, 
3  and she yearned to be able to automate the process. She began to ask linguists what it would take to automate the transcription of Chatino. She was told that most said ASR was not possible for minority languages because they lacked large corpora to feed the ASR models.   This question led her to collaborate with Damir and Malgorzata Cavar from Indiana University. By reading aloud numerous previously transcribed texts, they developed the first corpus of Chatino texts for ASR training (Cavar et al. 2016). This corpus has a creative commons license, meaning that anyone can download and use it. When the author became a Neukom Fellow at Dartmouth College, she set out to improve and expand on this corpus, while looking for ways to develop ASR for Chatino and other minority languages.   In another part of the world, linguist Alexis Michaud, who works with Yongning Na, a language of Southwest China, had similar goals: to automate the transcription process of the Na languages (Michaud et al. 2018). He designed his recordings so that they could eventually be used for ASR training. He began a successful collaboration with Oliver Adams, a computer scientist based out of the Melbourne University, who is now a Postdoctoral Fellow at Johns Hopkins University.   Along the way, Adams developed an open-source ASR toolkit called Persephone, which relies on neural networks, and quickly began to yield promising results in the transcription of Na. The tool was yielding a 20% error rate, and Michaud began to deploy Persephone into his linguistic workflow (Adams et al. 2018).They also found that Persephone could attain reasonable accuracy for a single speaker with as little as thirty minutes of data—an auspicious sign for endangered languages (Adams et al. 2018).  Next, Michaud and Adams wished to test the model on a comparable tonal language, and they found their way to the Chatino corpus in Global Open Resources and Information for Language and Linguistics Analysis. They invited me to evaluate some of Persephone’s output (Adams et al. 2018), and to my great surprise, the system performed well for Chatino. At this time, Persephone is only accessible to computer scientists, requiring an interface overhaul to reach a broader audience. Seeing the results from the cross-comparation of Yongning Na and Chatino, motivated the first author to continue seeking collaborations with specialists in Natural language processing to continue advancing and improving ASR for Chatino and other indigenous languages of the Americas. This is how the idea of the retreat began. 2.0 The retreat The William H. Neukom Foundation at Dartmouth College advocates for and funds interdisciplinary working groups to foster cross-disciplinary dialogue to advance scientific research. Often organized through “retreats,” scholars with a common mission come together in a friendly and intimate place—usually the Upper Valley in New Hampshire and Vermont—to discuss solutions to a problem or a question that they have been pondering.  Daniel Rockmore, the dean of sciences at Dartmouth College and director of the Neukom Institute, encouraged the first author to host a retreat to discuss the development of ASR for endangered languages. With Rockmore’s support, she proceeded to invite computer scientists, linguists, native speakers, and language activists to join me in Quechee, Vermont, where we 
4  would discuss ways to advance ASR for lesser-studied languages.2 The event took place from July 12-14, 2018.  The twenty people who participated in the retreat came from John Hopkins, Carnegie Mellon, Yale University, University of North Texas, University of Texas at Austin, Universidad Autonoma de Mexico, and the Centro de Investigaciones y Estudios Superiores en Antropología, Mexico. The meeting struck a balance between engineers, linguists, native speakers, and language activists.  All of the participants stayed in a ski lodge called the Owl's Nest. The environment was low-key and relaxed. There were no PowerPoint presentations, just everyone gathered together in the living room. During catered meal breaks, participants organically broke into mixed groups and carried on the conversations of the day. We spent the first full day with introductions, sharing research interests, and setting an agenda for the weekend. Before dinner, we took an excursion paddling in canoes on the Connecticut River. The second day was marked with more detailed descriptions of everyone's research and concluded the day to a visit to Vermont Institute of Natural Science, a raptor education center and bird sanctuary.  On the second day, we shared and discussed what resources we had at our disposal for model training. Questions ranged from what languages participants had worked on and how many hours of recordings we had elicited, to more technical matters, such as recording format, file types (word, PDF, and ELAN),3 to demographic information, including the number, age, and gender of speakers in the corpus.    Participants spoke or studied languages from six language families and four continents: from Australia: Nyulnyulan (Bardi) Pama-Nyungan (Djambarrpuyngu, Djapu); from Africa: Masso (Burkina Faso); from India: Tibeto-Burma (Manipuri and 17 others); and from the Americas: Otomanguean (Chatino, Otomi); Maya (Tzetsal, Tzotzil, and Mocho). Many of these languages are severely endangered. The Australian languages, for instance, have an average of four to five speakers, while one of the two varieties of Mocho Maya languages have one speaker each.   Both the linguists and the computer scientists were eager to learn about each other’s workflows and the steps needed to complete a task. While most field linguists undergo an iterative process of data collection and documentation, computer scientists usually begin their research by reading academic papers and then replicating what they learn.                                                          2 ASREL retreat: https://sites.dartmouth.edu/neukom/asrel/) 3 A software used by linguists for transcription, translation, and annotation. 
5     
  Though collaboration was our goal, we quickly learned that ASR models require substantial technical expertise to be used effectively. Persephone, for example, has preliminary support for ELAN files—which is great for linguists— and a web-API is under development so that Persephone might be used by a broader audience.  Moreover, we learned that there is no theoretical obstacle to creating an interface that would allow a linguist to upload speech and transcriptions for model training. It is largely a matter of having a professional software engineer develop the tool. Such automation has the potential to improve the rate of language documentation. Automating the transcription process yields three beneficial results. First, there is a potential for greater consistency in the transcription. Second, the researcher becomes less of a transcriber and more of an editor. Finally, automated transcriptions can provide fresh insight into the nature of the language under study.   We reached several milestones during our retreat. It was the first meeting of its kind to be convened by a native speaker of an endangered language. In the past, there has been little interest in ASR projects for minority languages. Native speakers have been historically denied the right to become literate in their languages, and as a result, those minority languages are under-represented and under-resourced in academia.   Native speakers need to be involved in conversations about ASR, as they bring community-oriented perspectives and accountability that are often overlooked or ignored by non-

6  native speaker linguists and computer scientists. The event was a resounding success. It was productive and enjoyable. People left eager to continue the conversation on how improve and promote ASR for endangered languages.   References  Adams, Oliver & Cohn, Trevor & Neubig, Graham & Cruz, Hilaria & Bird, Steven & Michaud, Alexis. 2018. Evaluating phonemic transcription of low-resource tonal languages for language documentation. Proceedings of LREC 2018 (Language Resources and Evaluation Conference).. https://halshs.archives-ouvertes.fr/halshs-01709648.  Ćavar, Małgorzata E. &Cavar, Damir & Cruz, Hilaria. 2016. Endangered Language Documentation: Bootstrapping a Chatino Speech Corpus, Forced Aligner, ASR. LREC. 4004–4011.  Hernández Mena, Carlos Daniel & Herrera, Abel. 2017. CIEMPIESS (Corpus de Investigación en Español de México del Posgrado de Ingeniería Eléctrica y Servicio Social) Light. Linguistic Data Consortium. (https://catalog.ldc.upenn.edu/LDC2017S23).  Michaud, Alexis & Adams, Oliver & Cohn, Trevor A. & Neubig, Graham & Guillaume, Séverine. 2018. Integrating automatic transcription into the language documentation workflow: experiments with Na data and the Persephone toolkit. Language Documentation and Conservation 12. 393-429.   Mithun, Marianne. 1998. The significance of diversity in language endangerment and preservation. In L. Grenoble and L. Whaley (eds.), Endangered languages: Current Issues and Future Prospects, 163-191. Cambridge: Cambridge University Press.   ","1   using technology to save endangered languages1 how linguists and computer scientists came together in a retreat to explore ways to advance automatic speech recognition for endangered languages hilaria cruz and joseph waring   abstract in august 2018 a retreat in quechee vermont brought together computer scientists specializing in natural language processing linguists native speakers and endangered language activists under one roof during the retreat participants discussed ways to utilize the latest advances in automatic speech recognition especially neural networks to transcribe endangered languages and tackle the difficulties of transcribing natural language addressing what is known as the bottle neck of language transcription in a relaxed environment where work was mixed with fun everyone who participated became friends quickly and interacted with collegiality exhibiting great potential for future collaborations 10 background automatic speech recognition asr is a burgeoning technology with near limitless potential voice recognition which was once considered science fiction is now commonplace alexa siri and ok google live on countertops and bedside tables in our homes nevertheless this technology has been limited to major dominant languages such as english german and spanish   in the 19th and 20th centuries nation states sought to stamp out linguistic and cultural diversity setting language decline in rapid motion all over the world most of the worlds 7000 languages will fall out of use by the end of this century if language loss continues at its current rate limiting humanitys ability to appreciate the full creative capacities of the human mind mithun 1998189  the rapid development of asr technologies especially of neural networks could expedite the transcription translation and linguistic annotation of endangered languages providing resources for research revitalization and promotion before this can be achieved linguists and computational scientists must overcome several technological and methodological obstacles  traditional asr models such as markov chains forced alignment and hidden markov models require vast quantities of training data to get a model running michaud et al 2018 most endangered languages lack large corpora alphabets or speakers for data elicitation a great number of these languages only have a few speakers left manual transcription and annotation of                                                 1 we are grateful to the neukom foundation the linguistics program and the native american program at dartmouth college for supporting the retreat likewise many thanks to michael abramov and oliver adams for comments on this paper  
2  speech is timeconsuming as a native speaker of chatino it takes me on average 30 minutes to transcribe one minute of text for nonnative speakers the process could take much longer   speakers of minority languages frequently forgo literacy in their native languages to become competent in the dominant language of their nation state which makes it difficult to obtain corpora for asr models of minority languages the first author was literate in spanish and english long before she could read and write chatino which did not have a working alphabet until the author was forty years old   researchers of dominant languages such as spanish do not face the same problem for instance carlos hernandez mena a computer scientist from unam who participated in the retreat related that he uses students doing their compulsory social service to transcribe and edit data that carlos downloads from youtube hernndez mena  herrera 2017 this workflow has allowed him to acquire massive corpora of mexican spanish researchers of endangered languages do not have this same privilege  in contrast transcription of endangered languages is a long and roundabout process a field linguist usually with western training collaborates with a language consultant they listen and discuss the sounds of the language together the linguist makes notes and formulates questions and the language consultant repeats those sounds over and over again  because of these obstacles crossdisciplinary dialogue between linguists and computer scientists is a necessity computer scientists developing asr models often do not understand the many difficulties that field linguists face conflictridden locales malaria outbreaks or a severe lack of remaining language consultants on the other hand linguists are frequently unaware of the asr technologies available to them  hightech industries do not develop asr models for lesserstudied languages because they are not deemed profitable while computational linguists often cite pressure to get university tenure as a reason to forgo research on minority languages what has been written about tools for low resource languages in the literature of computer science focuses on the needs and desires of western linguists with little mention of native speakers and their role in the advancement of these tools collaborative conversations have not taken place in part because native speakers lack the influence the funding and the connections to convene researchers with a common vision most conversations about asr take place in formal settings such as conferences workshops and forums and are not well attended by native speakers   the need to automate the transcription of chatino became more urgent for the first author when she began to transcribe audio recordings that lynn hou an assistant professor of linguistics at the university of california santa barbara made in san juan quiahije by working with families of deaf children lina is deaf and relies on transcription of any spoken language she encounters   the author endeavored to provide lina with careful annotations of the chatino materials she collected so that she could have reliable data to analyze the task was extremely timeconsuming and laborious the author found herself typing the same words over and over again 
3  and she yearned to be able to automate the process she began to ask linguists what it would take to automate the transcription of chatino she was told that most said asr was not possible for minority languages because they lacked large corpora to feed the asr models   this question led her to collaborate with damir and malgorzata cavar from indiana university by reading aloud numerous previously transcribed texts they developed the first corpus of chatino texts for asr training cavar et al 2016 this corpus has a creative commons license meaning that anyone can download and use it when the author became a neukom fellow at dartmouth college she set out to improve and expand on this corpus while looking for ways to develop asr for chatino and other minority languages   in another part of the world linguist alexis michaud who works with yongning na a language of southwest china had similar goals to automate the transcription process of the na languages michaud et al 2018 he designed his recordings so that they could eventually be used for asr training he began a successful collaboration with oliver adams a computer scientist based out of the melbourne university who is now a postdoctoral fellow at johns hopkins university   along the way adams developed an opensource asr toolkit called persephone which relies on neural networks and quickly began to yield promising results in the transcription of na the tool was yielding a 20 error rate and michaud began to deploy persephone into his linguistic workflow adams et al 2018they also found that persephone could attain reasonable accuracy for a single speaker with as little as thirty minutes of dataan auspicious sign for endangered languages adams et al 2018  next michaud and adams wished to test the model on a comparable tonal language and they found their way to the chatino corpus in global open resources and information for language and linguistics analysis they invited me to evaluate some of persephones output adams et al 2018 and to my great surprise the system performed well for chatino at this time persephone is only accessible to computer scientists requiring an interface overhaul to reach a broader audience seeing the results from the crosscomparation of yongning na and chatino motivated the first author to continue seeking collaborations with specialists in natural language processing to continue advancing and improving asr for chatino and other indigenous languages of the americas this is how the idea of the retreat began 20 the retreat the william h neukom foundation at dartmouth college advocates for and funds interdisciplinary working groups to foster crossdisciplinary dialogue to advance scientific research often organized through retreats scholars with a common mission come together in a friendly and intimate placeusually the upper valley in new hampshire and vermontto discuss solutions to a problem or a question that they have been pondering  daniel rockmore the dean of sciences at dartmouth college and director of the neukom institute encouraged the first author to host a retreat to discuss the development of asr for endangered languages with rockmores support she proceeded to invite computer scientists linguists native speakers and language activists to join me in quechee vermont where we 
4  would discuss ways to advance asr for lesserstudied languages2 the event took place from july 1214 2018  the twenty people who participated in the retreat came from john hopkins carnegie mellon yale university university of north texas university of texas at austin universidad autonoma de mexico and the centro de investigaciones y estudios superiores en antropologa mexico the meeting struck a balance between engineers linguists native speakers and language activists  all of the participants stayed in a ski lodge called the owls nest the environment was lowkey and relaxed there were no powerpoint presentations just everyone gathered together in the living room during catered meal breaks participants organically broke into mixed groups and carried on the conversations of the day we spent the first full day with introductions sharing research interests and setting an agenda for the weekend before dinner we took an excursion paddling in canoes on the connecticut river the second day was marked with more detailed descriptions of everyones research and concluded the day to a visit to vermont institute of natural science a raptor education center and bird sanctuary  on the second day we shared and discussed what resources we had at our disposal for model training questions ranged from what languages participants had worked on and how many hours of recordings we had elicited to more technical matters such as recording format file types word pdf and elan3 to demographic information including the number age and gender of speakers in the corpus    participants spoke or studied languages from six language families and four continents from australia nyulnyulan bardi pamanyungan djambarrpuyngu djapu from africa masso burkina faso from india tibetoburma manipuri and 17 others and from the americas otomanguean chatino otomi maya tzetsal tzotzil and mocho many of these languages are severely endangered the australian languages for instance have an average of four to five speakers while one of the two varieties of mocho maya languages have one speaker each   both the linguists and the computer scientists were eager to learn about each others workflows and the steps needed to complete a task while most field linguists undergo an iterative process of data collection and documentation computer scientists usually begin their research by reading academic papers and then replicating what they learn                                                          2 asrel retreat httpssitesdartmoutheduneukomasrel 3 a software used by linguists for transcription translation and annotation 
5     
  though collaboration was our goal we quickly learned that asr models require substantial technical expertise to be used effectively persephone for example has preliminary support for elan fileswhich is great for linguists and a webapi is under development so that persephone might be used by a broader audience  moreover we learned that there is no theoretical obstacle to creating an interface that would allow a linguist to upload speech and transcriptions for model training it is largely a matter of having a professional software engineer develop the tool such automation has the potential to improve the rate of language documentation automating the transcription process yields three beneficial results first there is a potential for greater consistency in the transcription second the researcher becomes less of a transcriber and more of an editor finally automated transcriptions can provide fresh insight into the nature of the language under study   we reached several milestones during our retreat it was the first meeting of its kind to be convened by a native speaker of an endangered language in the past there has been little interest in asr projects for minority languages native speakers have been historically denied the right to become literate in their languages and as a result those minority languages are underrepresented and underresourced in academia   native speakers need to be involved in conversations about asr as they bring communityoriented perspectives and accountability that are often overlooked or ignored by non

6  native speaker linguists and computer scientists the event was a resounding success it was productive and enjoyable people left eager to continue the conversation on how improve and promote asr for endangered languages   references  adams oliver  cohn trevor  neubig graham  cruz hilaria  bird steven  michaud alexis 2018 evaluating phonemic transcription of lowresource tonal languages for language documentation proceedings of lrec 2018 language resources and evaluation conference httpshalshsarchivesouvertesfrhalshs01709648  avar magorzata e cavar damir  cruz hilaria 2016 endangered language documentation bootstrapping a chatino speech corpus forced aligner asr lrec 40044011  hernndez mena carlos daniel  herrera abel 2017 ciempiess corpus de investigacin en espaol de mxico del posgrado de ingeniera elctrica y servicio social light linguistic data consortium httpscatalogldcupenneduldc2017s23  michaud alexis  adams oliver  cohn trevor a  neubig graham  guillaume sverine 2018 integrating automatic transcription into the language documentation workflow experiments with na data and the persephone toolkit language documentation and conservation 12 393429   mithun marianne 1998 the significance of diversity in language endangerment and preservation in l grenoble and l whaley eds endangered languages current issues and future prospects 163191 cambridge cambridge university press","['httpshalshsarchivesouvertesfrhalshs01709648', 'crossdisciplinary', 'transcribing', 'httpssitesdartmoutheduneukomasrel', '40044011', 'httpscatalogldcupenneduldc2017s23', 'burgeoning', 'djambarrpuyngu', 'transcriber', 'crosscomparation']",4
Supporting Undotted Arabic with Pre-trained Language Models,"['Aviad Rom', 'Kfir Bar']",2021,http://arxiv.org/abs/2111.09791v1,"Supporting Undotted Arabic with Pre-trained Language Models
Aviad Rom and Kﬁr Bar
The Data Science Institute, Reichman University, Herzliya, Israel
{aviad.rom,kfir.bar}@post.idc.ac.il
Abstract
We observe a recent behaviour on social me-
dia, in which users intentionally remove con-
sonantal dots from Arabic letters, in order to
bypass content-classiﬁcation algorithms. Con-
tent classiﬁcation is typically done by ﬁne-
tuning pre-trained language models, which
have been recently employed by many natural-
language-processing applications. In this work
we study the effect of applying pre-trained
Arabic language models on “undotted” Ara-
bic texts. We suggest several ways of sup-
porting undotted texts with pre-trained models,
without additional training, and measure their
performance on two Arabic natural-language-
processing downstream tasks. The results are
encouraging; in one of the tasks our method
shows nearly perfect performance.
1 Introduction
Arabic is a highly inﬂected Semitic language, spo-
ken by almost 400 million native speakers around
the world. Arabic words are highly ambiguous,
mostly due to the lack of short vowels, represented
by diacritic vocalization marks, which are typically
omitted in standard writing. Modern Standard Ara-
bic (MSA), is the language that is used in ofﬁcial
settings, while the dialectal variants of Arabic are
used in day-to-day conversations. In addition to
vocalization marks, some Arabic letters carry dots,
called i’jaam (ÐAj.«@), which are used to distinguish
between consonants represented by the same or-
thographic form, or rasm (ÕæP) in Arabic. For ex-
ample, the letters T ¯a ( K), Y¯a ( K
), Th ¯a ( K), B¯a ( K.),
and Nun ( 	K) have exactly the same orthographic
shape, excluding the number and location of the
dots they carry. Without the dots, the letter remains
ambiguous. Nevertheless, some dots are sometimes
forgotten in handwritten scripts, forcing the reader
to use the surrounding context in order to resolve
such ambiguities. It becomes slightly more com-
plicated when some of the letters turn into otherArabic letters after their dots are being removed.
For example, by removing the three dots from the
letter Sh ¯ın ( ) we get the letter S ¯ın ( ), and that
makes different words look the same. For exam-
ple, the reader may have difﬁculty understanding
the meaning of the word I.ª(sa’b), which can be
interpreted without the dots as ""sigh"", and with the
dots I.ª(sha’b ) as ""people"". Additional examples
are provided in Table 2.
Fortunately, dots are strictly used in digitized
texts. However, we have noticed a recent trend of
removing dots from Arabic posts on social media
(Drißner, 2021)1, where people use special key-
boards and applications to naturally write with-
out dots, mainly for bypassing automatic content-
ﬁltering algorithms to avoid having their message
classiﬁed as offensive. It seems like most native
Arabic speakers can still understand the meaning
of the text, even if provided dotless. Table 1 shows
an example for a text and its undotted version.
The use of dots for distinguishing between con-
sonants was introduced to the Arabic language after
the rise of Islam, when non native speakers started
showing interest in the new religion. Until that
time, the knowledge of how to pronounce undot-
ted text was based on the reader’s memory and the
surrounding context (Daniels, 2014).
The use of Transformer (Vaswani et al., 2017)
in natural language processing (NLP) has become
fundamental to achieve state-of-the-art results in
different downstream tasks, including content ﬁl-
tering. Since Transformer-based language mod-
els are trained with digitized texts, the vocabulary
acquired from the data is represented with dots.
Therefore, the undotted letters that are not part of
the ofﬁcial Arabic language, are not recognized
by the model, even if they exist in the Unicode
character set (e.g., ""Dotless Archaic Beh"" [ H]).
In this work, we study the effect of removing
dots from text written in Arabic, on the perfor-
1https://arabic-for-nerds.com/dotless-arabic/arXiv:2111.09791v1  [cs.CL]  18 Nov 2021
mance of a Transformer-based language model,
employed as a typical content-ﬁltering classiﬁer.
Our results show that replacing the dotted MSA
letters with their corresponding dotless versions,
causes a strong adversarial effect on the perfor-
mance of the language model that was ﬁne-tuned
on various downstream tasks. We describe our at-
tempts to handle undotted Arabic, none of them
require re-training the language model, and discuss
their results and potential contributions.
2 Related Work
2.1 Arabic Transformer Models
Multilingual BERT, or mBERT (Devlin et al.,
2019), was the ﬁrst pre-trained language model
to include Arabic. It covers only MSA, and usually
do not perform well enough on downstream Ara-
bic NLP tasks, due to the relatively small Arabic
training data it was trained on. AraBERT (An-
toun et al., 2020) and GigaBERT (Lan et al., 2020)
are two language models that were trained on a
much larger portion of Arabic texts, still only MSA.
Both offer better performance on downstream tasks.
Two recent models, MARBERT (Abdul-Mageed
et al., 2021a), and CAMeLBERT (Inoue et al.,
2021), include Dialectical Arabic in their training
data, reaching better performance on relevant tasks.
None of these models have been used with undotted
Arabic, which is the main focus of our work.
2.2 Adversarial Inputs in NLP
Adversarial inputs are crafted examples to deceive
neural networks at inference time. Such attacks
have already been introduced and discussed by
Szegedy et al. 2013 and Goodfellow et al. 2015, fo-
cusing mostly on adversarial perturbations in vision
tasks. Generating adversarial inputs in NLP is con-
sidered to be more challenging than in computer vi-
sion, mostly due to the relatively large importance
every word has in a given input text, comparing to
the small importance a single pixel has in an input
image. Nonetheless, it has been recently addressed
by Jin et al. (2020), who presented an efﬁcient way
of generating adversarial textual inputs for a BERT
(Devlin et al., 2019), by modifying the texts seman-
tically based on some word statistics taken from
the language model itself. They showed that while
their modiﬁed texts are understandable by human
readers, their BERT-based models have struggled
to produce the correct output. In this work, we eval-
uate a more natural approach for fooling an Arabiclanguage model, simply by converting some letters
to their undotted versions, keeping the modiﬁed
text understandable for human readers.
3 Handling Undotted Arabic
We begin by ﬁne-tuning a Transformer-based Ara-
bic language model on two downstream tasks, and
evaluate their performance on undotted inputs. Fol-
lowing that, we develop different computational
approaches for recovering the missing information
that was lost with undotting, without pre-training
the language model itself. We evaluate the different
approaches on the same downstream tasks, and re-
port on the results in the following section. For all
our experiments we use the recent CAMeLBERT-
Mix base model (Inoue et al., 2021), which was
pre-trained on a mix of MSA, Classical Arabic, and
Dialectical Arabic texts.
3.1 Undotting
In order to remove dots from the text, we created
a mapping for all the Arabic characters available
in the Unicode character set, for which we match
the most resemblant undotted character. The map-
ping table is provided in Appendix A. Some Arabic
letters have different forms, depending on whether
they appear at the beginning, middle or end of a
word. Therefore, we map all the forms of a relevant
letter. Undotting an input text is a simple replace-
ment of all relevant letters with their orthographic
equivalents.
3.2 Supporting Undotted Arabic
As reported in the following section, ﬁne-tuned
Arabic language models do not perform well on
undotted texts. Therefore, we suggest two ways
to handle undotted texts. In one way, we make
changes to the tokenizer of the model, and in an-
other way we develop an algorithm for restoring
the dots of the input text, which runs as a pre-
processing step before submitting the text to the
language model.
3.2.1 Changing the Tokenizer
Before processing the text with a pre-trained lan-
guage model, it is necessary to break it into tokens
using the same tokenizer that was used during the
pre-training phase of the model. CAMeLBERT-
Mix uses a standard BERT tokenizer, provided by
Hugging Face2, with a vocabulary of 30,000 tokens.
2https://github.com/huggingface/
tokenizers
OriginaléJ
K
ñºË@éJ
ÒJ
Ê¯B@ èAJ
ÖÏ@ ú
	¯ QåJ	K ú
æË@ ©Ë@éJ
K
ñºË@ P 	Qm.Ì'@ øYg@ èðPA¯@ YªKð
Undotted éJJKñºË@ éJÒJÊ¯B @ èAJÖ Ï@ ú¯ QåJJK úæË@ ©Ë@ éJJKñºË@ PQm Ì'@ øYg@ èðPA¯@ YªKð
Translation Qaruh is one of the nine Kuwaiti islands in the Kuwaiti territorial waters
Table 1: Arabic text, given with and without the dots. The text was taken from https://arabic.cnn.com/
travel/article/2021/07/13/qaruh-island-kuwait .
Each token has a numeric identiﬁer. We take two
different approaches for changing the conﬁguration
of the tokenizer in order to handle undotted texts
without having to pre-train the language model, nor
ﬁne-tuning it on a downstream task.
Undotting the Tokenizer Vocabulary. Accord-
ing to this approach, we undot the entire vocabu-
lary of the tokenizer, thereby enabling it to seam-
lessly recognize undotted letters and words. Obvi-
ously, after undotting the vocabulary some of the
tokens (5,852 out of the original 30,000 tokens,
or19:52%) become identical, leaving some of the
token identiﬁers unused; therefore, the model’s vo-
cabulary get smaller. Since we suspect that work-
ing with a smaller vocabulary may be detrimental
to the performance of the model on downstream
tasks, we suggest another approach for modifying
the tokenizer.
Extending the Tokenizer Vocabulary. Under
this approach, we extend the tokenizer’s vocabu-
lary by adding the undotted version of the relevant
tokens and mapping them to the same identiﬁer of
their original token. This way the tokenizer keeps
the original dotted version of every token, and thus
can accept both, dotted and undotted inputs. We
add the undotted version of a token only if it is not
already part of the vocabulary; overall, we added
17,280 undotted versions. The resulting vocabulary
has about 57% token identiﬁers that are mapped to
two token versions.
3.2.2 AReDotter: Restoring Arabic Dots
As opposed to the previous approach, here we de-
velop an algorithm for pre-processing the input un-
dotted text to restore its dots. The language model
itself remains unmodiﬁed.
We train a sequence-to-sequence machine-
translation (MT) model on the unlabeled 10M Ara-
bic tweets dataset published with the second NADI
shared task (Abdul-Mageed et al., 2021b). The
tweets were posted from multiple geographies.
For creating parallel texts for training, every
tweet from the original corpus was paired withits automatically generated undotted version, using
the mappings provided in Appendix A. We remove
from the tweets URLs, user mentions, and hash-
tags.
Our MT model is based on the pre-trained
Arabic-to-English Marian MT (Tiedemann and
Thottingal, 2020) architecture3, which was ﬁne-
tuned for ""undotted Arabic""-to-Arabic translation.
We ﬁne-tune our model on the entire parallel
dataset for two epochs.
4 Experimental Results
To evaluate our proposed methods, we ﬁne-tune
CAMeLBERT on two tasks, sentence level and
token level.
For the sentence-level task we use the sentiment
analysis subtask of ArSarcasm-v2 (Abu Farha et al.,
2021), designed as a three-labels (positive, nega-
tive, neutral) classiﬁcation task. As we did with
NADI, we preprocess the text to remove URLs,
user mentions, and hashtags. For evaluation, we
use the ofﬁcial evaluation objective metric, deﬁned
as macro average F1 score of both non-neutral la-
bels.
For a token-level downstream task, we evaluate
our language model on the named-entity recogni-
tion (NER) task using the ANERcorp dataset (Be-
najiba et al., 2007). We use the modiﬁed version of
the dataset, which was recently released by Obeid
et al. (2020). Following previous works on NER,
we use the micro average F1 metric for evaluation.
For each task, we ﬁne-tune CAMeLBERT on the
original preprocessed training data for 10 epochs,
using the ofﬁcial train/test split, and evaluate it
on the undotted version of the test set. We use
the standard Hugging Face’s pipelines, AutoMod-
elForSequenceClassiﬁcation and AutoModelFor-
TokenClassiﬁcation4for the sentiment analysis and
NER tasks, respectively. We evaluate the models
under different conditions of supporting undotted
3Speciﬁcally, we used the Helsinki-NLP/opus-mt-ar-en
model from Hugging Face.
4https://huggingface.co/transformers/
model_doc/auto.html
Undotted Option 1 (pronunciation, meaning) Option 2 (pronunciation, meaning)
IjJ¯ I.j.J
	¯(fyajib , ""must"") IjJ	¯(fatahat , ""opened"")
PA®KPA	®K(tafaruq , ""leave"")PA	®K.(bifariq , ""difference"")
PAm' PAm.	'(najaar , ""carpenter"") PAm'.(bahaar , ""seas"")
HñJk H.ñJ.k(hubub , ""cereal"") H.ñ	Jk.(janub , ""south"")
Table 2: Examples of undotted ambiguous words. We do not provide all the possible pronunciations in each row.
ArSarcasm V2 - Sentiment ANERCorp
Original Text 70:55 81:39
Undotted Text 44:86 9:16
Undotted Text + Undotted Tokenizer 64:50 72:85
Undotted Text + Extended Tokenizer 65:03 71:68
AReDotter 68:27 67:97
Table 3: Model performance on downstream tasks, using different undotted text handling approaches.
texts, as described in the previous section.
4.1 Results
The results, reported in Table 3, demonstrate the ad-
versarial effect of processing undotted Arabic with
a vanilla, unmodiﬁed CAMeLBERT model. The
ﬁrst row lists the results we get by working with the
original texts. In the second row we provide the re-
sults of using the same model, but this time applied
on the undotted version of the texts. As observed,
the metrics measured for the two tasks dropped
signiﬁcantly on undotted texts. Unsurprisingly, the
tokenizer of the vanilla language model does not
recognize tokens with undotted letters, which are
excluded from the modern Arabic script, and thus
treating them as “unknown” tokens.
The two tokenizer-updating approaches, whose
results are reported in the 3rd and 4th rows, prove
to be effective for undotted texts, in both tasks.
This improvement is achieved mainly due to the
reduction in the number of unknown tokens the
model is assigned with. Among the two, we ob-
serve that the extended tokenizer is slightly better
on the sentiment analysis task, while the undotted
tokenizer is better on the NER task. However, the
difference in those results is insigniﬁcant.
Interestingly, AReDotter, our MT dots restora-
tion model, which we run as a preprocessor be-
fore submitting the text to the language model,
provides competitive results in both task. It is
slightly better than the tokenizer-updating tech-
niques on sentiment analysis, but slightly worse on
the NER task. Naturally, a sequence-to-sequence
translation model may sometimes generate someout-of-context tokens in the target sequence. We
believe that NER is more sensitive to this type of
mistakes than sentiment analysis task. For future
work, we plan to work with a simple sequential-
tagging model instead of the sequence-to-sequence
MT model, to avoid generating such tokens. The
results we get from AReDotter are encouraging; it
provides an elegant way to support undotted text
without modifying the model or the tokenizer.
5 Conclusion
Undotting has been recently adopted by social-
media users in order to bypass content-ﬁltering
gateways. We studied the effect of undotting on
the performance of a standard pre-trained language
model. Our results show that processing undotted
text with a vanilla, unmodiﬁed language model, has
a detrimental effect in two downstream NLP tasks.
By simply editing the tokenizer, which is used by
the language model, we are able to show signiﬁcant
improvements over the vanilla model.
Our third approach, which does not require
changing the tokenizer, is using a machine-
translation model for restoring the missing dots.
With this technique we show competitive results to
the tokenizer-updating techniques, without having
to modify the model or its tokenizer. We believe
that our study provides some conclusions as for
how undotted texts should be treated with modern
Transformer-based language models. We recom-
mend that at least one of our techniques will be
adopted as a standard step in a common Arabic
NLP pipeline.
References
Muhammad Abdul-Mageed, AbdelRahim Elmadany,
and El Moatez Billah Nagoudi. 2021a. ARBERT
& MARBERT: Deep Bidirectional Transformers for
Arabic. In Proceedings of the ACL-IJCNLP 2021
Main Conference . Association for Computational
Linguistics.
Muhammad Abdul-Mageed, Chiyu Zhang, Abdel-
Rahim Elmadany, Houda Bouamor, and Nizar
Habash. 2021b. NADI 2021: The second nuanced
Arabic dialect identiﬁcation shared task. In Proceed-
ings of the Sixth Arabic Natural Language Process-
ing Workshop , pages 244–259, Kyiv, Ukraine (Vir-
tual). Association for Computational Linguistics.
Ibrahim Abu Farha, Wajdi Zaghouani, and Walid
Magdy. 2021. Overview of the WANLP 2021 shared
task on sarcasm and sentiment detection in Arabic.
InProceedings of the Sixth Arabic Natural Lan-
guage Processing Workshop , pages 296–305, Kyiv,
Ukraine (Virtual). Association for Computational
Linguistics.
Wissam Antoun, Fady Baly, and Hazem Hajj. 2020.
AraBERT: Transformer-based model for Arabic lan-
guage understanding. In Proceedings of the 4th
Workshop on Open-Source Arabic Corpora and Pro-
cessing Tools, with a Shared Task on Offensive Lan-
guage Detection , pages 9–15, Marseille, France. Eu-
ropean Language Resource Association.
Yassine Benajiba, Paolo Rosso, and José Miguel
BenedíRuiz. 2007. ANERsys: An Arabic named
entity recognition system based on maximum en-
tropy. In Computational Linguistics and Intelligent
Text Processing , pages 143–153, Berlin, Heidelberg.
Springer Berlin Heidelberg.
Peter T. Daniels. 2014. The Type and Spread of Ara-
bic Script , pages 25 – 39. Brill, Leiden, The Nether-
lands.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers) ,
pages 4171–4186, Minneapolis, Minnesota. Associ-
ation for Computational Linguistics.
Gerald Drißner. 2021. Social media & palestine: Dot-
less Arabic outsmarts algorithms.
Ian Goodfellow, Jonathon Shlens, and Christian
Szegedy. 2015. Explaining and harnessing adversar-
ial examples. In International Conference on Learn-
ing Representations .
Go Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda
Bouamor, and Nizar Habash. 2021. The interplay
of variant, size, and task type in Arabic pre-trained
language models. In Proceedings of the Sixth Ara-
bic Natural Language Processing Workshop , Kyiv,
Ukraine (Online). Association for Computational
Linguistics.Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter
Szolovits. 2020. Is BERT really robust? A strong
baseline for natural language attack on text clas-
siﬁcation and entailment. In The Thirty-Fourth
AAAI Conference on Artiﬁcial Intelligence, AAAI
2020, The Thirty-Second Innovative Applications of
Artiﬁcial Intelligence Conference, IAAI 2020, The
Tenth AAAI Symposium on Educational Advances
in Artiﬁcial Intelligence, EAAI 2020, New York, NY,
USA, February 7-12, 2020 , pages 8018–8025. AAAI
Press.
Wuwei Lan, Yang Chen, Wei Xu, and Alan Ritter. 2020.
An empirical study of pre-trained transformers for
Arabic information extraction. In Proceedings of the
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , pages 4727–4734,
Online. Association for Computational Linguistics.
Ossama Obeid, Nasser Zalmout, Salam Khalifa, Dima
Taji, Mai Oudah, Bashar Alhafni, Go Inoue, Fadhl
Eryani, Alexander Erdmann, and Nizar Habash.
2020. CAMeL tools: An open source python toolkit
for Arabic natural language processing. In Proceed-
ings of the 12th Language Resources and Evaluation
Conference , pages 7022–7032, Marseille, France.
European Language Resources Association.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever,
Joan Bruna, Dumitru Erhan, Ian Goodfellow, and
Rob Fergus. 2013. Intriguing properties of neural
networks. arXiv preprint arXiv:1312.6199 .
Jörg Tiedemann and Santhosh Thottingal. 2020.
OPUS-MT — Building open translation services for
the World. In Proceedings of the 22nd Annual Con-
ferenec of the European Association for Machine
Translation (EAMT) , Lisbon, Portugal.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, ukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems , volume 30. Curran Associates, Inc.
A Appendix A: Undotting Table
Initial/Medial Terminal
Letter MSA Undotted Undotted
Ba H. K H
Ta H K H
Tha H K H
Jim h. k h
Kha p k h
Dhal	X X X
Zayn 	P P P
Shin   
Dad	  
Za’	  £  
Ghayn	¨ « ¨
Fa	¬ ¯ ¬
Qaf ¯ 
Nun	à K à
Ya ø
K ø
Table 4: Character mapping used for our undotting
function, specifying only the letters which are not iden-
tical to their undotted version.","supporting undotted arabic with pretrained language models
aviad rom and kr bar
the data science institute reichman university herzliya israel
aviadromkfirbarpostidcacil
abstract
we observe a recent behaviour on social me
dia in which users intentionally remove con
sonantal dots from arabic letters in order to
bypass contentclassication algorithms con
tent classication is typically done by ne
tuning pretrained language models which
have been recently employed by many natural
languageprocessing applications in this work
we study the effect of applying pretrained
arabic language models on undotted ara
bic texts we suggest several ways of sup
porting undotted texts with pretrained models
without additional training and measure their
performance on two arabic naturallanguage
processing downstream tasks the results are
encouraging in one of the tasks our method
shows nearly perfect performance
1 introduction
arabic is a highly inected semitic language spo
ken by almost 400 million native speakers around
the world arabic words are highly ambiguous
mostly due to the lack of short vowels represented
by diacritic vocalization marks which are typically
omitted in standard writing modern standard ara
bic msa is the language that is used in ofcial
settings while the dialectal variants of arabic are
used in daytoday conversations in addition to
vocalization marks some arabic letters carry dots
called ijaam aj which are used to distinguish
between consonants represented by the same or
thographic form or rasm p in arabic for ex
ample the letters t a  k ya  k
 th a  k ba  k
and nun  	k have exactly the same orthographic
shape excluding the number and location of the
dots they carry without the dots the letter remains
ambiguous nevertheless some dots are sometimes
forgotten in handwritten scripts forcing the reader
to use the surrounding context in order to resolve
such ambiguities it becomes slightly more com
plicated when some of the letters turn into otherarabic letters after their dots are being removed
for example by removing the three dots from the
letter sh n   we get the letter s n   and that
makes different words look the same for exam
ple the reader may have difculty understanding
the meaning of the word isab which can be
interpreted without the dots as sigh and with the
dots ishab  as people additional examples
are provided in table 2
fortunately dots are strictly used in digitized
texts however we have noticed a recent trend of
removing dots from arabic posts on social media
driner 20211 where people use special key
boards and applications to naturally write with
out dots mainly for bypassing automatic content
ltering algorithms to avoid having their message
classied as offensive it seems like most native
arabic speakers can still understand the meaning
of the text even if provided dotless table 1 shows
an example for a text and its undotted version
the use of dots for distinguishing between con
sonants was introduced to the arabic language after
the rise of islam when non native speakers started
showing interest in the new religion until that
time the knowledge of how to pronounce undot
ted text was based on the readers memory and the
surrounding context daniels 2014
the use of transformer vaswani et al 2017
in natural language processing nlp has become
fundamental to achieve stateoftheart results in
different downstream tasks including content l
tering since transformerbased language mod
els are trained with digitized texts the vocabulary
acquired from the data is represented with dots
therefore the undotted letters that are not part of
the ofcial arabic language are not recognized
by the model even if they exist in the unicode
character set eg dotless archaic beh  h
in this work we study the effect of removing
dots from text written in arabic on the perfor
1httpsarabicfornerdscomdotlessarabicarxiv211109791v1  cscl  18 nov 2021
mance of a transformerbased language model
employed as a typical contentltering classier
our results show that replacing the dotted msa
letters with their corresponding dotless versions
causes a strong adversarial effect on the perfor
mance of the language model that was netuned
on various downstream tasks we describe our at
tempts to handle undotted arabic none of them
require retraining the language model and discuss
their results and potential contributions
2 related work
21 arabic transformer models
multilingual bert or mbert devlin et al
2019 was the rst pretrained language model
to include arabic it covers only msa and usually
do not perform well enough on downstream ara
bic nlp tasks due to the relatively small arabic
training data it was trained on arabert an
toun et al 2020 and gigabert lan et al 2020
are two language models that were trained on a
much larger portion of arabic texts still only msa
both offer better performance on downstream tasks
two recent models marbert abdulmageed
et al 2021a and camelbert inoue et al
2021 include dialectical arabic in their training
data reaching better performance on relevant tasks
none of these models have been used with undotted
arabic which is the main focus of our work
22 adversarial inputs in nlp
adversarial inputs are crafted examples to deceive
neural networks at inference time such attacks
have already been introduced and discussed by
szegedy et al 2013 and goodfellow et al 2015 fo
cusing mostly on adversarial perturbations in vision
tasks generating adversarial inputs in nlp is con
sidered to be more challenging than in computer vi
sion mostly due to the relatively large importance
every word has in a given input text comparing to
the small importance a single pixel has in an input
image nonetheless it has been recently addressed
by jin et al 2020 who presented an efcient way
of generating adversarial textual inputs for a bert
devlin et al 2019 by modifying the texts seman
tically based on some word statistics taken from
the language model itself they showed that while
their modied texts are understandable by human
readers their bertbased models have struggled
to produce the correct output in this work we eval
uate a more natural approach for fooling an arabiclanguage model simply by converting some letters
to their undotted versions keeping the modied
text understandable for human readers
3 handling undotted arabic
we begin by netuning a transformerbased ara
bic language model on two downstream tasks and
evaluate their performance on undotted inputs fol
lowing that we develop different computational
approaches for recovering the missing information
that was lost with undotting without pretraining
the language model itself we evaluate the different
approaches on the same downstream tasks and re
port on the results in the following section for all
our experiments we use the recent camelbert
mix base model inoue et al 2021 which was
pretrained on a mix of msa classical arabic and
dialectical arabic texts
31 undotting
in order to remove dots from the text we created
a mapping for all the arabic characters available
in the unicode character set for which we match
the most resemblant undotted character the map
ping table is provided in appendix a some arabic
letters have different forms depending on whether
they appear at the beginning middle or end of a
word therefore we map all the forms of a relevant
letter undotting an input text is a simple replace
ment of all relevant letters with their orthographic
equivalents
32 supporting undotted arabic
as reported in the following section netuned
arabic language models do not perform well on
undotted texts therefore we suggest two ways
to handle undotted texts in one way we make
changes to the tokenizer of the model and in an
other way we develop an algorithm for restoring
the dots of the input text which runs as a pre
processing step before submitting the text to the
language model
321 changing the tokenizer
before processing the text with a pretrained lan
guage model it is necessary to break it into tokens
using the same tokenizer that was used during the
pretraining phase of the model camelbert
mix uses a standard bert tokenizer provided by
hugging face2 with a vocabulary of 30000 tokens
2httpsgithubcomhuggingface
tokenizers
originalj
k
j
j
b aj
 
	 qj	k 
 j
k
 p 	qm yg pa yk
undotted jjk jjb  aj   qjjk   jjk pqm  yg pa yk
translation qaruh is one of the nine kuwaiti islands in the kuwaiti territorial waters
table 1 arabic text given with and without the dots the text was taken from httpsarabiccnncom
travelarticle20210713qaruhislandkuwait 
each token has a numeric identier we take two
different approaches for changing the conguration
of the tokenizer in order to handle undotted texts
without having to pretrain the language model nor
netuning it on a downstream task
undotting the tokenizer vocabulary accord
ing to this approach we undot the entire vocabu
lary of the tokenizer thereby enabling it to seam
lessly recognize undotted letters and words obvi
ously after undotting the vocabulary some of the
tokens 5852 out of the original 30000 tokens
or1952 become identical leaving some of the
token identiers unused therefore the models vo
cabulary get smaller since we suspect that work
ing with a smaller vocabulary may be detrimental
to the performance of the model on downstream
tasks we suggest another approach for modifying
the tokenizer
extending the tokenizer vocabulary under
this approach we extend the tokenizers vocabu
lary by adding the undotted version of the relevant
tokens and mapping them to the same identier of
their original token this way the tokenizer keeps
the original dotted version of every token and thus
can accept both dotted and undotted inputs we
add the undotted version of a token only if it is not
already part of the vocabulary overall we added
17280 undotted versions the resulting vocabulary
has about 57 token identiers that are mapped to
two token versions
322 aredotter restoring arabic dots
as opposed to the previous approach here we de
velop an algorithm for preprocessing the input un
dotted text to restore its dots the language model
itself remains unmodied
we train a sequencetosequence machine
translation mt model on the unlabeled 10m ara
bic tweets dataset published with the second nadi
shared task abdulmageed et al 2021b the
tweets were posted from multiple geographies
for creating parallel texts for training every
tweet from the original corpus was paired withits automatically generated undotted version using
the mappings provided in appendix a we remove
from the tweets urls user mentions and hash
tags
our mt model is based on the pretrained
arabictoenglish marian mt tiedemann and
thottingal 2020 architecture3 which was ne
tuned for undotted arabictoarabic translation
we netune our model on the entire parallel
dataset for two epochs
4 experimental results
to evaluate our proposed methods we netune
camelbert on two tasks sentence level and
token level
for the sentencelevel task we use the sentiment
analysis subtask of arsarcasmv2 abu farha et al
2021 designed as a threelabels positive nega
tive neutral classication task as we did with
nadi we preprocess the text to remove urls
user mentions and hashtags for evaluation we
use the ofcial evaluation objective metric dened
as macro average f1 score of both nonneutral la
bels
for a tokenlevel downstream task we evaluate
our language model on the namedentity recogni
tion ner task using the anercorp dataset be
najiba et al 2007 we use the modied version of
the dataset which was recently released by obeid
et al 2020 following previous works on ner
we use the micro average f1 metric for evaluation
for each task we netune camelbert on the
original preprocessed training data for 10 epochs
using the ofcial traintest split and evaluate it
on the undotted version of the test set we use
the standard hugging faces pipelines automod
elforsequenceclassication and automodelfor
tokenclassication4for the sentiment analysis and
ner tasks respectively we evaluate the models
under different conditions of supporting undotted
3specically we used the helsinkinlpopusmtaren
model from hugging face
4httpshuggingfacecotransformers
modeldocautohtml
undotted option 1 pronunciation meaning option 2 pronunciation meaning
ijj ijj
	fyajib  must ijj	fatahat  opened
pakpa	ktafaruq  leavepa	kbifariq  difference
pam pam	najaar  carpenter pambahaar  seas
hjk hjkhubub  cereal h	jkjanub  south
table 2 examples of undotted ambiguous words we do not provide all the possible pronunciations in each row
arsarcasm v2  sentiment anercorp
original text 7055 8139
undotted text 4486 916
undotted text  undotted tokenizer 6450 7285
undotted text  extended tokenizer 6503 7168
aredotter 6827 6797
table 3 model performance on downstream tasks using different undotted text handling approaches
texts as described in the previous section
41 results
the results reported in table 3 demonstrate the ad
versarial effect of processing undotted arabic with
a vanilla unmodied camelbert model the
rst row lists the results we get by working with the
original texts in the second row we provide the re
sults of using the same model but this time applied
on the undotted version of the texts as observed
the metrics measured for the two tasks dropped
signicantly on undotted texts unsurprisingly the
tokenizer of the vanilla language model does not
recognize tokens with undotted letters which are
excluded from the modern arabic script and thus
treating them as unknown tokens
the two tokenizerupdating approaches whose
results are reported in the 3rd and 4th rows prove
to be effective for undotted texts in both tasks
this improvement is achieved mainly due to the
reduction in the number of unknown tokens the
model is assigned with among the two we ob
serve that the extended tokenizer is slightly better
on the sentiment analysis task while the undotted
tokenizer is better on the ner task however the
difference in those results is insignicant
interestingly aredotter our mt dots restora
tion model which we run as a preprocessor be
fore submitting the text to the language model
provides competitive results in both task it is
slightly better than the tokenizerupdating tech
niques on sentiment analysis but slightly worse on
the ner task naturally a sequencetosequence
translation model may sometimes generate someoutofcontext tokens in the target sequence we
believe that ner is more sensitive to this type of
mistakes than sentiment analysis task for future
work we plan to work with a simple sequential
tagging model instead of the sequencetosequence
mt model to avoid generating such tokens the
results we get from aredotter are encouraging it
provides an elegant way to support undotted text
without modifying the model or the tokenizer
5 conclusion
undotting has been recently adopted by social
media users in order to bypass contentltering
gateways we studied the effect of undotting on
the performance of a standard pretrained language
model our results show that processing undotted
text with a vanilla unmodied language model has
a detrimental effect in two downstream nlp tasks
by simply editing the tokenizer which is used by
the language model we are able to show signicant
improvements over the vanilla model
our third approach which does not require
changing the tokenizer is using a machine
translation model for restoring the missing dots
with this technique we show competitive results to
the tokenizerupdating techniques without having
to modify the model or its tokenizer we believe
that our study provides some conclusions as for
how undotted texts should be treated with modern
transformerbased language models we recom
mend that at least one of our techniques will be
adopted as a standard step in a common arabic
nlp pipeline
references
muhammad abdulmageed abdelrahim elmadany
and el moatez billah nagoudi 2021a arbert
 marbert deep bidirectional transformers for
arabic in proceedings of the aclijcnlp 2021
main conference  association for computational
linguistics
muhammad abdulmageed chiyu zhang abdel
rahim elmadany houda bouamor and nizar
habash 2021b nadi 2021 the second nuanced
arabic dialect identication shared task in proceed
ings of the sixth arabic natural language process
ing workshop  pages 244259 kyiv ukraine vir
tual association for computational linguistics
ibrahim abu farha wajdi zaghouani and walid
magdy 2021 overview of the wanlp 2021 shared
task on sarcasm and sentiment detection in arabic
inproceedings of the sixth arabic natural lan
guage processing workshop  pages 296305 kyiv
ukraine virtual association for computational
linguistics
wissam antoun fady baly and hazem hajj 2020
arabert transformerbased model for arabic lan
guage understanding in proceedings of the 4th
workshop on opensource arabic corpora and pro
cessing tools with a shared task on offensive lan
guage detection  pages 915 marseille france eu
ropean language resource association
yassine benajiba paolo rosso and jos miguel
benedruiz 2007 anersys an arabic named
entity recognition system based on maximum en
tropy in computational linguistics and intelligent
text processing  pages 143153 berlin heidelberg
springer berlin heidelberg
peter t daniels 2014 the type and spread of ara
bic script  pages 25  39 brill leiden the nether
lands
jacob devlin mingwei chang kenton lee and
kristina toutanova 2019 bert pretraining of
deep bidirectional transformers for language under
standing in proceedings of the 2019 conference
of the north american chapter of the association
for computational linguistics human language
technologies volume 1 long and short papers 
pages 41714186 minneapolis minnesota associ
ation for computational linguistics
gerald driner 2021 social media  palestine dot
less arabic outsmarts algorithms
ian goodfellow jonathon shlens and christian
szegedy 2015 explaining and harnessing adversar
ial examples in international conference on learn
ing representations 
go inoue bashar alhafni nurpeiis baimukan houda
bouamor and nizar habash 2021 the interplay
of variant size and task type in arabic pretrained
language models in proceedings of the sixth ara
bic natural language processing workshop  kyiv
ukraine online association for computational
linguisticsdi jin zhijing jin joey tianyi zhou and peter
szolovits 2020 is bert really robust a strong
baseline for natural language attack on text clas
sication and entailment in the thirtyfourth
aaai conference on articial intelligence aaai
2020 the thirtysecond innovative applications of
articial intelligence conference iaai 2020 the
tenth aaai symposium on educational advances
in articial intelligence eaai 2020 new york ny
usa february 712 2020  pages 80188025 aaai
press
wuwei lan yang chen wei xu and alan ritter 2020
an empirical study of pretrained transformers for
arabic information extraction in proceedings of the
2020 conference on empirical methods in natural
language processing emnlp  pages 47274734
online association for computational linguistics
ossama obeid nasser zalmout salam khalifa dima
taji mai oudah bashar alhafni go inoue fadhl
eryani alexander erdmann and nizar habash
2020 camel tools an open source python toolkit
for arabic natural language processing in proceed
ings of the 12th language resources and evaluation
conference  pages 70227032 marseille france
european language resources association
christian szegedy wojciech zaremba ilya sutskever
joan bruna dumitru erhan ian goodfellow and
rob fergus 2013 intriguing properties of neural
networks arxiv preprint arxiv13126199 
jrg tiedemann and santhosh thottingal 2020
opusmt  building open translation services for
the world in proceedings of the 22nd annual con
ferenec of the european association for machine
translation eamt  lisbon portugal
ashish vaswani noam shazeer niki parmar jakob
uszkoreit llion jones aidan n gomez ukasz
kaiser and illia polosukhin 2017 attention is all
you need in advances in neural information pro
cessing systems  volume 30 curran associates inc
a appendix a undotting table
initialmedial terminal
letter msa undotted undotted
ba h k h
ta h k h
tha h k h
jim h k h
kha p k h
dhal	x x x
zayn 	p p p
shin   
dad	  
za	    
ghayn	  
fa	  
qaf  
nun	 k 
ya 
k 
table 4 character mapping used for our undotting
function specifying only the letters which are not iden
tical to their undotted version","['1httpsarabicfornerdscomdotlessarabicarxiv211109791v1', 'travelarticle20210713qaruhislandkuwait', 'aviadromkfirbarpostidcacil', 'languageprocessing', '4httpshuggingfacecotransformers', 'modeldocautohtml', 'elforsequenceclassication', '2httpsgithubcomhuggingface', 'ambiguities', 'preprocessing']",3
