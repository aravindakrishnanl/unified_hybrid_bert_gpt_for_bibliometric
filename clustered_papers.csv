id,title,doi,publication_year,authors,abstract,open_access,host_venue,clean_abstract,keywords,entities,gmm_cluster,gmm_probs
https://openalex.org/W4221143046,Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,https://doi.org/10.48550/arxiv.2201.11903,2022,"Jason Lee, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H., Quoc V. Le, Denny Zhou","We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.",True,,we explore how generating a chain of thought  a series of intermediate reasoning steps  significantly improves the ability of large language models to perform complex reasoning in particular we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting where a few chain of thought demonstrations are provided as exemplars in prompting experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic commonsense and symbolic reasoning tasks the empirical gains can be striking for instance prompting a 540bparameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the gsm8k benchmark of math word problems surpassing even finetuned gpt3 with a verifier,"['reasoning abilities', 'reasoning tasks', 'intermediate reasoning', 'thought prompting', 'prompting improves']","['models', 'model', 'gsm8k benchmark', 'arithmetic commonsense', 'performance', 'instance', 'demonstrations', 'art accuracy', 'prompting', 'symbolic', 'reasoning', 'gpt3', 'math word', 'empirical gains', 'complex', 'experiments', 'abilities', 'chain of thought', 'language', 'intermediate reasoning']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W3168867926,LoRA: Low-Rank Adaptation of Large Language Models,https://doi.org/10.48550/arxiv.2106.09685,2021,"J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Weizhu Chen","An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.",True,,an important paradigm of natural language processing consists of largescale pretraining on general domain data and adaptation to particular tasks or domains as we pretrain larger models full finetuning which retrains all model parameters becomes less feasible using gpt3 175b as an example  deploying independent instances of finetuned models each with 175b parameters is prohibitively expensive we propose lowrank adaptation or lora which freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the transformer architecture greatly reducing the number of trainable parameters for downstream tasks compared to gpt3 175b finetuned with adam lora can reduce the number of trainable parameters by 10000 times and the gpu memory requirement by 3 times lora performs onpar or better than finetuning in model quality on roberta deberta gpt2 and gpt3 despite having fewer trainable parameters a higher training throughput and unlike adapters no additional inference latency we also provide an empirical investigation into rankdeficiency in language model adaptation which sheds light on the efficacy of lora we release a package that facilitates the integration of lora with pytorch models and provide our implementations and model checkpoints for roberta deberta and gpt2 at httpsgithubcommicrosoftlora,"['rankdeficiency language', 'lowrank adaptation', 'training throughput', 'model adaptation', 'pretrained model']","['gpt2', 'times', 'rankdeficiency', 'reducing', 'expensive', 'models', 'finetuning', 'model', 'deploying', 'decomposition', 'gpt3 175b', 'rank', 'adam lora', 'implementations', 'requirement', 'natural language', 'adapters', 'layer', 'trainable', 'empirical', 'finetuned', 'parameters', 'paradigm', 'training', 'integration', 'gpt3', 'largescale', 'downstream', 'tasks', 'gpu', 'lowrank adaptation', 'memory', 'general domain', 'pretrain larger', 'efficacy', 'investigation', 'roberta deberta', 'data', 'architecture', 'language', 'package', 'lora', 'adaptation', 'domains', 'transformer']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4319662928,Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models,https://doi.org/10.1371/journal.pdig.0000198,2023,"Tiffany H. Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, Victor Tseng","We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.",True,,we evaluated the performance of a large language model called chatgpt on the united states medical licensing exam usmle which consists of three exams step 1 step 2ck and step 3 chatgpt performed at or near the passing threshold for all three exams without any specialized training or reinforcement additionally chatgpt demonstrated a high level of concordance and insight in its explanations these results suggest that large language models may have the potential to assist with medical education and potentially clinical decisionmaking,"['clinical decisionmaking', 'medical licensing', 'exam usmle', 'medical education', 'licensing exam']","['model', 'models', 'explanations', 'concordance', 'level', 'reinforcement', 'performance', 'threshold', 'training', 'chatgpt', 'medical licensing', 'results', 'assist', 'exams', 'potential', 'united states', 'evaluated', 'medical education', 'specialized', 'clinical decisionmaking', 'language']",3,"[0.0, 0.0, 0.0, 1.0, 0.0]"
https://openalex.org/W4384071683,Large language models encode clinical knowledge,https://doi.org/10.1038/s41586-023-06291-2,2023,"Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Lee, Hyung Won Chung, Nathan Scales, Ajay Kumar Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry W. Payne, Martin Seneviratne, Paul Gamble, Christopher Kelly, Abubakr Babiker, Nathanael Schärli, Aakanksha Chowdhery, P. Mansfield, Dina Demner‐Fushman, Blaise Agüera y Arcas, Dale R. Webster, Greg S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomašev, Yun Liu, Alvin Rajkomar, Joëlle Barral, Christopher Semturs, Alan Karthikesalingam, Vivek Natarajan","Abstract Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model 1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM 2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA 3 , MedMCQA 4 , PubMedQA 5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics 6 ), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.",True,,abstract large language models llms have demonstrated impressive capabilities but the bar for clinical applications is high attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks here to address these limitations we present multimedqa a benchmark combining six existing medical question answering datasets spanning professional medicine research and consumer queries and a new dataset of medical questions searched online healthsearchqa we propose a human evaluation framework for model answers along multiple axes including factuality comprehension reasoning possible harm and bias in addition we evaluate pathways language model 1 palm a 540billion parameter llm and its instructiontuned variant flanpalm 2 on multimedqa using a combination of prompting strategies flanpalm achieves stateoftheart accuracy on every multimedqa multiplechoice dataset medqa 3  medmcqa 4  pubmedqa 5 and measuring massive multitask language understanding mmlu clinical topics 6  including 676 accuracy on medqa us medical licensing examstyle questions surpassing the prior state of the art by more than 17 however human evaluation reveals key gaps to resolve this we introduce instruction prompt tuning a parameterefficient approach for aligning llms to new domains using a few exemplars the resulting model medpalm performs encouragingly but remains inferior to clinicians we show that comprehension knowledge recall and reasoning improve with model scale and instruction prompt tuning suggesting the potential utility of llms in medicine our human evaluations reveal limitations of todays models reinforcing the importance of both evaluation frameworks and method development in creating safe helpful llms for clinical applications,"['question answering', 'language models', 'knowledge recall', 'model answers', 'answering datasets']","['mmlu', 'multimedqa', 'variant', 'accuracy', 'medical question', 'models', 'evaluations', 'palm', 'limitations', 'datasets', 'bias', 'instruction', 'research', 'comprehension', 'todays models', 'dataset', 'medqa', 'measuring', 'factuality', 'medicine', 'evaluation', 'human', 'bar', 'prompting strategies flanpalm', 'abstract large language', '540billion parameter llm', 'model scale', 'combination', 'capabilities', 'medical questions', 'reasoning', 'model answers', 'potential', 'harm', 'clinical applications', 'queries', 'benchmarks', 'clinicians', 'professional medicine', 'pubmedqa 5', 'medical licensing examstyle questions', 'model medpalm', 'llms', 'parameterefficient approach', 'pathways language', 'method development', 'improve', 'consumer', 'knowledge', 'massive', 'multiple axes', 'impressive', 'automated', 'evaluate', 'clinical', 'domains', 'evaluation frameworks']",3,"[0.0, 0.0, 0.0, 1.0, 0.0]"
https://openalex.org/W3177813494,Evaluating Large Language Models Trained on Code,https://doi.org/10.48550/arxiv.2107.03374,2021,"Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Łukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth A. Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, I. Babuschkin, Suchir Balaji, Shantanu Jain, William S. Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba","We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.",True,,we introduce codex a gpt language model finetuned on publicly available code from github and study its python codewriting capabilities a distinct production version of codex powers github copilot on humaneval a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings our model solves 288 of the problems while gpt3 solves 0 and gptj solves 114 furthermore we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts using this method we solve 702 of our problems with 100 samples per problem careful investigation of our model reveals its limitations including difficulty with docstrings describing long chains of operations and with binding operations to variables finally we discuss the potential broader impacts of deploying powerful code generation technologies covering safety security and economics,"['gpt language', 'code generation', 'python codewriting', 'synthesizing programs', 'github copilot']","['study', 'long chains', 'model', 'codex powers', 'limitations', 'deploying', 'measure', 'working solutions', 'difficulty', 'functional', 'evaluation', 'production', 'gptj', 'economics', 'prompts', 'capabilities', 'gpt3 solves', 'method', 'potential', 'docstrings', 'safety', 'effective', 'sampling', 'humaneval', 'github', 'investigation', 'impacts', 'gpt language', 'operations', 'security', 'variables', 'samples', 'python codewriting', 'binding operations', 'copilot', 'problems', 'code']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4362515116,A Survey of Large Language Models,https://doi.org/10.48550/arxiv.2303.18223,2023,"Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Yang Chen, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian‐Yun Nie, Ji-Rong Wen","Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.",True,,language is essentially a complex intricate system of human expressions governed by grammatical rules it poses a significant challenge to develop capable ai algorithms for comprehending and grasping a language as a major approach language modeling has been widely studied for language understanding and generation in the past two decades evolving from statistical language models to neural language models recently pretrained language models plms have been proposed by pretraining transformer models over largescale corpora showing strong capabilities in solving various nlp tasks since researchers have found that model scaling can lead to performance improvement they further study the scaling effect by increasing the model size to an even larger size interestingly when the parameter scale exceeds a certain level these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in smallscale language models to discriminate the difference in parameter scale the research community has coined the term large language models llm for the plms of significant size recently the research on llms has been largely advanced by both academia and industry and a remarkable progress is the launch of chatgpt which has attracted widespread attention from society the technical evolution of llms has been making an important impact on the entire ai community which would revolutionize the way how we develop and use ai algorithms in this survey we review the recent advances of llms by introducing the background key findings and mainstream techniques in particular we focus on four major aspects of llms namely pretraining adaptation tuning utilization and capacity evaluation besides we also summarize the available resources for developing llms and discuss the remaining issues for future directions,"['language models', 'large language', 'language modeling', 'smallscale language', 'enlarged language']","['improvement', 'study', 'coined', 'findings', 'directions', 'models', 'expressions', 'model', 'parameter scale', 'research', 'adaptation', 'discriminate', 'community', 'level', 'performance', 'impact', 'enlarged', 'smallscale', 'evaluation', 'human', 'comprehending', 'capacity', 'significant', 'capabilities', 'largescale corpora', 'grasping', 'chatgpt', 'plms', 'grammatical rules', 'launch', 'neural language', 'tasks', 'survey', 'evolution', 'modeling', 'generation', 'nlp', 'decades', 'progress', 'complex', 'evolving', 'significant size', 'pretraining', 'llms', 'utilization', 'statistical language', 'mainstream techniques', 'technical', 'industry', 'researchers', 'society', 'abilities', 'academia', 'size', 'transformer models', 'scaling', 'scaling effect', 'resources', 'language', 'increasing', 'algorithms']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4283026156,Emergent Abilities of Large Language Models,https://doi.org/10.48550/arxiv.2206.07682,2022,"Jason Lee, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H., Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus","Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.",True,,scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks this paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models we consider an ability to be emergent if it is not present in smaller models but is present in larger models thus emergent abilities cannot be predicted simply by extrapolating the performance of smaller models the existence of such emergence implies that additional scaling could further expand the range of capabilities of language models,"['scaling language', 'large language', 'language models', 'models emergent', 'larger models']","['unpredictable', 'models', 'implies', 'larger', 'performance', 'emergence', 'efficiency', 'predicted', 'capabilities', 'language models', 'downstream', 'emergent', 'sample', 'phenomenon', 'improve', 'abilities', 'scaling', 'language', 'existence', 'smaller']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4281557260,Large Language Models are Zero-Shot Reasoners,https://doi.org/10.48550/arxiv.2205.11916,2022,"Takeshi Kojima, Shixiang Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa","Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding ""Let's think step by step"" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with large InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.",True,,pretrained large language models llms are widely used in many subfields of natural language processing nlp and generally known as excellent fewshot learners with taskspecific exemplars notably chain of thought cot prompting a recent technique for eliciting complex multistep reasoning through stepbystep answer examples achieved the stateoftheart performances in arithmetics and symbolic reasoning difficult system2 tasks that do not follow the standard scaling laws for llms while these successes are often attributed to llms ability for fewshot learning we show that llms are decent zeroshot reasoners by simply adding lets think step by step before each answer experimental results demonstrate that our zeroshotcot using the same single prompt template significantly outperforms zeroshot llm performances on diverse benchmark reasoning tasks including arithmetics multiarith gsm8k aquarat svamp symbolic reasoning last letter coin flip and other logical reasoning tasks date understanding tracking shuffled objects without any handcrafted fewshot examples eg increasing the accuracy on multiarith from 177 to 787 and gsm8k from 104 to 407 with large instructgpt model textdavinci002 as well as similar magnitudes of improvements with another offtheshelf large model 540b parameter palm the versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zeroshot capabilities of llms suggesting highlevel multitask broad cognitive capabilities may be extracted by simple prompting we hope our work not only serves as the minimal strongest zeroshot baseline for the challenging reasoning benchmarks but also highlights the importance of carefully exploring and analyzing the enormous zeroshot knowledge hidden inside llms before crafting finetuning datasets or fewshot exemplars,"['reasoning benchmarks', 'zeroshot reasoners', 'reasoning tasks', 'learning llms', 'fewshot learning']","['system2', 'hidden', 'accuracy', 'diverse', 'models', 'model', 'instructgpt model', 'reasoning tasks', 'palm', 'zeroshot', 'magnitudes', 'multitask broad', 'baseline', 'fewshot learning', 'natural language', 'standard', 'zeroshot llm', 'untapped', 'fewshot', 'zeroshotcot', 'fewshot learners', 'outperforms', 'logical reasoning tasks', 'capabilities', 'successes', 'cot', 'symbolic', 'decent', 'prompting', 'multiarith', 'zeroshot reasoners', 'versatility', 'benchmark reasoning tasks', 'arithmetics', 'complex', 'fewshot examples', 'reasoning benchmarks', 'coin flip', 'llms', 'technique', 'parameter', 'finetuning datasets', 'processing nlp', 'hints', 'gsm8k aquarat', 'tracking shuffled objects', 'scaling', 'template', 'gsm8k', 'fundamental', 'enormous', 'language', 'cognitive', 'performances', 'improvements', 'increasing', 'highlevel', 'minimal']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W2109664771,Large Language Models in Machine Translation,,2007,"Thorsten Brants, Ashok C. Popat, Peng Xu, Franz Josef Och, Jay B. Dean","Systems, methods, and computer program products for machine translation are provided. In some implementations a system is provided. The system includes a language model including a collection of n-grams from a corpus, each n-gram having a corresponding relative frequency in the corpus and an order n corresponding to a number of tokens in the n-gram, each n-gram corresponding to a backoff n-gram having an order of n-1 and a collection of backoff scores, each backoff score associated with an n-gram, the backoff score determined as a function of a backoff factor and a relative frequency of a corresponding backoff n-gram in the corpus.",False,,systems methods and computer program products for machine translation are provided in some implementations a system is provided the system includes a language model including a collection of ngrams from a corpus each ngram having a corresponding relative frequency in the corpus and an order n corresponding to a number of tokens in the ngram each ngram corresponding to a backoff ngram having an order of n1 and a collection of backoff scores each backoff score associated with an ngram the backoff score determined as a function of a backoff factor and a relative frequency of a corresponding backoff ngram in the corpus,"['machine translation', 'ngrams corpus', 'ngram corpus', 'corpus ngram', 'language model']","['tokens', 'system', 'systems methods', 'model', 'function', 'backoff', 'collection', 'ngrams', 'frequency', 'machine translation', 'ngram', 'backoff scores', 'language', 'associated with', 'backoff score', 'backoff factor', 'corpus', 'computer program products']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4391136507,A Survey on Evaluation of Large Language Models,https://doi.org/10.1145/3641289,2024,"Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie","Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate , where to evaluate , and how to evaluate . Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey",True,,large language models llms are gaining increasing popularity in both academia and industry owing to their unprecedented performance in various applications as llms continue to play a vital role in both research and daily use their evaluation becomes increasingly critical not only at the task level but also at the society level for better understanding of their potential risks over the past years significant efforts have been made to examine llms from various perspectives this paper presents a comprehensive review of these evaluation methods for llms focusing on three key dimensions what to evaluate  where to evaluate  and how to evaluate  firstly we provide an overview from the perspective of evaluation tasks encompassing general natural language processing tasks reasoning medical usage ethics education natural and social sciences agent applications and other areas secondly we answer the where and how questions by diving into the evaluation methods and benchmarks which serve as crucial components in assessing the performance of llms then we summarize the success and failure cases of llms in different tasks finally we shed light on several future challenges that lie ahead in llms evaluation our aim is to offer invaluable insights to researchers in the realm of llms evaluation thereby aiding the development of more proficient llms our key point is that evaluation should be treated as an essential discipline to better assist the development of llms we consistently maintain the related opensource materials at httpsgithubcommlgroupjlullmevalsurvey,"['llms evaluation', 'llms summarize', 'evaluation increasingly', 'evaluation tasks', 'evaluation aiding']","['evaluation methods', 'development', 'opensource materials', 'models', 'unprecedented', 'risks', 'popularity', 'research', 'agent', 'level', 'comprehensive', 'performance', 'httpsgithubcommlgroupjlullmevalsurvey', 'questions', 'evaluation', 'daily', 'general natural language', 'perspective', 'proficient', 'components', 'cases', 'assist', 'success', 'tasks', 'applications', 'potential', 'medical usage', 'natural', 'social sciences', 'benchmarks', 'dimensions', 'task', 'failure', 'overview', 'llms', 'realm', 'discipline', 'industry', 'society', 'researchers', 'academia', 'evaluate', 'treated', 'diving', 'language', 'review']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4319460874,How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment,https://doi.org/10.2196/45312,2023,"Aidan Gilson, Conrad W. Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard A. Taylor, David Chartash","Background Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input. Objective This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as to analyze responses for user interpretability. Methods We used 2 sets of multiple-choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT’s performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT’s answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P&lt;.001) and NBME-Free-Step2 (P=.001) data sets, respectively. Conclusions ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT’s capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning.",True,,background chat generative pretrained transformer chatgpt is a 175billionparameter natural language processing model that can generate conversationstyle responses to user input objective this study aimed to evaluate the performance of chatgpt on questions within the scope of the united states medical licensing examination usmle step 1 and step 2 exams as well as to analyze responses for user interpretability methods we used 2 sets of multiplechoice questions to evaluate chatgpts performance each with questions pertaining to step 1 and step 2 the first set was derived from amboss a commonly used question bank for medical students which also provides statistics on question difficulty and the performance on an exam relative to the user base the second set was the national board of medical examiners nbme free 120 questions chatgpts performance was compared to 2 other large language models gpt3 and instructgpt the text output of each chatgpt response was evaluated across 3 qualitative metrics logical justification of the answer selected presence of information internal to the question and presence of information external to the question results of the 4 data sets ambossstep1 ambossstep2 nbmefreestep1 and nbmefreestep2 chatgpt achieved accuracies of 44 44100 42 42100 644 5687 and 578 59102 respectively chatgpt outperformed instructgpt by 815 on average across all data sets and gpt3 performed similarly to random chance the model demonstrated a significant decrease in performance as question difficulty increased p01 within the ambossstep1 data set we found that logical justification for chatgpts answer selection was present in 100 of outputs of the nbme data sets internal information to the question was present in 968 183189 of all questions the presence of information external to the question was 445 and 27 lower for incorrect answers relative to correct answers on the nbmefreestep1 plt001 and nbmefreestep2 p001 data sets respectively conclusions chatgpt marks a significant improvement in natural language processing models on the tasks of medical question answering by performing at a greater than 60 threshold on the nbmefreestep1 data set we show that the model achieves the equivalent of a passing score for a thirdyear medical student additionally we highlight chatgpts capacity to provide logic and informational context across the majority of answers these facts taken together make a compelling case for the potential applications of chatgpt as an interactive medical education tool to support learning,"['evaluate chatgpts', 'questions chatgpts', 'chatgpt questions', 'conclusions chatgpt', 'performance chatgpt']","['conversationstyle', 'medical licensing examination', 'study', 'user base', 'improvement', 'information internal', 'medical question', 'models', 'model', 'medical education tool', 'presence', 'p01', 'ambossstep1', 'thirdyear', 'ambossstep2', 'transformer chatgpt', 'difficulty', 'average', 'chance', 'performance', 'random', 'questions', 'output', 'natural language', 'scope', 'outputs', 'answers', 'internal information', 'user interpretability methods', 'capacity', 'nbmefreestep1', 'passing score', 'threshold', 'nbme', 'significant', 'chatgpts', 'processing model', 'chatgpt', 'decrease', 'logic', 'multiplechoice questions', 'gpt3', 'medical examiners', 'results', 'chatgpt response', 'nbmefreestep2', 'exams', 'potential', 'national board', 'united states', 'evaluated', 'exam', 'responses', 'information', 'medical', 'amboss', 'instructgpt', 'selection', 'medical students', 'incorrect', 'marks', 'data set', 'logical justification', 'student', 'question', 'data sets', 'processing models', 'qualitative', 'informational', 'evaluate', 'generative', 'language', 'accuracies', 'interactive', 'analyze']",3,"[0.0, 0.0, 0.0, 1.0, 0.0]"
https://openalex.org/W4312220150,A large language model for electronic health records,https://doi.org/10.1038/s41746-022-00742-2,2022,"Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin B. Compas, Cheryl Martin, Anthony Costa, Mona G. Flores, Ying Zhang, Tanja Magoč, Christopher A. Harle, Gloria Lipori, Duane A. Mitchell, William R. Hogan, Elizabeth Shenkman, Jiang Bian, Yonghui Wu","Abstract There is an increasing interest in developing artificial intelligence (AI) systems to process and interpret electronic health records (EHRs). Natural language processing (NLP) powered by pretrained language models is the key technology for medical AI systems utilizing clinical narratives. However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain). It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured EHRs. In this study, we develop from scratch a large clinical language model—GatorTron—using &gt;90 billion words of text (including &gt;82 billion words of de-identified clinical text) and systematically evaluate it on five clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference (NLI), and medical question answering (MQA). We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks. GatorTron models scale up the clinical language model from 110 million to 8.9 billion parameters and improve five clinical NLP tasks (e.g., 9.6% and 9.5% improvement in accuracy for NLI and MQA), which can be applied to medical AI systems to improve healthcare delivery. The GatorTron models are publicly available at: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og .",True,,abstract there is an increasing interest in developing artificial intelligence ai systems to process and interpret electronic health records ehrs natural language processing nlp powered by pretrained language models is the key technology for medical ai systems utilizing clinical narratives however there are few clinical language models the largest of which trained in the clinical domain is comparatively small at 110 million parameters compared with billions of parameters in the general domain it is not clear how large clinical language models with billions of parameters can help medical ai systems utilize unstructured ehrs in this study we develop from scratch a large clinical language modelgatortronusing gt90 billion words of text including gt82 billion words of deidentified clinical text and systematically evaluate it on five clinical nlp tasks including clinical concept extraction medical relation extraction semantic textual similarity natural language inference nli and medical question answering mqa we examine how 1 scaling up the number of parameters and 2 scaling up the size of the training data could benefit these nlp tasks gatortron models scale up the clinical language model from 110 million to 89 billion parameters and improve five clinical nlp tasks eg 96 and 95 improvement in accuracy for nli and mqa which can be applied to medical ai systems to improve healthcare delivery the gatortron models are publicly available at httpscatalogngcnvidiacomorgsnvidiateamsclaramodelsgatortronog,"['clinical nlp', 'clinical text', 'processing nlp', 'nlp tasks', 'medical ai']","['mqa', 'study', 'improvement', 'accuracy', 'medical question', 'models', 'abstract', 'gatortron models', 'deidentified', 'systematically evaluate', 'billion', 'clinical domain', 'clinical narratives', 'clinical nlp tasks', 'natural language', 'gt82 billion words', 'process', 'parameters', 'ehrs', 'training', 'billions', 'semantic textual', 'million', 'medical', 'clinical nlp', 'general domain', 'gt90', 'clinical text', 'clinical language', 'medical ai systems', 'scratch', 'improve', 'technology', 'data', 'httpscatalogngcnvidiacomorgsnvidiateamsclaramodelsgatortronog', 'healthcare delivery', 'size', 'medical relation extraction', 'scaling', 'artificial intelligence', 'clinical', 'language', 'increasing', 'electronic health records ehrs']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4225591000,Training Compute-Optimal Large Language Models,https://doi.org/10.48550/arxiv.2203.15556,2022,"Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Laurent Sifre","We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4$\times$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.",True,,we investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget we find that current large language models are significantly undertrained a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant by training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens we find that for computeoptimal training the model size and the number of training tokens should be scaled equally for every doubling of model size the number of training tokens should also be doubled we test this hypothesis by training a predicted computeoptimal model chinchilla that uses the same compute budget as gopher but with 70b parameters and 4times more more data chinchilla uniformly and significantly outperforms gopher 280b gpt3 175b jurassic1 178b and megatronturing nlg 530b on a large range of downstream evaluation tasks this also means that chinchilla uses substantially less compute for finetuning and inference greatly facilitating downstream usage as a highlight chinchilla reaches a stateoftheart average accuracy of 675 on the mmlu benchmark greater than a 7 improvement over gopher,"['large language', 'scaling language', 'language models', 'language model', 'computeoptimal training']","['mmlu', 'improvement', 'investigate', 'doubling', 'model', 'budget', 'models', 'chinchilla', 'finetuning', 'accuracy', 'gopher', 'billion', 'evaluation', 'megatronturing nlg', 'parameters', 'model size', 'training', 'downstream', 'keeping', 'tokens', 'data chinchilla', 'optimal', 'training tokens', 'computeoptimal training', 'jurassic1', 'transformer language', 'data constant', 'size', 'hypothesis', 'scaling', 'language', 'downstream usage', 'computeoptimal model', 'consequence of']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4387500346,The future landscape of large language models in medicine,https://doi.org/10.1038/s43856-023-00370-1,2023,"Jan Clusmann, Fiona R. Kolbinger, Hannah Sophie Muti, Zunamys I. Carrero, Jan‐Niklas Eckardt, Narmin Ghaffari Laleh, Chiara Maria Lavinia Löffler, Sophie-Caroline Schwarzkopf, Michaela Unger, Gregory P. Veldhuizen, Sophia J. Wagner, Jakob Nikolas Kather","Abstract Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI’s ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.",True,,abstract large language models llms are artificial intelligence ai tools specifically trained to process and generate text llms attracted substantial public attention after openais chatgpt was made publicly available in november 2022 llms can often answer questions summarize paraphrase and translate text on a level that is nearly indistinguishable from human capabilities the possibility to actively interact with models like chatgpt makes llms attractive tools in various fields including medicine while these models have the potential to democratize medical knowledge and facilitate access to healthcare they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency in this article we provide a systematic and comprehensive overview of the potentials and limitations of llms in clinical practice medical research and medical education,"['text llms', 'llms clinical', 'medical knowledge', 'ai tools', 'medicine models']","['accountability', 'lack', 'models', 'artificial', 'limitations', 'level', 'comprehensive', 'medicine', 'clinical practice medical research', 'human', 'substantial public attention', 'process', 'fields', 'abstract large language', 'distribute', 'exacerbate', 'openais chatgpt', 'translate', 'capabilities', 'systematic', 'chatgpt', 'healthcare', 'potential', 'scientific misconduct', 'potentials', 'intelligence', 'tools', 'llms', 'overview', 'medical education', 'medical knowledge', 'misinformation', 'paraphrase', 'transparency']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W3160638507,Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm,https://doi.org/10.1145/3411763.3451760,2021,"Laria Reynolds, Kyle McDonell","Prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe models' novel capabilities. Using GPT-3 as a case study, we show that 0-shot prompts can significantly outperform few-shot prompts. We suggest that the function of few-shot examples in these cases is better described as locating an already learned task rather than meta-learning. This analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models. We discuss methods of prompt programming, emphasizing the usefulness of considering prompts through the lens of natural language. We explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict. Informed by this more encompassing theory of prompt programming, we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks. Finally, we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications.",True,,prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe models novel capabilities using gpt3 as a case study we show that 0shot prompts can significantly outperform fewshot prompts we suggest that the function of fewshot examples in these cases is better described as locating an already learned task rather than metalearning this analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models we discuss methods of prompt programming emphasizing the usefulness of considering prompts through the lens of natural language we explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict informed by this more encompassing theory of prompt programming we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks finally we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications,"['prompt programming', 'language prompts', 'generative language', 'considering prompts', 'prompts suggest']","['problem', 'exploiting', 'probe models', 'models', 'function', 'model', 'outperform', 'intentions', 'narratives', 'fail', 'practical', 'natural language', 'existing', 'usefulness', 'capacity', 'controlling', 'prompts', 'capabilities', 'components', 'language models', 'locating', 'cases', 'programming', 'gpt3', 'interacting', 'tasks', 'general methods', 'methods', 'benchmarks', 'encode', 'techniques', 'fewshot examples', 'prevailing methods', 'fewshot prompts', 'motivates', 'evaluating', 'lens', 'analysis', 'theory', 'cultural anchors', 'metaprompt', 'supervised', 'mapping large', 'case study', 'prompt', 'seeds', 'language', 'rethinking']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4383346782,The imperative for regulatory oversight of large language models (or generative AI) in healthcare,https://doi.org/10.1038/s41746-023-00873-0,2023,"Bertalan Meskó, Eric J. Topol","The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",True,,the rapid advancements in artificial intelligence ai have led to the development of sophisticated large language models llms such as gpt4 and bard the potential implementation of llms in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation obtaining insurance preauthorization summarizing research papers or working as a chatbot to answer questions for patients about their specific data and concerns while offering transformative potential llms warrant a very cautious approach since these models are trained differently from aibased medical technologies that are regulated already especially within the critical context of caring for patients the newest version gpt4 that was released in march 2023 brings the potentials of this technology to support multiple medical tasks and risks from mishandling results it provides to varying reliability to a new level besides being an advanced llm it will be able to read texts on images and analyze the context of those images the regulation of gpt4 and generative ai in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety maintain ethical standards and protect patient privacy we argue that regulatory oversight should assure medical professionals and patients can use llms without causing harm or compromising their data or privacy this paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality,"['ai medicine', 'patient privacy', 'protect patient', 'aibased medical', 'data privacy']","['development', 'context', 'attention', 'chatbot', 'regulated', 'reality', 'diverse', 'models', 'patient privacy', 'risks', 'clinical documentation', 'reliability', 'level', 'medical technologies', 'gpt4', 'cautious', 'medicine', 'advancements', 'newest', 'version gpt4', 'regulation', 'vision', 'medical professionals', 'healthcare', 'images', 'regulatory', 'caring', 'assure', 'applications', 'insurance preauthorization', 'potential', 'safety', 'harm', 'medical tasks', 'privacy', 'potentials', 'read texts', 'research papers', 'healthcare settings', 'patients', 'llms', 'regulators', 'sophisticated large', 'data', 'technology', 'implementation', 'recommendations', 'working', 'concerns', 'transformative', 'timely', 'generative', 'ethical standards', 'artificial intelligence', 'bard', 'language', 'brings', 'mishandling', 'analyze']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4318718936,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models,https://doi.org/10.48550/arxiv.2301.12597,2023,"Junnan Li, Dongxu Li, Silvio Savarese, Steven C. H. Hoi","The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",True,,the cost of visionandlanguage pretraining has become increasingly prohibitive due to endtoend training of largescale models this paper proposes blip2 a generic and efficient pretraining strategy that bootstraps visionlanguage pretraining from offtheshelf frozen pretrained image encoders and frozen large language models blip2 bridges the modality gap with a lightweight querying transformer which is pretrained in two stages the first stage bootstraps visionlanguage representation learning from a frozen image encoder the second stage bootstraps visiontolanguage generative learning from a frozen language model blip2 achieves stateoftheart performance on various visionlanguage tasks despite having significantly fewer trainable parameters than existing methods for example our model outperforms flamingo80b by 87 on zeroshot vqav2 with 54x fewer trainable parameters we also demonstrate the models emerging capabilities of zeroshot imagetotext generation that can follow natural language instructions,"['visionlanguage pretraining', 'visionandlanguage pretraining', 'visiontolanguage generative', 'visionlanguage tasks', 'pretrained image']","['largescale models', 'efficient', 'stages', 'model', 'models', 'blip2', 'generic', 'vqav2', 'zeroshot', 'visionandlanguage', 'image encoder', 'performance', 'endtoend training', 'parameters', 'capabilities', 'pretraining strategy', 'zeroshot imagetotext', 'natural', 'stage bootstraps', 'visionlanguage tasks', 'methods', 'generation', 'bootstraps visionlanguage', 'bridges', 'cost', 'frozen language', 'stage bootstraps visiontolanguage', 'modality', 'frozen', 'generative learning', 'language', 'instructions', 'image encoders']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4287553002,Extracting Training Data from Large Language Models,https://doi.org/10.48550/arxiv.2012.07805,2020,"Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Úlfar Erlingsson, Alina Oprea, Colin Raffel","It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. Worryingly, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.",True,,it has become common to publish large billion parameter language models that have been trained on private datasets this paper demonstrates that in such settings an adversary can perform a training data extraction attack to recover individual training examples by querying the language model we demonstrate our attack on gpt2 a language model trained on scrapes of the public internet and are able to extract hundreds of verbatim text sequences from the models training data these extracted examples include public personally identifiable information names phone numbers and email addresses irc conversations code and 128bit uuids our attack is possible even though each of the above sequences are included in just one document in the training data we comprehensively evaluate our extraction attack to understand the factors that contribute to its success worryingly we find that larger models are more vulnerable than smaller models we conclude by drawing lessons and discussing possible safeguards for training large language models,"['private datasets', 'extraction attack', 'language models', 'large language', 'models vulnerable']","['gpt2', 'extract', 'uuids', 'models', 'model', 'factors', 'discussing', 'document', 'safeguards', 'billion', 'numbers', 'public internet', 'email addresses', 'training', 'lessons', 'public', 'sequences', 'success', 'vulnerable', 'extraction', 'attack', 'smaller', 'adversary', 'data', 'training examples', 'language', 'scrapes', 'private datasets', 'information names', 'conversations code', 'evaluate', 'querying', 'publish', 'larger']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4281763794,A systematic evaluation of large language models of code,https://doi.org/10.1145/3520312.3534862,2022,"Frank F. Xu, Uri Alon, Graham Neubig, Vincent J. Hellendoorn","Large language models (LMs) of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions. However, the current state-of-the-art code LMs (e.g., Codex) are not publicly available, leaving many questions about their model and data design decisions. We aim to fill in some of these blanks through a systematic evaluation of the largest existing models: Codex, GPT-J, GPT-Neo, GPT-NeoX-20B, and CodeParrot, across various programming languages. Although Codex itself is not open-source, we find that existing opensource models do achieve close results in some programming languages, although targeted mainly for natural language modeling. We further identify an important missing piece in the form of a large open-source model trained exclusively on a multi-lingual corpus of code. We release a new model, PolyCoder, with 2.7B parameters based on the GPT-2 architecture, that was trained on 249GB of code across 12 programming languages on a single machine. In the C programming language, PolyCoder outperforms all models including Codex. Our trained models are open-source and publicly available at https://github.com/VHellendoorn/Code-LMs, which enables future research and application in this area. We have an online appendix at https://arxiv.org/abs/2202.13169.",True,,large language models lms of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions however the current stateoftheart code lms eg codex are not publicly available leaving many questions about their model and data design decisions we aim to fill in some of these blanks through a systematic evaluation of the largest existing models codex gptj gptneo gptneox20b and codeparrot across various programming languages although codex itself is not opensource we find that existing opensource models do achieve close results in some programming languages although targeted mainly for natural language modeling we further identify an important missing piece in the form of a large opensource model trained exclusively on a multilingual corpus of code we release a new model polycoder with 27b parameters based on the gpt2 architecture that was trained on 249gb of code across 12 programming languages on a single machine in the c programming language polycoder outperforms all models including codex our trained models are opensource and publicly available at httpsgithubcomvhellendoorncodelms which enables future research and application in this area we have an online appendix at httpsarxivorgabs220213169,"['models opensource', 'opensource models', 'opensource model', 'codex opensource', 'large opensource']","['gpt2', 'httpsgithubcomvhellendoorncodelms', 'missing piece', 'models', 'model', 'research', 'single machine', 'opensource', 'decisions', 'opensource models', 'natural language', 'evaluation', 'parameters', 'systematic', 'multilingual', 'gptneox20b', 'results', 'polycoder outperforms', 'application', 'codeparrot', 'opensource model', 'natural', 'data design', 'descriptions', 'httpsarxivorgabs220213169', 'modeling', 'programming languages', 'blanks', 'online appendix', 'architecture', 'gptj gptneo', 'language', 'corpus', 'code']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W3184144760,Persistent Anti-Muslim Bias in Large Language Models,https://doi.org/10.1145/3461702.3462624,2021,"Abubakar Abid, Maheen Farooqi, James Zou","It has been observed that large-scale language models capture undesirable societal biases, e.g. relating to race and gender; yet religious bias has been relatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual language model, captures persistent Muslim-violence bias. We probe GPT-3 in various ways, including prompt completion, analogical reasoning, and story generation, to understand this anti-Muslim bias, demonstrating that it appears consistently and creatively in different uses of the model and that it is severe even compared to biases about other religious groups. For instance, Muslim is analogized to terrorist in 23% of test cases, while Jewish is mapped to its most common stereotype, money, in 5% of test cases. We quantify the positive distraction needed to overcome this bias with adversarial text prompts, and find that use of the most positive 6 adjectives reduces violent completions for Muslims from 66% to 20%, but which is still higher than for other religious groups.",True,,it has been observed that largescale language models capture undesirable societal biases eg relating to race and gender yet religious bias has been relatively unexplored we demonstrate that gpt3 a stateoftheart contextual language model captures persistent muslimviolence bias we probe gpt3 in various ways including prompt completion analogical reasoning and story generation to understand this antimuslim bias demonstrating that it appears consistently and creatively in different uses of the model and that it is severe even compared to biases about other religious groups for instance muslim is analogized to terrorist in 23 of test cases while jewish is mapped to its most common stereotype money in 5 of test cases we quantify the positive distraction needed to overcome this bias with adversarial text prompts and find that use of the most positive 6 adjectives reduces violent completions for muslims from 66 to 20 but which is still higher than for other religious groups,"['muslimviolence bias', 'biases religious', 'religious bias', 'muslim analogized', 'persistent muslimviolence']","['reduces', 'models', 'model', 'jewish', 'biases', 'muslims', 'bias', 'completion', 'analogical reasoning', 'positive', 'gender', 'distraction', 'adversarial text prompts', 'terrorist', 'severe', 'cases', 'gpt3', 'antimuslim', 'largescale', 'test', 'persistent', 'story', 'muslimviolence', 'quantify', 'stereotype money', 'societal biases', 'instance muslim', 'race', 'violent completions', 'religious groups', 'probe', 'language']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4385988359,Summary of ChatGPT-Related research and perspective towards the future of large language models,https://doi.org/10.1016/j.metrad.2023.100017,2023,"Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li, Mengshen He, Zhengliang Liu, Zihao Wu, Lin Zhao, Dajiang Zhu, Xiang Li, Qiang Ning, Dingang Shen, Tianming Liu, Bao Ge","This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.",True,,this paper presents a comprehensive survey of chatgptrelated gpt35 and gpt4 research stateoftheart large language models llm from the gpt series and their prospective applications across diverse domains indeed key innovations such as largescale pretraining that captures knowledge across the entire world wide web instruction finetuning and reinforcement learning from human feedback rlhf have played significant roles in enhancing llms adaptability and performance we performed an indepth analysis of 194 relevant papers on arxiv encompassing trend analysis word cloud representation and distribution analysis across various application domains the findings reveal a significant and increasing interest in chatgptrelated research predominantly centered on direct natural language processing applications while also demonstrating considerable potential in areas ranging from education and history to mathematics medicine and physics this study endeavors to furnish insights into chatgpts capabilities potential implications ethical concerns and offer direction for future advancements in this field,"['insights chatgpts', 'chatgptrelated research', 'chatgpts capabilities', 'chatgpts', 'chatgptrelated gpt35']","['direction', 'findings', 'diverse', 'models', 'research', 'trend analysis', 'comprehensive', 'performance', 'gpt4', 'chatgptrelated gpt35', 'innovations', 'chatgptrelated research', 'human', 'relevant', 'advancements', 'mathematics medicine', 'significant', 'physics', 'chatgpts', 'capabilities', 'history', 'largescale', 'study endeavors', 'survey', 'natural', 'potential', 'adaptability', 'education', 'papers', 'arxiv', 'processing', 'captures', 'gpt series', 'llms', 'analysis', 'reinforcement learning', 'ethical concerns', 'knowledge', 'furnish', 'distribution analysis', 'language', 'increasing', 'domains']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4384200891,ChatGPT and large language models in academia: opportunities and challenges,https://doi.org/10.1186/s13040-023-00339-9,2023,"Jesse G. Meyer, Ryan J. Urbanowicz, Patrick Martin, Karen O’Connor, Ruowang Li, Pei-Chen Peng, Tiffani J Bright, Nicholas P. Tatonetti, Kyoung‐Jae Won, Graciela Gonzalez‐Hernandez, Jason H. Moore","Abstract The introduction of large language models (LLMs) that allow iterative “chat” in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans. LLM-based chatbots have immense potential to improve academic work efficiency, but the ethical implications of their fair use and inherent bias must be considered. In this editorial, we discuss this technology from the academic’s perspective with regard to its limitations and utility for academic writing, education, and programming. We end with our stance with regard to using LLMs and chatbots in academia, which is summarized as (1) we must find ways to effectively use them, (2) their use does not constitute plagiarism (although they may produce plagiarized text), (3) we must quantify their bias, (4) users must be cautious of their poor accuracy, and (5) the future is bright for their application to research and as an academic tool.",True,,abstract the introduction of large language models llms that allow iterative chat in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans llmbased chatbots have immense potential to improve academic work efficiency but the ethical implications of their fair use and inherent bias must be considered in this editorial we discuss this technology from the academics perspective with regard to its limitations and utility for academic writing education and programming we end with our stance with regard to using llms and chatbots in academia which is summarized as 1 we must find ways to effectively use them 2 their use does not constitute plagiarism although they may produce plagiarized text 3 we must quantify their bias 4 users must be cautious of their poor accuracy and 5 the future is bright for their application to research and as an academic tool,"['chatbots academia', 'llmbased chatbots', 'llms chatbots', 'chatbots', 'chatbots immense']","['stance', 'models', 'fair use', 'abstract', 'humans', 'academic writing education', 'bias', 'written', 'limitations', 'research', 'plagiarized', 'users', 'academics', 'cautious', 'perspective', 'efficiency', 'poor accuracy', 'paradigm', 'programming', 'academic', 'potential', 'academic tool', 'quantify', 'chatbots', 'generation', 'llms', 'editorial', 'technology', 'inherent', 'academia', 'plagiarism', 'llmbased chatbots', 'future', 'language', 'ethical']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4390692489,Unifying Large Language Models and Knowledge Graphs: A Roadmap,https://doi.org/10.1109/tkde.2024.3352100,2024,"Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu","Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1) KG-enhanced LLMs,</i> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2) LLM-augmented KGs,</i> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">3) Synergized LLMs + KGs</i> , in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.",False,,large language models llms such as chatgpt and gpt4 are making new waves in the field of natural language processing and artificial intelligence due to their emergent ability and generalizability however llms are blackbox models which often fall short of capturing and accessing factual knowledge in contrast knowledge graphs kgs wikipedia and huapu for example are structured knowledge models that explicitly store rich factual knowledge kgs can enhance llms by providing external knowledge for inference and interpretability meanwhile kgs are difficult to construct and evolve by nature which challenges the existing methods in kgs to generate new facts and represent unseen knowledge therefore it is complementary to unify llms and kgs together and simultaneously leverage their advantages in this article we present a forwardlooking roadmap for the unification of llms and kgs our roadmap consists of three general frameworks namely italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink1 kgenhanced llmsi which incorporate kgs during the pretraining and inference phases of llms or for the purpose of enhancing understanding of the knowledge learned by llms italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink2 llmaugmented kgsi that leverage llms for different kg tasks such as embedding completion construction graphtotext generation and question answering and italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink3 synergized llms  kgsi  in which llms and kgs play equal roles and work in a mutually beneficial way to enhance both llms and kgs for bidirectional reasoning driven by both data and knowledge we review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions,"['knowledge kgs', 'language models', 'unification llms', 'knowledge models', 'knowledge inference']","['knowledge models', 'bidirectional reasoning driven', 'contrast knowledge graphs', 'graphtotext generation', 'models', 'store', 'kgs wikipedia', 'completion', 'evolve', 'answering', 'knowledge kgs', 'nature', 'xmlnsxlinkhttpwwww3org1999xlink3', 'blackbox models', 'unification', 'factual', 'gpt4', 'natural language', 'capturing', 'frameworks', 'research directions', 'generalizability', 'chatgpt', 'italic xmlnsmmlhttpwwww3org1998mathmathml', 'construct', 'roadmap', 'huapu', 'external', 'tasks', 'emergent', 'processing', 'methods', 'interpretability', 'general frameworks', 'facts', 'inference phases', 'pretraining', 'llms', 'waves', 'kgs', 'leverage', 'data', 'knowledge', 'embedding', 'simultaneously', 'kgs together', 'italic', 'artificial intelligence', 'ability', 'language', 'review', 'inference', 'xmlnsxlinkhttpwwww3org1999xlink2']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4389991792,Autonomous chemical research with large language models,https://doi.org/10.1038/s41586-023-06792-0,2023,"Daniil A. Boiko, Robert MacKnight, Ben Kline, Gabriel dos Passos Gomes","Transformer-based large language models are making significant strides in various fields, such as natural language processing",True,,transformerbased large language models are making significant strides in various fields such as natural language processing,"['language models', 'transformerbased large', 'large language', 'language processing', 'transformerbased']","['natural language', 'models', 'fields', 'strides', 'language', 'transformerbased']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4366850747,MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models,https://doi.org/10.48550/arxiv.2304.10592,2023,"Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny","The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability. Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/.",True,,the recent gpt4 has demonstrated extraordinary multimodal abilities such as directly generating websites from handwritten text and identifying humorous elements within images these features are rarely observed in previous visionlanguage models however the technical details behind gpt4 continue to remain undisclosed we believe that the enhanced multimodal generation capabilities of gpt4 stem from the utilization of sophisticated large language models llm to examine this phenomenon we present minigpt4 which aligns a frozen visual encoder with a frozen advanced llm vicuna using one projection layer our work for the first time uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multimodal abilities demonstrated by gpt4 such as detailed image description generation and website creation from handdrawn drafts furthermore we also observe other emerging capabilities in minigpt4 including writing stories and poems inspired by given images teaching users how to cook based on food photos and so on in our experiment we found that the model trained on short image caption pairs could produce unnatural language outputs eg repetition and fragmentation to address this problem we curate a detailed image description dataset in the second stage to finetune the model which consequently improves the models generation reliability and overall usability our code pretrained model and collected dataset are available at httpsminigpt4githubio,"['multimodal generation', 'multimodal', 'enhanced multimodal', 'visionlanguage models', 'extraordinary multimodal']","['gpt4 stem', 'problem', 'frozen advanced llm vicuna', 'multimodal abilities', 'extraordinary', 'models', 'model', 'minigpt4', 'finetune', 'handwritten text', 'website', 'users', 'reliability', 'dataset', 'writing stories', 'features', 'gpt4', 'visionlanguage models', 'visual features', 'outputs', 'fragmentation', 'capabilities', 'image', 'teaching', 'images', 'humorous elements', 'multimodal generation', 'visual encoder', 'poems', 'short image', 'phenomenon', 'utilization', 'food photos', 'creation', 'sophisticated large', 'handdrawn', 'unnatural language', 'repetition', 'technical', 'frozen', 'code pretrained model', 'experiment', 'language', 'projection layer']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4330336443,GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models,https://doi.org/10.48550/arxiv.2303.10130,2023,"Tyna Eloundou, Sam Manning, Pamela Mishkin, Daniel L. Rock","We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.",True,,we investigate the potential implications of large language models llms such as generative pretrained transformers gpts on the us labor market focusing on the increased capabilities arising from llmpowered software compared to llms on their own using a new rubric we assess occupations based on their alignment with llm capabilities integrating both human expertise and gpt4 classifications our findings reveal that around 80 of the us workforce could have at least 10 of their work tasks affected by the introduction of llms while approximately 19 of workers may see at least 50 of their tasks impacted we do not make predictions about the development or adoption timeline of such llms the projected effects span all wage levels with higherincome jobs potentially facing greater exposure to llm capabilities and llmpowered software significantly these impacts are not restricted to industries with higher recent productivity growth our analysis suggests that with access to an llm about 15 of all worker tasks in the us could be completed significantly faster at the same level of quality when incorporating software and tooling built on top of llms this share increases to between 47 and 56 of all tasks this finding implies that llmpowered software will have a substantial effect on scaling the economic impacts of the underlying models we conclude that llms such as gpts exhibit traits of generalpurpose technologies indicating that they could have considerable economic social and policy implications,"['llm capabilities', 'recent productivity', 'higherincome jobs', 'productivity', 'increased capabilities']","['development', 'higherincome jobs', 'investigate', 'findings', 'models', 'introduction', 'levels', 'increased', 'social', 'implies', 'span', 'traits', 'level', 'workers', 'gpt4', 'llmpowered software', 'expertise', 'human', 'economic impacts', 'llm', 'predictions', 'increases', 'timeline', 'capabilities', 'generalpurpose technologies', 'classifications', 'policy', 'gpts', 'exposure to', 'transformers gpts', 'tasks', 'potential', 'adoption', 'industries', 'impacted', 'labor market', 'quality', 'occupations', 'tooling', 'software', 'projected effects', 'analysis', 'llms', 'impacts', 'economic', 'implications', 'rubric', 'share', 'productivity growth', 'alignment', 'assess', 'scaling', 'generative', 'wage', 'language', 'worker', 'workforce']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4366989525,ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health,https://doi.org/10.3389/fpubh.2023.1166120,2023,"Luigi De Angelis, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, Caterina Rizzo","Large Language Models (LLMs) have recently gathered attention with the release of ChatGPT, a user-centered chatbot released by OpenAI. In this perspective article, we retrace the evolution of LLMs to understand the revolution brought by ChatGPT in the artificial intelligence (AI) field. The opportunities offered by LLMs in supporting scientific research are multiple and various models have already been tested in Natural Language Processing (NLP) tasks in this domain. The impact of ChatGPT has been huge for the general public and the research community, with many authors using the chatbot to write part of their articles and some papers even listing ChatGPT as an author. Alarming ethical and practical challenges emerge from the use of LLMs, particularly in the medical field for the potential impact on public health. Infodemic is a trending topic in public health and the ability of LLMs to rapidly produce vast amounts of text could leverage misinformation spread at an unprecedented scale, this could create an ""AI-driven infodemic,"" a novel public health threat. Policies to contrast this phenomenon need to be rapidly elaborated, the inability to accurately detect artificial-intelligence-produced text is an unresolved issue.",True,,large language models llms have recently gathered attention with the release of chatgpt a usercentered chatbot released by openai in this perspective article we retrace the evolution of llms to understand the revolution brought by chatgpt in the artificial intelligence ai field the opportunities offered by llms in supporting scientific research are multiple and various models have already been tested in natural language processing nlp tasks in this domain the impact of chatgpt has been huge for the general public and the research community with many authors using the chatbot to write part of their articles and some papers even listing chatgpt as an author alarming ethical and practical challenges emerge from the use of llms particularly in the medical field for the potential impact on public health infodemic is a trending topic in public health and the ability of llms to rapidly produce vast amounts of text could leverage misinformation spread at an unprecedented scale this could create an aidriven infodemic a novel public health threat policies to contrast this phenomenon need to be rapidly elaborated the inability to accurately detect artificialintelligenceproduced text is an unresolved issue,"['artificialintelligenceproduced text', 'chatbot write', 'natural language', 'chatgpt artificial', 'chatbot']","['public health', 'chatbot', 'models', 'articles', 'author', 'detect', 'public health threat', 'elaborated', 'research', 'community', 'usercentered chatbot', 'impact', 'practical', 'natural language', 'perspective', 'infodemic', 'policies', 'chatgpt', 'release', 'opportunities', 'tasks', 'potential', 'papers', 'evolution', 'text', 'inability', 'phenomenon', 'llms', 'medical field', 'spread', 'leverage', 'multiple', 'authors', 'scientific research', 'misinformation', 'general public', 'artificial intelligence', 'language', 'public health infodemic', 'ethical']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4361866125,BloombergGPT: A Large Language Model for Finance,https://doi.org/10.48550/arxiv.2303.17564,2023,"Shijie Wu, Ozan İrsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, Gideon Mann","The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.",True,,the use of nlp in the realm of financial technology is broad and complex with applications ranging from sentiment analysis and named entity recognition to question answering large language models llms have been shown to be effective on a variety of tasks however no llm specialized for the financial domain has been reported in literature in this work we present bloomberggpt a 50 billion parameter language model that is trained on a wide range of financial data we construct a 363 billion token dataset based on bloombergs extensive data sources perhaps the largest domainspecific dataset yet augmented with 345 billion tokens from general purpose datasets we validate bloomberggpt on standard llm benchmarks open financial benchmarks and a suite of internal benchmarks that most accurately reflect our intended usage our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general llm benchmarks additionally we explain our modeling choices training process and evaluation methodology we release training chronicles appendix c detailing our experience in training bloomberggpt,"['bloombergs extensive', 'nlp realm', 'training bloomberggpt', 'use nlp', 'token dataset']","['general llm benchmarks', 'appendix c', 'models', 'model', 'training process', 'datasets', 'financial', 'training bloomberggpt', 'dataset', 'billion', 'financial tasks', 'entity', 'performance', 'standard', 'augmented', 'usage', 'suite', 'outperforms', 'extensive', 'training', 'sacrificing', 'tokens', 'financial technology', 'sentiment analysis', 'effective', 'margins', 'modeling', 'nlp', 'sources', 'literature', 'bloombergs', 'complex', 'financial domain', 'evaluation methodology', 'internal benchmarks', 'llms', 'realm', 'data', 'domainspecific', 'bloomberggpt', 'recognition', 'specialized', 'language']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4321605350,Academic Integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond,https://doi.org/10.53761/1.20.02.07,2023,Mike Perkins,"This paper explores the academic integrity considerations of students’ use of Artificial Intelligence (AI) tools using Large Language Models (LLMs) such as ChatGPT in formal assessments. We examine the evolution of these tools, and highlight the potential ways that LLMs can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and AI, supporting EFL learners, and improving Automated Writing Evaluations (AWE). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that LLMs raise for both Higher Education Institutions (HEIs) and students, we conclude that it is not the student use of any AI tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of LLMs by students can be defined as academic misconduct is determined by the academic integrity policies of any given HEI, which must be updated to consider how these tools will be used in future educational environments.",True,,this paper explores the academic integrity considerations of students use of artificial intelligence ai tools using large language models llms such as chatgpt in formal assessments we examine the evolution of these tools and highlight the potential ways that llms can support in the education of students in digital writing and beyond including the teaching of writing and composition the possibilities of cocreation between humans and ai supporting efl learners and improving automated writing evaluations awe we describe and demonstrate the potential that these tools have in creating original coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike demonstrating a major academic integrity concern related to the use of these tools by students analysing the various issues related to academic integrity that llms raise for both higher education institutions heis and students we conclude that it is not the student use of any ai tools that defines whether plagiarism or a breach of academic integrity has occurred but whether any use is made clear by the student deciding whether any particular use of llms by students can be defined as academic misconduct is determined by the academic integrity policies of any given hei which must be updated to consider how these tools will be used in future educational environments,"['academic integrity', 'academic misconduct', 'automated writing', 'students analysing', 'education students']","['models', 'humans', 'raise', 'integrity', 'detection', 'technological methods', 'academic staff', 'improving', 'evaluations awe', 'writing', 'education institutions', 'coherent', 'policies', 'assessments', 'chatgpt', 'composition', 'possibilities', 'digital writing', 'academic', 'academic integrity', 'potential', 'education', 'issues', 'evolution', 'learners', 'considerations', 'heis', 'tools', 'llms', 'students', 'student', 'cocreation', 'plagiarism', 'automated', 'artificial intelligence', 'academic misconduct', 'language', 'educational environments', 'teaching']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4287024925,Program Synthesis with Large Language Models,https://doi.org/10.48550/arxiv.2108.07732,2021,"Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, D. Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, Charles Sutton","This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. We evaluate a collection of such models (with between 244M and 137B parameters) on two new benchmarks, MBPP and MathQA-Python, in both the few-shot and fine-tuning regimes. Our benchmarks are designed to measure the ability of these models to synthesize short Python programs from natural language descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974 programming tasks, designed to be solvable by entry-level programmers. The MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text. On both datasets, we find that synthesis performance scales log-linearly with model size. Our largest models, even without finetuning on a code dataset, can synthesize solutions to 59.6 percent of the problems from MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a held-out portion of the dataset improves performance by about 10 percentage points across most model sizes. On the MathQA-Python dataset, the largest fine-tuned model achieves 83.8 percent accuracy. Going further, we study the model's ability to engage in dialog about code, incorporating human feedback to improve its solutions. We find that natural language feedback from a human halves the error rate compared to the model's initial prediction. Additionally, we conduct an error analysis to shed light on where these models fall short and what types of programs are most difficult to generate. Finally, we explore the semantic grounding of these models by fine-tuning them to predict the results of program execution. We find that even our best models are generally unable to predict the output of a program given a specific input.",True,,this paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages we evaluate a collection of such models with between 244m and 137b parameters on two new benchmarks mbpp and mathqapython in both the fewshot and finetuning regimes our benchmarks are designed to measure the ability of these models to synthesize short python programs from natural language descriptions the mostly basic programming problems mbpp dataset contains 974 programming tasks designed to be solvable by entrylevel programmers the mathqapython dataset a python version of the mathqa benchmark contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text on both datasets we find that synthesis performance scales loglinearly with model size our largest models even without finetuning on a code dataset can synthesize solutions to 596 percent of the problems from mbpp using fewshot learning with a welldesigned prompt finetuning on a heldout portion of the dataset improves performance by about 10 percentage points across most model sizes on the mathqapython dataset the largest finetuned model achieves 838 percent accuracy going further we study the models ability to engage in dialog about code incorporating human feedback to improve its solutions we find that natural language feedback from a human halves the error rate compared to the models initial prediction additionally we conduct an error analysis to shed light on where these models fall short and what types of programs are most difficult to generate finally we explore the semantic grounding of these models by finetuning them to predict the results of program execution we find that even our best models are generally unable to predict the output of a program given a specific input,"['program synthesis', 'programming languages', 'synthesize code', 'large language', 'programming']","['python version', 'study', 'synthesize', '137b', 'accuracy', 'models', 'finetuning', 'mathqa benchmark', 'model', 'limits', 'datasets', 'measure', 'dataset', 'programming tasks', 'mbpp', 'performance', 'fewshot learning', 'solvable', 'execution', 'natural language', 'output', 'synthesis', 'human', 'fewshot', 'parameters', 'collection', 'programming', 'engage', 'results', 'regimes', 'short python programs', 'descriptions', 'program', 'benchmarks', 'generation', 'programs', 'programming languages', 'solutions', 'mathqapython dataset', 'input', 'complex', 'rate', 'mathqapython', 'error', 'portion', 'evaluate', 'semantic grounding', 'dialog', 'language', 'prediction', 'problems', 'code']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4221055872,Wordcraft: Story Writing With Large Language Models,https://doi.org/10.1145/3490099.3511105,2022,"Ann Yuan, Andy Coenen, Emily Reif, Daphne Ippolito","The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers’ custom requests expressed in natural language (such as ”rewrite this text to be more Dickensian”), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.",True,,the latest generation of large neural language models such as gpt3 have achieved new levels of performance on benchmarks for language understanding and generation these models have even demonstrated an ability to perform arbitrary tasks without explicit training in this work we sought to learn how people might use such models in the process of creative writing we built wordcraft a text editor in which users collaborate with a generative language model to write a story we evaluated wordcraft with a user study in which participants wrote short stories with and without the tool our results show that large language models enable novel cowriting experiences for example the language model is able to engage in openended conversation about the story respond to writers custom requests expressed in natural language such as rewrite this text to be more dickensian and generate suggestions that serve to unblock writers in the creative process based on these results we discuss design implications for future humanai cowriting systems,"['writers custom', 'generative language', 'writers creative', 'stories tool', 'respond writers']","['creative process', 'explicit training', 'editor', 'levels', 'models', 'model', 'people', 'users', 'unblock writers', 'performance', 'generate', 'natural language', 'suggestions', 'process', 'rewrite', 'writing', 'openended conversation', 'experiences', 'engage', 'gpt3', 'results', 'writers', 'expressed', 'neural language', 'design', 'story', 'participants', 'creative', 'evaluated', 'user study', 'arbitrary', 'benchmarks', 'generation', 'short stories', 'wordcraft', 'custom requests', 'generative language', 'humanai', 'tool', 'language', 'dickensian']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4320005767,Galactica: A Large Language Model for Science,https://doi.org/10.48550/arxiv.2211.09085,2022,"Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony S. Hartshorn, Elvis Saravia, Andrew M. Poulton, Viktor Kerkez, Robert Stojnic","Information overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. In this paper we introduce Galactica: a large language model that can store, combine and reason about scientific knowledge. We train on a large scientific corpus of papers, reference material, knowledge bases and many other sources. We outperform existing models on a range of scientific tasks. On technical knowledge probes such as LaTeX equations, Galactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also performs well on reasoning, outperforming Chinchilla on mathematical MMLU by 41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It also sets a new state-of-the-art on downstream tasks such as PubMedQA and MedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general corpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these results demonstrate the potential for language models as a new interface for science. We open source the model for the benefit of the scientific community.",True,,information overload is a major obstacle to scientific progress the explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information today scientific knowledge is accessed through search engines but they are unable to organize scientific knowledge alone in this paper we introduce galactica a large language model that can store combine and reason about scientific knowledge we train on a large scientific corpus of papers reference material knowledge bases and many other sources we outperform existing models on a range of scientific tasks on technical knowledge probes such as latex equations galactica outperforms the latest gpt3 by 682 versus 490 galactica also performs well on reasoning outperforming chinchilla on mathematical mmlu by 413 to 357 and palm 540b on math with a score of 204 versus 88 it also sets a new stateoftheart on downstream tasks such as pubmedqa and medmcqa dev of 776 and 529 and despite not being trained on a general corpus galactica outperforms bloom and opt175b on bigbench we believe these results demonstrate the potential for language models as a new interface for science we open source the model for the benefit of the scientific community,"['scientific corpus', 'language models', 'galactica outperforms', 'knowledge probes', 'large language']","['general corpus galactica', 'information overload', 'equations galactica', 'chinchilla', 'model', 'models', 'palm', 'downstream tasks', 'medmcqa', 'outperform', 'scientific tasks', 'outperforming', 'scientific corpus', 'scientific', 'scientific community', 'technical knowledge probes', 'explosive growth', 'math', 'combine', 'gpt3', 'results', 'bloom', 'accessed', 'scientific knowledge', 'discover', 'mass', 'galactica', 'potential', 'papers', 'information', 'benefit', 'scientific literature', 'sources', 'knowledge bases', 'progress', 'dev', 'mathematical mmlu', 'data', 'latex', 'bigbench', 'science', 'score', 'language', 'pubmedqa', 'organize']",2,"[0.0, 0.0, 1.0, 0.0, 0.0]"
https://openalex.org/W4377130677,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,https://doi.org/10.48550/arxiv.2305.10601,2023,"Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan","Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.",True,,language models are increasingly being deployed for general problem solving across a wide range of tasks but are still confined to tokenlevel lefttoright decisionmaking processes during inference this means they can fall short in tasks that require exploration strategic lookahead or where initial decisions play a pivotal role to surmount these challenges we introduce a new framework for language model inference tree of thoughts tot which generalizes over the popular chain of thought approach to prompting language models and enables exploration over coherent units of text thoughts that serve as intermediate steps toward problem solving tot allows lms to perform deliberate decision making by considering multiple different reasoning paths and selfevaluating choices to decide the next course of action as well as looking ahead or backtracking when necessary to make global choices our experiments show that tot significantly enhances language models problemsolving abilities on three novel tasks requiring nontrivial planning or search game of 24 creative writing and mini crosswords for instance in game of 24 while gpt4 with chainofthought prompting only solved 4 of tasks our method achieved a success rate of 74 code repo with all prompts httpsgithubcomprincetonnlptreeofthoughtllm,"['reasoning paths', 'tree thoughts', 'language models', 'prompting language', 'thought approach']","['problemsolving', 'decision making', 'models', 'generalizes', 'framework', 'general problem solving', 'deployed', 'decisions', 'enhances', 'global', 'gpt4', 'instance', 'ahead', 'writing', 'coherent', 'prompts', 'prompting', 'success rate', 'intermediate', 'tasks', 'tokenlevel', 'method', 'mini', 'chainofthought prompting', 'reasoning paths', 'selfevaluating', 'tot', 'thoughts', 'problem solving tot', 'experiments', 'next course of', 'abilities', 'exploration', 'lefttoright decisionmaking', 'nontrivial planning', 'thoughts tot', 'language', 'game', 'code']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4384389802,A Comprehensive Overview of Large Language Models,https://doi.org/10.48550/arxiv.2307.06435,2023,"Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Nick Barnes, Ajmal Mian","Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multi-modal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the existing literature on a broad range of LLM-related concepts. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to not only provide a systematic survey but also a quick comprehensive reference for the researchers and practitioners to draw insights from extensive informative summaries of the existing works to advance the LLM research.",True,,large language models llms have recently demonstrated remarkable capabilities in natural language processing tasks and beyond this success of llms has led to a large influx of research contributions in this direction these works encompass diverse topics such as architectural innovations better training strategies context length improvements finetuning multimodal llms robotics datasets benchmarking efficiency and more with the rapid development of techniques and regular breakthroughs in llm research it has become considerably challenging to perceive the bigger picture of the advances in this direction considering the rapidly emerging plethora of literature on llms it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field this article provides an overview of the existing literature on a broad range of llmrelated concepts our selfcontained comprehensive overview of llms discusses relevant background concepts along with covering the advanced topics at the frontier of research in llms this review article is intended to not only provide a systematic survey but also a quick comprehensive reference for the researchers and practitioners to draw insights from extensive informative summaries of the existing works to advance the llm research,"['multimodal llms', 'llms robotics', 'language models', 'overview llms', 'natural language']","['direction', 'development', 'context', 'diverse', 'models', 'influx', 'research contributions', 'research', 'community', 'review', 'comprehensive', 'natural language', 'topics', 'plethora', 'relevant', 'concepts', 'training strategies', 'finetuning multimodal', 'efficiency', 'capabilities', 'systematic survey', 'regular breakthroughs', 'success', 'bigger', 'developments', 'benefit', 'frontier', 'practitioners', 'perceive', 'literature', 'techniques', 'advances', 'background concepts', 'llmrelated', 'overview', 'llms', 'robotics datasets', 'length', 'informative summaries', 'researchers', 'processing tasks', 'architectural innovations', 'language', 'reference', 'improvements', 'concise']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4313451803,Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models,https://doi.org/10.1101/2022.12.19.22283643,2022,"Tiffany H. Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, Victor Tseng","ABSTRACT We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.",True,,abstract we evaluated the performance of a large language model called chatgpt on the united states medical licensing exam usmle which consists of three exams step 1 step 2ck and step 3 chatgpt performed at or near the passing threshold for all three exams without any specialized training or reinforcement additionally chatgpt demonstrated a high level of concordance and insight in its explanations these results suggest that large language models may have the potential to assist with medical education and potentially clinical decisionmaking,"['clinical decisionmaking', 'medical licensing', 'exam usmle', 'licensing exam', 'medical education']","['model', 'models', 'explanations', 'abstract', 'concordance', 'level', 'reinforcement', 'performance', 'threshold', 'training', 'chatgpt', 'medical licensing', 'results', 'assist', 'exams', 'potential', 'united states', 'evaluated', 'medical education', 'specialized', 'clinical decisionmaking', 'language']",3,"[0.0, 0.0, 0.0, 1.0, 0.0]"
https://openalex.org/W4376866715,"Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions",https://doi.org/10.2196/48291,2023,"Alaa Abd‐Alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, M Healy, Syed Latifi, Sarah Aziz, Rafat Damseh, Sadam Alabed Alrazak, Javaid I. Sheikh","The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)-driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.",True,,the integration of large language models llms such as those in the generative pretrained transformers gpt series into medical education has the potential to transform learning experiences for students and elevate their knowledge skills and competence drawing on a wealth of professional and academic experience we propose that llms hold promise for revolutionizing medical curriculum development teaching methodologies personalized study plans and learning materials student assessments and more however we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias overreliance plagiarism misinformation inequity privacy and copyright concerns in medical education as we navigate the shift from an informationdriven educational paradigm to an artificial intelligence aidriven educational paradigm we argue that it is paramount to understand both the potential and the pitfalls of llms in medical education this paper thus offers our perspective on the opportunities and challenges of using llms in this context we believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field fostering the responsible and effective use of ai technologies in medical education,"['informationdriven educational', 'medical education', 'medical curriculum', 'plagiarism misinformation', 'education paper']","['learning materials', 'elevate', 'pitfalls', 'practices', 'models', 'experience', 'professional', 'algorithmic bias', 'field fostering', 'knowledge skills', 'assessments', 'experiences', 'integration', 'educational paradigm', 'academic', 'opportunities', 'potential', 'transform', 'transformers gpt', 'effective', 'issues', 'curriculum', 'privacy', 'medical', 'ai technologies', 'analysis', 'llms', 'medical education', 'students', 'student', 'revolutionizing', 'recommendations', 'wealth', 'plagiarism', 'methodologies', 'misinformation', 'generative', 'artificial intelligence', 'language', 'competence', 'teaching']",0,"[1.0, 0.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4385620388,Creation and Adoption of Large Language Models in Medicine,https://doi.org/10.1001/jama.2023.14217,2023,"Nigam H. Shah, David A. Entwistle, Michael A. Pfeffer","There is increased interest in and potential benefits from using large language models (LLMs) in medicine. However, by simply wondering how the LLMs and the applications powered by them will reshape medicine instead of getting actively involved, the agency in shaping how these tools can be used in medicine is lost.Applications powered by LLMs are increasingly used to perform medical tasks without the underlying language model being trained on medical records and without verifying their purported benefit in performing those tasks.The creation and use of LLMs in medicine need to be actively shaped by provisioning relevant training data, specifying the desired benefits, and evaluating the benefits via testing in real-world deployments.",False,,there is increased interest in and potential benefits from using large language models llms in medicine however by simply wondering how the llms and the applications powered by them will reshape medicine instead of getting actively involved the agency in shaping how these tools can be used in medicine is lostapplications powered by llms are increasingly used to perform medical tasks without the underlying language model being trained on medical records and without verifying their purported benefit in performing those tasksthe creation and use of llms in medicine need to be actively shaped by provisioning relevant training data specifying the desired benefits and evaluating the benefits via testing in realworld deployments,"['llms medicine', 'llms applications', 'language model', 'models llms', 'language models']","['deployments', 'models', 'increased', 'benefits', 'verifying', 'medicine', 'realworld', 'lostapplications', 'language model', 'wondering', 'training', 'applications', 'shaping', 'potential', 'purported', 'medical tasks', 'evaluating', 'tools', 'llms', 'creation', 'agency', 'testing', 'provisioning', 'data', 'medical records', 'language']",3,"[0.0, 0.0, 0.0, 1.0, 0.0]"
https://openalex.org/W4225108562,Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models,https://doi.org/10.1145/3491101.3519665,2022,"Priyan Vaithilingam, Tianyi Zhang, Elena L. Glassman","Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants' feedback.",False,,recent advances in large language models llm have made automatic code generation possible for realworld programming tasks in generalpurpose programming languages such as python however there are few human studies on the usability of these tools and how they fit the programming workflow in this work we conducted a withinsubjects user study with 24 participants to understand how programmers use and perceive copilot a llmbased code generation tool we found that while copilot did not necessarily improve the task completion time or success rate most participants preferred to use copilot in daily programming tasks since copilot often provided a useful starting point and saved the effort of searching online however participants did face difficulties in understanding editing and debugging code snippets generated by copilot which significantly hindered their tasksolving effectiveness finally we highlighted several promising directions for improving the design of copilot based on our observations and participants feedback,"['code generation', 'programming tasks', 'code snippets', 'automatic code', 'programming']","['directions', 'models', 'python', 'tasksolving', 'task completion time', 'llmbased code generation tool', 'programming tasks', 'observations', 'debugging', 'improving', 'editing', 'automatic code generation', 'realworld', 'daily', 'code snippets', 'success rate', 'human studies', 'programming', 'effectiveness', 'design', 'participants', 'user study', 'programming languages', 'tools', 'programmers', 'feedback', 'improve', 'language', 'perceive', 'copilot']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4283705032,Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models,https://doi.org/10.1145/3501385.3543957,2022,"Sami Sarsa, Paul Denny, Arto Hellas, Juho Leinonen","This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.",True,,this article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses using openai codex as the large language model we create programming exercises including sample solutions and test cases and code explanations assessing these qualitatively and quantitatively our results suggest that the majority of the automatically generated content is both novel and sensible and in some cases ready to use as is when creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain simply by supplying keywords as input to the model our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students we further discuss the implications of openai codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike,"['language generation', 'create programming', 'programming education', 'introductory programming', 'natural language']","['influence', 'content', 'programming exercises', 'massive generative machine learning', 'models', 'model', 'research streams', 'teachers', 'code explanations', 'quantitatively', 'exercises', 'test cases', 'introductory programming education', 'instructors', 'programming courses', 'programming concepts', 'production', 'capabilities', 'cases', 'results', 'supplying keywords', 'potential', 'natural', 'openai codex', 'educational experience', 'generation', 'quality', 'novel', 'themes', 'analysis', 'tools', 'students', 'improve', 'sample solutions', 'qualitatively', 'automatically', 'tool', 'language', 'learning resources']",1,"[0.0, 1.0, 0.0, 0.0, 0.0]"
https://openalex.org/W4389984066,Retrieval-Augmented Generation for Large Language Models: A Survey,https://doi.org/10.48550/arxiv.2312.10997,2023,"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Haofen Wang","Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.",True,,large language models llms showcase impressive capabilities but encounter challenges like hallucination outdated knowledge and nontransparent untraceable reasoning processes retrievalaugmented generation rag has emerged as a promising solution by incorporating knowledge from external databases this enhances the accuracy and credibility of the generation particularly for knowledgeintensive tasks and allows for continuous knowledge updates and integration of domainspecific information rag synergistically merges llms intrinsic knowledge with the vast dynamic repositories of external databases this comprehensive review paper offers a detailed examination of the progression of rag paradigms encompassing the naive rag the advanced rag and the modular rag it meticulously scrutinizes the tripartite foundation of rag frameworks which includes the retrieval the generation and the augmentation techniques the paper highlights the stateoftheart technologies embedded in each of these critical components providing a profound understanding of the advancements in rag systems furthermore this paper introduces uptodate evaluation framework and benchmark at the end this article delineates the challenges currently faced and points out prospective avenues for research and development,"['information rag', 'knowledge updates', 'retrievalaugmented generation', 'retrieval generation', 'advancements rag']","['development', 'reasoning processes', 'accuracy', 'hallucination', 'models', 'challenges', 'research', 'tripartite', 'synergistically merges', 'comprehensive', 'enhances', 'incorporating', 'technologies', 'advancements', 'advanced rag', 'progression', 'benchmark', 'frameworks', 'retrieval', 'capabilities', 'integration', 'nontransparent', 'solution', 'intrinsic', 'prospective avenues', 'external databases', 'dynamic', 'generation', 'continuous', 'credibility', 'showcase impressive', 'paradigms', 'examination', 'llms', 'knowledgeintensive tasks', 'domainspecific information', 'naive', 'knowledge', 'augmentation techniques', 'paper', 'uptodate', 'systems', 'evaluation framework', 'language', 'review']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
https://openalex.org/W4393065402,A survey on large language model based autonomous agents,https://doi.org/10.1007/s11704-024-40231-1,2024,"Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen","Abstract Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.",True,,abstract autonomous agents have long been a research focus in academic and industry communities previous research often focuses on training agents with limited knowledge within isolated environments which diverges significantly from human learning processes and makes the agents hard to achieve humanlike decisions recently through the acquisition of vast amounts of web knowledge large language models llms have shown potential in humanlevel intelligence leading to a surge in research on llmbased autonomous agents in this paper we present a comprehensive survey of these studies delivering a systematic review of llmbased autonomous agents from a holistic perspective we first discuss the construction of llmbased autonomous agents proposing a unified framework that encompasses much of previous work then we present a overview of the diverse applications of llmbased autonomous agents in social science natural science and engineering finally we delve into the evaluation strategies commonly used for llmbased autonomous agents based on the previous studies we also present several challenges and future directions in this field,"['autonomous agents', 'agents social', 'training agents', 'agents based', 'agents']","['agents', 'directions', 'diverse', 'models', 'natural science', 'abstract', 'challenges', 'framework', 'human learning processes', 'encompasses', 'research', 'studies', 'environments', 'unified', 'decisions', 'comprehensive', 'evaluation', 'autonomous agents', 'engineering', 'perspective', 'web', 'holistic', 'academic', 'applications', 'potential', 'survey', 'llmbased', 'systematic review', 'acquisition', 'isolated', 'intelligence', 'overview', 'llms', 'social science', 'industry', 'knowledge', 'construction', 'training agents', 'communities', 'language', 'humanlevel']",4,"[0.0, 0.0, 0.0, 0.0, 1.0]"
